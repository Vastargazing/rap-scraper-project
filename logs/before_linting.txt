[93mðŸ“‹ Linting with Ruff...[0m
[96mðŸ” Running: Ruff Check...[0m
I001 [*] Import block is un-sorted or un-formatted
  --> api.py:1:1
   |
 1 | / from fastapi import FastAPI, HTTPException
 2 | | from fastapi.middleware.cors import CORSMiddleware
 3 | | from fastapi.responses import HTMLResponse
 4 | | from pydantic import BaseModel
 5 | | from typing import List, Optional
 6 | | import asyncio
 7 | | import uvicorn
 8 | | import sys
 9 | | import os
   | |_________^
10 |
11 |   # Add project root to path
   |
help: Organize imports

UP035 `typing.List` is deprecated, use `list` instead
 --> api.py:5:1
  |
3 | from fastapi.responses import HTMLResponse
4 | from pydantic import BaseModel
5 | from typing import List, Optional
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
6 | import asyncio
7 | import uvicorn
  |

F401 [*] `typing.Optional` imported but unused
 --> api.py:5:26
  |
3 | from fastapi.responses import HTMLResponse
4 | from pydantic import BaseModel
5 | from typing import List, Optional
  |                          ^^^^^^^^
6 | import asyncio
7 | import uvicorn
  |
help: Remove unused import: `typing.Optional`

F401 [*] `asyncio` imported but unused
 --> api.py:6:8
  |
4 | from pydantic import BaseModel
5 | from typing import List, Optional
6 | import asyncio
  |        ^^^^^^^
7 | import uvicorn
8 | import sys
  |
help: Remove unused import: `asyncio`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> api.py:12:17
   |
11 | # Add project root to path
12 | sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
   |                 ^^^^^^^^^^^^^^^
13 |
14 | from src.models.config_models import AppConfig
   |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> api.py:12:33
   |
11 | # Add project root to path
12 | sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
   |                                 ^^^^^^^^^^^^^^^
13 |
14 | from src.models.config_models import AppConfig
   |
help: Replace with `Path(...).parent`

PTH100 `os.path.abspath()` should be replaced by `Path.resolve()`
  --> api.py:12:49
   |
11 | # Add project root to path
12 | sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
   |                                                 ^^^^^^^^^^^^^^^
13 |
14 | from src.models.config_models import AppConfig
   |
help: Replace with `Path(...).resolve()`

I001 [*] Import block is un-sorted or un-formatted
  --> api.py:14:1
   |
12 |   sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
13 |
14 | / from src.models.config_models import AppConfig
15 | | from src.models.analysis_models import AnalysisResult
16 | | from src.cli.text_analyzer import TextAnalyzer
17 | | from src.cli.batch_processor import BatchProcessor
18 | | from src.cli.performance_monitor import PerformanceMonitor
   | |__________________________________________________________^
19 |
20 |   app = FastAPI(
   |
help: Organize imports

UP006 [*] Use `list` instead of `List` for type annotation
  --> api.py:82:12
   |
81 | class BatchRequest(BaseModel):
82 |     texts: List[str]
   |            ^^^^
83 |     analyzer: str = "algorithmic_basic"
   |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
  --> api.py:88:26
   |
86 | class SystemStatus(BaseModel):
87 |     status: str
88 |     analyzers_available: List[str]
   |                          ^^^^
89 |     database_records: int
90 |     version: str
   |
help: Replace with `list`

W293 Blank line contains whitespace
   --> api.py:113:1
    |
111 |     <body>
112 |         <h1>ðŸŽµ Rap Lyrics Analyzer API</h1>
113 |         
    | ^^^^^^^^
114 |         <div class="container">
115 |             <h3>Quick Analysis</h3>
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> api.py:143:1
    |
141 |                 const text = document.getElementById('text').value;
142 |                 const analyzer = document.getElementById('analyzer').value;
143 |                 
    | ^^^^^^^^^^^^^^^^
144 |                 if (!text.trim()) {
145 |                     alert('Please enter some text to analyze');
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> api.py:155:1
    |
153 |                         body: JSON.stringify({text: text, analyzer: analyzer})
154 |                     });
155 |                     
    | ^^^^^^^^^^^^^^^^^^^^
156 |                     const result = await response.json();
157 |                     document.getElementById('result').innerHTML = 
    |
help: Remove whitespace from blank line

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> api.py:196:9
    |
194 |           )
195 |       except Exception as e:
196 | /         raise HTTPException(
197 | |             status_code=500, detail=f"System status check failed: {str(e)}"
198 | |         )
    | |_________^
    |

RUF010 [*] Use explicit conversion flag
   --> api.py:197:68
    |
195 |     except Exception as e:
196 |         raise HTTPException(
197 |             status_code=500, detail=f"System status check failed: {str(e)}"
    |                                                                    ^^^^^^
198 |         )
    |
help: Replace with conversion flag

TRY300 Consider moving this statement to an `else` block
   --> api.py:206:9
    |
204 |     try:
205 |         result = await text_analyzer.analyze_text(request.text, request.analyzer)
206 |         return result
    |         ^^^^^^^^^^^^^
207 |     except Exception as e:
208 |         raise HTTPException(status_code=400, detail=f"Analysis failed: {str(e)}")
    |

RET504 Unnecessary assignment to `result` before `return` statement
   --> api.py:206:16
    |
204 |     try:
205 |         result = await text_analyzer.analyze_text(request.text, request.analyzer)
206 |         return result
    |                ^^^^^^
207 |     except Exception as e:
208 |         raise HTTPException(status_code=400, detail=f"Analysis failed: {str(e)}")
    |
help: Remove unnecessary assignment

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> api.py:208:9
    |
206 |         return result
207 |     except Exception as e:
208 |         raise HTTPException(status_code=400, detail=f"Analysis failed: {str(e)}")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

RUF010 [*] Use explicit conversion flag
   --> api.py:208:73
    |
206 |         return result
207 |     except Exception as e:
208 |         raise HTTPException(status_code=400, detail=f"Analysis failed: {str(e)}")
    |                                                                         ^^^^^^
    |
help: Replace with conversion flag

UP006 [*] Use `list` instead of `List` for type annotation
   --> api.py:211:36
    |
211 | @app.post("/batch", response_model=List[AnalysisResult])
    |                                    ^^^^
212 | async def batch_analyze(request: BatchRequest):
213 |     """Analyze multiple texts in batch"""
    |
help: Replace with `list`

TRY300 Consider moving this statement to an `else` block
   --> api.py:220:9
    |
218 |             output_file=None,  # Return results directly
219 |         )
220 |         return results
    |         ^^^^^^^^^^^^^^
221 |     except Exception as e:
222 |         raise HTTPException(status_code=400, detail=f"Batch analysis failed: {str(e)}")
    |

RET504 Unnecessary assignment to `results` before `return` statement
   --> api.py:220:16
    |
218 |             output_file=None,  # Return results directly
219 |         )
220 |         return results
    |                ^^^^^^^
221 |     except Exception as e:
222 |         raise HTTPException(status_code=400, detail=f"Batch analysis failed: {str(e)}")
    |
help: Remove unnecessary assignment

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> api.py:222:9
    |
220 |         return results
221 |     except Exception as e:
222 |         raise HTTPException(status_code=400, detail=f"Batch analysis failed: {str(e)}")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

RUF010 [*] Use explicit conversion flag
   --> api.py:222:79
    |
220 |         return results
221 |     except Exception as e:
222 |         raise HTTPException(status_code=400, detail=f"Batch analysis failed: {str(e)}")
    |                                                                               ^^^^^^
    |
help: Replace with conversion flag

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> api.py:247:9
    |
245 |         }
246 |     except Exception as e:
247 |         raise HTTPException(status_code=500, detail=f"Benchmark failed: {str(e)}")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

RUF010 [*] Use explicit conversion flag
   --> api.py:247:74
    |
245 |         }
246 |     except Exception as e:
247 |         raise HTTPException(status_code=500, detail=f"Benchmark failed: {str(e)}")
    |                                                                          ^^^^^^
    |
help: Replace with conversion flag

DTZ005 `datetime.datetime.now()` called without a `tz` argument
  --> lint.py:65:21
   |
63 |         """Setup log directory and files"""
64 |         self.log_dir.mkdir(parents=True, exist_ok=True)
65 |         timestamp = datetime.now().strftime("%Y-%m-%d_%H%M%S")
   |                     ^^^^^^^^^^^^^^
66 |         self.log_file = self.log_dir / f"lint_{timestamp}.log"
67 |         self.log_latest = self.log_dir / "lint_latest.log"
   |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
  --> lint.py:74:13
   |
72 | ðŸ”¥ RAP SCRAPER LINT RUN
73 | {"=" * 60}
74 | Timestamp: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
   |             ^^^^^^^^^^^^^^
75 | Python: {sys.version.split()[0]}
76 | Platform: {sys.platform}
   |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
  --> lint.py:86:18
   |
84 |         """Write message to log file"""
85 |         if self.log_enabled and self.log_file:
86 |             with open(self.log_file, "a", encoding="utf-8") as f:
   |                  ^^^^
87 |                 f.write(message + "\n")
   |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
   --> lint.py:137:13
    |
135 |             if self.log_enabled:
136 |                 self._log(msg)
137 |             return True
    |             ^^^^^^^^^^^
138 |
139 |         except FileNotFoundError:
    |

I001 [*] Import block is un-sorted or un-formatted
  --> main.py:36:1
   |
34 |   """
35 |
36 | / import sys
37 | | import asyncio
38 | | import argparse
39 | | import json
40 | | import time
41 | | from pathlib import Path
42 | | from typing import Dict, Any, List, Optional
43 | | from dotenv import load_dotenv
   | |______________________________^
44 |
45 |   # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> main.py:42:1
   |
40 | import time
41 | from pathlib import Path
42 | from typing import Dict, Any, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43 | from dotenv import load_dotenv
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> main.py:42:1
   |
40 | import time
41 | from pathlib import Path
42 | from typing import Dict, Any, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43 | from dotenv import load_dotenv
   |

F401 [*] `typing.Optional` imported but unused
  --> main.py:42:37
   |
40 | import time
41 | from pathlib import Path
42 | from typing import Dict, Any, List, Optional
   |                                     ^^^^^^^^
43 | from dotenv import load_dotenv
   |
help: Remove unused import: `typing.Optional`

I001 [*] Import block is un-sorted or un-formatted
  --> main.py:52:5
   |
51 |   try:
52 | /     from src.core.app import create_app
53 | |     from src.cli import AnalyzerCLI, BatchProcessor, PerformanceMonitor
54 | |     from src.interfaces.analyzer_interface import AnalyzerFactory
55 | |     from src.scrapers.rap_scraper_postgres import OptimizedPostgreSQLScraper
   | |____________________________________________________________________________^
56 |   except ImportError as e:
57 |       print(f"âŒ Import error: {e}")
   |
help: Organize imports

F401 `src.interfaces.analyzer_interface.AnalyzerFactory` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> main.py:54:51
   |
52 |     from src.core.app import create_app
53 |     from src.cli import AnalyzerCLI, BatchProcessor, PerformanceMonitor
54 |     from src.interfaces.analyzer_interface import AnalyzerFactory
   |                                                   ^^^^^^^^^^^^^^^
55 |     from src.scrapers.rap_scraper_postgres import OptimizedPostgreSQLScraper
56 | except ImportError as e:
   |
help: Remove unused import: `src.interfaces.analyzer_interface.AnalyzerFactory`

PLR0912 Too many branches (14 > 12)
   --> main.py:110:15
    |
108 |         print()
109 |
110 |     async def run_interactive_mode(self) -> None:
    |               ^^^^^^^^^^^^^^^^^^^^
111 |         """Ð—Ð°Ð¿ÑƒÑÐº Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ñ€ÐµÐ¶Ð¸Ð¼Ð°"""
112 |         while True:
    |

PLR1714 Consider merging multiple comparisons: `choice in {"", "1"}`.
   --> main.py:171:12
    |
170 |         # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð²Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Continue scraping
171 |         if choice == "" or choice == "1":
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
172 |             await self.continue_scraping()
173 |         elif choice == "0":
    |
help: Merge multiple comparisons

F541 [*] f-string without any placeholders
   --> main.py:219:23
    |
218 |             if result["success"]:
219 |                 print(f"âœ… Scraping completed!")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^
220 |                 print(f"  ðŸŽµ Songs found: {result.get('songs_found', 0)}")
221 |                 print(f"  ðŸ’¾ Songs saved: {result.get('songs_saved', 0)}")
    |
help: Remove extraneous `f` prefix

PLR0912 Too many branches (18 > 12)
   --> main.py:229:15
    |
227 |             print(f"âŒ Scraping error: {e}")
228 |
229 |     async def scrape_artist_list(self) -> None:
    |               ^^^^^^^^^^^^^^^^^^
230 |         """Ð¡ÐºÑ€Ð°Ð¿Ð¸Ð½Ð³ ÑÐ¿Ð¸ÑÐºÐ° Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²"""
231 |         print("\nðŸ“‹ Artist List Scraping")
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> main.py:247:22
    |
245 |             file_path = input("Enter text file path: ").strip()
246 |             try:
247 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                      ^^^^
248 |                     artists = [line.strip() for line in f if line.strip()]
249 |             except Exception as e:
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> main.py:247:38
    |
245 |             file_path = input("Enter text file path: ").strip()
246 |             try:
247 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                                      ^^^
248 |                     artists = [line.strip() for line in f if line.strip()]
249 |             except Exception as e:
    |
help: Remove mode argument

PTH123 `open()` should be replaced by `Path.open()`
   --> main.py:258:22
    |
256 |                 import json
257 |
258 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                      ^^^^
259 |                     data = json.load(f)
260 |                     if isinstance(data, list):
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> main.py:258:38
    |
256 |                 import json
257 |
258 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                                      ^^^
259 |                     data = json.load(f)
260 |                     if isinstance(data, list):
    |
help: Remove mode argument

F541 [*] f-string without any placeholders
   --> main.py:293:19
    |
292 |         try:
293 |             print(f"\nðŸ”„ Starting batch scraping...")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
294 |
295 |             from src.scrapers.rap_scraper_postgres import OptimizedPostgreSQLScraper
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:327:19
    |
325 |                     await asyncio.sleep(2)
326 |
327 |             print(f"\nðŸ† Batch scraping completed!")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
328 |             print(f"  ðŸŽ¤ Artists processed: {successful_artists}/{len(artists)}")
329 |             print(f"  ðŸŽµ Total songs scraped: {total_songs}")
    |
help: Remove extraneous `f` prefix

PTH123 `open()` should be replaced by `Path.open()`
   --> main.py:373:18
    |
371 |             import json
372 |
373 |             with open("data/remaining_artists.json", "r", encoding="utf-8") as f:
    |                  ^^^^
374 |                 data = json.load(f)
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> main.py:373:54
    |
371 |             import json
372 |
373 |             with open("data/remaining_artists.json", "r", encoding="utf-8") as f:
    |                                                      ^^^
374 |                 data = json.load(f)
    |
help: Remove mode argument

F541 [*] f-string without any placeholders
   --> main.py:407:31
    |
405 |                     # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ scraper (ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð²Ñ‹Ð·Ð¾Ð²)
406 |                     if not self.scraper:
407 |                         print(f"  âŒ Scraper not available (no Genius token)")
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
408 |                         continue
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:418:31
    |
416 |                         total_songs += songs_scraped
417 |                         print(f"  âœ… {songs_scraped} songs scraped")
418 |                         print(f"  ðŸ’¾ Saved to database")
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^
419 |                     else:
420 |                         print(f"  âš ï¸ No songs found")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:420:31
    |
418 |                         print(f"  ðŸ’¾ Saved to database")
419 |                     else:
420 |                         print(f"  âš ï¸ No songs found")
    |                               ^^^^^^^^^^^^^^^^^^^^^
421 |
422 |                 except Exception as artist_error:
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:426:19
    |
424 |                     continue
425 |
426 |             print(f"\nðŸ† Scraping completed!")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
427 |             print(f"  ðŸŽ¤ Artists processed: {successful_artists}/{len(artists)}")
428 |             print(f"  ðŸŽµ Total songs scraped: {total_songs}")
    |
help: Remove extraneous `f` prefix

PTH123 `open()` should be replaced by `Path.open()`
   --> main.py:438:18
    |
436 |             import json
437 |
438 |             with open(file_path, "r", encoding="utf-8") as f:
    |                  ^^^^
439 |                 data = json.load(f)
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> main.py:438:34
    |
436 |             import json
437 |
438 |             with open(file_path, "r", encoding="utf-8") as f:
    |                                  ^^^
439 |                 data = json.load(f)
    |
help: Remove mode argument

F541 [*] f-string without any placeholders
   --> main.py:471:31
    |
469 |                 try:
470 |                     if not self.scraper:
471 |                         print(f"  âŒ Scraper not available (no Genius token)")
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
472 |                         continue
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:482:31
    |
480 |                         total_songs += songs_scraped
481 |                         print(f"  âœ… {songs_scraped} songs scraped")
482 |                         print(f"  ðŸ’¾ Saved to database")
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^
483 |                     else:
484 |                         print(f"  âš ï¸ No songs found")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:484:31
    |
482 |                         print(f"  ðŸ’¾ Saved to database")
483 |                     else:
484 |                         print(f"  âš ï¸ No songs found")
    |                               ^^^^^^^^^^^^^^^^^^^^^
485 |
486 |                 except Exception as artist_error:
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:490:19
    |
488 |                     continue
489 |
490 |             print(f"\nðŸ† Scraping completed!")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
491 |             print(f"  ðŸŽ¤ Artists processed: {successful_artists}/{len(artists)}")
492 |             print(f"  ðŸŽµ Total songs scraped: {total_songs}")
    |
help: Remove extraneous `f` prefix

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> main.py:509:22
    |
508 |             # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð½Ð°Ñˆ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð½Ñ‹Ð¹ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ¸
509 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
510 |                 [sys.executable, "scripts/tools/database_diagnostics.py", "--quick"],
511 |                 capture_output=True,
    |
help: Add explicit `check=False`

PTH201 [*] Do not pass the current directory explicitly to `Path`
   --> main.py:513:26
    |
511 |                 capture_output=True,
512 |                 text=True,
513 |                 cwd=Path("."),
    |                          ^^^
514 |             )
    |
help: Remove the current directory argument

RET505 [*] Unnecessary `elif` after `return` statement
   --> main.py:547:9
    |
545 |         if choice == "0":
546 |             return
547 |         elif choice == "1":
    |         ^^^^
548 |             # ÐŸÐ¾Ð»Ð½Ð°Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ°
549 |             import subprocess
    |
help: Remove unnecessary `elif`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> main.py:551:22
    |
549 |             import subprocess
550 |
551 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
552 |                 [sys.executable, "scripts/tools/database_diagnostics.py"], cwd=Path(".")
553 |             )
    |
help: Add explicit `check=False`

PTH201 [*] Do not pass the current directory explicitly to `Path`
   --> main.py:552:85
    |
551 |             result = subprocess.run(
552 |                 [sys.executable, "scripts/tools/database_diagnostics.py"], cwd=Path(".")
    |                                                                                     ^^^
553 |             )
    |
help: Remove the current directory argument

F841 Local variable `result` is assigned to but never used
   --> main.py:562:13
    |
560 |             limit = limit if limit.isdigit() else "10"
561 |
562 |             result = subprocess.run(
    |             ^^^^^^
563 |                 [
564 |                     sys.executable,
    |
help: Remove assignment to unused variable `result`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> main.py:562:22
    |
560 |             limit = limit if limit.isdigit() else "10"
561 |
562 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
563 |                 [
564 |                     sys.executable,
    |
help: Add explicit `check=False`

PTH201 [*] Do not pass the current directory explicitly to `Path`
   --> main.py:570:26
    |
568 |                     limit,
569 |                 ],
570 |                 cwd=Path("."),
    |                          ^^^
571 |             )
    |
help: Remove the current directory argument

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> main.py:587:36
    |
586 |                 backup_name = (
587 |                     f"data_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
    |                                    ^^^^^^^^^^^^^^
588 |                 )
589 |                 backup_path = Path("data") / backup_name
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

ARG002 Unused method argument: `scraper`
   --> main.py:605:15
    |
604 |     async def _run_artist_scraping(
605 |         self, scraper, artist_name: str, max_songs: int
    |               ^^^^^^^
606 |     ) -> Dict[str, Any]:
607 |         """Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° ÑÐºÑ€Ð°Ð¿Ð¸Ð½Ð³Ð° Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°"""
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> main.py:606:10
    |
604 |     async def _run_artist_scraping(
605 |         self, scraper, artist_name: str, max_songs: int
606 |     ) -> Dict[str, Any]:
    |          ^^^^
607 |         """Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° ÑÐºÑ€Ð°Ð¿Ð¸Ð½Ð³Ð° Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°"""
608 |         try:
    |
help: Replace with `dict`

ERA001 Found commented-out code
   --> main.py:613:13
    |
612 |             # Ð—Ð´ÐµÑÑŒ Ð±ÑƒÐ´ÐµÑ‚ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð²Ñ‹Ð·Ð¾Ð² scraper.scrape_artist()
613 |             # result = scraper.scrape_artist(artist_name, max_songs)
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
614 |
615 |             # Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ°
    |
help: Remove commented-out code

PTH123 `open()` should be replaced by `Path.open()`
   --> main.py:680:22
    |
678 |             if save == "y":
679 |                 filename = f"analysis_result_{analyzer_type}_{result['timestamp'].replace(':', '-').replace(' ', '_')}.json"
680 |                 with open(filename, "w", encoding="utf-8") as f:
    |                      ^^^^
681 |                     json.dump(result, f, indent=2, ensure_ascii=False)
682 |                 print(f"ðŸ’¾ Results saved to: {filename}")
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> main.py:774:18
    |
772 |         try:
773 |             # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
774 |             with open(input_file, "r", encoding="utf-8") as f:
    |                  ^^^^
775 |                 if input_file.endswith(".json"):
776 |                     data = json.load(f)
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> main.py:774:35
    |
772 |         try:
773 |             # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
774 |             with open(input_file, "r", encoding="utf-8") as f:
    |                                   ^^^
775 |                 if input_file.endswith(".json"):
776 |                     data = json.load(f)
    |
help: Remove mode argument

F541 [*] f-string without any placeholders
   --> main.py:797:19
    |
795 |             failed = len(results) - successful
796 |
797 |             print(f"\nðŸ“Š Batch Processing Complete:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
798 |             print(f"  âœ… Successful: {successful}")
799 |             print(f"  âŒ Failed: {failed}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:853:19
    |
851 |                 print(f"  ðŸ’¾ Memory: {metrics.avg_memory_mb:.1f} MB")
852 |
853 |             print(f"\nðŸ“„ Detailed report saved to: performance_benchmark.json")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
854 |
855 |         except Exception as e:
    |
help: Remove extraneous `f` prefix

PLR0912 Too many branches (13 > 12)
   --> main.py:858:15
    |
856 |             print(f"âŒ Benchmark failed: {e}")
857 |
858 |     async def show_system_info(self) -> None:
    |               ^^^^^^^^^^^^^^^^
859 |         """ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ"""
860 |         print("\nðŸ” System Information")
    |

F541 [*] f-string without any placeholders
   --> main.py:866:19
    |
864 |             # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸
865 |             print("ðŸ“± Application Info:")
866 |             print(f"  Version: 1.0.0")
    |                   ^^^^^^^^^^^^^^^^^^^
867 |             print(f"  Python: {sys.version.split()[0]}")
868 |             print(f"  Project root: {Path('.').absolute()}")
    |
help: Remove extraneous `f` prefix

PTH201 [*] Do not pass the current directory explicitly to `Path`
   --> main.py:868:43
    |
866 |             print(f"  Version: 1.0.0")
867 |             print(f"  Python: {sys.version.split()[0]}")
868 |             print(f"  Project root: {Path('.').absolute()}")
    |                                           ^^^
869 |
870 |             # ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ñ‹
    |
help: Remove the current directory argument

SIM108 Use ternary operator `status = "âœ… Ready" if analyzer_obj else "âŒ Error"` instead of `if`-`else`-block
   --> main.py:875:17
    |
873 |               for analyzer in analyzers:
874 |                   analyzer_obj = self.app.get_analyzer(analyzer)
875 | /                 if analyzer_obj:
876 | |                     status = "âœ… Ready"
877 | |                 else:
878 | |                     status = "âŒ Error"
    | |_______________________________________^
879 |                   print(f"  {analyzer}: {status}")
    |
help: Replace `if`-`else`-block with `status = "âœ… Ready" if analyzer_obj else "âŒ Error"`

F541 [*] f-string without any placeholders
   --> main.py:882:19
    |
881 |             # ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ
882 |             print(f"\nâš™ï¸  Configuration:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
883 |
884 |             # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‚Ð¸Ð¿ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:901:23
    |
899 |             # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð‘Ð” (ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°)
900 |             try:
901 |                 print(f"\nðŸ“Š Database Stats:")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^
902 |                 if hasattr(self.app, "database") and self.app.database:
903 |                     print(f"  Connection: âœ… Connected")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:903:27
    |
901 |                 print(f"\nðŸ“Š Database Stats:")
902 |                 if hasattr(self.app, "database") and self.app.database:
903 |                     print(f"  Connection: âœ… Connected")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
904 |
905 |                     # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¸Ð· PostgreSQL
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:913:35
    |
911 |                     if hasattr(self.app.database, "_vector_enabled"):
912 |                         if self.app.database._vector_enabled:
913 |                             print(f"  ML Features: âœ… pgvector enabled")
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
914 |                         else:
915 |                             print(f"  ML Features: âŒ pgvector not available")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:915:35
    |
913 |                             print(f"  ML Features: âœ… pgvector enabled")
914 |                         else:
915 |                             print(f"  ML Features: âŒ pgvector not available")
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
916 |                 else:
917 |                     print(f"  Connection: âŒ Not initialized")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:917:27
    |
915 |                             print(f"  ML Features: âŒ pgvector not available")
916 |                 else:
917 |                     print(f"  Connection: âŒ Not initialized")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
918 |             except Exception as e:
919 |                 print(f"  Connection: âŒ Error: {e}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:956:19
    |
954 |                 return
955 |
956 |             print(f"ðŸ”„ Running tests...")
    |                   ^^^^^^^^^^^^^^^^^^^^^^
957 |             result = subprocess.run(cmd, capture_output=True, text=True)
    |
help: Remove extraneous `f` prefix

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> main.py:957:22
    |
956 |             print(f"ðŸ”„ Running tests...")
957 |             result = subprocess.run(cmd, capture_output=True, text=True)
    |                      ^^^^^^^^^^^^^^
958 |
959 |             print("ðŸ“Š Test Results:")
    |
help: Add explicit `check=False`

F541 [*] f-string without any placeholders
   --> main.py:983:23
    |
981 |             # Database config
982 |             if hasattr(config, "database"):
983 |                 print(f"ðŸ“Š Database:")
    |                       ^^^^^^^^^^^^^^^
984 |                 db_config = config.database
985 |                 print(f"  Path: {getattr(db_config, 'path', 'Not set')}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:990:23
    |
988 |             # Logging config
989 |             if hasattr(config, "logging"):
990 |                 print(f"ðŸ“ Logging:")
    |                       ^^^^^^^^^^^^^^
991 |                 log_config = config.logging
992 |                 print(f"  Level: {getattr(log_config, 'level', 'Not set')}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> main.py:997:19
    |
996 |             # Analyzer configs
997 |             print(f"ðŸ§  Analyzers:")
    |                   ^^^^^^^^^^^^^^^^
998 |             for analyzer_name in self.app.list_analyzers():
999 |                 print(f"  {analyzer_name}: Registered")
    |
help: Remove extraneous `f` prefix

UP006 [*] Use `list` instead of `List` for type annotation
    --> main.py:1004:51
     |
1002 |             print(f"âŒ Failed to show configuration: {e}")
1003 |
1004 |     def _generate_test_texts(self, count: int) -> List[str]:
     |                                                   ^^^^
1005 |         """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ñ‚ÐµÐºÑÑ‚Ð¾Ð² Ð´Ð»Ñ Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ°"""
1006 |         base_texts = [
     |
help: Replace with `list`

PTH123 `open()` should be replaced by `Path.open()`
    --> main.py:1065:18
     |
1063 |         elif args.batch:
1064 |             # Batch processing
1065 |             with open(args.batch, "r", encoding="utf-8") as f:
     |                  ^^^^
1066 |                 if args.batch.endswith(".json"):
1067 |                     data = json.load(f)
     |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
    --> main.py:1065:35
     |
1063 |         elif args.batch:
1064 |             # Batch processing
1065 |             with open(args.batch, "r", encoding="utf-8") as f:
     |                                   ^^^
1066 |                 if args.batch.endswith(".json"):
1067 |                     data = json.load(f)
     |
help: Remove mode argument

PLR1722 Use `sys.exit()` instead of `exit`
    --> main.py:1113:5
     |
1112 | if __name__ == "__main__":
1113 |     exit(asyncio.run(main()))
     |     ^^^^
     |
help: Replace `exit` with `sys.exit()`

F403 `from .style_transfer import *` used; unable to detect undefined names
  --> models/__init__.py:18:5
   |
16 | # Import main models for easy access
17 | try:
18 |     from .style_transfer import *
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
19 |     from .quality_predictor import *
20 |     from .trend_analysis import *
   |

I001 [*] Import block is un-sorted or un-formatted
  --> models/__init__.py:18:5
   |
16 |   # Import main models for easy access
17 |   try:
18 | /     from .style_transfer import *
19 | |     from .quality_predictor import *
20 | |     from .trend_analysis import *
   | |_________________________________^
21 |       # QWEN model is imported separately in test_qwen.py when needed
22 |   except ImportError as e:
   |
help: Organize imports

F403 `from .quality_predictor import *` used; unable to detect undefined names
  --> models/__init__.py:19:5
   |
17 | try:
18 |     from .style_transfer import *
19 |     from .quality_predictor import *
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
20 |     from .trend_analysis import *
21 |     # QWEN model is imported separately in test_qwen.py when needed
   |

F403 `from .trend_analysis import *` used; unable to detect undefined names
  --> models/__init__.py:20:5
   |
18 |     from .style_transfer import *
19 |     from .quality_predictor import *
20 |     from .trend_analysis import *
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
21 |     # QWEN model is imported separately in test_qwen.py when needed
22 | except ImportError as e:
   |

I001 [*] Import block is un-sorted or un-formatted
  --> models/quality_prediction.py:12:1
   |
10 |   """
11 |
12 | / import pandas as pd
13 | | import numpy as np
14 | | import pickle
15 | | import sys
16 | | import os
17 | | from pathlib import Path
18 | | from datetime import datetime
19 | | import logging
20 | | from typing import Dict, List, Optional, Tuple
21 | | import warnings
   | |_______________^
22 |
23 |   warnings.filterwarnings("ignore")
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> models/quality_prediction.py:20:1
   |
18 | from datetime import datetime
19 | import logging
20 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
21 | import warnings
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> models/quality_prediction.py:20:1
   |
18 | from datetime import datetime
19 | import logging
20 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
21 | import warnings
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> models/quality_prediction.py:20:1
   |
18 | from datetime import datetime
19 | import logging
20 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
21 | import warnings
   |

F401 [*] `typing.Optional` imported but unused
  --> models/quality_prediction.py:20:32
   |
18 | from datetime import datetime
19 | import logging
20 | from typing import Dict, List, Optional, Tuple
   |                                ^^^^^^^^
21 | import warnings
   |
help: Remove unused import

F401 [*] `typing.Tuple` imported but unused
  --> models/quality_prediction.py:20:42
   |
18 | from datetime import datetime
19 | import logging
20 | from typing import Dict, List, Optional, Tuple
   |                                          ^^^^^
21 | import warnings
   |
help: Remove unused import

E402 Module level import not at top of file
  --> models/quality_prediction.py:26:1
   |
25 | # ML libraries
26 | from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
27 | from sklearn.linear_model import LinearRegression, Ridge
28 | from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
   |

I001 [*] Import block is un-sorted or un-formatted
  --> models/quality_prediction.py:26:1
   |
25 |   # ML libraries
26 | / from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
27 | | from sklearn.linear_model import LinearRegression, Ridge
28 | | from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
29 | | from sklearn.preprocessing import StandardScaler, LabelEncoder
30 | | from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
31 | | import joblib
32 | |
33 | | # Visualization
34 | | import matplotlib.pyplot as plt
35 | | import seaborn as sns
   | |_____________________^
36 |
37 |   # Add project root to path
   |
help: Organize imports

E402 Module level import not at top of file
  --> models/quality_prediction.py:27:1
   |
25 | # ML libraries
26 | from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
27 | from sklearn.linear_model import LinearRegression, Ridge
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
28 | from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
29 | from sklearn.preprocessing import StandardScaler, LabelEncoder
   |

F401 [*] `sklearn.linear_model.LinearRegression` imported but unused
  --> models/quality_prediction.py:27:34
   |
25 | # ML libraries
26 | from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
27 | from sklearn.linear_model import LinearRegression, Ridge
   |                                  ^^^^^^^^^^^^^^^^
28 | from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
29 | from sklearn.preprocessing import StandardScaler, LabelEncoder
   |
help: Remove unused import

F401 [*] `sklearn.linear_model.Ridge` imported but unused
  --> models/quality_prediction.py:27:52
   |
25 | # ML libraries
26 | from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
27 | from sklearn.linear_model import LinearRegression, Ridge
   |                                                    ^^^^^
28 | from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
29 | from sklearn.preprocessing import StandardScaler, LabelEncoder
   |
help: Remove unused import

E402 Module level import not at top of file
  --> models/quality_prediction.py:28:1
   |
26 | from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
27 | from sklearn.linear_model import LinearRegression, Ridge
28 | from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
29 | from sklearn.preprocessing import StandardScaler, LabelEncoder
30 | from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
   |

F401 [*] `sklearn.model_selection.GridSearchCV` imported but unused
  --> models/quality_prediction.py:28:72
   |
26 | from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
27 | from sklearn.linear_model import LinearRegression, Ridge
28 | from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
   |                                                                        ^^^^^^^^^^^^
29 | from sklearn.preprocessing import StandardScaler, LabelEncoder
30 | from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
   |
help: Remove unused import: `sklearn.model_selection.GridSearchCV`

E402 Module level import not at top of file
  --> models/quality_prediction.py:29:1
   |
27 | from sklearn.linear_model import LinearRegression, Ridge
28 | from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
29 | from sklearn.preprocessing import StandardScaler, LabelEncoder
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30 | from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
31 | import joblib
   |

E402 Module level import not at top of file
  --> models/quality_prediction.py:30:1
   |
28 | from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
29 | from sklearn.preprocessing import StandardScaler, LabelEncoder
30 | from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
31 | import joblib
   |

E402 Module level import not at top of file
  --> models/quality_prediction.py:31:1
   |
29 | from sklearn.preprocessing import StandardScaler, LabelEncoder
30 | from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
31 | import joblib
   | ^^^^^^^^^^^^^
32 |
33 | # Visualization
   |

E402 Module level import not at top of file
  --> models/quality_prediction.py:34:1
   |
33 | # Visualization
34 | import matplotlib.pyplot as plt
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
35 | import seaborn as sns
   |

F401 [*] `matplotlib.pyplot` imported but unused
  --> models/quality_prediction.py:34:29
   |
33 | # Visualization
34 | import matplotlib.pyplot as plt
   |                             ^^^
35 | import seaborn as sns
   |
help: Remove unused import: `matplotlib.pyplot`

E402 Module level import not at top of file
  --> models/quality_prediction.py:35:1
   |
33 | # Visualization
34 | import matplotlib.pyplot as plt
35 | import seaborn as sns
   | ^^^^^^^^^^^^^^^^^^^^^
36 |
37 | # Add project root to path
   |

F401 [*] `seaborn` imported but unused
  --> models/quality_prediction.py:35:19
   |
33 | # Visualization
34 | import matplotlib.pyplot as plt
35 | import seaborn as sns
   |                   ^^^
36 |
37 | # Add project root to path
   |
help: Remove unused import: `seaborn`

PTH123 `open()` should be replaced by `Path.open()`
  --> models/quality_prediction.py:72:18
   |
71 |         try:
72 |             with open(dataset_path, "rb") as f:
   |                  ^^^^
73 |                 ml_dataset = pickle.load(f)
   |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
  --> models/quality_prediction.py:86:13
   |
85 |             logger.info(f"ðŸ“Š Filtered to {len(df_filtered)} quality tracks")
86 |             return df_filtered
   |             ^^^^^^^^^^^^^^^^^^
87 |
88 |         except Exception as e:
   |

PLR0915 Too many statements (78 > 50)
  --> models/quality_prediction.py:92:9
   |
90 |             raise
91 |
92 |     def engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:
   |         ^^^^^^^^^^^^^^^^^
93 |         """Engineer comprehensive features for quality prediction"""
94 |         logger.info("ðŸ”§ Engineering features for quality prediction...")
   |

PLW2901 `for` loop variable `line` overwritten by assignment target
   --> models/quality_prediction.py:122:17
    |
120 |             line_counts = {}
121 |             for line in lines:
122 |                 line = line.strip().lower()
    |                 ^^^^
123 |                 if len(line) > 5:  # Ignore very short lines
124 |                     line_counts[line] = line_counts.get(line, 0) + 1
    |

PLR0915 Too many statements (61 > 50)
   --> models/quality_prediction.py:284:9
    |
282 |         return features_df
283 |
284 |     def create_target_variables(self, df: pd.DataFrame) -> pd.DataFrame:
    |         ^^^^^^^^^^^^^^^^^^^^^^^
285 |         """Create target variables for prediction"""
286 |         logger.info("ðŸŽ¯ Creating target variables...")
    |

E722 Do not use bare `except`
   --> models/quality_prediction.py:334:17
    |
332 |                     else:
333 |                         score += 0.5 * 0.4  # Default
334 |                 except:
    |                 ^^^^^^
335 |                     score += 0.5 * 0.4
336 |             else:
    |

E722 Do not use bare `except`
   --> models/quality_prediction.py:385:17
    |
383 |                     else:
384 |                         score += 0.5 * 0.4
385 |                 except:
    |                 ^^^^^^
386 |                     score += 0.5 * 0.4
387 |             else:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/quality_prediction.py:439:10
    |
437 |         test_size: float = 0.2,
438 |         cv_folds: int = 5,
439 |     ) -> Dict:
    |          ^^^^
440 |         """Train multi-target regression models"""
    |
help: Replace with `dict`

N806 Variable `X` in function should be lowercase
   --> models/quality_prediction.py:447:13
    |
445 |             # Load and prepare data
446 |             df = self.load_training_data(dataset_path)
447 |             X = self.engineer_features(df)
    |             ^
448 |             y = self.create_target_variables(df)
    |

N806 Variable `X_scaled` in function should be lowercase
   --> models/quality_prediction.py:454:13
    |
453 |             # Scale features
454 |             X_scaled = pd.DataFrame(
    |             ^^^^^^^^
455 |                 self.scaler.fit_transform(X), columns=X.columns, index=X.index
456 |             )
    |

N806 Variable `X_train` in function should be lowercase
   --> models/quality_prediction.py:459:13
    |
458 |             # Split data
459 |             X_train, X_test, y_train, y_test = train_test_split(
    |             ^^^^^^^
460 |                 X_scaled, y, test_size=test_size, random_state=42
461 |             )
    |

N806 Variable `X_test` in function should be lowercase
   --> models/quality_prediction.py:459:22
    |
458 |             # Split data
459 |             X_train, X_test, y_train, y_test = train_test_split(
    |                      ^^^^^^
460 |                 X_scaled, y, test_size=test_size, random_state=42
461 |             )
    |

B905 `zip()` without an explicit `strict=` parameter
   --> models/quality_prediction.py:514:25
    |
512 |                     "cv_std": cv_scores.std(),
513 |                     "feature_importance": dict(
514 |                         zip(X.columns, model.feature_importances_)
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
515 |                     ),
516 |                 }
    |
help: Add explicit value for parameter `strict=`

TRY300 Consider moving this statement to an `else` block
   --> models/quality_prediction.py:532:13
    |
531 |             logger.info("\nâœ… Model training completed successfully!")
532 |             return results
    |             ^^^^^^^^^^^^^^
533 |
534 |         except Exception as e:
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> models/quality_prediction.py:538:58
    |
536 |             raise
537 |
538 |     def _analyze_feature_importance(self, feature_names: List[str]):
    |                                                          ^^^^
539 |         """Analyze feature importance across all models"""
540 |         logger.info("ðŸ“Š Analyzing feature importance...")
    |
help: Replace with `list`

B007 Loop control variable `target` not used within loop body
   --> models/quality_prediction.py:544:13
    |
542 |         # Aggregate feature importance across models
543 |         importance_sum = {}
544 |         for target, model in self.models.items():
    |             ^^^^^^
545 |             if hasattr(model, "feature_importances_"):
546 |                 for feature, importance in zip(
    |
help: Rename unused `target` to `_target`

PERF102 When using only the values of a dict use the `values()` method
   --> models/quality_prediction.py:544:30
    |
542 |         # Aggregate feature importance across models
543 |         importance_sum = {}
544 |         for target, model in self.models.items():
    |                              ^^^^^^^^^^^^^^^^^
545 |             if hasattr(model, "feature_importances_"):
546 |                 for feature, importance in zip(
    |
help: Replace `.items()` with `.values()`

B905 `zip()` without an explicit `strict=` parameter
   --> models/quality_prediction.py:546:44
    |
544 |           for target, model in self.models.items():
545 |               if hasattr(model, "feature_importances_"):
546 |                   for feature, importance in zip(
    |  ____________________________________________^
547 | |                     feature_names, model.feature_importances_
548 | |                 ):
    | |_________________^
549 |                       importance_sum[feature] = (
550 |                           importance_sum.get(feature, 0) + importance
    |
help: Add explicit value for parameter `strict=`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/quality_prediction.py:570:10
    |
568 |         theme_category: str = "general",
569 |         sentiment: str = "neutral",
570 |     ) -> Dict:
    |          ^^^^
571 |         """Predict quality metrics for new lyrics"""
    |
help: Replace with `dict`

N806 Variable `X` in function should be lowercase
   --> models/quality_prediction.py:597:13
    |
596 |             # Engineer features
597 |             X = self.engineer_features(df_dummy)
    |             ^
598 |
599 |             # Scale features
    |

N806 Variable `X_scaled` in function should be lowercase
   --> models/quality_prediction.py:600:13
    |
599 |             # Scale features
600 |             X_scaled = pd.DataFrame(self.scaler.transform(X), columns=X.columns)
    |             ^^^^^^^^
601 |
602 |             # Make predictions
    |

TRY300 Consider moving this statement to an `else` block
   --> models/quality_prediction.py:608:13
    |
606 |                 predictions[target_name] = round(max(0, min(1, pred_value)), 3)
607 |
608 |             return predictions
    |             ^^^^^^^^^^^^^^^^^^
609 |
610 |         except Exception as e:
    |

C420 [*] Unnecessary dict comprehension for iterable; use `dict.fromkeys` instead
   --> models/quality_prediction.py:612:20
    |
610 |         except Exception as e:
611 |             logger.error(f"âŒ Prediction failed: {e}")
612 |             return {target: 0.5 for target in self.models.keys()}
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
613 |
614 |     def save_models(self, output_path: str = "./models/quality_predictor.pkl"):
    |
help: Replace with `dict.fromkeys(iterable)`)

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> models/quality_prediction.py:612:37
    |
610 |         except Exception as e:
611 |             logger.error(f"âŒ Prediction failed: {e}")
612 |             return {target: 0.5 for target in self.models.keys()}
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
613 |
614 |     def save_models(self, output_path: str = "./models/quality_predictor.pkl"):
    |
help: Remove `.keys()`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> models/quality_prediction.py:626:34
    |
624 |             "training_results": getattr(self, "training_results", {}),
625 |             "metadata": {
626 |                 "creation_date": datetime.now().isoformat(),
    |                                  ^^^^^^^^^^^^^^
627 |                 "model_type": "Multi-target Quality Prediction",
628 |                 "targets": list(self.models.keys()),
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   --> models/quality_prediction.py:633:9
    |
631 |         }
632 |
633 |         os.makedirs(os.path.dirname(output_path), exist_ok=True)
    |         ^^^^^^^^^^^
634 |         with open(output_path, "wb") as f:
635 |             joblib.dump(model_data, f)
    |
help: Replace with `Path(...).mkdir(parents=True)`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
   --> models/quality_prediction.py:633:21
    |
631 |         }
632 |
633 |         os.makedirs(os.path.dirname(output_path), exist_ok=True)
    |                     ^^^^^^^^^^^^^^^
634 |         with open(output_path, "wb") as f:
635 |             joblib.dump(model_data, f)
    |
help: Replace with `Path(...).parent`

PTH123 `open()` should be replaced by `Path.open()`
   --> models/quality_prediction.py:634:14
    |
633 |         os.makedirs(os.path.dirname(output_path), exist_ok=True)
634 |         with open(output_path, "wb") as f:
    |              ^^^^
635 |             joblib.dump(model_data, f)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> models/quality_prediction.py:645:18
    |
644 |         try:
645 |             with open(model_path, "rb") as f:
    |                  ^^^^
646 |                 model_data = joblib.load(f)
    |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
   --> models/quality_prediction.py:657:13
    |
656 |             logger.info("âœ… Models loaded successfully")
657 |             return predictor
    |             ^^^^^^^^^^^^^^^^
658 |
659 |         except Exception as e:
    |

F841 Local variable `results` is assigned to but never used
   --> models/quality_prediction.py:674:9
    |
673 |         # Train all models
674 |         results = predictor.train_models(
    |         ^^^^^^^
675 |             dataset_path="data/ml/quick_dataset.pkl", test_size=0.2, cv_folds=5
676 |         )
    |
help: Remove assignment to unused variable `results`

W293 Blank line contains whitespace
   --> models/quality_prediction.py:689:1
    |
687 |         Money on my mind but I keep it real
688 |         This is how I'm living, this is how I feel
689 |         
    | ^^^^^^^^
690 |         Success don't come easy, that's the truth
691 |         But I keep on grinding since I was a youth
    |
help: Remove whitespace from blank line

TRY300 Consider moving this statement to an `else` block
   --> models/quality_prediction.py:732:9
    |
730 |         )
731 |
732 |         return True
    |         ^^^^^^^^^^^
733 |
734 |     except Exception as e:
    |

W293 Blank line contains whitespace
   --> models/quality_prediction.py:768:1
    |
766 |                 We need change, we need hope, we need a voice
767 |                 Stand together, make the right choice
768 |                 
    | ^^^^^^^^^^^^^^^^
769 |                 Education over incarceration
770 |                 Love over hate across the nation
    |
help: Remove whitespace from blank line

F541 [*] f-string without any placeholders
   --> models/quality_prediction.py:807:19
    |
805 |             )
806 |
807 |             print(f"\nðŸ“Š QUALITY ANALYSIS:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^
808 |             print("-" * 40)
809 |             for metric, score in predictions.items():
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> models/quality_prediction.py:818:19
    |
817 |             # Recommendations
818 |             print(f"\nðŸ’¡ RECOMMENDATIONS:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^
819 |             if predictions["commercial_potential"] > 0.7:
820 |                 print("   ðŸŽµ High commercial potential - radio ready!")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> models/style_transfer.py:12:1
   |
10 |   """
11 |
12 | / import torch
13 | | import torch.nn as nn
14 | | from torch.utils.data import Dataset, DataLoader
15 | | from transformers import (
16 | |     T5ForConditionalGeneration,
17 | |     T5Tokenizer,
18 | |     TrainingArguments,
19 | |     Trainer,
20 | | )
21 | | import json
22 | | import pickle
23 | | import pandas as pd
24 | | import numpy as np
25 | | from typing import List, Dict, Optional, Tuple
26 | | import logging
27 | | from datetime import datetime
28 | | import os
29 | | import sys
30 | | from pathlib import Path
31 | | import warnings
32 | | import random
33 | | from collections import defaultdict
   | |___________________________________^
34 |
35 |   warnings.filterwarnings("ignore")
   |
help: Organize imports

PLR0402 [*] Use `from torch import nn` in lieu of alias
  --> models/style_transfer.py:13:8
   |
12 | import torch
13 | import torch.nn as nn
   |        ^^^^^^^^^^^^^^
14 | from torch.utils.data import Dataset, DataLoader
15 | from transformers import (
   |
help: Replace with `from torch import nn`

F401 [*] `torch.nn` imported but unused
  --> models/style_transfer.py:13:20
   |
12 | import torch
13 | import torch.nn as nn
   |                    ^^
14 | from torch.utils.data import Dataset, DataLoader
15 | from transformers import (
   |
help: Remove unused import: `torch.nn`

F401 [*] `torch.utils.data.DataLoader` imported but unused
  --> models/style_transfer.py:14:39
   |
12 | import torch
13 | import torch.nn as nn
14 | from torch.utils.data import Dataset, DataLoader
   |                                       ^^^^^^^^^^
15 | from transformers import (
16 |     T5ForConditionalGeneration,
   |
help: Remove unused import: `torch.utils.data.DataLoader`

F401 [*] `numpy` imported but unused
  --> models/style_transfer.py:24:17
   |
22 | import pickle
23 | import pandas as pd
24 | import numpy as np
   |                 ^^
25 | from typing import List, Dict, Optional, Tuple
26 | import logging
   |
help: Remove unused import: `numpy`

UP035 `typing.List` is deprecated, use `list` instead
  --> models/style_transfer.py:25:1
   |
23 | import pandas as pd
24 | import numpy as np
25 | from typing import List, Dict, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
26 | import logging
27 | from datetime import datetime
   |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> models/style_transfer.py:25:1
   |
23 | import pandas as pd
24 | import numpy as np
25 | from typing import List, Dict, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
26 | import logging
27 | from datetime import datetime
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> models/style_transfer.py:25:1
   |
23 | import pandas as pd
24 | import numpy as np
25 | from typing import List, Dict, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
26 | import logging
27 | from datetime import datetime
   |

F401 [*] `typing.Dict` imported but unused
  --> models/style_transfer.py:25:26
   |
23 | import pandas as pd
24 | import numpy as np
25 | from typing import List, Dict, Optional, Tuple
   |                          ^^^^
26 | import logging
27 | from datetime import datetime
   |
help: Remove unused import

F401 [*] `typing.Optional` imported but unused
  --> models/style_transfer.py:25:32
   |
23 | import pandas as pd
24 | import numpy as np
25 | from typing import List, Dict, Optional, Tuple
   |                                ^^^^^^^^
26 | import logging
27 | from datetime import datetime
   |
help: Remove unused import

F401 [*] `collections.defaultdict` imported but unused
  --> models/style_transfer.py:33:25
   |
31 | import warnings
32 | import random
33 | from collections import defaultdict
   |                         ^^^^^^^^^^^
34 |
35 | warnings.filterwarnings("ignore")
   |
help: Remove unused import: `collections.defaultdict`

PTH123 `open()` should be replaced by `Path.open()`
  --> models/style_transfer.py:75:18
   |
74 |         try:
75 |             with open(dataset_path, "rb") as f:
   |                  ^^^^
76 |                 ml_dataset = pickle.load(f)
   |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
  --> models/style_transfer.py:89:13
   |
88 |             logger.info(f"ðŸ“Š Filtered to {len(df_filtered)} tracks from major artists")
89 |             return df_filtered
   |             ^^^^^^^^^^^^^^^^^^
90 |
91 |         except Exception as e:
   |

UP006 [*] Use `list` instead of `List` for type annotation
  --> models/style_transfer.py:97:10
   |
95 |     def create_style_transfer_pairs(
96 |         self, df: pd.DataFrame, max_pairs_per_theme: int = 50
97 |     ) -> List[Tuple[str, str]]:
   |          ^^^^
98 |         """
99 |         Create style transfer training pairs
   |
help: Replace with `list`

UP006 [*] Use `tuple` instead of `Tuple` for type annotation
  --> models/style_transfer.py:97:15
   |
95 |     def create_style_transfer_pairs(
96 |         self, df: pd.DataFrame, max_pairs_per_theme: int = 50
97 |     ) -> List[Tuple[str, str]]:
   |               ^^^^^
98 |         """
99 |         Create style transfer training pairs
   |
help: Replace with `tuple`

B007 Loop control variable `theme` not used within loop body
   --> models/style_transfer.py:109:13
    |
107 |         theme_groups = df.groupby("theme_category")
108 |
109 |         for theme, theme_df in theme_groups:
    |             ^^^^^
110 |             if len(theme_df) < 2:
111 |                 continue
    |
help: Rename unused `theme` to `_theme`

UP006 [*] Use `list` instead of `List` for type annotation
   --> models/style_transfer.py:168:31
    |
167 |     def create_dataset(
168 |         self, transfer_pairs: List[Tuple[str, str]], max_length: int = 512
    |                               ^^^^
169 |     ) -> Dataset:
170 |         """Create PyTorch dataset for style transfer training"""
    |
help: Replace with `list`

UP006 [*] Use `tuple` instead of `Tuple` for type annotation
   --> models/style_transfer.py:168:36
    |
167 |     def create_dataset(
168 |         self, transfer_pairs: List[Tuple[str, str]], max_length: int = 512
    |                                    ^^^^^
169 |     ) -> Dataset:
170 |         """Create PyTorch dataset for style transfer training"""
    |
help: Replace with `tuple`

TRY301 Abstract `raise` to an inner function
   --> models/style_transfer.py:239:17
    |
238 |             if len(transfer_pairs) == 0:
239 |                 raise ValueError("No transfer pairs created")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
240 |
241 |             # Limit pairs if specified
    |

F541 [*] f-string without any placeholders
   --> models/style_transfer.py:280:25
    |
279 |             # Start training
280 |             logger.info(f"ðŸŽ¯ Starting training:")
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^
281 |             logger.info(f"   Pairs: {len(transfer_pairs)}")
282 |             logger.info(f"   Epochs: {epochs}")
    |
help: Remove extraneous `f` prefix

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> models/style_transfer.py:296:34
    |
294 |             # Save training metadata
295 |             training_metadata = {
296 |                 "training_date": datetime.now().isoformat(),
    |                                  ^^^^^^^^^^^^^^
297 |                 "training_pairs": len(transfer_pairs),
298 |                 "epochs": epochs,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> models/style_transfer.py:305:18
    |
303 |             }
304 |
305 |             with open(f"{output_dir}/training_metadata.json", "w") as f:
    |                  ^^^^
306 |                 json.dump(training_metadata, f, indent=2)
    |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
   --> models/style_transfer.py:311:13
    |
309 |             logger.info(f"   Model saved to: {output_dir}")
310 |
311 |             return output_dir
    |             ^^^^^^^^^^^^^^^^^
312 |
313 |         except Exception as e:
    |

SIM210 Remove unnecessary `True if ... else False`
   --> models/style_transfer.py:351:27
    |
349 |                 early_stopping=True,
350 |                 temperature=temperature,
351 |                 do_sample=True if temperature > 0 else False,
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
352 |                 pad_token_id=self.tokenizer.pad_token_id,
353 |                 eos_token_id=self.tokenizer.eos_token_id,
    |
help: Remove unnecessary `True if ... else False`

UP006 [*] Use `list` instead of `List` for type annotation
   --> models/style_transfer.py:361:28
    |
360 |     def batch_transfer(
361 |         self, lyrics_list: List[str], target_styles: List[str], max_length: int = 200
    |                            ^^^^
362 |     ) -> List[str]:
363 |         """Perform batch style transfer"""
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> models/style_transfer.py:361:54
    |
360 |     def batch_transfer(
361 |         self, lyrics_list: List[str], target_styles: List[str], max_length: int = 200
    |                                                      ^^^^
362 |     ) -> List[str]:
363 |         """Perform batch style transfer"""
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> models/style_transfer.py:362:10
    |
360 |     def batch_transfer(
361 |         self, lyrics_list: List[str], target_styles: List[str], max_length: int = 200
362 |     ) -> List[str]:
    |          ^^^^
363 |         """Perform batch style transfer"""
    |
help: Replace with `list`

B905 `zip()` without an explicit `strict=` parameter
   --> models/style_transfer.py:367:30
    |
365 |         results = []
366 |
367 |         for lyrics, style in zip(lyrics_list, target_styles):
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
368 |             try:
369 |                 transferred = self.transfer_style(lyrics, style, max_length)
    |
help: Add explicit value for parameter `strict=`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> models/style_transfer.py:371:13
    |
369 |                   transferred = self.transfer_style(lyrics, style, max_length)
370 |                   results.append(transferred)
371 | /             except Exception as e:
372 | |                 logger.warning(f"âš ï¸ Transfer failed for style {style}: {e}")
373 | |                 results.append(lyrics)  # Fallback to original
    | |______________________________________^
374 |
375 |           return results
    |

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   --> models/style_transfer.py:396:29
    |
395 |             # Load metadata if available
396 |             metadata_path = os.path.join(model_path, "training_metadata.json")
    |                             ^^^^^^^^^^^^
397 |             if os.path.exists(metadata_path):
398 |                 with open(metadata_path, "r") as f:
    |

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> models/style_transfer.py:397:16
    |
395 |             # Load metadata if available
396 |             metadata_path = os.path.join(model_path, "training_metadata.json")
397 |             if os.path.exists(metadata_path):
    |                ^^^^^^^^^^^^^^
398 |                 with open(metadata_path, "r") as f:
399 |                     metadata = json.load(f)
    |
help: Replace with `Path(...).exists()`

PTH123 `open()` should be replaced by `Path.open()`
   --> models/style_transfer.py:398:22
    |
396 |             metadata_path = os.path.join(model_path, "training_metadata.json")
397 |             if os.path.exists(metadata_path):
398 |                 with open(metadata_path, "r") as f:
    |                      ^^^^
399 |                     metadata = json.load(f)
400 |                     transfer_model.task_prefix = metadata.get(
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> models/style_transfer.py:398:42
    |
396 |             metadata_path = os.path.join(model_path, "training_metadata.json")
397 |             if os.path.exists(metadata_path):
398 |                 with open(metadata_path, "r") as f:
    |                                          ^^^
399 |                     metadata = json.load(f)
400 |                     transfer_model.task_prefix = metadata.get(
    |
help: Remove mode argument

TRY300 Consider moving this statement to an `else` block
   --> models/style_transfer.py:407:13
    |
406 |             logger.info("âœ… Pre-trained style transfer model loaded")
407 |             return transfer_model
    |             ^^^^^^^^^^^^^^^^^^^^^
408 |
409 |         except Exception as e:
    |

TRY300 Consider moving this statement to an `else` block
   --> models/style_transfer.py:460:9
    |
458 |         logger.info(f"Model saved to: {model_path}")
459 |
460 |         return True
    |         ^^^^^^^^^^^
461 |
462 |     except Exception as e:
    |

I001 [*] Import block is un-sorted or un-formatted
  --> models/test_qwen.py:29:1
   |
27 |   """
28 |
29 | / import os
30 | | import sys
31 | | import json
32 | | import asyncio
33 | | import argparse
34 | | import logging
35 | | from pathlib import Path
36 | | from typing import Dict, List, Any, Optional, Tuple
37 | | from datetime import datetime
38 | | from dataclasses import dataclass
39 | | from dotenv import load_dotenv
   | |______________________________^
40 |
41 |   # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> models/test_qwen.py:36:1
   |
34 | import logging
35 | from pathlib import Path
36 | from typing import Dict, List, Any, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37 | from datetime import datetime
38 | from dataclasses import dataclass
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> models/test_qwen.py:36:1
   |
34 | import logging
35 | from pathlib import Path
36 | from typing import Dict, List, Any, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37 | from datetime import datetime
38 | from dataclasses import dataclass
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> models/test_qwen.py:36:1
   |
34 | import logging
35 | from pathlib import Path
36 | from typing import Dict, List, Any, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37 | from datetime import datetime
38 | from dataclasses import dataclass
   |

F401 [*] `typing.List` imported but unused
  --> models/test_qwen.py:36:26
   |
34 | import logging
35 | from pathlib import Path
36 | from typing import Dict, List, Any, Optional, Tuple
   |                          ^^^^
37 | from datetime import datetime
38 | from dataclasses import dataclass
   |
help: Remove unused import: `typing.List`

F401 `openai` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> models/test_qwen.py:50:12
   |
48 | # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹
49 | try:
50 |     import openai
   |            ^^^^^^
51 |     from openai import OpenAI
   |
help: Remove unused import: `openai`

I001 [*] Import block is un-sorted or un-formatted
  --> models/test_qwen.py:59:5
   |
58 |   try:
59 | /     import pandas as pd
60 | |     import numpy as np
   | |______________________^
61 |
62 |       HAS_PANDAS = True
   |
help: Organize imports

F401 `pandas` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> models/test_qwen.py:59:22
   |
58 | try:
59 |     import pandas as pd
   |                      ^^
60 |     import numpy as np
   |
help: Remove unused import: `pandas`

UP045 [*] Use `X | None` for type annotations
  --> models/test_qwen.py:90:14
   |
88 |     # API Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ (Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½ base_url)
89 |     base_url: str = "https://api.novita.ai/openai"
90 |     api_key: Optional[str] = None
   |              ^^^^^^^^^^^^^
91 |     # ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ (Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð´Ð»Ñ QWEN)
92 |     temperature: float = 0.7
   |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> models/test_qwen.py:105:32
    |
103 |     """Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ QWEN Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ rap Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
104 |
105 |     def __init__(self, config: Optional[QwenConfig] = None):
    |                                ^^^^^^^^^^^^^^^^^^^^
106 |         self.config = config or QwenConfig()
107 |         self.config.api_key = self.config.api_key or os.getenv("NOVITA_API_KEY")
    |
help: Convert to `X | None`

TRY300 Consider moving this statement to an `else` block
   --> models/test_qwen.py:138:13
    |
136 |             )
137 |             logger.info(f"âœ… QWEN ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½: {self.config.primary_model}")
138 |             return True
    |             ^^^^^^^^^^^
139 |         except Exception as e:
140 |             logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°: {e}")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> models/test_qwen.py:271:21
    |
269 |                           processed_data.append(training_example)
270 |
271 | /                     except Exception as e:
272 | |                         logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð·Ð°Ð¿Ð¸ÑÐ¸ {record['id']}: {e}")
273 | |                         continue
    | |________________________________^
274 |
275 |                   # Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð½Ð° train/eval
    |

F541 [*] f-string without any placeholders
   --> models/test_qwen.py:280:23
    |
278 |                 self.evaluation_data = processed_data[split_idx:]
279 |
280 |                 print(f"âœ… Dataset Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½:")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
281 |                 print(f"  ðŸ“š Training samples: {len(self.training_data)}")
282 |                 print(f"  ðŸ§ª Evaluation samples: {len(self.evaluation_data)}")
    |
help: Remove extraneous `f` prefix

PTH123 `open()` should be replaced by `Path.open()`
   --> models/test_qwen.py:286:22
    |
284 |                 # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°
285 |                 dataset_file = self.results_dir / "training_dataset.json"
286 |                 with open(dataset_file, "w", encoding="utf-8") as f:
    |                      ^^^^
287 |                     json.dump(
288 |                         {
    |
help: Replace with `Path.open()`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> models/test_qwen.py:292:43
    |
290 |                             "evaluation_data": self.evaluation_data,
291 |                             "config": self.config.__dict__,
292 |                             "created_at": datetime.now().isoformat(),
    |                                           ^^^^^^^^^^^^^^
293 |                         },
294 |                         f,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/test_qwen.py:309:47
    |
307 |                 await self.db_manager.close()
308 |
309 |     def create_training_prompt(self, example: Dict[str, Any]) -> Tuple[str, str]:
    |                                               ^^^^
310 |         """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð° Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ"""
    |
help: Replace with `dict`

UP006 [*] Use `tuple` instead of `Tuple` for type annotation
   --> models/test_qwen.py:309:66
    |
307 |                 await self.db_manager.close()
308 |
309 |     def create_training_prompt(self, example: Dict[str, Any]) -> Tuple[str, str]:
    |                                                                  ^^^^^
310 |         """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð° Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ"""
    |
help: Replace with `tuple`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/test_qwen.py:354:50
    |
352 |         return system_prompt, user_prompt
353 |
354 |     async def simulate_training_process(self) -> Dict[str, Any]:
    |                                                  ^^^^
355 |         """Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ (Ð¿Ð¾ÐºÐ° Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ fine-tuning Ñ‡ÐµÑ€ÐµÐ· API)"""
356 |         print("ðŸŽ¯ Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ training process...")
    |
help: Replace with `dict`

F541 [*] f-string without any placeholders
   --> models/test_qwen.py:373:27
    |
371 |             try:
372 |                 if not self.client:
373 |                     print(f"  âŒ ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^
374 |                     continue
    |
help: Remove extraneous `f` prefix

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> models/test_qwen.py:434:26
    |
432 |             "average_tokens_per_sample": total_tokens / max(successful, 1),
433 |             "results": results,
434 |             "timestamp": datetime.now().isoformat(),
    |                          ^^^^^^^^^^^^^^
435 |         }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> models/test_qwen.py:440:35
    |
438 |         results_file = (
439 |             self.results_dir
440 |             / f"training_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    |                                   ^^^^^^^^^^^^^^
441 |         )
442 |         with open(results_file, "w", encoding="utf-8") as f:
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> models/test_qwen.py:442:14
    |
440 |             / f"training_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
441 |         )
442 |         with open(results_file, "w", encoding="utf-8") as f:
    |              ^^^^
443 |             json.dump(training_results, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

F541 [*] f-string without any placeholders
   --> models/test_qwen.py:445:15
    |
443 |             json.dump(training_results, f, indent=2, ensure_ascii=False)
444 |
445 |         print(f"\nðŸ“Š Training Results:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^
446 |         print(f"  âœ… Success rate: {training_results['success_rate']:.1f}%")
447 |         print(f"  ðŸ”¢ Total tokens: {training_results['total_tokens_used']}")
    |
help: Remove extraneous `f` prefix

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/test_qwen.py:452:39
    |
450 |         return training_results
451 |
452 |     async def evaluate_model(self) -> Dict[str, Any]:
    |                                       ^^^^
453 |         """ÐžÑ†ÐµÐ½ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° evaluation Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
454 |         print("ðŸ“ˆ ÐžÑ†ÐµÐ½ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° evaluation dataset...")
    |
help: Replace with `dict`

F541 [*] f-string without any placeholders
   --> models/test_qwen.py:471:27
    |
469 |             try:
470 |                 if not self.client:
471 |                     print(f"  âŒ ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^
472 |                     continue
    |
help: Remove extraneous `f` prefix

E722 Do not use bare `except`
   --> models/test_qwen.py:495:17
    |
493 |                 try:
494 |                     predicted_score = float(predicted_score)
495 |                 except:
    |                 ^^^^^^
496 |                     predicted_score = 0.5
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> models/test_qwen.py:540:26
    |
538 |             "rmse": rmse,
539 |             "results": results,
540 |             "timestamp": datetime.now().isoformat(),
    |                          ^^^^^^^^^^^^^^
541 |         }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> models/test_qwen.py:546:37
    |
544 |         eval_file = (
545 |             self.results_dir
546 |             / f"evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    |                                     ^^^^^^^^^^^^^^
547 |         )
548 |         with open(eval_file, "w", encoding="utf-8") as f:
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> models/test_qwen.py:548:14
    |
546 |             / f"evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
547 |         )
548 |         with open(eval_file, "w", encoding="utf-8") as f:
    |              ^^^^
549 |             json.dump(evaluation_results, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

F541 [*] f-string without any placeholders
   --> models/test_qwen.py:551:15
    |
549 |             json.dump(evaluation_results, f, indent=2, ensure_ascii=False)
550 |
551 |         print(f"ðŸ“Š Evaluation Results:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^
552 |         print(f"  ðŸ“ˆ MAE: {mae:.3f}")
553 |         print(f"  ðŸ“ˆ RMSE: {rmse:.3f}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> models/test_qwen.py:620:11
    |
618 |     print(f"ðŸŽ¯ Model: {config.primary_model}")
619 |     print(f"ðŸ“Š Max Samples: {config.max_samples}")
620 |     print(f"ï¿½ Status: WORKING âœ…")
    |           ^^^^^^^^^^^^^^^^^^^^^^^
621 |     print("=" * 60)
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> models/trend_analysis.py:13:1
   |
11 |   """
12 |
13 | / import pandas as pd
14 | | import numpy as np
15 | | import pickle
16 | | import sys
17 | | import os
18 | | from pathlib import Path
19 | | from datetime import datetime, timedelta
20 | | import logging
21 | | from typing import Dict, List, Optional, Tuple
22 | | import warnings
23 | | import json
24 | | from collections import defaultdict, Counter
   | |____________________________________________^
25 |
26 |   warnings.filterwarnings("ignore")
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> models/trend_analysis.py:21:1
   |
19 | from datetime import datetime, timedelta
20 | import logging
21 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
22 | import warnings
23 | import json
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> models/trend_analysis.py:21:1
   |
19 | from datetime import datetime, timedelta
20 | import logging
21 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
22 | import warnings
23 | import json
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> models/trend_analysis.py:21:1
   |
19 | from datetime import datetime, timedelta
20 | import logging
21 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
22 | import warnings
23 | import json
   |

F401 [*] `typing.Optional` imported but unused
  --> models/trend_analysis.py:21:32
   |
19 | from datetime import datetime, timedelta
20 | import logging
21 | from typing import Dict, List, Optional, Tuple
   |                                ^^^^^^^^
22 | import warnings
23 | import json
   |
help: Remove unused import

F401 [*] `typing.Tuple` imported but unused
  --> models/trend_analysis.py:21:42
   |
19 | from datetime import datetime, timedelta
20 | import logging
21 | from typing import Dict, List, Optional, Tuple
   |                                          ^^^^^
22 | import warnings
23 | import json
   |
help: Remove unused import

F401 [*] `collections.defaultdict` imported but unused
  --> models/trend_analysis.py:24:25
   |
22 | import warnings
23 | import json
24 | from collections import defaultdict, Counter
   |                         ^^^^^^^^^^^
25 |
26 | warnings.filterwarnings("ignore")
   |
help: Remove unused import: `collections.defaultdict`

E402 Module level import not at top of file
  --> models/trend_analysis.py:29:1
   |
28 | # ML libraries
29 | from sklearn.cluster import KMeans
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30 | from sklearn.decomposition import PCA
31 | from sklearn.preprocessing import StandardScaler
   |

I001 [*] Import block is un-sorted or un-formatted
  --> models/trend_analysis.py:29:1
   |
28 |   # ML libraries
29 | / from sklearn.cluster import KMeans
30 | | from sklearn.decomposition import PCA
31 | | from sklearn.preprocessing import StandardScaler
32 | | from sklearn.feature_extraction.text import TfidfVectorizer
33 | |
34 | | # Visualization
35 | | import matplotlib.pyplot as plt
36 | | import seaborn as sns
   | |_____________________^
37 |
38 |   try:
   |
help: Organize imports

E402 Module level import not at top of file
  --> models/trend_analysis.py:30:1
   |
28 | # ML libraries
29 | from sklearn.cluster import KMeans
30 | from sklearn.decomposition import PCA
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
31 | from sklearn.preprocessing import StandardScaler
32 | from sklearn.feature_extraction.text import TfidfVectorizer
   |

E402 Module level import not at top of file
  --> models/trend_analysis.py:31:1
   |
29 | from sklearn.cluster import KMeans
30 | from sklearn.decomposition import PCA
31 | from sklearn.preprocessing import StandardScaler
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
32 | from sklearn.feature_extraction.text import TfidfVectorizer
   |

E402 Module level import not at top of file
  --> models/trend_analysis.py:32:1
   |
30 | from sklearn.decomposition import PCA
31 | from sklearn.preprocessing import StandardScaler
32 | from sklearn.feature_extraction.text import TfidfVectorizer
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
33 |
34 | # Visualization
   |

F401 [*] `sklearn.feature_extraction.text.TfidfVectorizer` imported but unused
  --> models/trend_analysis.py:32:45
   |
30 | from sklearn.decomposition import PCA
31 | from sklearn.preprocessing import StandardScaler
32 | from sklearn.feature_extraction.text import TfidfVectorizer
   |                                             ^^^^^^^^^^^^^^^
33 |
34 | # Visualization
   |
help: Remove unused import: `sklearn.feature_extraction.text.TfidfVectorizer`

E402 Module level import not at top of file
  --> models/trend_analysis.py:35:1
   |
34 | # Visualization
35 | import matplotlib.pyplot as plt
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
36 | import seaborn as sns
   |

E402 Module level import not at top of file
  --> models/trend_analysis.py:36:1
   |
34 | # Visualization
35 | import matplotlib.pyplot as plt
36 | import seaborn as sns
   | ^^^^^^^^^^^^^^^^^^^^^
37 |
38 | try:
   |

F401 [*] `seaborn` imported but unused
  --> models/trend_analysis.py:36:19
   |
34 | # Visualization
35 | import matplotlib.pyplot as plt
36 | import seaborn as sns
   |                   ^^^
37 |
38 | try:
   |
help: Remove unused import: `seaborn`

PTH123 `open()` should be replaced by `Path.open()`
  --> models/trend_analysis.py:83:18
   |
82 |         try:
83 |             with open(dataset_path, "rb") as f:
   |                  ^^^^
84 |                 ml_dataset = pickle.load(f)
   |
help: Replace with `Path.open()`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> models/trend_analysis.py:110:24
    |
109 |             # Generate mock dates over the last 2 years
110 |             end_date = datetime.now()
    |                        ^^^^^^^^^^^^^^
111 |             start_date = end_date - timedelta(days=730)
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

TRY300 Consider moving this statement to an `else` block
   --> models/trend_analysis.py:121:13
    |
119 |             df["quarter"] = df["analysis_date"].dt.to_period("Q")
120 |
121 |             return df
    |             ^^^^^^^^^
122 |
123 |         except Exception as e:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:127:60
    |
125 |             raise
126 |
127 |     def analyze_temporal_trends(self, df: pd.DataFrame) -> Dict:
    |                                                            ^^^^
128 |         """Analyze temporal trends in themes and sentiments"""
129 |         logger.info("ðŸ“ˆ Analyzing temporal trends...")
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:198:80
    |
196 |         return trends
197 |
198 |     def cluster_musical_styles(self, df: pd.DataFrame, n_clusters: int = 6) -> Dict:
    |                                                                                ^^^^
199 |         """Cluster musical styles based on features"""
200 |         logger.info(f"ðŸŽµ Clustering musical styles into {n_clusters} clusters...")
    |
help: Replace with `dict`

RUF046 [*] Value being cast to `int` is already an integer
   --> models/trend_analysis.py:243:25
    |
241 |             # Cluster characteristics
242 |             cluster_analysis[cluster_id] = {
243 |                 "size": int(len(cluster_data)),
    |                         ^^^^^^^^^^^^^^^^^^^^^^
244 |                 "percentage": float(len(cluster_data) / len(df) * 100),
245 |                 "top_artists": {
    |
help: Remove unnecessary `int` call

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:290:10
    |
288 |     def predict_emerging_trends(
289 |         self, df: pd.DataFrame, forecast_months: int = 6
290 |     ) -> Dict:
    |          ^^^^
291 |         """Predict emerging trends based on growth patterns"""
292 |         logger.info(
    |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> models/trend_analysis.py:389:30
    |
387 |             "emerging_trends": emerging_trends,
388 |             "forecast_period": forecast_months,
389 |             "analysis_date": datetime.now().isoformat(),
    |                              ^^^^^^^^^^^^^^
390 |         }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:392:59
    |
390 |         }
391 |
392 |     def analyze_viral_patterns(self, df: pd.DataFrame) -> Dict:
    |                                                           ^^^^
393 |         """Analyze patterns in viral/popular tracks"""
394 |         logger.info("ðŸš€ Analyzing viral patterns...")
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:453:68
    |
451 |         return viral_analysis
452 |
453 |     def _extract_theme_patterns(self, themes_series: pd.Series) -> Dict:
    |                                                                    ^^^^
454 |         """Extract common theme patterns"""
455 |         all_themes = []
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:469:10
    |
467 |     def generate_trend_report(
468 |         self, dataset_path: str = "data/ml/quick_dataset.pkl"
469 |     ) -> Dict:
    |          ^^^^
470 |         """Generate comprehensive trend analysis report"""
471 |         logger.info("ðŸ“Š Generating comprehensive trend report...")
    |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> models/trend_analysis.py:486:40
    |
484 |             report = {
485 |                 "metadata": {
486 |                     "generation_date": datetime.now().isoformat(),
    |                                        ^^^^^^^^^^^^^^
487 |                     "dataset_size": len(df),
488 |                     "analysis_period": f"{df['analysis_date'].min()} to {df['analysis_date'].max()}",
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   --> models/trend_analysis.py:505:13
    |
503 |             # Save report
504 |             output_path = "./models/trend_analysis_report.json"
505 |             os.makedirs(os.path.dirname(output_path), exist_ok=True)
    |             ^^^^^^^^^^^
506 |
507 |             with open(output_path, "w") as f:
    |
help: Replace with `Path(...).mkdir(parents=True)`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
   --> models/trend_analysis.py:505:25
    |
503 |             # Save report
504 |             output_path = "./models/trend_analysis_report.json"
505 |             os.makedirs(os.path.dirname(output_path), exist_ok=True)
    |                         ^^^^^^^^^^^^^^^
506 |
507 |             with open(output_path, "w") as f:
    |
help: Replace with `Path(...).parent`

PTH123 `open()` should be replaced by `Path.open()`
   --> models/trend_analysis.py:507:18
    |
505 |             os.makedirs(os.path.dirname(output_path), exist_ok=True)
506 |
507 |             with open(output_path, "w") as f:
    |                  ^^^^
508 |                 json.dump(report, f, indent=2, default=str)
    |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
   --> models/trend_analysis.py:511:13
    |
510 |             logger.info(f"âœ… Trend report saved to {output_path}")
511 |             return report
    |             ^^^^^^^^^^^^^
512 |
513 |         except Exception as e:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:518:32
    |
517 |     def _generate_key_insights(
518 |         self, temporal_trends: Dict, emerging_trends: Dict, viral_patterns: Dict
    |                                ^^^^
519 |     ) -> List[str]:
520 |         """Generate key insights from trend analysis"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:518:55
    |
517 |     def _generate_key_insights(
518 |         self, temporal_trends: Dict, emerging_trends: Dict, viral_patterns: Dict
    |                                                       ^^^^
519 |     ) -> List[str]:
520 |         """Generate key insights from trend analysis"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:518:77
    |
517 |     def _generate_key_insights(
518 |         self, temporal_trends: Dict, emerging_trends: Dict, viral_patterns: Dict
    |                                                                             ^^^^
519 |     ) -> List[str]:
520 |         """Generate key insights from trend analysis"""
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> models/trend_analysis.py:519:10
    |
517 |     def _generate_key_insights(
518 |         self, temporal_trends: Dict, emerging_trends: Dict, viral_patterns: Dict
519 |     ) -> List[str]:
    |          ^^^^
520 |         """Generate key insights from trend analysis"""
521 |         insights = []
    |
help: Replace with `list`

RUF015 Prefer `next(iter(emerging_trends["emerging_trends"].keys()))` over single element slice
   --> models/trend_analysis.py:525:25
    |
523 |         # Emerging trend insight
524 |         if emerging_trends.get("emerging_trends"):
525 |             top_trend = list(emerging_trends["emerging_trends"].keys())[0]
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
526 |             growth_rate = emerging_trends["emerging_trends"][top_trend][
527 |                 "growth_rate_percent"
    |
help: Replace with `next(iter(emerging_trends["emerging_trends"].keys()))`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:562:54
    |
560 |         return insights
561 |
562 |     def create_visualization_dashboard(self, report: Dict) -> str:
    |                                                      ^^^^
563 |         """Create interactive visualization dashboard"""
564 |         logger.info("ðŸ“Š Creating trend visualization dashboard...")
    |
help: Replace with `dict`

C408 Unnecessary `dict()` call (rewrite as a literal)
   --> models/trend_analysis.py:598:28
    |
596 |                     orientation="h",
597 |                     name="Growth Rate %",
598 |                     marker=dict(color=growth_rates, colorscale="Viridis"),
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
599 |                 ),
600 |                 row=1,
    |
help: Rewrite as a literal

C408 Unnecessary `dict()` call (rewrite as a literal)
   --> models/trend_analysis.py:623:32
    |
621 |                         mode="markers",
622 |                         name=f"Cluster {cluster_id}",
623 |                         marker=dict(size=5),
    |                                ^^^^^^^^^^^^
624 |                     ),
625 |                     row=1,
    |
help: Rewrite as a literal

C408 Unnecessary `dict()` call (rewrite as a literal)
   --> models/trend_analysis.py:640:28
    |
638 |                     y=values,
639 |                     name="Viral Features",
640 |                     marker=dict(color="red", opacity=0.7),
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
641 |                 ),
642 |                 row=2,
    |
help: Rewrite as a literal

C408 Unnecessary `dict()` call (rewrite as a literal)
   --> models/trend_analysis.py:659:32
    |
657 |                         y=counts,
658 |                         name="Theme Frequency",
659 |                         marker=dict(color="blue", opacity=0.7),
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
660 |                     ),
661 |                     row=2,
    |
help: Rewrite as a literal

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> models/trend_analysis.py:679:52
    |
677 |         return dashboard_path
678 |
679 |     def _create_matplotlib_dashboard(self, report: Dict) -> str:
    |                                                    ^^^^
680 |         """Create simple matplotlib dashboard as fallback"""
681 |         fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    |
help: Replace with `dict`

F541 [*] f-string without any placeholders
   --> models/trend_analysis.py:763:19
    |
761 |         emerging = report.get("emerging_trends", {}).get("emerging_trends", {})
762 |         if emerging:
763 |             print(f"\nðŸ“ˆ TOP 10 EMERGING TRENDS:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
764 |             print("-" * 50)
765 |             for i, (theme, data) in enumerate(list(emerging.items())[:10], 1):
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> models/trend_analysis.py:775:19
    |
773 |         viral = report.get("viral_patterns", {})
774 |         if viral:
775 |             print(f"\nðŸš€ VIRAL PATTERNS:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^
776 |             print("-" * 50)
777 |             print(f"  Viral tracks identified: {viral.get('total_viral_tracks', 0)}")
    |
help: Remove extraneous `f` prefix

RUF015 Prefer `next(iter(viral.get('viral_themes', {}).keys()))` over single element slice
   --> models/trend_analysis.py:782:39
    |
780 |             )
781 |             print(
782 |                 f"  Top viral theme: {list(viral.get('viral_themes', {}).keys())[0] if viral.get('viral_themes') else 'N/A'}"
    |                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
783 |             )
    |
help: Replace with `next(iter(viral.get('viral_themes', {}).keys()))`

F541 [*] f-string without any placeholders
   --> models/trend_analysis.py:785:15
    |
783 |             )
784 |
785 |         print(f"\nðŸ“Š ANALYSIS COMPLETE!")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^
786 |         print(f"Report saved to: ./models/trend_analysis_report.json")
787 |         print(f"Dashboard saved to: {dashboard_path}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> models/trend_analysis.py:786:15
    |
785 |         print(f"\nðŸ“Š ANALYSIS COMPLETE!")
786 |         print(f"Report saved to: ./models/trend_analysis_report.json")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
787 |         print(f"Dashboard saved to: {dashboard_path}")
    |
help: Remove extraneous `f` prefix

TRY300 Consider moving this statement to an `else` block
   --> models/trend_analysis.py:789:9
    |
787 |         print(f"Dashboard saved to: {dashboard_path}")
788 |
789 |         return True
    |         ^^^^^^^^^^^
790 |
791 |     except Exception as e:
    |

I001 [*] Import block is un-sorted or un-formatted
  --> monitoring/scripts/system_monitor.py:7:1
   |
 5 |   """
 6 |
 7 | / import psutil
 8 | | import time
 9 | | import json
10 | | import os
11 | | from datetime import datetime
12 | | from typing import Dict, Any
   | |____________________________^
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> monitoring/scripts/system_monitor.py:12:1
   |
10 | import os
11 | from datetime import datetime
12 | from typing import Dict, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> monitoring/scripts/system_monitor.py:21:32
   |
19 |         self.start_time = time.time()
20 |
21 |     def get_cpu_stats(self) -> Dict[str, Any]:
   |                                ^^^^
22 |         """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° CPU"""
23 |         cpu_stats = {
   |
help: Replace with `dict`

B009 [*] Do not call `getattr` with a constant attribute value. It is not any safer than normal property access.
  --> monitoring/scripts/system_monitor.py:31:45
   |
29 |         if hasattr(os, "getloadavg"):
30 |             try:
31 |                 cpu_stats["load_average"] = getattr(os, "getloadavg")()
   |                                             ^^^^^^^^^^^^^^^^^^^^^^^^^
32 |             except:
33 |                 cpu_stats["load_average"] = None
   |
help: Replace `getattr` with attribute access

E722 Do not use bare `except`
  --> monitoring/scripts/system_monitor.py:32:13
   |
30 |             try:
31 |                 cpu_stats["load_average"] = getattr(os, "getloadavg")()
32 |             except:
   |             ^^^^^^
33 |                 cpu_stats["load_average"] = None
34 |         else:
   |

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> monitoring/scripts/system_monitor.py:40:35
   |
38 |         return cpu_stats
39 |
40 |     def get_memory_stats(self) -> Dict[str, Any]:
   |                                   ^^^^
41 |         """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð°Ð¼ÑÑ‚Ð¸"""
42 |         memory = psutil.virtual_memory()
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> monitoring/scripts/system_monitor.py:50:33
   |
48 |         }
49 |
50 |     def get_disk_stats(self) -> Dict[str, Any]:
   |                                 ^^^^
51 |         """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð´Ð¸ÑÐºÐ°"""
52 |         disk = psutil.disk_usage("/")
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> monitoring/scripts/system_monitor.py:60:36
   |
58 |         }
59 |
60 |     def get_network_stats(self) -> Dict[str, Any]:
   |                                    ^^^^
61 |         """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÑÐµÑ‚Ð¸"""
62 |         net = psutil.net_io_counters()
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> monitoring/scripts/system_monitor.py:70:36
   |
68 |         }
69 |
70 |     def get_process_stats(self) -> Dict[str, Any]:
   |                                    ^^^^
71 |         """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ð² Python"""
72 |         stats = {"total_processes": len(psutil.pids()), "python_processes": []}
   |
help: Replace with `dict`

PERF203 `try`-`except` within a loop incurs performance overhead
  --> monitoring/scripts/system_monitor.py:87:13
   |
85 |                           }
86 |                       )
87 | /             except (psutil.NoSuchProcess, psutil.AccessDenied):
88 | |                 continue
   | |________________________^
89 |
90 |           return stats
   |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> monitoring/scripts/system_monitor.py:98:29
    |
 96 |         while True:
 97 |             try:
 98 |                 timestamp = datetime.now().isoformat()
    |                             ^^^^^^^^^^^^^^
 99 |
100 |                 # Collect all metrics
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   --> monitoring/scripts/system_monitor.py:125:32
    |
124 |                 # Save metrics
125 |                 metrics_file = os.path.join(
    |                                ^^^^^^^^^^^^
126 |                     os.path.dirname(__file__), "..", "metrics", "system_metrics.json"
127 |                 )
    |

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
   --> monitoring/scripts/system_monitor.py:126:21
    |
124 |                 # Save metrics
125 |                 metrics_file = os.path.join(
126 |                     os.path.dirname(__file__), "..", "metrics", "system_metrics.json"
    |                     ^^^^^^^^^^^^^^^
127 |                 )
    |
help: Replace with `Path(...).parent`

PTH123 `open()` should be replaced by `Path.open()`
   --> monitoring/scripts/system_monitor.py:129:22
    |
127 |                 )
128 |
129 |                 with open(metrics_file, "w", encoding="utf-8") as f:
    |                      ^^^^
130 |                     json.dump(metrics, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> monitoring/scripts/system_monitor.py:134:13
    |
132 |                   time.sleep(interval)
133 |
134 | /             except KeyboardInterrupt:
135 | |                 print("\nðŸ‘‹ System monitoring stopped by user")
136 | |                 break
    | |_____________________^
137 |               except Exception as e:
138 |                   print(f"âŒ System monitoring error: {e}")
    |

PLR1722 Use `sys.exit()` instead of `exit`
   --> monitoring/scripts/system_monitor.py:156:5
    |
155 | if __name__ == "__main__":
156 |     exit(main())
    |     ^^^^
    |
help: Replace `exit` with `sys.exit()`

I001 [*] Import block is un-sorted or un-formatted
  --> multi-region/test-multi-region.py:7:1
   |
 5 |   """
 6 |
 7 | / import asyncio
 8 | | import json
 9 | | import subprocess
10 | | import time
11 | | from datetime import datetime
12 | | from typing import Dict, List, Optional
13 | | import asyncpg
14 | | import aiohttp
15 | | import logging
   | |______________^
16 |
17 |   # Configure logging
   |
help: Organize imports

F401 [*] `time` imported but unused
  --> multi-region/test-multi-region.py:10:8
   |
 8 | import json
 9 | import subprocess
10 | import time
   |        ^^^^
11 | from datetime import datetime
12 | from typing import Dict, List, Optional
   |
help: Remove unused import: `time`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> multi-region/test-multi-region.py:12:1
   |
10 | import time
11 | from datetime import datetime
12 | from typing import Dict, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
13 | import asyncpg
14 | import aiohttp
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> multi-region/test-multi-region.py:12:1
   |
10 | import time
11 | from datetime import datetime
12 | from typing import Dict, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
13 | import asyncpg
14 | import aiohttp
   |

F401 [*] `typing.List` imported but unused
  --> multi-region/test-multi-region.py:12:26
   |
10 | import time
11 | from datetime import datetime
12 | from typing import Dict, List, Optional
   |                          ^^^^
13 | import asyncpg
14 | import aiohttp
   |
help: Remove unused import

F401 [*] `typing.Optional` imported but unused
  --> multi-region/test-multi-region.py:12:32
   |
10 | import time
11 | from datetime import datetime
12 | from typing import Dict, List, Optional
   |                                ^^^^^^^^
13 | import asyncpg
14 | import aiohttp
   |
help: Remove unused import

F401 [*] `asyncpg` imported but unused
  --> multi-region/test-multi-region.py:13:8
   |
11 | from datetime import datetime
12 | from typing import Dict, List, Optional
13 | import asyncpg
   |        ^^^^^^^
14 | import aiohttp
15 | import logging
   |
help: Remove unused import: `asyncpg`

PLW1510 [*] `subprocess.run` without explicit `check` argument
  --> multi-region/test-multi-region.py:52:22
   |
50 |         try:
51 |             cmd = f"kubectl --context={context} {command}"
52 |             result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
   |                      ^^^^^^^^^^^^^^
53 |             if result.returncode != 0:
54 |                 logger.error(f"Command failed: {cmd}")
   |
help: Add explicit `check=False`

TRY300 Consider moving this statement to an `else` block
  --> multi-region/test-multi-region.py:57:13
   |
55 |                 logger.error(f"Error: {result.stderr}")
56 |                 return ""
57 |             return result.stdout
   |             ^^^^^^^^^^^^^^^^^^^^
58 |         except Exception as e:
59 |             logger.error(f"Failed to run kubectl command: {e}")
   |

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> multi-region/test-multi-region.py:62:50
   |
60 |             return ""
61 |
62 |     async def test_cluster_connectivity(self) -> Dict[str, bool]:
   |                                                  ^^^^
63 |         """Test connectivity to all Kubernetes clusters"""
64 |         logger.info("ðŸ”— Testing cluster connectivity...")
   |
help: Replace with `dict`

PERF203 `try`-`except` within a loop incurs performance overhead
  --> multi-region/test-multi-region.py:77:13
   |
75 |                       f"  {status} {region}: {'Connected' if results[region] else 'Failed'}"
76 |                   )
77 | /             except Exception as e:
78 | |                 results[region] = False
79 | |                 logger.error(f"  âŒ {region}: {e}")
   | |___________________________________________________^
80 |
81 |           return results
   |

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> multi-region/test-multi-region.py:83:40
   |
81 |         return results
82 |
83 |     async def test_pod_status(self) -> Dict[str, Dict[str, bool]]:
   |                                        ^^^^
84 |         """Test if all pods are running in each region"""
85 |         logger.info("ðŸš€ Testing pod status...")
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> multi-region/test-multi-region.py:83:50
   |
81 |         return results
82 |
83 |     async def test_pod_status(self) -> Dict[str, Dict[str, bool]]:
   |                                                  ^^^^
84 |         """Test if all pods are running in each region"""
85 |         logger.info("ðŸš€ Testing pod status...")
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> multi-region/test-multi-region.py:115:50
    |
113 |         return results
114 |
115 |     async def test_database_replication(self) -> Dict[str, Dict]:
    |                                                  ^^^^
116 |         """Test PostgreSQL replication status"""
117 |         logger.info("ðŸ˜ Testing database replication...")
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> multi-region/test-multi-region.py:115:60
    |
113 |         return results
114 |
115 |     async def test_database_replication(self) -> Dict[str, Dict]:
    |                                                            ^^^^
116 |         """Test PostgreSQL replication status"""
117 |         logger.info("ðŸ˜ Testing database replication...")
    |
help: Replace with `dict`

ISC003 [*] Explicitly concatenated string should be implicitly concatenated
   --> multi-region/test-multi-region.py:134:25
    |
132 |                       pg_test = await self.run_kubectl_command(
133 |                           config["context"],
134 | /                         f"exec -n rap-analyzer postgresql-{config['role']}-0 -- "
135 | |                         + "psql -U postgres -c 'SELECT version();'",
    | |___________________________________________________________________^
136 |                       )
137 |                       results[region]["connectivity"] = "PostgreSQL" in pg_test
    |
help: Remove redundant '+' operator to implicitly concatenate

F541 [*] f-string without any placeholders
   --> multi-region/test-multi-region.py:143:29
    |
141 |                         repl_test = await self.run_kubectl_command(
142 |                             config["context"],
143 |                             f"exec -n rap-analyzer postgresql-primary-0 -- "
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
144 |                             + "psql -U postgres -c 'SELECT * FROM pg_stat_replication;'",
145 |                         )
    |
help: Remove extraneous `f` prefix

ISC003 [*] Explicitly concatenated string should be implicitly concatenated
   --> multi-region/test-multi-region.py:143:29
    |
141 |                           repl_test = await self.run_kubectl_command(
142 |                               config["context"],
143 | /                             f"exec -n rap-analyzer postgresql-primary-0 -- "
144 | |                             + "psql -U postgres -c 'SELECT * FROM pg_stat_replication;'",
    | |________________________________________________________________________________________^
145 |                           )
146 |                           results[region]["replication_active"] = (
    |
help: Remove redundant '+' operator to implicitly concatenate

F541 [*] f-string without any placeholders
   --> multi-region/test-multi-region.py:152:29
    |
150 |                         recovery_test = await self.run_kubectl_command(
151 |                             config["context"],
152 |                             f"exec -n rap-analyzer postgresql-replica-0 -- "
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
153 |                             + "psql -U postgres -c 'SELECT pg_is_in_recovery();'",
154 |                         )
    |
help: Remove extraneous `f` prefix

ISC003 [*] Explicitly concatenated string should be implicitly concatenated
   --> multi-region/test-multi-region.py:152:29
    |
150 |                           recovery_test = await self.run_kubectl_command(
151 |                               config["context"],
152 | /                             f"exec -n rap-analyzer postgresql-replica-0 -- "
153 | |                             + "psql -U postgres -c 'SELECT pg_is_in_recovery();'",
    | |_________________________________________________________________________________^
154 |                           )
155 |                           results[region]["is_replica"] = "t" in recovery_test.lower()
    |
help: Remove redundant '+' operator to implicitly concatenate

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> multi-region/test-multi-region.py:166:43
    |
164 |         return results
165 |
166 |     async def test_api_endpoints(self) -> Dict[str, Dict]:
    |                                           ^^^^
167 |         """Test API endpoints in each region"""
168 |         logger.info("ðŸŒ Testing API endpoints...")
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> multi-region/test-multi-region.py:166:53
    |
164 |         return results
165 |
166 |     async def test_api_endpoints(self) -> Dict[str, Dict]:
    |                                                     ^^^^
167 |         """Test API endpoints in each region"""
168 |         logger.info("ðŸŒ Testing API endpoints...")
    |
help: Replace with `dict`

F841 Local variable `session` is assigned to but never used
   --> multi-region/test-multi-region.py:173:14
    |
171 |         async with aiohttp.ClientSession(
172 |             timeout=aiohttp.ClientTimeout(total=30)
173 |         ) as session:
    |              ^^^^^^^
174 |             for region, config in self.regions.items():
175 |                 results[region] = {}
    |
help: Remove assignment to unused variable `session`

F841 Local variable `health_url` is assigned to but never used
   --> multi-region/test-multi-region.py:182:21
    |
181 |                     # Test health endpoint
182 |                     health_url = f"{config['api_url']}/health"
    |                     ^^^^^^^^^^
183 |
184 |                     # For testing, we'll check if the service exists
    |
help: Remove assignment to unused variable `health_url`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> multi-region/test-multi-region.py:212:50
    |
210 |         return results
211 |
212 |     async def test_cross_region_latency(self) -> Dict[str, Dict]:
    |                                                  ^^^^
213 |         """Test network latency between regions"""
214 |         logger.info("âš¡ Testing cross-region latency...")
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> multi-region/test-multi-region.py:212:60
    |
210 |         return results
211 |
212 |     async def test_cross_region_latency(self) -> Dict[str, Dict]:
    |                                                            ^^^^
213 |         """Test network latency between regions"""
214 |         logger.info("âš¡ Testing cross-region latency...")
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> multi-region/test-multi-region.py:254:46
    |
252 |         return results
253 |
254 |     async def test_data_consistency(self) -> Dict[str, bool]:
    |                                              ^^^^
255 |         """Test data consistency across regions"""
256 |         logger.info("ðŸ” Testing data consistency...")
    |
help: Replace with `dict`

F541 [*] f-string without any placeholders
   --> multi-region/test-multi-region.py:265:17
    |
263 |             primary_result = await self.run_kubectl_command(
264 |                 self.regions["us-east-1"]["context"],
265 |                 f"exec -n rap-analyzer postgresql-primary-0 -- "
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
266 |                 + f'psql -U postgres -c "{test_query}"',
267 |             )
    |
help: Remove extraneous `f` prefix

ISC003 [*] Explicitly concatenated string should be implicitly concatenated
   --> multi-region/test-multi-region.py:265:17
    |
263 |               primary_result = await self.run_kubectl_command(
264 |                   self.regions["us-east-1"]["context"],
265 | /                 f"exec -n rap-analyzer postgresql-primary-0 -- "
266 | |                 + f'psql -U postgres -c "{test_query}"',
    | |_______________________________________________________^
267 |               )
    |
help: Remove redundant '+' operator to implicitly concatenate

F541 [*] f-string without any placeholders
   --> multi-region/test-multi-region.py:276:21
    |
274 |                 replica_result = await self.run_kubectl_command(
275 |                     self.regions[region]["context"],
276 |                     f"exec -n rap-analyzer postgresql-replica-0 -- "
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
277 |                     + f'psql -U postgres -c "{test_query}"',
278 |                 )
    |
help: Remove extraneous `f` prefix

ISC003 [*] Explicitly concatenated string should be implicitly concatenated
   --> multi-region/test-multi-region.py:276:21
    |
274 |                   replica_result = await self.run_kubectl_command(
275 |                       self.regions[region]["context"],
276 | /                     f"exec -n rap-analyzer postgresql-replica-0 -- "
277 | |                     + f'psql -U postgres -c "{test_query}"',
    | |___________________________________________________________^
278 |                   )
    |
help: Remove redundant '+' operator to implicitly concatenate

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> multi-region/test-multi-region.py:292:46
    |
290 |         return results
291 |
292 |     async def test_monitoring_stack(self) -> Dict[str, bool]:
    |                                              ^^^^
293 |         """Test monitoring components"""
294 |         logger.info("ðŸ“Š Testing monitoring stack...")
    |
help: Replace with `dict`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> multi-region/test-multi-region.py:310:17
    |
308 |                       results[region][component] = "Running" in pod_output
309 |
310 | /                 except Exception as e:
311 | |                     results[region][component] = False
312 | |                     logger.error(
313 | |                         f"Monitoring test failed for {component} in {region}: {e}"
314 | |                     )
    | |_____________________^
315 |
316 |           return results
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> multi-region/test-multi-region.py:318:45
    |
316 |         return results
317 |
318 |     async def generate_test_report(self) -> Dict:
    |                                             ^^^^
319 |         """Generate comprehensive test report"""
320 |         logger.info("ðŸ“‹ Generating test report...")
    |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> multi-region/test-multi-region.py:323:26
    |
322 |         report = {
323 |             "timestamp": datetime.now().isoformat(),
    |                          ^^^^^^^^^^^^^^
324 |             "test_summary": {},
325 |             "detailed_results": {},
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PERF203 `try`-`except` within a loop incurs performance overhead
   --> multi-region/test-multi-region.py:373:13
    |
371 |                       }
372 |
373 | /             except Exception as e:
374 | |                 logger.error(f"Test {test_name} failed: {e}")
375 | |                 report["detailed_results"][test_name] = {"error": str(e)}
376 | |                 report["test_summary"][test_name] = {
377 | |                     "passed": 0,
378 | |                     "total": 1,
379 | |                     "success_rate": "0.0%",
380 | |                 }
    | |_________________^
381 |
382 |           # Overall summary
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> multi-region/test-multi-region.py:391:36
    |
389 |         return report
390 |
391 |     def print_report(self, report: Dict):
    |                                    ^^^^
392 |         """Print formatted test report"""
393 |         print("\n" + "=" * 60)
    |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> multi-region/test-multi-region.py:443:21
    |
442 |         # Save report to file
443 |         timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    |                     ^^^^^^^^^^^^^^
444 |         report_file = f"multi-region-test-report-{timestamp}.json"
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> multi-region/test-multi-region.py:446:14
    |
444 |         report_file = f"multi-region-test-report-{timestamp}.json"
445 |
446 |         with open(report_file, "w") as f:
    |              ^^^^
447 |             json.dump(report, f, indent=2)
    |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
   --> multi-region/test-multi-region.py:465:9
    |
463 |             )
464 |
465 |         return exit_code
    |         ^^^^^^^^^^^^^^^^
466 |
467 |     except Exception as e:
    |

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/db_browser.py:23:1
   |
21 |   """
22 |
23 | / import asyncio
24 | | import sys
25 | | import os
26 | | import json
27 | | from typing import Optional, List, Dict
28 | | import argparse
   | |_______________^
29 |
30 |   sys.path.append(".")
   |
help: Organize imports

F401 [*] `os` imported but unused
  --> scripts/db_browser.py:25:8
   |
23 | import asyncio
24 | import sys
25 | import os
   |        ^^
26 | import json
27 | from typing import Optional, List, Dict
   |
help: Remove unused import: `os`

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/db_browser.py:27:1
   |
25 | import os
26 | import json
27 | from typing import Optional, List, Dict
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
28 | import argparse
   |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/db_browser.py:27:1
   |
25 | import os
26 | import json
27 | from typing import Optional, List, Dict
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
28 | import argparse
   |

F401 [*] `typing.List` imported but unused
  --> scripts/db_browser.py:27:30
   |
25 | import os
26 | import json
27 | from typing import Optional, List, Dict
   |                              ^^^^
28 | import argparse
   |
help: Remove unused import

F401 [*] `typing.Dict` imported but unused
  --> scripts/db_browser.py:27:36
   |
25 | import os
26 | import json
27 | from typing import Optional, List, Dict
   |                                    ^^^^
28 | import argparse
   |
help: Remove unused import

F541 [*] f-string without any placeholders
   --> scripts/db_browser.py:151:19
    |
149 |             print(f"ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ð¾ÑÑ‚ÑŒ: {track['popularity_score'] or 'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾'}")
150 |
151 |             print(f"\nðŸ“ Ð¢Ð•ÐšÐ¡Ð¢ ÐŸÐ•Ð¡ÐÐ˜:")
    |                   ^^^^^^^^^^^^^^^^^^^^
152 |             print("-" * 40)
153 |             print(track["lyrics"][:500] + ("..." if len(track["lyrics"]) > 500 else ""))
    |
help: Remove extraneous `f` prefix

UP045 [*] Use `X | None` for type annotations
   --> scripts/db_browser.py:185:41
    |
183 |                 print("-" * 20)
184 |
185 |     async def list_tracks(self, artist: Optional[str] = None, limit: int = 20):
    |                                         ^^^^^^^^^^^^^
186 |         """Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ‚Ñ€ÐµÐºÐ¾Ð²"""
187 |         async with self.db.get_connection() as conn:
    |
help: Convert to `X | None`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/development/analyze_confidence_results.py:16:10
   |
15 |     # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
16 |     with open("confidence_test_updated.json", "r", encoding="utf-8") as f:
   |          ^^^^
17 |         data = json.load(f)
   |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
  --> scripts/development/analyze_confidence_results.py:16:47
   |
15 |     # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
16 |     with open("confidence_test_updated.json", "r", encoding="utf-8") as f:
   |                                               ^^^
17 |         data = json.load(f)
   |
help: Remove mode argument

F541 [*] f-string without any placeholders
  --> scripts/development/analyze_confidence_results.py:44:15
   |
42 |         avg_confidence = sum(confidences.values()) / len(confidences)
43 |
44 |         print(f"ðŸ“Š CONFIDENCE SCORES:")
   |               ^^^^^^^^^^^^^^^^^^^^^^^^
45 |         for metric, score in confidences.items():
46 |             status = "ðŸŸ¢" if score >= 0.7 else "ðŸŸ¡" if score >= 0.5 else "ðŸ”´"
   |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
  --> scripts/development/analyze_confidence_results.py:82:15
   |
81 |         # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
82 |         print(f"\nðŸ“ˆ ÐšÐ›Ð®Ð§Ð•Ð’Ð«Ð• ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜:")
   |               ^^^^^^^^^^^^^^^^^^^^^^^^^
83 |         print(
84 |             f"   Metaphor Count: {features.get('metaphor_count', 0)} (confidence: {confidences['metaphor']:.3f})"
   |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:114:11
    |
112 |         print(f"   {practice}")
113 |
114 |     print(f"\nðŸ’¡ ÐŸÐ Ð˜ÐœÐ•ÐÐ•ÐÐ˜Ð• Ð’ ML PIPELINE:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
115 |     print(f"   â€¢ Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ confidence")
116 |     print(f"   â€¢ Weighted loss functions Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ confidence")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:115:11
    |
114 |     print(f"\nðŸ’¡ ÐŸÐ Ð˜ÐœÐ•ÐÐ•ÐÐ˜Ð• Ð’ ML PIPELINE:")
115 |     print(f"   â€¢ Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ confidence")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
116 |     print(f"   â€¢ Weighted loss functions Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ confidence")
117 |     print(f"   â€¢ Uncertainty-aware predictions")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:116:11
    |
114 |     print(f"\nðŸ’¡ ÐŸÐ Ð˜ÐœÐ•ÐÐ•ÐÐ˜Ð• Ð’ ML PIPELINE:")
115 |     print(f"   â€¢ Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ confidence")
116 |     print(f"   â€¢ Weighted loss functions Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ confidence")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
117 |     print(f"   â€¢ Uncertainty-aware predictions")
118 |     print(f"   â€¢ ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð»Ð°Ð±ÐµÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ high confidence")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:117:11
    |
115 |     print(f"   â€¢ Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¼Ñƒ confidence")
116 |     print(f"   â€¢ Weighted loss functions Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ confidence")
117 |     print(f"   â€¢ Uncertainty-aware predictions")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
118 |     print(f"   â€¢ ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð»Ð°Ð±ÐµÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ high confidence")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:118:11
    |
116 |     print(f"   â€¢ Weighted loss functions Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ confidence")
117 |     print(f"   â€¢ Uncertainty-aware predictions")
118 |     print(f"   â€¢ ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð»Ð°Ð±ÐµÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ high confidence")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:126:15
    |
124 |         show_best_practices()
125 |
126 |         print(f"\nðŸŽ‰ Ð—ÐÐ”ÐÐ§Ð Ð’Ð«ÐŸÐžÐ›ÐÐ•ÐÐ Ð£Ð¡ÐŸÐ•Ð¨ÐÐž!")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
127 |         print(f"âœ… Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹ confidence scores Ð´Ð»Ñ:")
128 |         print(f"   â€¢ Rhyme detection & scheme analysis")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:127:15
    |
126 |         print(f"\nðŸŽ‰ Ð—ÐÐ”ÐÐ§Ð Ð’Ð«ÐŸÐžÐ›ÐÐ•ÐÐ Ð£Ð¡ÐŸÐ•Ð¨ÐÐž!")
127 |         print(f"âœ… Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹ confidence scores Ð´Ð»Ñ:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
128 |         print(f"   â€¢ Rhyme detection & scheme analysis")
129 |         print(f"   â€¢ Metaphor & wordplay detection")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:128:15
    |
126 |         print(f"\nðŸŽ‰ Ð—ÐÐ”ÐÐ§Ð Ð’Ð«ÐŸÐžÐ›ÐÐ•ÐÐ Ð£Ð¡ÐŸÐ•Ð¨ÐÐž!")
127 |         print(f"âœ… Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹ confidence scores Ð´Ð»Ñ:")
128 |         print(f"   â€¢ Rhyme detection & scheme analysis")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
129 |         print(f"   â€¢ Metaphor & wordplay detection")
130 |         print(f"   â€¢ Flow & stress pattern analysis")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:129:15
    |
127 |         print(f"âœ… Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹ confidence scores Ð´Ð»Ñ:")
128 |         print(f"   â€¢ Rhyme detection & scheme analysis")
129 |         print(f"   â€¢ Metaphor & wordplay detection")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
130 |         print(f"   â€¢ Flow & stress pattern analysis")
131 |         print(f"   â€¢ Creativity assessment")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:130:15
    |
128 |         print(f"   â€¢ Rhyme detection & scheme analysis")
129 |         print(f"   â€¢ Metaphor & wordplay detection")
130 |         print(f"   â€¢ Flow & stress pattern analysis")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
131 |         print(f"   â€¢ Creativity assessment")
132 |         print(f"\nðŸ“¦ Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð²:")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:131:15
    |
129 |         print(f"   â€¢ Metaphor & wordplay detection")
130 |         print(f"   â€¢ Flow & stress pattern analysis")
131 |         print(f"   â€¢ Creativity assessment")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
132 |         print(f"\nðŸ“¦ Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð²:")
133 |         print(f"   â€¢ SimplifiedFeatureAnalyzer")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:132:15
    |
130 |         print(f"   â€¢ Flow & stress pattern analysis")
131 |         print(f"   â€¢ Creativity assessment")
132 |         print(f"\nðŸ“¦ Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð²:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^
133 |         print(f"   â€¢ SimplifiedFeatureAnalyzer")
134 |         print(f"   â€¢ CLI ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ (JSON/CSV)")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:133:15
    |
131 |         print(f"   â€¢ Creativity assessment")
132 |         print(f"\nðŸ“¦ Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð²:")
133 |         print(f"   â€¢ SimplifiedFeatureAnalyzer")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
134 |         print(f"   â€¢ CLI ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ (JSON/CSV)")
135 |         print(f"   â€¢ Pydantic Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:134:15
    |
132 |         print(f"\nðŸ“¦ Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð²:")
133 |         print(f"   â€¢ SimplifiedFeatureAnalyzer")
134 |         print(f"   â€¢ CLI ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ (JSON/CSV)")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
135 |         print(f"   â€¢ Pydantic Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/development/analyze_confidence_results.py:135:15
    |
133 |         print(f"   â€¢ SimplifiedFeatureAnalyzer")
134 |         print(f"   â€¢ CLI ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ (JSON/CSV)")
135 |         print(f"   â€¢ Pydantic Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
136 |
137 |     except FileNotFoundError:
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/development/demo_confidence_scores.py:8:1
   |
 6 |   """
 7 |
 8 | / import sys
 9 | | import os
   | |_________^
10 |
11 |   sys.path.append(os.path.join(os.path.dirname(__file__), "..", ".."))
   |
help: Organize imports

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
  --> scripts/development/demo_confidence_scores.py:11:17
   |
 9 | import os
10 |
11 | sys.path.append(os.path.join(os.path.dirname(__file__), "..", ".."))
   |                 ^^^^^^^^^^^^
12 |
13 | from src.analyzers.simplified_feature_analyzer import SimplifiedFeatureAnalyzer
   |

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> scripts/development/demo_confidence_scores.py:11:30
   |
 9 | import os
10 |
11 | sys.path.append(os.path.join(os.path.dirname(__file__), "..", ".."))
   |                              ^^^^^^^^^^^^^^^
12 |
13 | from src.analyzers.simplified_feature_analyzer import SimplifiedFeatureAnalyzer
   |
help: Replace with `Path(...).parent`

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/development/demo_confidence_scores.py:13:1
   |
11 |   sys.path.append(os.path.join(os.path.dirname(__file__), "..", ".."))
12 |
13 | / from src.analyzers.simplified_feature_analyzer import SimplifiedFeatureAnalyzer
14 | | import json
   | |___________^
   |
help: Organize imports

F541 [*] f-string without any placeholders
  --> scripts/development/demo_confidence_scores.py:61:15
   |
60 |         # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ñ confidence scores
61 |         print(f"ðŸŽ¯ RHYME ANALYSIS:")
   |               ^^^^^^^^^^^^^^^^^^^^^
62 |         print(f"   Rhyme Density: {features.rhyme_analysis.rhyme_density:.3f}")
63 |         print(
   |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
  --> scripts/development/demo_confidence_scores.py:71:15
   |
69 |         )
70 |
71 |         print(f"\nðŸŽ­ METAPHOR ANALYSIS:")
   |               ^^^^^^^^^^^^^^^^^^^^^^^^^^
72 |         print(f"   Metaphor Count: {features.metaphor_analysis.metaphor_count}")
73 |         print(
   |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
  --> scripts/development/demo_confidence_scores.py:85:15
   |
83 |         )
84 |
85 |         print(f"\nðŸŒŠ FLOW ANALYSIS:")
   |               ^^^^^^^^^^^^^^^^^^^^^^
86 |         print(f"   Syllable Count: {features.flow_analysis.syllable_count}")
87 |         print(
   |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/development/demo_simplified_ml_features.py:12:1
   |
10 |   """
11 |
12 | / import sys
13 | | import json
14 | | import time
15 | | from pathlib import Path
   | |________________________^
16 |
17 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð² Ð¿ÑƒÑ‚ÑŒ
   |
help: Organize imports

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/development/demo_simplified_ml_features.py:20:1
   |
18 |   sys.path.append(str(Path(__file__).parent.parent.parent))
19 |
20 | / from src.analyzers.simplified_feature_analyzer import (
21 | |     SimplifiedFeatureAnalyzer,
22 | |     extract_simplified_features,
23 | |     demo_simplified_analysis,
24 | | )
   | |_^
   |
help: Organize imports

F401 [*] `src.analyzers.simplified_feature_analyzer.demo_simplified_analysis` imported but unused
  --> scripts/development/demo_simplified_ml_features.py:23:5
   |
21 |     SimplifiedFeatureAnalyzer,
22 |     extract_simplified_features,
23 |     demo_simplified_analysis,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^
24 | )
   |
help: Remove unused import: `src.analyzers.simplified_feature_analyzer.demo_simplified_analysis`

F841 Local variable `analyzer` is assigned to but never used
  --> scripts/development/demo_simplified_ml_features.py:52:5
   |
50 |     }
51 |
52 |     analyzer = SimplifiedFeatureAnalyzer()
   |     ^^^^^^^^
53 |
54 |     for sample_name, lyrics in rhyme_samples.items():
   |
help: Remove assignment to unused variable `analyzer`

W293 Blank line contains whitespace
   --> scripts/development/demo_simplified_ml_features.py:264:1
    |
262 |     Ð’ Ð»Ð°Ð±Ð¸Ñ€Ð¸Ð½Ñ‚Ðµ Ð¸Ð· ÑÐ»Ð¾Ð² Ñ Ð½Ð°ÑˆÑ‘Ð» Ð´Ð¾Ñ€Ð¾Ð³Ñƒ Ðº ÑÐ²ÐµÑ‚Ñƒ
263 |     Ð¤Ð»Ð¾Ñƒ Ð»ÑŒÑ‘Ñ‚ÑÑ ÐºÐ°Ðº Ñ€ÐµÐºÐ°, Ð½ÐµÑÑ‘Ñ‚ Ð¼ÐµÐ½Ñ Ðº Ð¿Ð¾Ð±ÐµÐ´Ðµ
264 |     
    | ^^^^
265 |     Ð’Ñ€ÐµÐ¼Ñ â€” Ð´ÐµÐ½ÑŒÐ³Ð¸, Ð½Ð¾ Ð¼ÑƒÐ´Ñ€Ð¾ÑÑ‚ÑŒ Ð´Ð¾Ñ€Ð¾Ð¶Ðµ Ð·Ð¾Ð»Ð¾Ñ‚Ð°
266 |     Ð’ Ð¸Ð³Ñ€Ðµ Ñ‚ÐµÐ½ÐµÐ¹ Ñ ÑÐ¾Ð·Ð´Ð°ÑŽ Ð½Ð¾Ð²ÑƒÑŽ ÑÐ¿Ð¾Ñ…Ñƒ
    |
help: Remove whitespace from blank line

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/development/demo_simplified_ml_features.py:287:10
    |
285 |     # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² Ñ„Ð°Ð¹Ð»
286 |     output_file = "results/sample_simplified_ml_features.json"
287 |     with open(output_file, "w", encoding="utf-8") as f:
    |          ^^^^
288 |         json.dump(sample_data, f, ensure_ascii=False, indent=2)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/development/demo_simplified_ml_features.py:339:10
    |
338 |     # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ
339 |     with open("results/style_comparison.json", "w", encoding="utf-8") as f:
    |          ^^^^
340 |         json.dump(comparison_results, f, ensure_ascii=False, indent=2)
    |
help: Replace with `Path.open()`

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/development/run_remaining_artists.py:6:1
   |
 4 |   """
 5 |
 6 | / import sys
 7 | | import os
 8 | | from pathlib import Path
   | |________________________^
 9 |
10 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² Ð¿ÑƒÑ‚ÑŒ
   |
help: Organize imports

F401 [*] `os` imported but unused
 --> scripts/development/run_remaining_artists.py:7:8
  |
6 | import sys
7 | import os
  |        ^^
8 | from pathlib import Path
  |
help: Remove unused import: `os`

E402 Module level import not at top of file
  --> scripts/development/run_remaining_artists.py:14:1
   |
12 | sys.path.insert(0, str(project_root))
13 |
14 | from src.scrapers.rap_scraper_optimized import main
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
15 |
16 | if __name__ == "__main__":
   |

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/development/run_scraping_debug.py:6:1
   |
 4 |   """
 5 |
 6 | / import sys
 7 | | import os
 8 | | import logging
 9 | | import json
10 | | from pathlib import Path
   | |________________________^
11 |
12 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² Ð¿ÑƒÑ‚ÑŒ
   |
help: Organize imports

F401 [*] `os` imported but unused
 --> scripts/development/run_scraping_debug.py:7:8
  |
6 | import sys
7 | import os
  |        ^^
8 | import logging
9 | import json
  |
help: Remove unused import: `os`

E402 Module level import not at top of file
  --> scripts/development/run_scraping_debug.py:16:1
   |
14 | sys.path.insert(0, str(project_root))
15 |
16 | from src.scrapers.rap_scraper_optimized import OptimizedGeniusScraper, load_artist_list
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
17 | from src.utils.config import GENIUS_TOKEN, LOG_FORMAT, LOG_FILE, DATA_DIR
   |

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/development/run_scraping_debug.py:16:1
   |
14 |   sys.path.insert(0, str(project_root))
15 |
16 | / from src.scrapers.rap_scraper_optimized import OptimizedGeniusScraper, load_artist_list
17 | | from src.utils.config import GENIUS_TOKEN, LOG_FORMAT, LOG_FILE, DATA_DIR
   | |_________________________________________________________________________^
18 |
19 |   # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
   |
help: Organize imports

E402 Module level import not at top of file
  --> scripts/development/run_scraping_debug.py:17:1
   |
16 | from src.scrapers.rap_scraper_optimized import OptimizedGeniusScraper, load_artist_list
17 | from src.utils.config import GENIUS_TOKEN, LOG_FORMAT, LOG_FILE, DATA_DIR
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18 |
19 | # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
   |

F541 [*] f-string without any placeholders
  --> scripts/development/run_scraping_debug.py:38:17
   |
37 |     logger.info(f"ðŸ“‚ DATA_DIR: {DATA_DIR}")
38 |     logger.info(f"ðŸ“‚ ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ„Ð°Ð¹Ð»Ñ‹:")
   |                 ^^^^^^^^^^^^^^^^^^^^^^
39 |
40 |     files_to_check = [
   |
help: Remove extraneous `f` prefix

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/development/run_scraping_debug.py:52:22
   |
50 |         if exists:
51 |             try:
52 |                 with open(file_path, "r", encoding="utf-8") as f:
   |                      ^^^^
53 |                     artists = json.load(f)
54 |                     logger.info(f"    Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ {len(artists)} Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²")
   |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
  --> scripts/development/run_scraping_debug.py:52:38
   |
50 |         if exists:
51 |             try:
52 |                 with open(file_path, "r", encoding="utf-8") as f:
   |                                      ^^^
53 |                     artists = json.load(f)
54 |                     logger.info(f"    Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ {len(artists)} Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²")
   |
help: Remove mode argument

TRY300 Consider moving this statement to an `else` block
  --> scripts/development/run_scraping_debug.py:68:9
   |
66 |         logger.info(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(artists)} Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²")
67 |         logger.info(f"ÐŸÐµÑ€Ð²Ñ‹Ðµ 5 Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²: {artists[:5]}")
68 |         return artists
   |         ^^^^^^^^^^^^^^
69 |     except Exception as e:
70 |         logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸: {e}")
   |

N806 Variable `MEMORY_LIMIT_MB` in function should be lowercase
   --> scripts/development/run_scraping_debug.py:100:5
    |
 99 |     # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐºÑ€Ð°Ð¿ÐµÑ€
100 |     MEMORY_LIMIT_MB = 3072
    |     ^^^^^^^^^^^^^^^
101 |     scraper = OptimizedGeniusScraper(GENIUS_TOKEN, None, MEMORY_LIMIT_MB)
    |

N806 Variable `SONGS_PER_ARTIST` in function should be lowercase
   --> scripts/development/run_scraping_debug.py:104:9
    |
103 |     try:
104 |         SONGS_PER_ARTIST = 500
    |         ^^^^^^^^^^^^^^^^
105 |
106 |         logger.info(f"ðŸŽ¯ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(artists)} Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²")
    |

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/development/run_scraping_improved.py:7:1
   |
 5 |   """
 6 |
 7 | / import sys
 8 | | import os
 9 | | import logging
10 | | import json
11 | | import time
12 | | from pathlib import Path
   | |________________________^
13 |
14 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² Ð¿ÑƒÑ‚ÑŒ
   |
help: Organize imports

F401 [*] `os` imported but unused
  --> scripts/development/run_scraping_improved.py:8:8
   |
 7 | import sys
 8 | import os
   |        ^^
 9 | import logging
10 | import json
   |
help: Remove unused import: `os`

F401 [*] `time` imported but unused
  --> scripts/development/run_scraping_improved.py:11:8
   |
 9 | import logging
10 | import json
11 | import time
   |        ^^^^
12 | from pathlib import Path
   |
help: Remove unused import: `time`

E402 Module level import not at top of file
  --> scripts/development/run_scraping_improved.py:18:1
   |
16 | sys.path.insert(0, str(project_root))
17 |
18 | from src.scrapers.rap_scraper_optimized import OptimizedGeniusScraper, load_artist_list
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
19 | from src.utils.config import GENIUS_TOKEN, LOG_FORMAT, LOG_FILE, DATA_DIR
   |

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/development/run_scraping_improved.py:18:1
   |
16 |   sys.path.insert(0, str(project_root))
17 |
18 | / from src.scrapers.rap_scraper_optimized import OptimizedGeniusScraper, load_artist_list
19 | | from src.utils.config import GENIUS_TOKEN, LOG_FORMAT, LOG_FILE, DATA_DIR
   | |_________________________________________________________________________^
   |
help: Organize imports

E402 Module level import not at top of file
  --> scripts/development/run_scraping_improved.py:19:1
   |
18 | from src.scrapers.rap_scraper_optimized import OptimizedGeniusScraper, load_artist_list
19 | from src.utils.config import GENIUS_TOKEN, LOG_FORMAT, LOG_FILE, DATA_DIR
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/development/run_scraping_improved.py:70:14
   |
68 |     if remaining:
69 |         remaining_file = DATA_DIR / "remaining_artists.json"
70 |         with open(remaining_file, "w", encoding="utf-8") as f:
   |              ^^^^
71 |             json.dump(remaining, f, indent=2, ensure_ascii=False)
72 |         logging.info(
   |
help: Replace with `Path.open()`

PLR0915 Too many statements (53 > 50)
  --> scripts/development/run_scraping_improved.py:77:5
   |
77 | def main():
   |     ^^^^
78 |     """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹ Ð¾ÑˆÐ¸Ð±Ð¾Ðº"""
79 |     logger = setup_logging()
   |

N806 Variable `MEMORY_LIMIT_MB` in function should be lowercase
  --> scripts/development/run_scraping_improved.py:89:5
   |
88 |     # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
89 |     MEMORY_LIMIT_MB = 4096  # Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð¿Ð°Ð¼ÑÑ‚Ð¸
   |     ^^^^^^^^^^^^^^^
90 |     SONGS_PER_ARTIST = 100  # Ð£Ð¼ÐµÐ½ÑŒÑˆÐ°ÐµÐ¼ Ð´Ð»Ñ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸
   |

N806 Variable `SONGS_PER_ARTIST` in function should be lowercase
  --> scripts/development/run_scraping_improved.py:90:5
   |
88 |     # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
89 |     MEMORY_LIMIT_MB = 4096  # Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð¿Ð°Ð¼ÑÑ‚Ð¸
90 |     SONGS_PER_ARTIST = 100  # Ð£Ð¼ÐµÐ½ÑŒÑˆÐ°ÐµÐ¼ Ð´Ð»Ñ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸
   |     ^^^^^^^^^^^^^^^^
91 |
92 |     # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÑÐ¿Ð¸ÑÐºÐ° Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²
   |

G003 Logging statement uses `+`
   --> scripts/development/run_scraping_improved.py:128:21
    |
126 |     processed_count = 0
127 |     try:
128 |         logger.info("\n" + "=" * 60)
    |                     ^^^^^^^^^^^^^^^
129 |         logger.info("ðŸŽµ ÐÐÐ§Ð˜ÐÐÐ•Ðœ Ð¡ÐšÐ ÐÐŸÐ˜ÐÐ“")
130 |         logger.info("=" * 60)
    |

E722 Do not use bare `except`
   --> scripts/development/run_scraping_improved.py:158:9
    |
156 |             scraper.close()
157 |             logger.info("ðŸ”’ Ð¡ÐºÑ€Ð°Ð¿ÐµÑ€ Ð·Ð°ÐºÑ€Ñ‹Ñ‚")
158 |         except:
    |         ^^^^^^
159 |             pass
    |

I001 [*] Import block is un-sorted or un-formatted
 --> scripts/legacy/rap_scraper_optimized.py:4:1
  |
2 |   """Backward compatibility wrapper for rap_scraper_optimized.py"""
3 |
4 | / import sys
5 | | import os
  | |_________^
6 |
7 |   sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
  |
help: Organize imports

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
 --> scripts/legacy/rap_scraper_optimized.py:7:17
  |
5 | import os
6 |
7 | sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
  |                 ^^^^^^^^^^^^^^^
8 |
9 | from src.scrapers.rap_scraper_optimized import main
  |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
 --> scripts/legacy/rap_scraper_optimized.py:7:33
  |
5 | import os
6 |
7 | sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
  |                                 ^^^^^^^^^^^^^^^
8 |
9 | from src.scrapers.rap_scraper_optimized import main
  |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
 --> scripts/legacy/rap_scraper_optimized.py:7:49
  |
5 | import os
6 |
7 | sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
  |                                                 ^^^^^^^^^^^^^^^
8 |
9 | from src.scrapers.rap_scraper_optimized import main
  |
help: Replace with `Path(...).parent`

I001 [*] Import block is un-sorted or un-formatted
 --> scripts/legacy/run_analysis.py:4:1
  |
2 |   """Main analysis entry point."""
3 |
4 | / import sys
5 | | import os
  | |_________^
6 |
7 |   sys.path.append(os.path.dirname(os.path.dirname(__file__)))
  |
help: Organize imports

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
 --> scripts/legacy/run_analysis.py:7:17
  |
5 | import os
6 |
7 | sys.path.append(os.path.dirname(os.path.dirname(__file__)))
  |                 ^^^^^^^^^^^^^^^
8 |
9 | from src.analyzers.multi_model_analyzer import main
  |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
 --> scripts/legacy/run_analysis.py:7:33
  |
5 | import os
6 |
7 | sys.path.append(os.path.dirname(os.path.dirname(__file__)))
  |                                 ^^^^^^^^^^^^^^^
8 |
9 | from src.analyzers.multi_model_analyzer import main
  |
help: Replace with `Path(...).parent`

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/legacy/run_scraping.py:11:1
   |
 9 |   """
10 |
11 | / import sys
12 | | import os
   | |_________^
13 |
14 |   sys.path.append(os.path.dirname(os.path.dirname(__file__)))
   |
help: Organize imports

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> scripts/legacy/run_scraping.py:14:17
   |
12 | import os
13 |
14 | sys.path.append(os.path.dirname(os.path.dirname(__file__)))
   |                 ^^^^^^^^^^^^^^^
15 |
16 | from src.scrapers.rap_scraper_optimized import main
   |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> scripts/legacy/run_scraping.py:14:33
   |
12 | import os
13 |
14 | sys.path.append(os.path.dirname(os.path.dirname(__file__)))
   |                                 ^^^^^^^^^^^^^^^
15 |
16 | from src.scrapers.rap_scraper_optimized import main
   |
help: Replace with `Path(...).parent`

I001 [*] Import block is un-sorted or un-formatted
 --> scripts/ml/analyze_dataset.py:1:1
  |
1 | / import pandas as pd
2 | | import pickle
  | |_____________^
3 |
4 |   # Load dataset
  |
help: Organize imports

F401 [*] `pandas` imported but unused
 --> scripts/ml/analyze_dataset.py:1:18
  |
1 | import pandas as pd
  |                  ^^
2 | import pickle
  |
help: Remove unused import: `pandas`

PTH123 `open()` should be replaced by `Path.open()`
 --> scripts/ml/analyze_dataset.py:5:6
  |
4 | # Load dataset
5 | with open("data/ml/quick_dataset.pkl", "rb") as f:
  |      ^^^^
6 |     data = pickle.load(f)
  |
help: Replace with `Path.open()`

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/ml/data_preparation.py:9:1
   |
 7 |   """
 8 |
 9 | / import pandas as pd
10 | | import numpy as np
11 | | import asyncio
12 | | import json
13 | | import pickle
14 | | import sys
15 | | import os
16 | | from pathlib import Path
17 | | from datetime import datetime
18 | | from typing import Dict, List, Optional, Tuple
19 | | import logging
   | |______________^
20 |
21 |   # Add project root to path
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/ml/data_preparation.py:18:1
   |
16 | from pathlib import Path
17 | from datetime import datetime
18 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
19 | import logging
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/ml/data_preparation.py:18:1
   |
16 | from pathlib import Path
17 | from datetime import datetime
18 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
19 | import logging
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/ml/data_preparation.py:18:1
   |
16 | from pathlib import Path
17 | from datetime import datetime
18 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
19 | import logging
   |

F401 [*] `typing.List` imported but unused
  --> scripts/ml/data_preparation.py:18:26
   |
16 | from pathlib import Path
17 | from datetime import datetime
18 | from typing import Dict, List, Optional, Tuple
   |                          ^^^^
19 | import logging
   |
help: Remove unused import

F401 [*] `typing.Optional` imported but unused
  --> scripts/ml/data_preparation.py:18:32
   |
16 | from pathlib import Path
17 | from datetime import datetime
18 | from typing import Dict, List, Optional, Tuple
   |                                ^^^^^^^^
19 | import logging
   |
help: Remove unused import

F401 [*] `typing.Tuple` imported but unused
  --> scripts/ml/data_preparation.py:18:42
   |
16 | from pathlib import Path
17 | from datetime import datetime
18 | from typing import Dict, List, Optional, Tuple
   |                                          ^^^^^
19 | import logging
   |
help: Remove unused import

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/ml/data_preparation.py:24:1
   |
22 |   sys.path.append(str(Path(__file__).parent.parent.parent))
23 |
24 | / from src.database.postgres_adapter import PostgreSQLManager
25 | | from sentence_transformers import SentenceTransformer
26 | | from sklearn.preprocessing import LabelEncoder, StandardScaler
27 | | from sklearn.decomposition import PCA
28 | | import warnings
   | |_______________^
29 |
30 |   warnings.filterwarnings("ignore")
   |
help: Organize imports

W293 Blank line contains whitespace
  --> scripts/ml/data_preparation.py:87:1
   |
85 |             t.popularity_score, t.lyrics_quality_score,
86 |             COALESCE(CHAR_LENGTH(t.lyrics), 0) as lyrics_length,
87 |             
   | ^^^^^^^^^^^^
88 |             -- AI Analysis aggregated results (latest per analyzer)
89 |             MAX(CASE WHEN ar.analyzer_type = 'qwen-3-4b-fp8' THEN ar.sentiment END) as qwen_sentiment,
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> scripts/ml/data_preparation.py:94:1
   |
92 |             MAX(CASE WHEN ar.analyzer_type = 'qwen-3-4b-fp8' THEN ar.complexity_score END) as qwen_complexity,
93 |             MAX(CASE WHEN ar.analyzer_type = 'qwen-3-4b-fp8' THEN ar.analysis_data END) as qwen_analysis,
94 |             
   | ^^^^^^^^^^^^
95 |             MAX(CASE WHEN ar.analyzer_type = 'gemma-3-27b-it' THEN ar.sentiment END) as gemma_sentiment,
96 |             MAX(CASE WHEN ar.analyzer_type = 'gemma-3-27b-it' THEN ar.confidence END) as gemma_confidence,
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> scripts/ml/data_preparation.py:98:1
   |
96 |             MAX(CASE WHEN ar.analyzer_type = 'gemma-3-27b-it' THEN ar.confidence END) as gemma_confidence,
97 |             MAX(CASE WHEN ar.analyzer_type = 'gemma-3-27b-it' THEN ar.complexity_score END) as gemma_complexity,
98 |             
   | ^^^^^^^^^^^^
99 |             MAX(CASE WHEN ar.analyzer_type = 'simplified_features_v2' THEN ar.analysis_data END) as algo_features,
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/ml/data_preparation.py:100:1
    |
 99 |             MAX(CASE WHEN ar.analyzer_type = 'simplified_features_v2' THEN ar.analysis_data END) as algo_features,
100 |             
    | ^^^^^^^^^^^^
101 |             -- Spotify data (JSON parsing)
102 |             t.spotify_data,
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/ml/data_preparation.py:103:1
    |
101 |             -- Spotify data (JSON parsing)
102 |             t.spotify_data,
103 |             
    | ^^^^^^^^^^^^
104 |             -- Analysis counts and coverage
105 |             COUNT(ar.id) as total_analyses,
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/ml/data_preparation.py:107:1
    |
105 |             COUNT(ar.id) as total_analyses,
106 |             COUNT(DISTINCT ar.analyzer_type) as analyzer_count
107 |             
    | ^^^^^^^^^^^^
108 |         FROM tracks t
109 |         LEFT JOIN analysis_results ar ON t.id = ar.track_id
    |
help: Remove whitespace from blank line

TRY301 Abstract `raise` to an inner function
   --> scripts/ml/data_preparation.py:129:17
    |
128 |             if len(df) == 0:
129 |                 raise ValueError("No data extracted from database")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
130 |
131 |             return df
    |

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/data_preparation.py:131:13
    |
129 |                 raise ValueError("No data extracted from database")
130 |
131 |             return df
    |             ^^^^^^^^^
132 |
133 |         except Exception as e:
    |

F841 [*] Local variable `e` is assigned to but never used
   --> scripts/ml/data_preparation.py:192:71
    |
190 |                         )
191 |
192 |                 except (json.JSONDecodeError, TypeError, KeyError) as e:
    |                                                                       ^
193 |                     continue
    |
help: Remove assignment to unused variable `e`

PLR0912 Too many branches (13 > 12)
   --> scripts/ml/data_preparation.py:228:9
    |
226 |         return df
227 |
228 |     def parse_ai_analysis_features(self, df: pd.DataFrame) -> pd.DataFrame:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^
229 |         """Parse and engineer features from AI analysis results"""
230 |         logger.info("ðŸ¤– Parsing AI analysis features...")
    |

PLW2901 `for` loop variable `line` overwritten by assignment target
   --> scripts/ml/data_preparation.py:343:17
    |
341 |             line_counts = {}
342 |             for line in lines:
343 |                 line = line.strip().lower()
    |                 ^^^^
344 |                 if len(line) > 10:  # Ignore short lines
345 |                     line_counts[line] = line_counts.get(line, 0) + 1
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/data_preparation.py:409:14
    |
408 |         # Save PCA model for later use
409 |         with open("data/ml/text_embedding_pca.pkl", "wb") as f:
    |              ^^^^
410 |             pickle.dump(pca, f)
    |
help: Replace with `Path.open()`

PLR0915 Too many statements (60 > 50)
   --> scripts/ml/data_preparation.py:417:9
    |
415 |         return df
416 |
417 |     def create_style_labels(self, df: pd.DataFrame) -> pd.DataFrame:
    |         ^^^^^^^^^^^^^^^^^^^
418 |         """Create style and target labels for ML models"""
419 |         logger.info("ðŸ·ï¸ Creating style and target labels...")
    |

PLR0911 Too many return statements (7 > 6)
   --> scripts/ml/data_preparation.py:475:13
    |
474 |         # Theme categories (simplified)
475 |         def categorize_themes(themes_str):
    |             ^^^^^^^^^^^^^^^^^
476 |             if pd.isna(themes_str):
477 |                 return "general"
    |

RET505 [*] Unnecessary `elif` after `return` statement
   --> scripts/ml/data_preparation.py:485:13
    |
483 |             ):
484 |                 return "love"
485 |             elif any(
    |             ^^^^
486 |                 word in themes_lower for word in ["money", "success", "wealth", "fame"]
487 |             ):
    |
help: Remove unnecessary `elif`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/ml/data_preparation.py:557:58
    |
555 |         return df
556 |
557 |     def prepare_final_dataset(self, df: pd.DataFrame) -> Dict:
    |                                                          ^^^^
558 |         """Prepare final ML-ready dataset with feature selection"""
559 |         logger.info("ðŸŽ¯ Preparing final ML dataset...")
    |
help: Replace with `dict`

N806 Variable `X` in function should be lowercase
   --> scripts/ml/data_preparation.py:642:9
    |
641 |         # Create final feature matrix
642 |         X = df[feature_columns].fillna(0)  # Fill any remaining NaNs
    |         ^
643 |         y = df[target_columns]
    |

N806 Variable `X_scaled` in function should be lowercase
   --> scripts/ml/data_preparation.py:646:9
    |
645 |         # Scale features
646 |         X_scaled = pd.DataFrame(
    |         ^^^^^^^^
647 |             self.scaler.fit_transform(X), columns=X.columns, index=X.index
648 |         )
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/data_preparation.py:652:30
    |
650 |         # Prepare metadata
651 |         metadata = {
652 |             "creation_date": datetime.now().isoformat(),
    |                              ^^^^^^^^^^^^^^
653 |             "total_tracks": len(df),
654 |             "feature_count": len(feature_columns),
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

F541 [*] f-string without any placeholders
   --> scripts/ml/data_preparation.py:669:21
    |
667 |         }
668 |
669 |         logger.info(f"âœ… Final dataset prepared:")
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
670 |         logger.info(f"   Tracks: {len(df)}")
671 |         logger.info(f"   Features: {len(feature_columns)}")
    |
help: Remove extraneous `f` prefix

PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   --> scripts/ml/data_preparation.py:709:13
    |
707 |             # Save dataset
708 |             logger.info(f"ðŸ’¾ Saving ML dataset to {output_path}...")
709 |             os.makedirs(os.path.dirname(output_path), exist_ok=True)
    |             ^^^^^^^^^^^
710 |
711 |             with open(output_path, "wb") as f:
    |
help: Replace with `Path(...).mkdir(parents=True)`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
   --> scripts/ml/data_preparation.py:709:25
    |
707 |             # Save dataset
708 |             logger.info(f"ðŸ’¾ Saving ML dataset to {output_path}...")
709 |             os.makedirs(os.path.dirname(output_path), exist_ok=True)
    |                         ^^^^^^^^^^^^^^^
710 |
711 |             with open(output_path, "wb") as f:
    |
help: Replace with `Path(...).parent`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/data_preparation.py:711:18
    |
709 |             os.makedirs(os.path.dirname(output_path), exist_ok=True)
710 |
711 |             with open(output_path, "wb") as f:
    |                  ^^^^
712 |                 pickle.dump(ml_dataset, f)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/data_preparation.py:716:18
    |
714 |             # Save metadata separately
715 |             metadata_path = output_path.replace(".pkl", "_metadata.json")
716 |             with open(metadata_path, "w") as f:
    |                  ^^^^
717 |                 json.dump(ml_dataset["metadata"], f, indent=2)
    |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/data_preparation.py:728:13
    |
726 |             logger.info(f"   CSV Export: {csv_path}")
727 |
728 |             return ml_dataset
    |             ^^^^^^^^^^^^^^^^^
729 |
730 |         except Exception as e:
    |

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/ml/mlops_training_pipeline.py:16:1
   |
14 |   """
15 |
16 | / import os
17 | | import sys
18 | | import json
19 | | import pickle
20 | | import logging
21 | | import asyncio
22 | | from pathlib import Path
23 | | from datetime import datetime, timedelta
24 | | from typing import Dict, List, Optional, Tuple, Any
25 | | import pandas as pd
26 | | import numpy as np
27 | | from dataclasses import dataclass, asdict
28 | | import schedule
29 | | import time
30 | | import traceback
31 | |
32 | | # ML libraries
33 | | from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
34 | | from sklearn.model_selection import cross_val_score
   | |___________________________________________________^
35 |
36 |   # Add project root to path
   |
help: Organize imports

F401 [*] `asyncio` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:21:8
   |
19 | import pickle
20 | import logging
21 | import asyncio
   |        ^^^^^^^
22 | from pathlib import Path
23 | from datetime import datetime, timedelta
   |
help: Remove unused import: `asyncio`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/ml/mlops_training_pipeline.py:24:1
   |
22 | from pathlib import Path
23 | from datetime import datetime, timedelta
24 | from typing import Dict, List, Optional, Tuple, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
25 | import pandas as pd
26 | import numpy as np
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/ml/mlops_training_pipeline.py:24:1
   |
22 | from pathlib import Path
23 | from datetime import datetime, timedelta
24 | from typing import Dict, List, Optional, Tuple, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
25 | import pandas as pd
26 | import numpy as np
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/ml/mlops_training_pipeline.py:24:1
   |
22 | from pathlib import Path
23 | from datetime import datetime, timedelta
24 | from typing import Dict, List, Optional, Tuple, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
25 | import pandas as pd
26 | import numpy as np
   |

F401 [*] `typing.List` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:24:26
   |
22 | from pathlib import Path
23 | from datetime import datetime, timedelta
24 | from typing import Dict, List, Optional, Tuple, Any
   |                          ^^^^
25 | import pandas as pd
26 | import numpy as np
   |
help: Remove unused import

F401 [*] `typing.Optional` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:24:32
   |
22 | from pathlib import Path
23 | from datetime import datetime, timedelta
24 | from typing import Dict, List, Optional, Tuple, Any
   |                                ^^^^^^^^
25 | import pandas as pd
26 | import numpy as np
   |
help: Remove unused import

F401 [*] `typing.Tuple` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:24:42
   |
22 | from pathlib import Path
23 | from datetime import datetime, timedelta
24 | from typing import Dict, List, Optional, Tuple, Any
   |                                          ^^^^^
25 | import pandas as pd
26 | import numpy as np
   |
help: Remove unused import

F401 [*] `typing.Any` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:24:49
   |
22 | from pathlib import Path
23 | from datetime import datetime, timedelta
24 | from typing import Dict, List, Optional, Tuple, Any
   |                                                 ^^^
25 | import pandas as pd
26 | import numpy as np
   |
help: Remove unused import

F401 [*] `numpy` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:26:17
   |
24 | from typing import Dict, List, Optional, Tuple, Any
25 | import pandas as pd
26 | import numpy as np
   |                 ^^
27 | from dataclasses import dataclass, asdict
28 | import schedule
   |
help: Remove unused import: `numpy`

F401 [*] `sklearn.metrics.accuracy_score` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:33:29
   |
32 | # ML libraries
33 | from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
   |                             ^^^^^^^^^^^^^^
34 | from sklearn.model_selection import cross_val_score
   |
help: Remove unused import

F401 [*] `sklearn.metrics.precision_score` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:33:45
   |
32 | # ML libraries
33 | from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
   |                                             ^^^^^^^^^^^^^^^
34 | from sklearn.model_selection import cross_val_score
   |
help: Remove unused import

F401 [*] `sklearn.metrics.recall_score` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:33:62
   |
32 | # ML libraries
33 | from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
   |                                                              ^^^^^^^^^^^^
34 | from sklearn.model_selection import cross_val_score
   |
help: Remove unused import

F401 [*] `sklearn.metrics.f1_score` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:33:76
   |
32 | # ML libraries
33 | from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
   |                                                                            ^^^^^^^^
34 | from sklearn.model_selection import cross_val_score
   |
help: Remove unused import

F401 [*] `sklearn.model_selection.cross_val_score` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:34:37
   |
32 | # ML libraries
33 | from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
34 | from sklearn.model_selection import cross_val_score
   |                                     ^^^^^^^^^^^^^^^
35 |
36 | # Add project root to path
   |
help: Remove unused import: `sklearn.model_selection.cross_val_score`

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/ml/mlops_training_pipeline.py:40:1
   |
39 |   # Import ML models
40 | / from models.conditional_generation import ConditionalRapGenerator
41 | | from models.style_transfer import RapStyleTransfer
42 | | from models.quality_prediction import RapQualityPredictor
43 | | from models.trend_analysis import RapTrendAnalyzer
44 | | from scripts.ml.quick_data_prep import QuickDatasetPreparator
   | |_____________________________________________________________^
45 |
46 |   # Setup logging
   |
help: Organize imports

F401 [*] `models.style_transfer.RapStyleTransfer` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:41:35
   |
39 | # Import ML models
40 | from models.conditional_generation import ConditionalRapGenerator
41 | from models.style_transfer import RapStyleTransfer
   |                                   ^^^^^^^^^^^^^^^^
42 | from models.quality_prediction import RapQualityPredictor
43 | from models.trend_analysis import RapTrendAnalyzer
   |
help: Remove unused import: `models.style_transfer.RapStyleTransfer`

F401 [*] `scripts.ml.quick_data_prep.QuickDatasetPreparator` imported but unused
  --> scripts/ml/mlops_training_pipeline.py:44:40
   |
42 | from models.quality_prediction import RapQualityPredictor
43 | from models.trend_analysis import RapTrendAnalyzer
44 | from scripts.ml.quick_data_prep import QuickDatasetPreparator
   |                                        ^^^^^^^^^^^^^^^^^^^^^^
45 |
46 | # Setup logging
   |
help: Remove unused import: `scripts.ml.quick_data_prep.QuickDatasetPreparator`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> scripts/ml/mlops_training_pipeline.py:72:25
   |
70 |     timestamp: str
71 |     dataset_size: int
72 |     additional_metrics: Dict[str, float]
   |                         ^^^^
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/ml/mlops_training_pipeline.py:122:31
    |
120 |         self.trend_analyzer = None
121 |
122 |     def _load_config(self) -> Dict:
    |                               ^^^^
123 |         """Load MLOps configuration"""
124 |         default_config = {
    |
help: Replace with `dict`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> scripts/ml/mlops_training_pipeline.py:179:16
    |
178 |         try:
179 |             if os.path.exists(self.config_path):
    |                ^^^^^^^^^^^^^^
180 |                 with open(self.config_path, "r") as f:
181 |                     loaded_config = json.load(f)
    |
help: Replace with `Path(...).exists()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:180:22
    |
178 |         try:
179 |             if os.path.exists(self.config_path):
180 |                 with open(self.config_path, "r") as f:
    |                      ^^^^
181 |                     loaded_config = json.load(f)
182 |                 # Merge with defaults
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/ml/mlops_training_pipeline.py:180:45
    |
178 |         try:
179 |             if os.path.exists(self.config_path):
180 |                 with open(self.config_path, "r") as f:
    |                                             ^^^
181 |                     loaded_config = json.load(f)
182 |                 # Merge with defaults
    |
help: Remove mode argument

PLC0206 Extracting value from dictionary without calling `.items()`
   --> scripts/ml/mlops_training_pipeline.py:183:17
    |
181 |                       loaded_config = json.load(f)
182 |                   # Merge with defaults
183 | /                 for key in default_config:
184 | |                     if key not in loaded_config:
185 | |                         loaded_config[key] = default_config[key]
    | |________________________________________________________________^
186 |                   return loaded_config
187 |               else:
    |

RET505 [*] Unnecessary `else` after `return` statement
   --> scripts/ml/mlops_training_pipeline.py:187:13
    |
185 |                         loaded_config[key] = default_config[key]
186 |                 return loaded_config
187 |             else:
    |             ^^^^
188 |                 # Save default config
189 |                 os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
    |
help: Remove unnecessary `else`

PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   --> scripts/ml/mlops_training_pipeline.py:189:17
    |
187 |             else:
188 |                 # Save default config
189 |                 os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
    |                 ^^^^^^^^^^^
190 |                 with open(self.config_path, "w") as f:
191 |                     json.dump(default_config, f, indent=2)
    |
help: Replace with `Path(...).mkdir(parents=True)`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
   --> scripts/ml/mlops_training_pipeline.py:189:29
    |
187 |             else:
188 |                 # Save default config
189 |                 os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
    |                             ^^^^^^^^^^^^^^^
190 |                 with open(self.config_path, "w") as f:
191 |                     json.dump(default_config, f, indent=2)
    |
help: Replace with `Path(...).parent`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:190:22
    |
188 |                 # Save default config
189 |                 os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
190 |                 with open(self.config_path, "w") as f:
    |                      ^^^^
191 |                     json.dump(default_config, f, indent=2)
192 |                 return default_config
    |
help: Replace with `Path.open()`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:230:26
    |
229 |         try:
230 |             start_time = datetime.now()
    |                          ^^^^^^^^^^^^^^
231 |             config = self.config["models"][model_name]
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:263:30
    |
262 |             # Calculate training time
263 |             training_time = (datetime.now() - start_time).total_seconds() / 60
    |                              ^^^^^^^^^^^^^^
264 |
265 |             if success:
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

RET505 [*] Unnecessary `else` after `return` statement
   --> scripts/ml/mlops_training_pipeline.py:277:17
    |
276 |                     return True
277 |                 else:
    |                 ^^^^
278 |                     logger.error(
279 |                         f"âŒ {model_name}: Model validation failed, rolling back"
    |
help: Remove unnecessary `else`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> scripts/ml/mlops_training_pipeline.py:298:16
    |
296 |             # In real scenario, query PostgreSQL for recent tracks
297 |             dataset_path = "data/ml/quick_dataset.pkl"
298 |             if os.path.exists(dataset_path):
    |                ^^^^^^^^^^^^^^
299 |                 with open(dataset_path, "rb") as f:
300 |                     data = pickle.load(f)
    |
help: Replace with `Path(...).exists()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:299:22
    |
297 |             dataset_path = "data/ml/quick_dataset.pkl"
298 |             if os.path.exists(dataset_path):
299 |                 with open(dataset_path, "rb") as f:
    |                      ^^^^
300 |                     data = pickle.load(f)
301 |                 available_count = len(data.get("raw_data", []))
    |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/mlops_training_pipeline.py:304:13
    |
302 |                 logger.info(f"ðŸ“Š {model_name}: Available data: {available_count}")
303 |                 return available_count >= min_threshold
304 |             return False
    |             ^^^^^^^^^^^^
305 |         except Exception as e:
306 |             logger.error(f"âŒ Data availability check failed: {e}")
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:312:25
    |
310 |         """Backup current model before retraining"""
311 |         try:
312 |             timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    |                         ^^^^^^^^^^^^^^
313 |             backup_dir = self.models_dir / "backups" / model_name
314 |             backup_dir.mkdir(parents=True, exist_ok=True)
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:337:18
    |
335 |         try:
336 |             dataset_path = "data/ml/quick_dataset.pkl"
337 |             with open(dataset_path, "rb") as f:
    |                  ^^^^
338 |                 data = pickle.load(f)
339 |             return data["raw_data"]
    |
help: Replace with `Path.open()`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/ml/mlops_training_pipeline.py:344:72
    |
342 |             return pd.DataFrame()
343 |
344 |     def _retrain_generation_model(self, dataset: pd.DataFrame, config: Dict) -> bool:
    |                                                                        ^^^^
345 |         """Retrain conditional generation model"""
346 |         try:
    |
help: Replace with `dict`

F841 Local variable `generator` is assigned to but never used
   --> scripts/ml/mlops_training_pipeline.py:350:13
    |
349 |             # Initialize model
350 |             generator = ConditionalRapGenerator()
    |             ^^^^^^^^^
351 |
352 |             # Prepare training data
    |
help: Remove assignment to unused variable `generator`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:368:18
    |
366 |             # Save model (mock)
367 |             model_path = self.models_dir / "conditional_generation.pkl"
368 |             with open(model_path, "wb") as f:
    |                  ^^^^
369 |                 pickle.dump(
370 |                     {
    |
help: Replace with `Path.open()`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:372:36
    |
370 |                     {
371 |                         "model_type": "conditional_generation",
372 |                         "version": datetime.now().isoformat(),
    |                                    ^^^^^^^^^^^^^^
373 |                         "training_samples": len(train_texts),
374 |                         "config": config,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:382:25
    |
380 |             metrics = ModelMetrics(
381 |                 model_name="conditional_generation",
382 |                 version=datetime.now().strftime("%Y%m%d_%H%M%S"),
    |                         ^^^^^^^^^^^^^^
383 |                 accuracy=0.85,  # Mock metrics
384 |                 precision=0.82,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:389:27
    |
387 |                 training_time=15.5,
388 |                 validation_loss=0.23,
389 |                 timestamp=datetime.now().isoformat(),
    |                           ^^^^^^^^^^^^^^
390 |                 dataset_size=len(train_texts),
391 |                 additional_metrics={"perplexity": 12.3, "bleu_score": 0.67},
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/mlops_training_pipeline.py:396:13
    |
395 |             logger.info("âœ… Conditional generation model retrained successfully")
396 |             return True
    |             ^^^^^^^^^^^
397 |
398 |         except Exception as e:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/ml/mlops_training_pipeline.py:403:46
    |
402 |     def _retrain_style_transfer_model(
403 |         self, dataset: pd.DataFrame, config: Dict
    |                                              ^^^^
404 |     ) -> bool:
405 |         """Retrain style transfer model"""
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:435:18
    |
433 |             # Save model
434 |             model_path = self.models_dir / "style_transfer.pkl"
435 |             with open(model_path, "wb") as f:
    |                  ^^^^
436 |                 pickle.dump(
437 |                     {
    |
help: Replace with `Path.open()`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:439:36
    |
437 |                     {
438 |                         "model_type": "style_transfer",
439 |                         "version": datetime.now().isoformat(),
    |                                    ^^^^^^^^^^^^^^
440 |                         "training_pairs": len(style_pairs),
441 |                         "artists": list(artists),
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:450:25
    |
448 |             metrics = ModelMetrics(
449 |                 model_name="style_transfer",
450 |                 version=datetime.now().strftime("%Y%m%d_%H%M%S"),
    |                         ^^^^^^^^^^^^^^
451 |                 accuracy=0.78,
452 |                 precision=0.75,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:457:27
    |
455 |                 training_time=12.3,
456 |                 validation_loss=0.31,
457 |                 timestamp=datetime.now().isoformat(),
    |                           ^^^^^^^^^^^^^^
458 |                 dataset_size=len(style_pairs),
459 |                 additional_metrics={
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/mlops_training_pipeline.py:467:13
    |
466 |             logger.info("âœ… Style transfer model retrained successfully")
467 |             return True
    |             ^^^^^^^^^^^
468 |
469 |         except Exception as e:
    |

ARG002 Unused method argument: `config`
   --> scripts/ml/mlops_training_pipeline.py:473:61
    |
471 |             return False
472 |
473 |     def _retrain_quality_model(self, dataset: pd.DataFrame, config: Dict) -> bool:
    |                                                             ^^^^^^
474 |         """Retrain quality prediction model"""
475 |         try:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/ml/mlops_training_pipeline.py:473:69
    |
471 |             return False
472 |
473 |     def _retrain_quality_model(self, dataset: pd.DataFrame, config: Dict) -> bool:
    |                                                                     ^^^^
474 |         """Retrain quality prediction model"""
475 |         try:
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:487:22
    |
485 |                 # Save model
486 |                 model_path = self.models_dir / "quality_prediction.pkl"
487 |                 with open(model_path, "wb") as f:
    |                      ^^^^
488 |                     pickle.dump(predictor, f)
    |
help: Replace with `Path.open()`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:493:29
    |
491 |                 metrics = ModelMetrics(
492 |                     model_name="quality_prediction",
493 |                     version=datetime.now().strftime("%Y%m%d_%H%M%S"),
    |                             ^^^^^^^^^^^^^^
494 |                     accuracy=0.89,
495 |                     precision=0.86,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:500:31
    |
498 |                     training_time=8.7,
499 |                     validation_loss=0.18,
500 |                     timestamp=datetime.now().isoformat(),
    |                               ^^^^^^^^^^^^^^
501 |                     dataset_size=len(dataset),
502 |                     additional_metrics={"r2_score": 0.84, "mae": 0.12},
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/mlops_training_pipeline.py:509:13
    |
507 |                 return True
508 |
509 |             return False
    |             ^^^^^^^^^^^^
510 |
511 |         except Exception as e:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/ml/mlops_training_pipeline.py:515:67
    |
513 |             return False
514 |
515 |     def _retrain_trend_model(self, dataset: pd.DataFrame, config: Dict) -> bool:
    |                                                                   ^^^^
516 |         """Retrain trend analysis model"""
517 |         try:
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:529:22
    |
527 |                 # Save model state
528 |                 model_path = self.models_dir / "trend_analysis.pkl"
529 |                 with open(model_path, "wb") as f:
    |                      ^^^^
530 |                     pickle.dump(
531 |                         {
    |
help: Replace with `Path.open()`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:533:40
    |
531 |                         {
532 |                             "model_type": "trend_analysis",
533 |                             "version": datetime.now().isoformat(),
    |                                        ^^^^^^^^^^^^^^
534 |                             "last_report": report,
535 |                             "config": config,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:543:29
    |
541 |                 metrics = ModelMetrics(
542 |                     model_name="trend_analysis",
543 |                     version=datetime.now().strftime("%Y%m%d_%H%M%S"),
    |                             ^^^^^^^^^^^^^^
544 |                     accuracy=0.76,
545 |                     precision=0.74,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:550:31
    |
548 |                     training_time=6.2,
549 |                     validation_loss=0.28,
550 |                     timestamp=datetime.now().isoformat(),
    |                               ^^^^^^^^^^^^^^
551 |                     dataset_size=len(dataset),
552 |                     additional_metrics={
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/mlops_training_pipeline.py:562:13
    |
560 |                 return True
561 |
562 |             return False
    |             ^^^^^^^^^^^^
563 |
564 |         except Exception as e:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/ml/mlops_training_pipeline.py:568:56
    |
566 |             return False
567 |
568 |     def _validate_model(self, model_name: str, config: Dict) -> bool:
    |                                                        ^^^^
569 |         """Validate newly trained model"""
570 |         try:
    |
help: Replace with `dict`

F841 Local variable `val_data` is assigned to but never used
   --> scripts/ml/mlops_training_pipeline.py:581:13
    |
579 |             # Split for validation
580 |             val_size = int(len(dataset) * config["validation_split"])
581 |             val_data = dataset.tail(val_size)
    |             ^^^^^^^^
582 |
583 |             # Model-specific validation
    |
help: Remove assignment to unused variable `val_data`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:588:26
    |
586 |                 predictor_path = self.models_dir / "quality_prediction.pkl"
587 |                 if predictor_path.exists():
588 |                     with open(predictor_path, "rb") as f:
    |                          ^^^^
589 |                         predictor = pickle.load(f)
    |
help: Replace with `Path.open()`

F841 Local variable `predictor` is assigned to but never used
   --> scripts/ml/mlops_training_pipeline.py:589:25
    |
587 |                 if predictor_path.exists():
588 |                     with open(predictor_path, "rb") as f:
589 |                         predictor = pickle.load(f)
    |                         ^^^^^^^^^
590 |
591 |                     # Mock validation
    |
help: Remove assignment to unused variable `predictor`

RET505 [*] Unnecessary `else` after `return` statement
   --> scripts/ml/mlops_training_pipeline.py:600:21
    |
598 |                         )
599 |                         return True
600 |                     else:
    |                     ^^^^
601 |                         logger.warning(
602 |                             f"âš ï¸ {model_name}: Validation failed (accuracy: {accuracy:.3f} < {threshold})"
    |
help: Remove unnecessary `else`

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/mlops_training_pipeline.py:608:13
    |
606 |             # For other models, assume validation passes
607 |             logger.info(f"âœ… {model_name}: Validation completed")
608 |             return True
    |             ^^^^^^^^^^^
609 |
610 |         except Exception as e:
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:622:18
    |
620 |             # Save to file
621 |             metrics_file = self.metrics_dir / f"metrics_{metrics.model_name}.jsonl"
622 |             with open(metrics_file, "a") as f:
    |                  ^^^^
623 |                 f.write(json.dumps(asdict(metrics)) + "\n")
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:628:18
    |
626 |             summary_file = self.metrics_dir / "metrics_summary.json"
627 |             summary = self._generate_metrics_summary()
628 |             with open(summary_file, "w") as f:
    |                  ^^^^
629 |                 json.dump(summary, f, indent=2)
    |
help: Replace with `Path.open()`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/ml/mlops_training_pipeline.py:636:44
    |
634 |             logger.error(f"âŒ Metrics saving failed: {e}")
635 |
636 |     def _generate_metrics_summary(self) -> Dict:
    |                                            ^^^^
637 |         """Generate metrics summary"""
638 |         summary = {
    |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:639:29
    |
637 |         """Generate metrics summary"""
638 |         summary = {
639 |             "last_updated": datetime.now().isoformat(),
    |                             ^^^^^^^^^^^^^^
640 |             "total_metrics": len(self.metrics_history),
641 |             "models": {},
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:679:32
    |
677 |             deployment_info = {
678 |                 "model_name": model_name,
679 |                 "deployed_at": datetime.now().isoformat(),
    |                                ^^^^^^^^^^^^^^
680 |                 "version": datetime.now().strftime("%Y%m%d_%H%M%S"),
681 |                 "status": "deployed",
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:680:28
    |
678 |                 "model_name": model_name,
679 |                 "deployed_at": datetime.now().isoformat(),
680 |                 "version": datetime.now().strftime("%Y%m%d_%H%M%S"),
    |                            ^^^^^^^^^^^^^^
681 |                 "status": "deployed",
682 |             }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:686:18
    |
684 |             # Save deployment record
685 |             deployment_file = self.models_dir / "deployments.jsonl"
686 |             with open(deployment_file, "a") as f:
    |                  ^^^^
687 |                 f.write(json.dumps(deployment_info) + "\n")
    |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/mlops_training_pipeline.py:716:13
    |
715 |             logger.warning(f"âš ï¸ No backup found for {model_name}")
716 |             return False
    |             ^^^^^^^^^^^^
717 |
718 |         except Exception as e:
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:728:30
    |
727 |             health_status = {
728 |                 "timestamp": datetime.now().isoformat(),
    |                              ^^^^^^^^^^^^^^
729 |                 "models": {},
730 |                 "system": {
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ006 `datetime.datetime.fromtimestamp()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:750:38
    |
748 |                       if model_path.exists()
749 |                       else 0,
750 |                       "last_modified": datetime.fromtimestamp(
    |  ______________________________________^
751 | |                         model_path.stat().st_mtime
752 | |                     ).isoformat()
    | |_____________________^
753 |                       if model_path.exists()
754 |                       else None,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/mlops_training_pipeline.py:759:18
    |
757 |             # Save health report
758 |             health_file = self.metrics_dir / "health_check.json"
759 |             with open(health_file, "w") as f:
    |                  ^^^^
760 |                 json.dump(health_status, f, indent=2)
    |
help: Replace with `Path.open()`

RUF059 Unpacked variable `free` is never used
   --> scripts/ml/mlops_training_pipeline.py:772:26
    |
770 |             import shutil
771 |
772 |             total, used, free = shutil.disk_usage(self.models_dir)
    |                          ^^^^
773 |             return (used / total) * 100
774 |         except:
    |
help: Prefix it with an underscore or any other dummy variable pattern

E722 Do not use bare `except`
   --> scripts/ml/mlops_training_pipeline.py:774:9
    |
772 |             total, used, free = shutil.disk_usage(self.models_dir)
773 |             return (used / total) * 100
774 |         except:
    |         ^^^^^^
775 |             return 0.0
    |

E722 Do not use bare `except`
   --> scripts/ml/mlops_training_pipeline.py:783:9
    |
782 |             return psutil.virtual_memory().percent
783 |         except:
    |         ^^^^^^
784 |             return 0.0
    |

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/mlops_training_pipeline.py:792:13
    |
791 |             response = requests.get("http://localhost:8002/health", timeout=5)
792 |             return response.status_code == 200
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
793 |         except:
794 |             return False
    |

E722 Do not use bare `except`
   --> scripts/ml/mlops_training_pipeline.py:793:9
    |
791 |             response = requests.get("http://localhost:8002/health", timeout=5)
792 |             return response.status_code == 200
793 |         except:
    |         ^^^^^^
794 |             return False
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/mlops_training_pipeline.py:802:27
    |
801 |             retention_days = self.config["monitoring"]["metrics_retention_days"]
802 |             cutoff_date = datetime.now() - timedelta(days=retention_days)
    |                           ^^^^^^^^^^^^^^
803 |
804 |             # Clean up old metrics files
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

F541 [*] f-string without any placeholders
   --> scripts/ml/mlops_training_pipeline.py:900:17
    |
898 |     total = len(results)
899 |
900 |     logger.info(f"\nðŸ“Š TRAINING SUMMARY:")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^
901 |     logger.info(f"  Successful: {successful}/{total}")
902 |     logger.info(f"  Failed: {total - successful}/{total}")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/ml/quick_data_prep.py:6:1
   |
 4 |   """
 5 |
 6 | / import pandas as pd
 7 | | import numpy as np
 8 | | import asyncio
 9 | | import json
10 | | import pickle
11 | | import sys
12 | | import os
13 | | from pathlib import Path
14 | | from datetime import datetime
15 | | import logging
   | |______________^
16 |
17 |   # Add project root to path
   |
help: Organize imports

F401 [*] `numpy` imported but unused
 --> scripts/ml/quick_data_prep.py:7:17
  |
6 | import pandas as pd
7 | import numpy as np
  |                 ^^
8 | import asyncio
9 | import json
  |
help: Remove unused import: `numpy`

F401 [*] `json` imported but unused
  --> scripts/ml/quick_data_prep.py:9:8
   |
 7 | import numpy as np
 8 | import asyncio
 9 | import json
   |        ^^^^
10 | import pickle
11 | import sys
   |
help: Remove unused import: `json`

W293 Blank line contains whitespace
  --> scripts/ml/quick_data_prep.py:54:1
   |
52 |             t.id, t.artist, t.title, t.lyrics,
53 |             t.word_count, t.explicit,
54 |             
   | ^^^^^^^^^^^^
55 |             -- Get latest Qwen analysis
56 |             ar.sentiment as qwen_sentiment,
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> scripts/ml/quick_data_prep.py:60:1
   |
58 |             ar.themes as qwen_themes,
59 |             ar.complexity_score as qwen_complexity,
60 |             
   | ^^^^^^^^^^^^
61 |             -- Parse Spotify data if available
62 |             t.spotify_data
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> scripts/ml/quick_data_prep.py:63:1
   |
61 |             -- Parse Spotify data if available
62 |             t.spotify_data
63 |             
   | ^^^^^^^^^^^^
64 |         FROM tracks t
65 |         LEFT JOIN analysis_results ar ON t.id = ar.track_id 
   |
help: Remove whitespace from blank line

TRY300 Consider moving this statement to an `else` block
  --> scripts/ml/quick_data_prep.py:79:13
   |
77 |             df = pd.DataFrame([dict(row) for row in result])
78 |             logger.info(f"ðŸ“Š Extracted {len(df)} sample tracks")
79 |             return df
   |             ^^^^^^^^^
80 |
81 |         except Exception as e:
   |

RET505 [*] Unnecessary `elif` after `return` statement
   --> scripts/ml/quick_data_prep.py:120:13
    |
118 |             if "love" in themes_lower or "romance" in themes_lower:
119 |                 return "love"
120 |             elif "money" in themes_lower or "success" in themes_lower:
    |             ^^^^
121 |                 return "success"
122 |             elif "struggle" in themes_lower or "pain" in themes_lower:
    |
help: Remove unnecessary `elif`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/ml/quick_data_prep.py:154:38
    |
152 |                 "raw_data": df,
153 |                 "metadata": {
154 |                     "creation_date": datetime.now().isoformat(),
    |                                      ^^^^^^^^^^^^^^
155 |                     "total_tracks": len(df),
156 |                     "sample_limit": limit,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   --> scripts/ml/quick_data_prep.py:161:13
    |
160 |             # Save dataset
161 |             os.makedirs(os.path.dirname(output_path), exist_ok=True)
    |             ^^^^^^^^^^^
162 |             with open(output_path, "wb") as f:
163 |                 pickle.dump(ml_dataset, f)
    |
help: Replace with `Path(...).mkdir(parents=True)`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
   --> scripts/ml/quick_data_prep.py:161:25
    |
160 |             # Save dataset
161 |             os.makedirs(os.path.dirname(output_path), exist_ok=True)
    |                         ^^^^^^^^^^^^^^^
162 |             with open(output_path, "wb") as f:
163 |                 pickle.dump(ml_dataset, f)
    |
help: Replace with `Path(...).parent`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/ml/quick_data_prep.py:162:18
    |
160 |             # Save dataset
161 |             os.makedirs(os.path.dirname(output_path), exist_ok=True)
162 |             with open(output_path, "wb") as f:
    |                  ^^^^
163 |                 pickle.dump(ml_dataset, f)
    |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/quick_data_prep.py:176:13
    |
174 |             logger.info(f"   Themes: {df['theme_category'].value_counts().to_dict()}")
175 |
176 |             return ml_dataset
    |             ^^^^^^^^^^^^^^^^^
177 |
178 |         except Exception as e:
    |

TRY300 Consider moving this statement to an `else` block
   --> scripts/ml/quick_data_prep.py:203:9
    |
201 |         print("Command: python models/conditional_generation.py --mode train")
202 |
203 |         return True
    |         ^^^^^^^^^^^
204 |
205 |     except Exception as e:
    |

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/monitor_postgres.py:34:1
   |
32 |   sys.path.append(str(Path(__file__).parent.parent))
33 |
34 | / from src.utils.postgres_db import PostgreSQLManager
35 | | import logging
   | |______________^
36 |
37 |   logging.basicConfig(level=logging.ERROR)  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð´Ð»Ñ Ñ‡Ð¸ÑÑ‚Ð¾Ð³Ð¾ Ð²Ñ‹Ð²Ð¾Ð´Ð°
   |
help: Organize imports

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
  --> scripts/monitor_postgres.py:71:9
   |
69 |           print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")
70 |       finally:
71 | /         try:
72 | |             db.close()
73 | |         except:
74 | |             pass
   | |________________^
   |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
  --> scripts/monitor_postgres.py:73:9
   |
71 |         try:
72 |             db.close()
73 |         except:
   |         ^^^^^^
74 |             pass
   |

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/rap_scraper_cli.py:32:1
   |
30 |   """
31 |
32 | / import sys
33 | | import os
34 | | import argparse
35 | | from pathlib import Path
   | |________________________^
36 |
37 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path
   |
help: Organize imports

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> scripts/rap_scraper_cli.py:38:17
   |
37 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path
38 | sys.path.append(os.path.dirname(os.path.dirname(__file__)))
   |                 ^^^^^^^^^^^^^^^
   |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> scripts/rap_scraper_cli.py:38:33
   |
37 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path
38 | sys.path.append(os.path.dirname(os.path.dirname(__file__)))
   |                                 ^^^^^^^^^^^^^^^
   |
help: Replace with `Path(...).parent`

PLW1510 [*] `subprocess.run` without explicit `check` argument
  --> scripts/rap_scraper_cli.py:76:22
   |
75 |             script_path = Path(__file__).parent / "development" / "scrape_artist_one.py"
76 |             result = subprocess.run(
   |                      ^^^^^^^^^^^^^^
77 |                 [sys.executable, str(script_path), args.artist],
78 |                 capture_output=True,
   |
help: Add explicit `check=False`

PLW1510 [*] `subprocess.run` without explicit `check` argument
  --> scripts/rap_scraper_cli.py:93:13
   |
91 |                 Path(__file__).parent / "development" / "test_fixed_scraper.py"
92 |             )
93 |             subprocess.run([sys.executable, str(script_path)])
   |             ^^^^^^^^^^^^^^
94 |
95 |         elif args.debug:
   |
help: Add explicit `check=False`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/rap_scraper_cli.py:103:13
    |
101 |                 Path(__file__).parent / "development" / "run_scraping_debug.py"
102 |             )
103 |             subprocess.run([sys.executable, str(script_path)])
    |             ^^^^^^^^^^^^^^
104 |
105 |         elif args.continue_mode:
    |
help: Add explicit `check=False`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/rap_scraper_cli.py:113:13
    |
111 |                 Path(__file__).parent / "development" / "run_remaining_artists.py"
112 |             )
113 |             subprocess.run([sys.executable, str(script_path)])
    |             ^^^^^^^^^^^^^^
114 |
115 |         else:
    |
help: Add explicit `check=False`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/rap_scraper_cli.py:141:13
    |
139 |             import subprocess
140 |
141 |             subprocess.run([sys.executable, "scripts/continue_spotify_enhancement.py"])
    |             ^^^^^^^^^^^^^^
142 |         except Exception as e:
143 |             print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Spotify enhancement: {e}")
    |
help: Add explicit `check=False`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/rap_scraper_cli.py:149:13
    |
147 |             import subprocess
148 |
149 |             subprocess.run([sys.executable, "scripts/run_spotify_enhancement.py"])
    |             ^^^^^^^^^^^^^^
150 |         except Exception as e:
151 |             print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Spotify enhancement: {e}")
    |
help: Add explicit `check=False`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/rap_scraper_cli.py:182:13
    |
180 |             import subprocess
181 |
182 |             subprocess.run([sys.executable, "scripts/archive/test_langchain.py"])
    |             ^^^^^^^^^^^^^^
183 |         except Exception as e:
184 |             print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° LangChain Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {e}")
    |
help: Add explicit `check=False`

PLR0912 Too many branches (33 > 12)
   --> scripts/rap_scraper_cli.py:194:5
    |
194 | def run_mlfeatures(args):
    |     ^^^^^^^^^^^^^^
195 |     """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ñ… ML-Ñ„Ð¸Ñ‡ÐµÐ¹"""
196 |     print("ðŸŽ¯ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ ML-Ñ„Ð¸Ñ‡ÐµÐ¹...")
    |

PLR0915 Too many statements (121 > 50)
   --> scripts/rap_scraper_cli.py:194:5
    |
194 | def run_mlfeatures(args):
    |     ^^^^^^^^^^^^^^
195 |     """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ñ… ML-Ñ„Ð¸Ñ‡ÐµÐ¹"""
196 |     print("ðŸŽ¯ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ ML-Ñ„Ð¸Ñ‡ÐµÐ¹...")
    |

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/rap_scraper_cli.py:206:13
    |
204 |                 Path(__file__).parent / "development" / "demo_simplified_ml_features.py"
205 |             )
206 |             subprocess.run([sys.executable, str(script_path)])
    |             ^^^^^^^^^^^^^^
207 |         except Exception as e:
208 |             print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸: {e}")
    |
help: Add explicit `check=False`

I001 [*] Import block is un-sorted or un-formatted
   --> scripts/rap_scraper_cli.py:213:13
    |
211 |           print(f"ðŸ“ ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°: '{args.text[:50]}...'")
212 |           try:
213 | /             from src.analyzers.simplified_feature_analyzer import (
214 | |                 extract_simplified_features,
215 | |             )
216 | |             import json
    | |_______________________^
217 |
218 |               features = extract_simplified_features(args.text)
    |
help: Organize imports

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/rap_scraper_cli.py:236:26
    |
235 |                 if args.export == "json":
236 |                     with open(output_path, "w", encoding="utf-8") as f:
    |                          ^^^^
237 |                         json.dump(
238 |                             {"text": args.text, "features": features},
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/rap_scraper_cli.py:251:18
    |
249 |         print(f"ðŸ“„ ÐÐ½Ð°Ð»Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°: {args.file}")
250 |         try:
251 |             with open(args.file, "r", encoding="utf-8") as f:
    |                  ^^^^
252 |                 text = f.read()
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/rap_scraper_cli.py:251:34
    |
249 |         print(f"ðŸ“„ ÐÐ½Ð°Ð»Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°: {args.file}")
250 |         try:
251 |             with open(args.file, "r", encoding="utf-8") as f:
    |                                  ^^^
252 |                 text = f.read()
    |
help: Remove mode argument

I001 [*] Import block is un-sorted or un-formatted
   --> scripts/rap_scraper_cli.py:254:13
    |
252 |                   text = f.read()
253 |
254 | /             from src.analyzers.simplified_feature_analyzer import (
255 | |                 extract_simplified_features,
256 | |             )
257 | |             import json
    | |_______________________^
258 |
259 |               features = extract_simplified_features(text)
    |
help: Organize imports

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/rap_scraper_cli.py:277:26
    |
276 |                 if args.export == "json":
277 |                     with open(output_path, "w", encoding="utf-8") as f:
    |                          ^^^^
278 |                         json.dump(
279 |                             {"file": args.file, "text": text, "features": features},
    |
help: Replace with `Path.open()`

I001 [*] Import block is un-sorted or un-formatted
   --> scripts/rap_scraper_cli.py:292:13
    |
290 |           print(f"ðŸ“¦ ÐŸÐ°ÐºÐµÑ‚Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° {args.batch} Ð·Ð°Ð¿Ð¸ÑÐµÐ¹ Ð¸Ð· Ð‘Ð”")
291 |           try:
292 | /             import sqlite3
293 | |             from src.analyzers.simplified_feature_analyzer import (
294 | |                 extract_simplified_features,
295 | |             )
296 | |             import json
297 | |             import time
    | |_______________________^
298 |
299 |               # ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ÑÑ Ðº Ð‘Ð”
    |
help: Organize imports

F821 Undefined name `songs`
   --> scripts/rap_scraper_cli.py:315:57
    |
313 |             start_time = time.time()
314 |
315 |             for i, (artist, title, lyrics) in enumerate(songs):
    |                                                         ^^^^^
316 |                 try:
317 |                     features = extract_simplified_features(lyrics)
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/rap_scraper_cli.py:325:17
    |
323 |                           print(f"   ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾: {i + 1}/{len(tracks)}")
324 |
325 | /                 except Exception as e:
326 | |                     print(f"   âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ '{artist} - {title}': {e}")
    | |_____________________________________________________________________________^
327 |
328 |               processing_time = time.time() - start_time
    |

F541 [*] f-string without any placeholders
   --> scripts/rap_scraper_cli.py:330:19
    |
328 |             processing_time = time.time() - start_time
329 |
330 |             print(f"\nâœ… ÐŸÐ°ÐºÐµÑ‚Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
331 |             print(f"   Ð’Ñ€ÐµÐ¼Ñ: {processing_time:.2f}Ñ")
332 |             print(f"   Ð£ÑÐ¿ÐµÑˆÐ½Ð¾: {len(results)}/{len(tracks)}")
    |
help: Remove extraneous `f` prefix

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/rap_scraper_cli.py:344:26
    |
343 |                 if args.export == "json":
344 |                     with open(output_path, "w", encoding="utf-8") as f:
    |                          ^^^^
345 |                         json.dump(
346 |                             {
    |
help: Replace with `Path.open()`

PLR1714 Consider merging multiple comparisons: `args.component in {"database", "all"}`.
   --> scripts/rap_scraper_cli.py:399:8
    |
397 |     print("ðŸ“Š Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°...")
398 |
399 |     if args.component == "database" or args.component == "all":
    |        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
400 |         print("ðŸ—„ï¸ ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
401 |         show_status()
    |
help: Merge multiple comparisons

PLR1714 Consider merging multiple comparisons: `args.component in {"analysis", "all"}`.
   --> scripts/rap_scraper_cli.py:405:8
    |
403 |             print("\n" + "=" * 50 + "\n")
404 |
405 |     if args.component == "analysis" or args.component == "all":
    |        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
406 |         print("ðŸ¤– Ð¡Ñ‚Ð°Ñ‚ÑƒÑ AI Ð°Ð½Ð°Ð»Ð¸Ð·Ð°")
407 |         try:
    |
help: Merge multiple comparisons

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/rap_scraper_cli.py:410:13
    |
408 |             import subprocess
409 |
410 |             subprocess.run([sys.executable, "monitoring/check_analysis_status.py"])
    |             ^^^^^^^^^^^^^^
411 |         except Exception as e:
412 |             print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {e}")
    |
help: Add explicit `check=False`

PLR1714 Consider merging multiple comparisons: `args.component in {"gemma", "all"}`.
   --> scripts/rap_scraper_cli.py:416:8
    |
414 |             print("\n" + "=" * 50 + "\n")
415 |
416 |     if args.component == "gemma" or args.component == "all":
    |        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
417 |         print("ðŸ”¥ ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ° Gemma")
418 |         try:
    |
help: Merge multiple comparisons

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/rap_scraper_cli.py:421:13
    |
419 |             import subprocess
420 |
421 |             subprocess.run([sys.executable, "monitoring/monitor_gemma_progress.py"])
    |             ^^^^^^^^^^^^^^
422 |         except Exception as e:
423 |             print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Gemma: {e}")
    |
help: Add explicit `check=False`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/rap_scraper_cli.py:452:13
    |
450 |             if args.execute:
451 |                 cmd.append("--execute")
452 |             subprocess.run(cmd)
    |             ^^^^^^^^^^^^^^
453 |         except Exception as e:
454 |             print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸: {e}")
    |
help: Add explicit `check=False`

W293 Blank line contains whitespace
   --> scripts/rap_scraper_cli.py:488:1
    |
486 |         epilog="""
487 | ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ:
488 |   
    | ^^
489 |   ðŸ“Š ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÐ°:
490 |     python scripts/rap_scraper_cli.py status
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/rap_scraper_cli.py:491:1
    |
489 |   ðŸ“Š ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÐ°:
490 |     python scripts/rap_scraper_cli.py status
491 |   
    | ^^
492 |   ðŸ•·ï¸ Ð¡ÐºÑ€Ð°Ð¿Ð¸Ð½Ð³ Ð´Ð°Ð½Ð½Ñ‹Ñ…:
493 |     python scripts/rap_scraper_cli.py scraping                    # ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ ÑÐºÑ€Ð°Ð¿Ð¸Ð½Ð³
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/rap_scraper_cli.py:498:1
    |
496 |     python scripts/rap_scraper_cli.py scraping --test             # Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼
497 |     python scripts/rap_scraper_cli.py scraping --debug           # ÐžÑ‚Ð»Ð°Ð´Ð¾Ñ‡Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼
498 |   
    | ^^
499 |   ðŸŽµ ÐžÐ±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ Spotify Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸:
500 |     python scripts/rap_scraper_cli.py spotify
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/rap_scraper_cli.py:502:1
    |
500 |     python scripts/rap_scraper_cli.py spotify
501 |     python scripts/rap_scraper_cli.py spotify --continue
502 |   
    | ^^
503 |   ðŸ¤– ML Ð°Ð½Ð°Ð»Ð¸Ð·:
504 |     python scripts/rap_scraper_cli.py analysis --analyzer gemma
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/rap_scraper_cli.py:506:1
    |
504 |     python scripts/rap_scraper_cli.py analysis --analyzer gemma
505 |     python scripts/rap_scraper_cli.py analysis --analyzer multi
506 |   
    | ^^
507 |   ðŸŽ¯ Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ML-Ñ„Ð¸Ñ‡ÐµÐ¹ (ÐÐžÐ’ÐžÐ•!):
508 |     python scripts/rap_scraper_cli.py mlfeatures --demo
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/rap_scraper_cli.py:511:1
    |
509 |     python scripts/rap_scraper_cli.py mlfeatures --text "Ð¼Ð¾Ð¹ Ñ€ÑÐ¿ Ñ‚ÐµÐºÑÑ‚"
510 |     python scripts/rap_scraper_cli.py mlfeatures --batch 100 --export json --output features.json
511 |   
    | ^^
512 |   ðŸ“Š ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³:
513 |     python scripts/rap_scraper_cli.py monitoring --component database
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/rap_scraper_cli.py:515:1
    |
513 |     python scripts/rap_scraper_cli.py monitoring --component database
514 |     python scripts/rap_scraper_cli.py monitoring --component analysis
515 |   
    | ^^
516 |   ðŸ› ï¸ Ð£Ñ‚Ð¸Ð»Ð¸Ñ‚Ñ‹:
517 |     python scripts/rap_scraper_cli.py utils --utility cleanup
    |
help: Remove whitespace from blank line

F841 Local variable `status_parser` is assigned to but never used
   --> scripts/rap_scraper_cli.py:525:5
    |
524 |     # Status command
525 |     status_parser = subparsers.add_parser("status", help="ðŸ“Š Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°")
    |     ^^^^^^^^^^^^^
526 |
527 |     # Scraping command
    |
help: Remove assignment to unused variable `status_parser`

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/tools/ai_context_manager.py:63:1
   |
61 |   """
62 |
63 | / import json
64 | | import os
65 | | import subprocess
66 | | import hashlib
67 | | import pickle
68 | | import time
69 | | from pathlib import Path
70 | | from typing import Dict, List, Set, Optional, Tuple
71 | | from dataclasses import dataclass, asdict, field
72 | | from datetime import datetime, timedelta
73 | | from collections import defaultdict, Counter
74 | | import re
75 | | import ast
   | |__________^
76 |
77 |   # ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ ML features
   |
help: Organize imports

F401 [*] `os` imported but unused
  --> scripts/tools/ai_context_manager.py:64:8
   |
63 | import json
64 | import os
   |        ^^
65 | import subprocess
66 | import hashlib
   |
help: Remove unused import: `os`

F401 [*] `time` imported but unused
  --> scripts/tools/ai_context_manager.py:68:8
   |
66 | import hashlib
67 | import pickle
68 | import time
   |        ^^^^
69 | from pathlib import Path
70 | from typing import Dict, List, Set, Optional, Tuple
   |
help: Remove unused import: `time`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/tools/ai_context_manager.py:70:1
   |
68 | import time
69 | from pathlib import Path
70 | from typing import Dict, List, Set, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
71 | from dataclasses import dataclass, asdict, field
72 | from datetime import datetime, timedelta
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/tools/ai_context_manager.py:70:1
   |
68 | import time
69 | from pathlib import Path
70 | from typing import Dict, List, Set, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
71 | from dataclasses import dataclass, asdict, field
72 | from datetime import datetime, timedelta
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> scripts/tools/ai_context_manager.py:70:1
   |
68 | import time
69 | from pathlib import Path
70 | from typing import Dict, List, Set, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
71 | from dataclasses import dataclass, asdict, field
72 | from datetime import datetime, timedelta
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/tools/ai_context_manager.py:70:1
   |
68 | import time
69 | from pathlib import Path
70 | from typing import Dict, List, Set, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
71 | from dataclasses import dataclass, asdict, field
72 | from datetime import datetime, timedelta
   |

F401 [*] `typing.Set` imported but unused
  --> scripts/tools/ai_context_manager.py:70:32
   |
68 | import time
69 | from pathlib import Path
70 | from typing import Dict, List, Set, Optional, Tuple
   |                                ^^^
71 | from dataclasses import dataclass, asdict, field
72 | from datetime import datetime, timedelta
   |
help: Remove unused import: `typing.Set`

F401 [*] `collections.Counter` imported but unused
  --> scripts/tools/ai_context_manager.py:73:38
   |
71 | from dataclasses import dataclass, asdict, field
72 | from datetime import datetime, timedelta
73 | from collections import defaultdict, Counter
   |                                      ^^^^^^^
74 | import re
75 | import ast
   |
help: Remove unused import: `collections.Counter`

F401 [*] `re` imported but unused
  --> scripts/tools/ai_context_manager.py:74:8
   |
72 | from datetime import datetime, timedelta
73 | from collections import defaultdict, Counter
74 | import re
   |        ^^
75 | import ast
   |
help: Remove unused import: `re`

F401 `numpy` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> scripts/tools/ai_context_manager.py:79:21
   |
77 | # ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ ML features
78 | try:
79 |     import numpy as np
   |                     ^^
80 |     from sklearn.feature_extraction.text import TfidfVectorizer
81 |     from sklearn.metrics.pairwise import cosine_similarity
   |
help: Remove unused import: `numpy`

I001 [*] Import block is un-sorted or un-formatted
   --> scripts/tools/ai_context_manager.py:97:5
    |
 96 |   try:
 97 | /     from fastapi import FastAPI, HTTPException, Query
 98 | |     from fastapi.middleware.cors import CORSMiddleware
 99 | |     from pydantic import BaseModel
100 | |     import uvicorn
    | |__________________^
101 |
102 |       API_AVAILABLE = True
    |
help: Organize imports

F401 `fastapi.HTTPException` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> scripts/tools/ai_context_manager.py:97:34
   |
96 | try:
97 |     from fastapi import FastAPI, HTTPException, Query
   |                                  ^^^^^^^^^^^^^
98 |     from fastapi.middleware.cors import CORSMiddleware
99 |     from pydantic import BaseModel
   |
help: Remove unused import

F401 `fastapi.Query` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> scripts/tools/ai_context_manager.py:97:49
   |
96 | try:
97 |     from fastapi import FastAPI, HTTPException, Query
   |                                                 ^^^^^
98 |     from fastapi.middleware.cors import CORSMiddleware
99 |     from pydantic import BaseModel
   |
help: Remove unused import

F401 `pydantic.BaseModel` imported but unused; consider using `importlib.util.find_spec` to test for availability
   --> scripts/tools/ai_context_manager.py:99:26
    |
 97 |     from fastapi import FastAPI, HTTPException, Query
 98 |     from fastapi.middleware.cors import CORSMiddleware
 99 |     from pydantic import BaseModel
    |                          ^^^^^^^^^
100 |     import uvicorn
    |
help: Remove unused import: `pydantic.BaseModel`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_context_manager.py:117:19
    |
115 |     last_modified: str
116 |     size_lines: int
117 |     dependencies: List[str]
    |                   ^^^^
118 |
119 |     # ÐÐ¾Ð²Ñ‹Ðµ Ð¿Ð¾Ð»Ñ Ð´Ð»Ñ ML
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_context_manager.py:122:18
    |
120 |     git_commits_count: int = 0
121 |     git_last_commit: str = ""
122 |     git_authors: List[str] = field(default_factory=list)
    |                  ^^^^
123 |     complexity_score: float = 0.0
124 |     coupling_score: float = 0.0  # Ð¡Ð²ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚ÑŒ Ñ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸ Ð¼Ð¾Ð´ÑƒÐ»ÑÐ¼Ð¸
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> scripts/tools/ai_context_manager.py:126:25
    |
124 |     coupling_score: float = 0.0  # Ð¡Ð²ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚ÑŒ Ñ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸ Ð¼Ð¾Ð´ÑƒÐ»ÑÐ¼Ð¸
125 |     usage_frequency: int = 0  # ÐšÐ°Ðº Ñ‡Ð°ÑÑ‚Ð¾ Ñ„Ð°Ð¹Ð» Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð² Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ
126 |     semantic_embedding: Optional[List[float]] = None  # Ð”Ð»Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°
    |                         ^^^^^^^^^^^^^^^^^^^^^
    |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_context_manager.py:126:34
    |
124 |     coupling_score: float = 0.0  # Ð¡Ð²ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚ÑŒ Ñ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸ Ð¼Ð¾Ð´ÑƒÐ»ÑÐ¼Ð¸
125 |     usage_frequency: int = 0  # ÐšÐ°Ðº Ñ‡Ð°ÑÑ‚Ð¾ Ñ„Ð°Ð¹Ð» Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð² Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ
126 |     semantic_embedding: Optional[List[float]] = None  # Ð”Ð»Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°
    |                                  ^^^^
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_context_manager.py:133:18
    |
131 |     """ÐšÐµÑˆ Ð´Ð»Ñ ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹"""
132 |
133 |     file_hashes: Dict[str, str] = field(default_factory=dict)
    |                  ^^^^
134 |     embeddings: Dict[str, List[float]] = field(default_factory=dict)
135 |     git_data: Dict[str, dict] = field(default_factory=dict)
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_context_manager.py:134:17
    |
133 |     file_hashes: Dict[str, str] = field(default_factory=dict)
134 |     embeddings: Dict[str, List[float]] = field(default_factory=dict)
    |                 ^^^^
135 |     git_data: Dict[str, dict] = field(default_factory=dict)
136 |     last_update: float = 0
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_context_manager.py:134:27
    |
133 |     file_hashes: Dict[str, str] = field(default_factory=dict)
134 |     embeddings: Dict[str, List[float]] = field(default_factory=dict)
    |                           ^^^^
135 |     git_data: Dict[str, dict] = field(default_factory=dict)
136 |     last_update: float = 0
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_context_manager.py:135:15
    |
133 |     file_hashes: Dict[str, str] = field(default_factory=dict)
134 |     embeddings: Dict[str, List[float]] = field(default_factory=dict)
135 |     git_data: Dict[str, dict] = field(default_factory=dict)
    |               ^^^^
136 |     last_update: float = 0
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_context_manager.py:145:49
    |
143 |         self.repo_path = repo_path
144 |
145 |     def get_file_stats(self, file_path: str) -> Dict:
    |                                                 ^^^^
146 |         """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ git ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð´Ð»Ñ Ñ„Ð°Ð¹Ð»Ð°"""
147 |         try:
    |
help: Replace with `dict`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/tools/ai_context_manager.py:150:17
    |
148 |             # ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ¾Ð¼Ð¼Ð¸Ñ‚Ð¾Ð²
149 |             commits = (
150 |                 subprocess.run(
    |                 ^^^^^^^^^^^^^^
151 |                     ["git", "log", "--oneline", file_path],
152 |                     capture_output=True,
    |
help: Add explicit `check=False`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/tools/ai_context_manager.py:162:27
    |
161 |             # ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ ÐºÐ¾Ð¼Ð¼Ð¸Ñ‚
162 |             last_commit = subprocess.run(
    |                           ^^^^^^^^^^^^^^
163 |                 ["git", "log", "-1", "--format=%ar", file_path],
164 |                 capture_output=True,
    |
help: Add explicit `check=False`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/tools/ai_context_manager.py:171:17
    |
169 |             # ÐÐ²Ñ‚Ð¾Ñ€Ñ‹
170 |             authors = (
171 |                 subprocess.run(
    |                 ^^^^^^^^^^^^^^
172 |                     ["git", "log", "--format=%an", file_path],
173 |                     capture_output=True,
    |
help: Add explicit `check=False`

C403 Unnecessary list comprehension (rewrite as a set comprehension)
   --> scripts/tools/ai_context_manager.py:180:35
    |
178 |                 .split("\n")
179 |             )
180 |             unique_authors = list(set([a for a in authors if a]))
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
181 |
182 |             return {
    |
help: Rewrite as a set comprehension

TRY300 Consider moving this statement to an `else` block
   --> scripts/tools/ai_context_manager.py:182:13
    |
180 |               unique_authors = list(set([a for a in authors if a]))
181 |
182 | /             return {
183 | |                 "commits": commit_count,
184 | |                 "last_commit": last_commit,
185 | |                 "authors": unique_authors,
186 | |             }
    | |_____________^
187 |           except Exception as e:
188 |               return {"commits": 0, "last_commit": "unknown", "authors": []}
    |

F841 [*] Local variable `e` is assigned to but never used
   --> scripts/tools/ai_context_manager.py:187:29
    |
185 |                 "authors": unique_authors,
186 |             }
187 |         except Exception as e:
    |                             ^
188 |             return {"commits": 0, "last_commit": "unknown", "authors": []}
    |
help: Remove assignment to unused variable `e`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_context_manager.py:190:52
    |
188 |             return {"commits": 0, "last_commit": "unknown", "authors": []}
189 |
190 |     def get_recent_changes(self, days: int = 7) -> List[str]:
    |                                                    ^^^^
191 |         """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð½ÐµÐ´Ð°Ð²Ð½Ð¾ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²"""
192 |         try:
    |
help: Replace with `list`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/tools/ai_context_manager.py:193:22
    |
191 |         """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð½ÐµÐ´Ð°Ð²Ð½Ð¾ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²"""
192 |         try:
193 |             since = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
    |                      ^^^^^^^^^^^^^^
194 |             result = subprocess.run(
195 |                 ["git", "log", f"--since={since}", "--name-only", "--format="],
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/tools/ai_context_manager.py:194:22
    |
192 |         try:
193 |             since = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
194 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
195 |                 ["git", "log", f"--since={since}", "--name-only", "--format="],
196 |                 capture_output=True,
    |
help: Add explicit `check=False`

E722 Do not use bare `except`
   --> scripts/tools/ai_context_manager.py:204:9
    |
202 |             ]
203 |             return list(set(files))
204 |         except:
    |         ^^^^^^
205 |             return []
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_context_manager.py:216:34
    |
214 |         self.embeddings = None
215 |
216 |     def build_index(self, files: Dict[str, EnhancedFileContext]) -> None:
    |                                  ^^^^
217 |         """Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ Ð¸Ð½Ð´ÐµÐºÑ Ð´Ð»Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°"""
218 |         if not ML_AVAILABLE:
    |
help: Replace with `dict`

B007 Loop control variable `context` not used within loop body
   --> scripts/tools/ai_context_manager.py:225:19
    |
223 |         file_paths = []
224 |
225 |         for path, context in files.items():
    |                   ^^^^^^^
226 |             if Path(path).exists():
227 |                 try:
    |
help: Rename unused `context` to `_context`

PERF102 When using only the keys of a dict use the `keys()` method
   --> scripts/tools/ai_context_manager.py:225:30
    |
223 |         file_paths = []
224 |
225 |         for path, context in files.items():
    |                              ^^^^^^^^^^^
226 |             if Path(path).exists():
227 |                 try:
    |
help: Replace `.items()` with `.keys()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_context_manager.py:228:26
    |
226 |             if Path(path).exists():
227 |                 try:
228 |                     with open(path, "r", encoding="utf-8") as f:
    |                          ^^^^
229 |                         content = f.read()
230 |                         # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ docstrings Ð¸ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/tools/ai_context_manager.py:228:37
    |
226 |             if Path(path).exists():
227 |                 try:
228 |                     with open(path, "r", encoding="utf-8") as f:
    |                                     ^^^
229 |                         content = f.read()
230 |                         # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ docstrings Ð¸ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ
    |
help: Remove mode argument

E722 Do not use bare `except`
   --> scripts/tools/ai_context_manager.py:235:17
    |
233 |                         file_paths.append(path)
234 |                         self.file_contents[path] = content
235 |                 except:
    |                 ^^^^^^
236 |                     pass
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_context_manager.py:246:54
    |
244 |             self.file_paths = file_paths
245 |
246 |     def search(self, query: str, top_k: int = 10) -> List[Tuple[str, float]]:
    |                                                      ^^^^
247 |         """Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ"""
248 |         if not ML_AVAILABLE or self.vectorizer is None:
    |
help: Replace with `list`

UP006 [*] Use `tuple` instead of `Tuple` for type annotation
   --> scripts/tools/ai_context_manager.py:246:59
    |
244 |             self.file_paths = file_paths
245 |
246 |     def search(self, query: str, top_k: int = 10) -> List[Tuple[str, float]]:
    |                                                           ^^^^^
247 |         """Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ"""
248 |         if not ML_AVAILABLE or self.vectorizer is None:
    |
help: Replace with `tuple`

PERF401 Use a list comprehension to create a transformed list
   --> scripts/tools/ai_context_manager.py:263:17
    |
261 |         for idx in top_indices:
262 |             if similarities[idx] > 0.1:  # ÐŸÐ¾Ñ€Ð¾Ð³ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚Ð¸
263 |                 results.append((self.file_paths[idx], float(similarities[idx])))
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
264 |
265 |         return results
    |
help: Replace for loop with list comprehension

E722 Do not use bare `except`
   --> scripts/tools/ai_context_manager.py:289:9
    |
288 |             return " ".join(semantic_parts)
289 |         except:
    |         ^^^^^^
290 |             return code[:1000]  # Fallback Ðº Ð¿ÐµÑ€Ð²Ñ‹Ð¼ 1000 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð°Ð¼
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_context_manager.py:384:18
    |
383 |         try:
384 |             with open(file_path, "r", encoding="utf-8") as f:
    |                  ^^^^
385 |                 content = f.read()[:2000]  # ÐŸÐµÑ€Ð²Ñ‹Ðµ 2000 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/tools/ai_context_manager.py:384:34
    |
383 |         try:
384 |             with open(file_path, "r", encoding="utf-8") as f:
    |                                  ^^^
385 |                 content = f.read()[:2000]  # ÐŸÐµÑ€Ð²Ñ‹Ðµ 2000 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
    |
help: Remove mode argument

TRY300 Consider moving this statement to an `else` block
   --> scripts/tools/ai_context_manager.py:391:13
    |
389 |             # ÐšÐµÑˆÐ¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
390 |             cache_file.write_text(description)
391 |             return description
    |             ^^^^^^^^^^^^^^^^^^
392 |
393 |         except Exception as e:
    |

F841 [*] Local variable `e` is assigned to but never used
   --> scripts/tools/ai_context_manager.py:393:29
    |
391 |             return description
392 |
393 |         except Exception as e:
    |                             ^
394 |             return self._fallback_description(file_path, "")
    |
help: Remove assignment to unused variable `e`

RET505 [*] Unnecessary `else` after `return` statement
   --> scripts/tools/ai_context_manager.py:408:9
    |
406 |         if self.provider == "ollama" and HTTPX_AVAILABLE:
407 |             return await self._call_ollama(prompt)
408 |         else:
    |         ^^^^
409 |             return self._fallback_description(Path(filename), content)
    |
help: Remove unnecessary `else`

RET505 [*] Unnecessary `elif` after `return` statement
   --> scripts/tools/ai_context_manager.py:437:9
    |
435 |         if "class" in content and "def" in content:
436 |             return f"Python module with classes and functions: {file_path.name}"
437 |         elif "class" in content:
    |         ^^^^
438 |             return f"Class definitions in {file_path.name}"
439 |         elif "def" in content:
    |
help: Remove unnecessary `elif`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_context_manager.py:445:52
    |
443 |         return f"Python file: {file_path.name}"
444 |
445 |     def generate_descriptions(self, file_contexts: Dict) -> Dict[str, str]:
    |                                                    ^^^^
446 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð´Ð»Ñ Ð²ÑÐµÑ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ"""
447 |         descriptions = {}
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_context_manager.py:445:61
    |
443 |         return f"Python file: {file_path.name}"
444 |
445 |     def generate_descriptions(self, file_contexts: Dict) -> Dict[str, str]:
    |                                                             ^^^^
446 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð´Ð»Ñ Ð²ÑÐµÑ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ"""
447 |         descriptions = {}
    |
help: Replace with `dict`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/tools/ai_context_manager.py:460:13
    |
458 |                   descriptions[file_path] = description
459 |                   print(f"âœ… {file_path}: {description[:50]}...")
460 | /             except Exception as e:
461 | |                 print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð´Ð»Ñ {file_path}: {e}")
462 | |                 descriptions[file_path] = self._fallback_description(
463 | |                     Path(file_path), context.content[:500]
464 | |                 )
    | |_________________^
465 |
466 |           return descriptions
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_context_manager.py:472:39
    |
470 |     """ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹"""
471 |
472 |     def __init__(self, file_contexts: Dict):
    |                                       ^^^^
473 |         self.file_contexts = file_contexts
474 |         self.output_dir = Path("results/visualizations")
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> scripts/tools/ai_context_manager.py:477:54
    |
475 |         self.output_dir.mkdir(exist_ok=True)
476 |
477 |     def generate_dependency_graph(self, focus_files: Optional[List[str]] = None) -> str:
    |                                                      ^^^^^^^^^^^^^^^^^^^
478 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð³Ñ€Ð°Ñ„ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹ Ð² DOT Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ"""
    |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_context_manager.py:477:63
    |
475 |         self.output_dir.mkdir(exist_ok=True)
476 |
477 |     def generate_dependency_graph(self, focus_files: Optional[List[str]] = None) -> str:
    |                                                               ^^^^
478 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð³Ñ€Ð°Ñ„ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹ Ð² DOT Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ"""
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> scripts/tools/ai_context_manager.py:543:42
    |
541 |         return "\n".join(dot_lines)
542 |
543 |     def save_graph(self, focus_category: Optional[str] = None) -> Path:
    |                                          ^^^^^^^^^^^^^
544 |         """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð³Ñ€Ð°Ñ„ Ð² Ñ„Ð°Ð¹Ð»"""
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> scripts/tools/ai_context_manager.py:618:40
    |
617 |         @self.app.get("/files")
618 |         async def list_files(category: Optional[str] = None, min_priority: float = 0.0):
    |                                        ^^^^^^^^^^^^^
619 |             """Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÐµÐ¹"""
620 |             files = []
    |
help: Convert to `X | None`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_context_manager.py:753:26
    |
751 |                 analyzer_results_file = self.results_dir / "project_analysis.json"
752 |                 if analyzer_results_file.exists():
753 |                     with open(analyzer_results_file, "r", encoding="utf-8") as f:
    |                          ^^^^
754 |                         self.analyzer_metrics = json.load(f)
755 |                 else:
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/tools/ai_context_manager.py:753:54
    |
751 |                 analyzer_results_file = self.results_dir / "project_analysis.json"
752 |                 if analyzer_results_file.exists():
753 |                     with open(analyzer_results_file, "r", encoding="utf-8") as f:
    |                                                      ^^^
754 |                         self.analyzer_metrics = json.load(f)
755 |                 else:
    |
help: Remove mode argument

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_context_manager.py:761:26
    |
760 |                     # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
761 |                     with open(analyzer_results_file, "w", encoding="utf-8") as f:
    |                          ^^^^
762 |                         json.dump(
763 |                             self.analyzer_metrics, f, indent=2, ensure_ascii=False
    |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
   --> scripts/tools/ai_context_manager.py:766:17
    |
764 |                         )
765 |
766 |                 return True
    |                 ^^^^^^^^^^^
767 |
768 |             except ImportError as e:
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_context_manager.py:806:59
    |
804 |                 context.priority += 0.5  # ÐŸÐ¾Ð²Ñ‹ÑˆÐ°ÐµÐ¼ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸ÑÐ¼Ð¸
805 |
806 |     def _generate_enhanced_insights(self, relevant_files: List[str]) -> List[str]:
    |                                                           ^^^^
807 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ðµ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ project analyzer"""
808 |         insights = []
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_context_manager.py:806:73
    |
804 |                 context.priority += 0.5  # ÐŸÐ¾Ð²Ñ‹ÑˆÐ°ÐµÐ¼ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸ÑÐ¼Ð¸
805 |
806 |     def _generate_enhanced_insights(self, relevant_files: List[str]) -> List[str]:
    |                                                                         ^^^^
807 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ðµ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ project analyzer"""
808 |         insights = []
    |
help: Replace with `list`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_context_manager.py:871:22
    |
869 |         if self.cache_file.exists():
870 |             try:
871 |                 with open(self.cache_file, "rb") as f:
    |                      ^^^^
872 |                     return pickle.load(f)
873 |             except:
    |
help: Replace with `Path.open()`

E722 Do not use bare `except`
   --> scripts/tools/ai_context_manager.py:873:13
    |
871 |                 with open(self.cache_file, "rb") as f:
872 |                     return pickle.load(f)
873 |             except:
    |             ^^^^^^
874 |                 pass
875 |         return ContextCache()
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_context_manager.py:880:18
    |
878 |         """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ ÐºÐµÑˆ Ð² Ñ„Ð°Ð¹Ð»"""
879 |         try:
880 |             with open(self.cache_file, "wb") as f:
    |                  ^^^^
881 |                 pickle.dump(self.cache, f)
882 |         except:
    |
help: Replace with `Path.open()`

E722 Do not use bare `except`
   --> scripts/tools/ai_context_manager.py:882:9
    |
880 |             with open(self.cache_file, "wb") as f:
881 |                 pickle.dump(self.cache, f)
882 |         except:
    |         ^^^^^^
883 |             pass
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_context_manager.py:888:18
    |
886 |         """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ ÐºÐµÑˆÐ°"""
887 |         if self.context_file.exists():
888 |             with open(self.context_file, "r", encoding="utf-8") as f:
    |                  ^^^^
889 |                 data = json.load(f)
890 |                 self.file_contexts = {
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/tools/ai_context_manager.py:888:42
    |
886 |         """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ ÐºÐµÑˆÐ°"""
887 |         if self.context_file.exists():
888 |             with open(self.context_file, "r", encoding="utf-8") as f:
    |                                          ^^^
889 |                 data = json.load(f)
890 |                 self.file_contexts = {
    |
help: Remove mode argument

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_context_manager.py:948:18
    |
946 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ Ñ…ÐµÑˆ Ñ„Ð°Ð¹Ð»Ð° Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹"""
947 |         try:
948 |             with open(file_path, "rb") as f:
    |                  ^^^^
949 |                 return hashlib.md5(f.read()).hexdigest()
950 |         except:
    |
help: Replace with `Path.open()`

E722 Do not use bare `except`
   --> scripts/tools/ai_context_manager.py:950:9
    |
948 |             with open(file_path, "rb") as f:
949 |                 return hashlib.md5(f.read()).hexdigest()
950 |         except:
    |         ^^^^^^
951 |             return ""
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_context_manager.py:956:18
    |
954 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ñ„Ð°Ð¹Ð»Ð°"""
955 |         try:
956 |             with open(file_path, "r", encoding="utf-8") as f:
    |                  ^^^^
957 |                 content = f.read()
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/tools/ai_context_manager.py:956:34
    |
954 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ñ„Ð°Ð¹Ð»Ð°"""
955 |         try:
956 |             with open(file_path, "r", encoding="utf-8") as f:
    |                                  ^^^
957 |                 content = f.read()
    |
help: Remove mode argument

TRY300 Consider moving this statement to an `else` block
   --> scripts/tools/ai_context_manager.py:970:13
    |
968 |                     complexity += 2
969 |
970 |             return complexity
    |             ^^^^^^^^^^^^^^^^^
971 |         except:
972 |             return 0.0
    |

E722 Do not use bare `except`
   --> scripts/tools/ai_context_manager.py:971:9
    |
970 |             return complexity
971 |         except:
    |         ^^^^^^
972 |             return 0.0
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_context_manager.py:977:18
    |
975 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ ÑÐ²ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÑƒÐ»Ñ Ñ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸"""
976 |         try:
977 |             with open(file_path, "r", encoding="utf-8") as f:
    |                  ^^^^
978 |                 content = f.read()
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/tools/ai_context_manager.py:977:34
    |
975 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ ÑÐ²ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÑƒÐ»Ñ Ñ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸"""
976 |         try:
977 |             with open(file_path, "r", encoding="utf-8") as f:
    |                                  ^^^
978 |                 content = f.read()
    |
help: Remove mode argument

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/tools/ai_context_manager.py:987:17
    |
985 |                       for alias in node.names:
986 |                           imports.add(alias.name)
987 | /                 elif isinstance(node, ast.ImportFrom):
988 | |                     if node.module:
    | |___________________________________^
989 |                           imports.add(node.module)
    |
help: Combine `if` statements using `and`

E722 Do not use bare `except`
   --> scripts/tools/ai_context_manager.py:997:9
    |
996 |             return float(internal_imports)
997 |         except:
    |         ^^^^^^
998 |             return 0.0
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> scripts/tools/ai_context_manager.py:1000:71
     |
 998 |             return 0.0
 999 |
1000 |     def generate_ai_context(self, task_type: str, query: str = "") -> Dict:
     |                                                                       ^^^^
1001 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ ML ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸ÑÐ¼Ð¸"""
     |
help: Replace with `dict`

ARG002 Unused method argument: `query`
    --> scripts/tools/ai_context_manager.py:1034:60
     |
1032 |         }
1033 |
1034 |     def _select_relevant_files_smart(self, task_type: str, query: str) -> List[str]:
     |                                                            ^^^^^
1035 |         """Ð£Ð¼Ð½Ð°Ñ ÑÐµÐ»ÐµÐºÑ†Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð¾Ð²"""
     |

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_context_manager.py:1034:75
     |
1032 |         }
1033 |
1034 |     def _select_relevant_files_smart(self, task_type: str, query: str) -> List[str]:
     |                                                                           ^^^^
1035 |         """Ð£Ð¼Ð½Ð°Ñ ÑÐµÐ»ÐµÐºÑ†Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð¾Ð²"""
     |
help: Replace with `list`

SIM102 Use a single `if` statement instead of nested `if` statements
    --> scripts/tools/ai_context_manager.py:1058:13
     |
1057 |           for path, ctx in sorted_files:
1058 | /             if ctx.category in task_categories.get(task_type, []):
1059 | |                 if path not in relevant:
     | |________________________________________^
1060 |                       relevant.append(path)
     |
help: Combine `if` statements using `and`

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_context_manager.py:1072:22
     |
1071 |     def _generate_smart_summary(
1072 |         self, files: List[str], task_type: str, query: str
     |                      ^^^^
1073 |     ) -> str:
1074 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ÑƒÐ¼Ð½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°"""
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_context_manager.py:1118:38
     |
1117 |     def _suggest_commands_smart(
1118 |         self, task_type: str, files: List[str], query: str
     |                                      ^^^^
1119 |     ) -> List[str]:
1120 |         """ÐŸÑ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°"""
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_context_manager.py:1119:10
     |
1117 |     def _suggest_commands_smart(
1118 |         self, task_type: str, files: List[str], query: str
1119 |     ) -> List[str]:
     |          ^^^^
1120 |         """ÐŸÑ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÑ‚ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°"""
     |
help: Replace with `list`

ARG002 Unused method argument: `task_type`
    --> scripts/tools/ai_context_manager.py:1165:40
     |
1163 |         return commands
1164 |
1165 |     def _generate_warnings_smart(self, task_type: str, files: List[str]) -> List[str]:
     |                                        ^^^^^^^^^
1166 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ÑƒÐ¼Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ"""
     |

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_context_manager.py:1165:63
     |
1163 |         return commands
1164 |
1165 |     def _generate_warnings_smart(self, task_type: str, files: List[str]) -> List[str]:
     |                                                               ^^^^
1166 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ÑƒÐ¼Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ"""
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_context_manager.py:1165:77
     |
1163 |         return commands
1164 |
1165 |     def _generate_warnings_smart(self, task_type: str, files: List[str]) -> List[str]:
     |                                                                             ^^^^
1166 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ÑƒÐ¼Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ"""
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_context_manager.py:1222:44
     |
1220 |         return warnings
1221 |
1222 |     def _generate_ml_insights(self, files: List[str], query: str) -> List[str]:
     |                                            ^^^^
1223 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ML-Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹"""
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_context_manager.py:1222:70
     |
1220 |         return warnings
1221 |
1222 |     def _generate_ml_insights(self, files: List[str], query: str) -> List[str]:
     |                                                                      ^^^^
1223 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ML-Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹"""
     |
help: Replace with `list`

PTH123 `open()` should be replaced by `Path.open()`
    --> scripts/tools/ai_context_manager.py:1266:14
     |
1264 |         """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ Ð½Ð¾Ð²Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸"""
1265 |         data = {path: asdict(ctx) for path, ctx in self.file_contexts.items()}
1266 |         with open(self.context_file, "w", encoding="utf-8") as f:
     |              ^^^^
1267 |             json.dump(data, f, indent=2, ensure_ascii=False)
     |
help: Replace with `Path.open()`

PLR0911 Too many return statements (10 > 6)
    --> scripts/tools/ai_context_manager.py:1314:9
     |
1312 |         return any(pattern in str(file_path) for pattern in skip_patterns)
1313 |
1314 |     def _determine_category(self, file_path: Path) -> str:
     |         ^^^^^^^^^^^^^^^^^^^
1315 |         """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ Ñ„Ð°Ð¹Ð»Ð°"""
1316 |         path_str = str(file_path).lower()
     |

RET505 [*] Unnecessary `elif` after `return` statement
    --> scripts/tools/ai_context_manager.py:1320:9
     |
1318 |         if "database" in path_str or "postgres" in path_str:
1319 |             return "database"
1320 |         elif "analyzer" in path_str:
     |         ^^^^
1321 |             return "analyzer"
1322 |         elif "cli" in path_str or file_path.name == "main.py":
     |
help: Remove unnecessary `elif`

PTH123 `open()` should be replaced by `Path.open()`
    --> scripts/tools/ai_context_manager.py:1342:18
     |
1340 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð°"""
1341 |         try:
1342 |             with open(file_path, "r", encoding="utf-8") as f:
     |                  ^^^^
1343 |                 first_lines = f.read(500)
     |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
    --> scripts/tools/ai_context_manager.py:1342:34
     |
1340 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ð°"""
1341 |         try:
1342 |             with open(file_path, "r", encoding="utf-8") as f:
     |                                  ^^^
1343 |                 first_lines = f.read(500)
     |
help: Remove mode argument

RET505 [*] Unnecessary `elif` after `return` statement
    --> scripts/tools/ai_context_manager.py:1353:13
     |
1351 |                 )
1352 |                 return docstring.strip()[:100]
1353 |             elif "#" in first_lines:
     |             ^^^^
1354 |                 comment = first_lines.split("\n")[0].replace("#", "").strip()
1355 |                 return comment[:100]
     |
help: Remove unnecessary `elif`

E722 Do not use bare `except`
    --> scripts/tools/ai_context_manager.py:1356:9
     |
1354 |                 comment = first_lines.split("\n")[0].replace("#", "").strip()
1355 |                 return comment[:100]
1356 |         except:
     |         ^^^^^^
1357 |             pass
     |

PTH123 `open()` should be replaced by `Path.open()`
    --> scripts/tools/ai_context_manager.py:1364:18
     |
1362 |         """ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÑ‚Ñ€Ð¾Ðº Ð² Ñ„Ð°Ð¹Ð»Ðµ"""
1363 |         try:
1364 |             with open(file_path, "r", encoding="utf-8") as f:
     |                  ^^^^
1365 |                 return len(f.readlines())
1366 |         except:
     |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
    --> scripts/tools/ai_context_manager.py:1364:34
     |
1362 |         """ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÑ‚Ñ€Ð¾Ðº Ð² Ñ„Ð°Ð¹Ð»Ðµ"""
1363 |         try:
1364 |             with open(file_path, "r", encoding="utf-8") as f:
     |                                  ^^^
1365 |                 return len(f.readlines())
1366 |         except:
     |
help: Remove mode argument

E722 Do not use bare `except`
    --> scripts/tools/ai_context_manager.py:1366:9
     |
1364 |             with open(file_path, "r", encoding="utf-8") as f:
1365 |                 return len(f.readlines())
1366 |         except:
     |         ^^^^^^
1367 |             return 0
     |

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_context_manager.py:1369:57
     |
1367 |             return 0
1368 |
1369 |     def _extract_dependencies(self, file_path: Path) -> List[str]:
     |                                                         ^^^^
1370 |         """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°"""
1371 |         if file_path.suffix != ".py":
     |
help: Replace with `list`

PTH123 `open()` should be replaced by `Path.open()`
    --> scripts/tools/ai_context_manager.py:1375:18
     |
1374 |         try:
1375 |             with open(file_path, "r", encoding="utf-8") as f:
     |                  ^^^^
1376 |                 content = f.read()
     |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
    --> scripts/tools/ai_context_manager.py:1375:34
     |
1374 |         try:
1375 |             with open(file_path, "r", encoding="utf-8") as f:
     |                                  ^^^
1376 |                 content = f.read()
     |
help: Remove mode argument

SIM102 Use a single `if` statement instead of nested `if` statements
    --> scripts/tools/ai_context_manager.py:1385:17
     |
1383 |                       for alias in node.names:
1384 |                           imports.add(alias.name.split(".")[0])
1385 | /                 elif isinstance(node, ast.ImportFrom):
1386 | |                     if node.module:
     | |___________________________________^
1387 |                           imports.add(node.module.split(".")[0])
     |
help: Combine `if` statements using `and`

E722 Do not use bare `except`
    --> scripts/tools/ai_context_manager.py:1390:9
     |
1389 |             return list(imports)
1390 |         except:
     |         ^^^^^^
1391 |             return []
     |

ARG002 Unused method argument: `output_path`
    --> scripts/tools/ai_context_manager.py:1404:39
     |
1402 |         print(f"âœ… Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹: {len(descriptions)}")
1403 |
1404 |     def create_dependency_graph(self, output_path: str = "dependency_graph.dot"):
     |                                       ^^^^^^^^^^^
1405 |         """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð³Ñ€Ð°Ñ„Ð° Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹"""
     |

F841 Local variable `graph_content` is assigned to but never used
    --> scripts/tools/ai_context_manager.py:1410:9
     |
1408 |             self.visualizer = DependencyVisualizer(self.file_contexts)
1409 |
1410 |         graph_content = self.visualizer.generate_dependency_graph()
     |         ^^^^^^^^^^^^^
1411 |         output_file = self.visualizer.save_graph()
1412 |         print(f"ðŸ“Š Ð“Ñ€Ð°Ñ„ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹ ÑÐ¾Ð·Ð´Ð°Ð½: {output_file}")
     |
help: Remove assignment to unused variable `graph_content`

RET505 [*] Unnecessary `elif` after `return` statement
    --> scripts/tools/ai_context_manager.py:1446:5
     |
1444 |     if any(kw in query_lower for kw in debug_keywords):
1445 |         return "debug"
1446 |     elif any(kw in query_lower for kw in develop_keywords):
     |     ^^^^
1447 |         return "develop"
1448 |     elif any(kw in query_lower for kw in analyze_keywords):
     |
help: Remove unnecessary `elif`

PLR0912 Too many branches (16 > 12)
    --> scripts/tools/ai_context_manager.py:1456:5
     |
1456 | def interactive_mode():
     |     ^^^^^^^^^^^^^^^^
1457 |     """Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼"""
1458 |     print("ðŸ¤– AI Context Manager PRO - Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼")
     |

PLR0915 Too many statements (56 > 50)
    --> scripts/tools/ai_context_manager.py:1456:5
     |
1456 | def interactive_mode():
     |     ^^^^^^^^^^^^^^^^
1457 |     """Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼"""
1458 |     print("ðŸ¤– AI Context Manager PRO - Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼")
     |

RET508 [*] Unnecessary `elif` after `break` statement
    --> scripts/tools/ai_context_manager.py:1477:9
     |
1475 |         if choice == "0":
1476 |             break
1477 |         elif choice == "1":
     |         ^^^^
1478 |             query = input("ðŸ” ÐžÐ¿Ð¸ÑˆÐ¸Ñ‚Ðµ Ð·Ð°Ð´Ð°Ñ‡Ñƒ: ").strip()
1479 |             if query:
     |
help: Remove unnecessary `elif`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> scripts/tools/ai_context_manager.py:1490:48
     |
1488 |                     export_context(
1489 |                         context,
1490 |                         f"context_{task_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
     |                                                ^^^^^^^^^^^^^^
1491 |                     )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> scripts/tools/ai_context_manager.py:1536:35
     |
1536 | def print_context_pretty(context: Dict):
     |                                   ^^^^
1537 |     """ÐšÑ€Ð°ÑÐ¸Ð²Ñ‹Ð¹ Ð²Ñ‹Ð²Ð¾Ð´ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°"""
1538 |     print("\n" + "=" * 60)
     |
help: Replace with `dict`

F541 [*] f-string without any placeholders
    --> scripts/tools/ai_context_manager.py:1550:15
     |
1549 |     if context.get("semantic_matches"):
1550 |         print(f"\nðŸ§  Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1551 |         for path, score in context["semantic_matches"]:
1552 |             filename = Path(path).name
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> scripts/tools/ai_context_manager.py:1555:11
     |
1553 |             print(f"  â€¢ {filename} (relevance: {score:.3f})")
1554 |
1555 |     print(f"\nðŸ’¡ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÐ¼Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹:")
     |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1556 |     for i, cmd in enumerate(context["suggested_commands"][:5], 1):
1557 |         print(f"  {i}. {cmd}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> scripts/tools/ai_context_manager.py:1559:11
     |
1557 |         print(f"  {i}. {cmd}")
1558 |
1559 |     print(f"\nâš ï¸ ÐŸÑ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ:")
     |           ^^^^^^^^^^^^^^^^^^^^^^
1560 |     for warning in context["warnings"][:3]:
1561 |         print(f"  â€¢ {warning}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> scripts/tools/ai_context_manager.py:1564:15
     |
1563 |     if context.get("ml_insights"):
1564 |         print(f"\nðŸš€ ML Ð˜Ð½ÑÐ°Ð¹Ñ‚Ñ‹:")
     |               ^^^^^^^^^^^^^^^^^^^
1565 |         for insight in context["ml_insights"]:
1566 |             print(f"  â€¢ {insight}")
     |
help: Remove extraneous `f` prefix

B007 Loop control variable `path` not used within loop body
    --> scripts/tools/ai_context_manager.py:1580:9
     |
1578 |     recent_count = 0
1579 |
1580 |     for path, ctx in manager.file_contexts.items():
     |         ^^^^
1581 |         categories[ctx.category].append(ctx)
1582 |         total_complexity += ctx.complexity_score
     |
help: Rename unused `path` to `_path`

PERF102 When using only the values of a dict use the `values()` method
    --> scripts/tools/ai_context_manager.py:1580:22
     |
1578 |     recent_count = 0
1579 |
1580 |     for path, ctx in manager.file_contexts.items():
     |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
1581 |         categories[ctx.category].append(ctx)
1582 |         total_complexity += ctx.complexity_score
     |
help: Replace `.items()` with `.values()`

F541 [*] f-string without any placeholders
    --> scripts/tools/ai_context_manager.py:1593:11
     |
1591 |     print(f"ðŸ§® Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ: {total_complexity / len(manager.file_contexts):.1f}")
1592 |
1593 |     print(f"\nðŸ“‚ Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑÐ¼:")
     |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1594 |     for category, contexts in categories.items():
1595 |         avg_priority = sum(ctx.priority for ctx in contexts) / len(contexts)
     |
help: Remove extraneous `f` prefix

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> scripts/tools/ai_context_manager.py:1601:29
     |
1601 | def export_context(context: Dict, filename: str):
     |                             ^^^^
1602 |     """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð² Ñ„Ð°Ð¹Ð»"""
1603 |     try:
     |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
    --> scripts/tools/ai_context_manager.py:1607:14
     |
1605 |         output_path.parent.mkdir(exist_ok=True)
1606 |
1607 |         with open(output_path, "w", encoding="utf-8") as f:
     |              ^^^^
1608 |             json.dump(context, f, indent=2, ensure_ascii=False)
     |
help: Replace with `Path.open()`

PLR1722 Use `sys.exit()` instead of `exit`
    --> scripts/tools/ai_context_manager.py:1721:9
     |
1719 |     if args.interactive:
1720 |         interactive_mode()
1721 |         exit()
     |         ^^^^
1722 |
1723 |     # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€
     |
help: Replace `exit` with `sys.exit()`

PLR1722 Use `sys.exit()` instead of `exit`
    --> scripts/tools/ai_context_manager.py:1735:9
     |
1733 |     except Exception as e:
1734 |         print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸: {e}")
1735 |         exit(1)
     |         ^^^^
1736 |
1737 |     # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÐºÐµÑˆÐ°
     |
help: Replace `exit` with `sys.exit()`

PLR1722 Use `sys.exit()` instead of `exit`
    --> scripts/tools/ai_context_manager.py:1743:9
     |
1741 |         manager.save_context()
1742 |         print("âœ… ÐšÐµÑˆ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½!")
1743 |         exit()
     |         ^^^^
1744 |
1745 |     # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
     |
help: Replace `exit` with `sys.exit()`

PLR1722 Use `sys.exit()` instead of `exit`
    --> scripts/tools/ai_context_manager.py:1748:9
     |
1746 |     if args.stats:
1747 |         print_project_stats(manager)
1748 |         exit()
     |         ^^^^
1749 |
1750 |     # Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº
     |
help: Replace `exit` with `sys.exit()`

PLR1722 Use `sys.exit()` instead of `exit`
    --> scripts/tools/ai_context_manager.py:1754:13
     |
1752 |         if not ML_AVAILABLE:
1753 |             print("âŒ Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½ - ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ scikit-learn")
1754 |             exit(1)
     |             ^^^^
1755 |
1756 |         print(f"ðŸ§  Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº: '{args.semantic_search}'")
     |
help: Replace `exit` with `sys.exit()`

PLR1722 Use `sys.exit()` instead of `exit`
    --> scripts/tools/ai_context_manager.py:1766:9
     |
1764 |         else:
1765 |             print("ðŸ¤· Ð ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹")
1766 |         exit()
     |         ^^^^
1767 |
1768 |     # Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ project analyzer
     |
help: Replace `exit` with `sys.exit()`

PLR1722 Use `sys.exit()` instead of `exit`
    --> scripts/tools/ai_context_manager.py:1778:9
     |
1776 |         else:
1777 |             print("âŒ Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð°ÑÑŒ")
1778 |         exit()
     |         ^^^^
1779 |
1780 |     # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ñ… Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÐµÐ¹
     |
help: Replace `exit` with `sys.exit()`

PLR1722 Use `sys.exit()` instead of `exit`
    --> scripts/tools/ai_context_manager.py:1790:9
     |
1788 |         print("ðŸ¤– Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ AI Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹...")
1789 |         manager.generate_llm_descriptions()
1790 |         exit()
     |         ^^^^
1791 |
1792 |     # Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹
     |
help: Replace `exit` with `sys.exit()`

PLR1722 Use `sys.exit()` instead of `exit`
    --> scripts/tools/ai_context_manager.py:1797:9
     |
1795 |         output_file = manager.create_dependency_graph()
1796 |         print(f"ðŸ“ Ð“Ñ€Ð°Ñ„ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½: {output_file}")
1797 |         exit()
     |         ^^^^
1798 |
1799 |     # Ð—Ð°Ð¿ÑƒÑÐº API ÑÐµÑ€Ð²ÐµÑ€Ð°
     |
help: Replace `exit` with `sys.exit()`

PLR1722 Use `sys.exit()` instead of `exit`
    --> scripts/tools/ai_context_manager.py:1803:9
     |
1801 |         print("ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº API ÑÐµÑ€Ð²ÐµÑ€Ð°...")
1802 |         manager.start_api_server(args.api_host, args.api_port)
1803 |         exit()
     |         ^^^^
1804 |
1805 |     # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
     |
help: Replace `exit` with `sys.exit()`

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/tools/ai_project_analyzer.py:28:1
   |
26 |   """
27 |
28 | / import os
29 | | import ast
30 | | import json
31 | | import sqlite3
32 | | import subprocess
33 | | import sys
34 | | import pickle
35 | | import time
36 | | import re
37 | | from pathlib import Path
38 | | from collections import defaultdict, Counter
39 | | from dataclasses import dataclass
40 | | from typing import Dict, List, Set, Tuple, Optional
41 | | import hashlib
   | |______________^
   |
help: Organize imports

F401 [*] `os` imported but unused
  --> scripts/tools/ai_project_analyzer.py:28:8
   |
26 | """
27 |
28 | import os
   |        ^^
29 | import ast
30 | import json
   |
help: Remove unused import: `os`

F401 [*] `sqlite3` imported but unused
  --> scripts/tools/ai_project_analyzer.py:31:8
   |
29 | import ast
30 | import json
31 | import sqlite3
   |        ^^^^^^^
32 | import subprocess
33 | import sys
   |
help: Remove unused import: `sqlite3`

F401 [*] `collections.Counter` imported but unused
  --> scripts/tools/ai_project_analyzer.py:38:38
   |
36 | import re
37 | from pathlib import Path
38 | from collections import defaultdict, Counter
   |                                      ^^^^^^^
39 | from dataclasses import dataclass
40 | from typing import Dict, List, Set, Tuple, Optional
   |
help: Remove unused import: `collections.Counter`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/tools/ai_project_analyzer.py:40:1
   |
38 | from collections import defaultdict, Counter
39 | from dataclasses import dataclass
40 | from typing import Dict, List, Set, Tuple, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
41 | import hashlib
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/tools/ai_project_analyzer.py:40:1
   |
38 | from collections import defaultdict, Counter
39 | from dataclasses import dataclass
40 | from typing import Dict, List, Set, Tuple, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
41 | import hashlib
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> scripts/tools/ai_project_analyzer.py:40:1
   |
38 | from collections import defaultdict, Counter
39 | from dataclasses import dataclass
40 | from typing import Dict, List, Set, Tuple, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
41 | import hashlib
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/tools/ai_project_analyzer.py:40:1
   |
38 | from collections import defaultdict, Counter
39 | from dataclasses import dataclass
40 | from typing import Dict, List, Set, Tuple, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
41 | import hashlib
   |

F401 [*] `typing.Set` imported but unused
  --> scripts/tools/ai_project_analyzer.py:40:32
   |
38 | from collections import defaultdict, Counter
39 | from dataclasses import dataclass
40 | from typing import Dict, List, Set, Tuple, Optional
   |                                ^^^
41 | import hashlib
   |
help: Remove unused import

F401 [*] `typing.Tuple` imported but unused
  --> scripts/tools/ai_project_analyzer.py:40:37
   |
38 | from collections import defaultdict, Counter
39 | from dataclasses import dataclass
40 | from typing import Dict, List, Set, Tuple, Optional
   |                                     ^^^^^
41 | import hashlib
   |
help: Remove unused import

UP006 [*] Use `list` instead of `List` for type annotation
  --> scripts/tools/ai_project_analyzer.py:48:16
   |
46 |     file_path: str
47 |     lines_of_code: int
48 |     functions: List[str]
   |                ^^^^
49 |     classes: List[str]
50 |     imports: List[str]
   |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
  --> scripts/tools/ai_project_analyzer.py:49:14
   |
47 |     lines_of_code: int
48 |     functions: List[str]
49 |     classes: List[str]
   |              ^^^^
50 |     imports: List[str]
51 |     complexity_score: float
   |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
  --> scripts/tools/ai_project_analyzer.py:50:14
   |
48 |     functions: List[str]
49 |     classes: List[str]
50 |     imports: List[str]
   |              ^^^^
51 |     complexity_score: float
52 |     last_modified: float
   |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
  --> scripts/tools/ai_project_analyzer.py:59:12
   |
57 | @dataclass
58 | class DuplicationResult:
59 |     files: List[str]
   |            ^^^^
60 |     similarity: float
61 |     common_functions: List[str]
   |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
  --> scripts/tools/ai_project_analyzer.py:61:23
   |
59 |     files: List[str]
60 |     similarity: float
61 |     common_functions: List[str]
   |                       ^^^^
   |
help: Replace with `list`

PLR0912 Too many branches (13 > 12)
  --> scripts/tools/ai_project_analyzer.py:71:9
   |
69 |         self.security_issues = []
70 |
71 |     def find_security_issues(self, file_metrics: Dict) -> List[str]:
   |         ^^^^^^^^^^^^^^^^^^^^
72 |         """ÐŸÐ¾Ð¸ÑÐº Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ Ð² ÐºÐ¾Ð´Ðµ"""
   |

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> scripts/tools/ai_project_analyzer.py:71:50
   |
69 |         self.security_issues = []
70 |
71 |     def find_security_issues(self, file_metrics: Dict) -> List[str]:
   |                                                  ^^^^
72 |         """ÐŸÐ¾Ð¸ÑÐº Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ Ð² ÐºÐ¾Ð´Ðµ"""
   |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
  --> scripts/tools/ai_project_analyzer.py:71:59
   |
69 |         self.security_issues = []
70 |
71 |     def find_security_issues(self, file_metrics: Dict) -> List[str]:
   |                                                           ^^^^
72 |         """ÐŸÐ¾Ð¸ÑÐº Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ Ð² ÐºÐ¾Ð´Ðµ"""
   |
help: Replace with `list`

B007 Loop control variable `metrics` not used within loop body
  --> scripts/tools/ai_project_analyzer.py:76:24
   |
74 |         issues = []
75 |
76 |         for file_path, metrics in file_metrics.items():
   |                        ^^^^^^^
77 |             try:
78 |                 with open(file_path, "r", encoding="utf-8") as f:
   |
help: Rename unused `metrics` to `_metrics`

PERF102 When using only the keys of a dict use the `keys()` method
  --> scripts/tools/ai_project_analyzer.py:76:35
   |
74 |         issues = []
75 |
76 |         for file_path, metrics in file_metrics.items():
   |                                   ^^^^^^^^^^^^^^^^^^
77 |             try:
78 |                 with open(file_path, "r", encoding="utf-8") as f:
   |
help: Replace `.items()` with `.keys()`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/tools/ai_project_analyzer.py:78:22
   |
76 |         for file_path, metrics in file_metrics.items():
77 |             try:
78 |                 with open(file_path, "r", encoding="utf-8") as f:
   |                      ^^^^
79 |                     content = f.read()
   |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
  --> scripts/tools/ai_project_analyzer.py:78:38
   |
76 |         for file_path, metrics in file_metrics.items():
77 |             try:
78 |                 with open(file_path, "r", encoding="utf-8") as f:
   |                                      ^^^
79 |                     content = f.read()
   |
help: Remove mode argument

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/tools/ai_project_analyzer.py:115:17
    |
114 |                   # Insecure random
115 | /                 if re.search(r"import random\b", content) and re.search(
116 | |                     r"random\.(choice|randint|random)", content
117 | |                 ):
118 | |                     if "password" in content.lower() or "token" in content.lower():
    | |___________________________________________________________________________________^
119 |                           issues.append(f"ðŸŽ² Insecure random for security in {file_path}")
    |
help: Combine `if` statements using `and`

F841 [*] Local variable `e` is assigned to but never used
   --> scripts/tools/ai_project_analyzer.py:132:33
    |
130 |                         break
131 |
132 |             except Exception as e:
    |                                 ^
133 |                 continue
    |
help: Remove assignment to unused variable `e`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_project_analyzer.py:145:53
    |
143 |         self.performance_issues = []
144 |
145 |     def find_performance_issues(self, file_metrics: Dict) -> List[str]:
    |                                                     ^^^^
146 |         """ÐŸÐ¾Ð¸ÑÐº Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð² ÐºÐ¾Ð´Ðµ"""
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_project_analyzer.py:145:62
    |
143 |         self.performance_issues = []
144 |
145 |     def find_performance_issues(self, file_metrics: Dict) -> List[str]:
    |                                                              ^^^^
146 |         """ÐŸÐ¾Ð¸ÑÐº Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð² ÐºÐ¾Ð´Ðµ"""
    |
help: Replace with `list`

B007 Loop control variable `metrics` not used within loop body
   --> scripts/tools/ai_project_analyzer.py:150:24
    |
148 |         issues = []
149 |
150 |         for file_path, metrics in file_metrics.items():
    |                        ^^^^^^^
151 |             try:
152 |                 with open(file_path, "r", encoding="utf-8") as f:
    |
help: Rename unused `metrics` to `_metrics`

PERF102 When using only the keys of a dict use the `keys()` method
   --> scripts/tools/ai_project_analyzer.py:150:35
    |
148 |         issues = []
149 |
150 |         for file_path, metrics in file_metrics.items():
    |                                   ^^^^^^^^^^^^^^^^^^
151 |             try:
152 |                 with open(file_path, "r", encoding="utf-8") as f:
    |
help: Replace `.items()` with `.keys()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_project_analyzer.py:152:22
    |
150 |         for file_path, metrics in file_metrics.items():
151 |             try:
152 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                      ^^^^
153 |                     content = f.read()
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/tools/ai_project_analyzer.py:152:38
    |
150 |         for file_path, metrics in file_metrics.items():
151 |             try:
152 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                                      ^^^
153 |                     content = f.read()
    |
help: Remove mode argument

PERF401 Use `list.extend` to create a transformed list
   --> scripts/tools/ai_project_analyzer.py:171:21
    |
169 |                   inefficient_ops = self._find_inefficient_loop_operations(tree, content)
170 |                   for op in inefficient_ops:
171 | /                     issues.append(
172 | |                         f"âš¡ Inefficient operation in loop: {op} in {file_path}"
173 | |                     )
    | |_____________________^
174 |
175 |                   # ÐŸÐ¾Ð¸ÑÐº Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² Ð² Ð¿Ð°Ð¼ÑÑ‚Ð¸
    |
help: Replace for loop with list.extend

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/tools/ai_project_analyzer.py:183:13
    |
181 |                       issues.append(f"â³ Synchronous I/O in loops in {file_path}")
182 |
183 | /             except Exception as e:
184 | |                 continue
    | |________________________^
185 |
186 |           return issues
    |

F841 [*] Local variable `e` is assigned to but never used
   --> scripts/tools/ai_project_analyzer.py:183:33
    |
181 |                     issues.append(f"â³ Synchronous I/O in loops in {file_path}")
182 |
183 |             except Exception as e:
    |                                 ^
184 |                 continue
    |
help: Remove assignment to unused variable `e`

ARG002 Unused method argument: `content`
   --> scripts/tools/ai_project_analyzer.py:205:54
    |
203 |         return max_depth
204 |
205 |     def _has_n_plus_one_pattern(self, tree: ast.AST, content: str) -> bool:
    |                                                      ^^^^^^^
206 |         """Ð˜Ñ‰ÐµÑ‚ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ N+1 Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²"""
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/tools/ai_project_analyzer.py:213:21
    |
211 |                   # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ SQL Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð² Ñ‚ÐµÐ»Ðµ Ñ†Ð¸ÐºÐ»Ð°
212 |                   for child in ast.walk(node):
213 | /                     if isinstance(child, ast.Call):
214 | |                         if isinstance(
215 | |                             child.func, ast.Attribute
216 | |                         ) and child.func.attr in ["execute", "query", "get", "filter"]:
    | |_______________________________________________________________________________________^
217 |                               return True
    |
help: Combine `if` statements using `and`

ARG002 Unused method argument: `content`
   --> scripts/tools/ai_project_analyzer.py:231:30
    |
230 |     def _find_inefficient_loop_operations(
231 |         self, tree: ast.AST, content: str
    |                              ^^^^^^^
232 |     ) -> List[str]:
233 |         """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð½ÐµÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð² Ñ†Ð¸ÐºÐ»Ð°Ñ…"""
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/ai_project_analyzer.py:232:10
    |
230 |     def _find_inefficient_loop_operations(
231 |         self, tree: ast.AST, content: str
232 |     ) -> List[str]:
    |          ^^^^
233 |         """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð½ÐµÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð² Ñ†Ð¸ÐºÐ»Ð°Ñ…"""
234 |         issues = []
    |
help: Replace with `list`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/tools/ai_project_analyzer.py:241:25
    |
239 |                   for child in ast.walk(node):
240 |                       if isinstance(child, ast.Call):
241 | /                         if isinstance(
242 | |                             child.func, ast.Attribute
243 | |                         ) and child.func.attr in ["append", "extend", "insert"]:
244 | |                             # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð»Ð¸ list.append Ð² Ñ†Ð¸ÐºÐ»Ðµ
245 | |                             if "append" in ast.dump(child):
    | |___________________________________________________________^
246 |                                   issues.append(
247 |                                       "list.append() in loop (consider list comprehension)"
    |
help: Combine `if` statements using `and`

SIM110 Use `return any(re.search(pattern, content) for pattern in memory_patterns)` instead of `for` loop
   --> scripts/tools/ai_project_analyzer.py:274:9
    |
272 |           ]
273 |
274 | /         for pattern in memory_patterns:
275 | |             if re.search(pattern, content):
276 | |                 return True
277 | |
278 | |         return False
    | |____________________^
279 |
280 |       def _has_sync_io_in_loops(self, tree: ast.AST, content: str) -> bool:
    |
help: Replace with `return any(re.search(pattern, content) for pattern in memory_patterns)`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_project_analyzer.py:310:50
    |
308 |         self.file_hotspots = {}
309 |
310 |     def analyze_git_patterns(self, file_metrics: Dict) -> Dict:
    |                                                  ^^^^
311 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð² git Ð´Ð»Ñ Ð²Ñ‹ÑÐ²Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ñ… Ð·Ð¾Ð½"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_project_analyzer.py:310:59
    |
308 |         self.file_hotspots = {}
309 |
310 |     def analyze_git_patterns(self, file_metrics: Dict) -> Dict:
    |                                                           ^^^^
311 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð² git Ð´Ð»Ñ Ð²Ñ‹ÑÐ²Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ñ… Ð·Ð¾Ð½"""
    |
help: Replace with `dict`

SIM118 [*] Use `key in dict` instead of `key in dict.keys()`
   --> scripts/tools/ai_project_analyzer.py:320:13
    |
318 |         }
319 |
320 |         for file_path in file_metrics.keys():
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
321 |             try:
322 |                 # ÐÐ½Ð°Ð»Ð¸Ð· Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹
    |
help: Remove `.keys()`

RUF015 Prefer `next(iter(authors.keys()))` over single element slice
   --> scripts/tools/ai_project_analyzer.py:339:44
    |
337 |                         {
338 |                             "file": file_path,
339 |                             "sole_author": list(authors.keys())[0],
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^
340 |                             "changes": change_count,
341 |                             "risk_level": "HIGH" if change_count > 30 else "MEDIUM",
    |
help: Replace with `next(iter(authors.keys()))`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/tools/ai_project_analyzer.py:354:13
    |
352 |                   results["change_frequency"][file_path] = change_count
353 |
354 | /             except Exception as e:
355 | |                 continue
    | |________________________^
356 |
357 |           return results
    |

F841 [*] Local variable `e` is assigned to but never used
   --> scripts/tools/ai_project_analyzer.py:354:33
    |
352 |                 results["change_frequency"][file_path] = change_count
353 |
354 |             except Exception as e:
    |                                 ^
355 |                 continue
    |
help: Remove assignment to unused variable `e`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/tools/ai_project_analyzer.py:362:22
    |
360 |         """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹ Ñ„Ð°Ð¹Ð»Ð° Ð¸Ð· git log"""
361 |         try:
362 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
363 |                 ["git", "log", "--oneline", "--", file_path],
364 |                 cwd=self.project_root,
    |
help: Add explicit `check=False`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_project_analyzer.py:381:52
    |
379 |         return 0
380 |
381 |     def _get_file_authors(self, file_path: str) -> Dict[str, int]:
    |                                                    ^^^^
382 |         """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð°Ð²Ñ‚Ð¾Ñ€Ð¾Ð² Ð¿Ð¾ Ñ„Ð°Ð¹Ð»Ñƒ"""
383 |         authors = {}
    |
help: Replace with `dict`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/tools/ai_project_analyzer.py:386:22
    |
385 |         try:
386 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
387 |                 ["git", "blame", "--line-porcelain", file_path],
388 |                 cwd=self.project_root,
    |
help: Add explicit `check=False`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_project_analyzer.py:421:52
    |
419 |         self.output_dir.mkdir(exist_ok=True, parents=True)
420 |
421 |     def generate_dashboard(self, analysis_results: Dict) -> Path:
    |                                                    ^^^^
422 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ HTML dashboard"""
    |
help: Replace with `dict`

I001 [*] Import block is un-sorted or un-formatted
   --> scripts/tools/ai_project_analyzer.py:425:13
    |
424 |           try:
425 | /             import plotly.graph_objects as go
426 | |             from plotly.subplots import make_subplots
427 | |             import plotly.express as px
    | |_______________________________________^
428 |           except ImportError:
429 |               print("âš ï¸ Plotly Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ: pip install plotly")
    |
help: Organize imports

F401 `plotly.express` imported but unused; consider using `importlib.util.find_spec` to test for availability
   --> scripts/tools/ai_project_analyzer.py:427:38
    |
425 |             import plotly.graph_objects as go
426 |             from plotly.subplots import make_subplots
427 |             import plotly.express as px
    |                                      ^^
428 |         except ImportError:
429 |             print("âš ï¸ Plotly Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ: pip install plotly")
    |
help: Remove unused import: `plotly.express`

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> scripts/tools/ai_project_analyzer.py:527:57
    |
525 |             )
526 |             if coupling_scores:
527 |                 x_vals = [coupling_scores.get(f, 0) for f in metrics.keys()]
    |                                                         ^^^^^^^^^^^^^^^^^^^
528 |                 y_vals = list(metrics.values())
    |
help: Remove `.keys()`

C408 Unnecessary `dict()` call (rewrite as a literal)
   --> scripts/tools/ai_project_analyzer.py:536:32
    |
534 |                           mode="markers",
535 |                           name="Ð¤Ð°Ð¹Ð»Ñ‹",
536 |                           marker=dict(
    |  ________________________________^
537 | |                             size=10, color=y_vals, colorscale="Reds", showscale=True
538 | |                         ),
    | |_________________________^
539 |                       ),
540 |                       row=3,
    |
help: Rewrite as a literal

C408 Unnecessary `dict()` call (rewrite as a literal)
   --> scripts/tools/ai_project_analyzer.py:560:24
    |
558 |           fig.add_trace(
559 |               go.Table(
560 |                   header=dict(
    |  ________________________^
561 | |                     values=["ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°", "Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ"], fill_color="lightblue", align="left"
562 | |                 ),
    | |_________________^
563 |                   cells=dict(
564 |                       values=[
    |
help: Rewrite as a literal

C408 Unnecessary `dict()` call (rewrite as a literal)
   --> scripts/tools/ai_project_analyzer.py:563:23
    |
561 |                       values=["ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°", "Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ"], fill_color="lightblue", align="left"
562 |                   ),
563 |                   cells=dict(
    |  _______________________^
564 | |                     values=[
565 | |                         [row[0] for row in stats_data],
566 | |                         [row[1] for row in stats_data],
567 | |                     ],
568 | |                     fill_color="white",
569 | |                     align="left",
570 | |                 ),
    | |_________________^
571 |               ),
572 |               row=3,
    |
help: Rewrite as a literal

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_project_analyzer.py:602:60
    |
600 |         return report_file
601 |
602 |     def _generate_simple_dashboard(self, analysis_results: Dict) -> Path:
    |                                                            ^^^^
603 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ HTML Ð¾Ñ‚Ñ‡ÐµÑ‚ Ð±ÐµÐ· Plotly"""
    |
help: Replace with `dict`

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:652:1
    |
650 |                     <p>ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ AI</p>
651 |                 </div>
652 |                 
    | ^^^^^^^^^^^^^^^^
653 |                 <div class="metrics">
654 |                     <div class="metric-card">
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:671:1
    |
669 |                     </div>
670 |                 </div>
671 |                 
    | ^^^^^^^^^^^^^^^^
672 |                 <div class="issues-section">
673 |                     <h2>ðŸ” Ð’Ñ‹ÑÐ²Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹</h2>
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:674:1
    |
672 |                 <div class="issues-section">
673 |                     <h2>ðŸ” Ð’Ñ‹ÑÐ²Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹</h2>
674 |                     
    | ^^^^^^^^^^^^^^^^^^^^
675 |                     <div class="issue-type">
676 |                         <h3>ðŸ”’ ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸: {len(analysis_results.get("security_issues", []))}</h3>
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:681:1
    |
679 | â€¦         </ul>
680 | â€¦     </div>
681 | â€¦     
^^^^^^^^^^^^
682 | â€¦     <div class="issue-type">
683 | â€¦         <h3>âš¡ ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸: {len(analysis_results.get("performance_issues", []))}</h3>
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:688:1
    |
686 | â€¦         </ul>
687 | â€¦     </div>
688 | â€¦     
^^^^^^^^^^^^
689 | â€¦     <div class="issue-type">
690 | â€¦         <h3>ðŸ—ï¸ ÐÐ°Ñ€ÑƒÑˆÐµÐ½Ð¸Ñ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹: {len(analysis_results.get("architecture_violations", []))}</h3>
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:696:1
    |
694 |                     </div>
695 |                 </div>
696 |                 
    | ^^^^^^^^^^^^^^^^
697 |                 <div class="recommendations">
698 |                     <h2>ðŸ’¡ AI Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸</h2>
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:703:1
    |
701 |                     </ul>
702 |                 </div>
703 |                 
    | ^^^^^^^^^^^^^^^^
704 |                 <div style="text-align: center; margin-top: 30px; color: #666;">
705 |                     <p>ÐžÑ‚Ñ‡ÐµÑ‚ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½ AI Project Analyzer</p>
    |
help: Remove whitespace from blank line

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_project_analyzer.py:718:73
    |
716 |         return report_file
717 |
718 |     def _create_html_template(self, plotly_html: str, analysis_results: Dict) -> str:
    |                                                                         ^^^^
719 |         """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ HTML ÑˆÐ°Ð±Ð»Ð¾Ð½ Ñ Plotly Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ°Ð¼Ð¸"""
    |
help: Replace with `dict`

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:803:1
    |
801 |                     <p>ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¼Ð¸ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ°Ð¼Ð¸</p>
802 |                 </div>
803 |                 
    | ^^^^^^^^^^^^^^^^
804 |                 <div class="content">
805 |                     <div class="summary-cards">
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:823:1
    |
821 |                         </div>
822 |                     </div>
823 |                     
    | ^^^^^^^^^^^^^^^^^^^^
824 |                     {plotly_html}
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:825:1
    |
824 |                     {plotly_html}
825 |                     
    | ^^^^^^^^^^^^^^^^^^^^
826 |                     <div class="issues-grid">
827 |                         <div class="issue-card">
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:833:1
    |
831 |                             </ul>
832 |                         </div>
833 |                         
    | ^^^^^^^^^^^^^^^^^^^^^^^^
834 |                         <div class="issue-card">
835 |                             <div class="issue-title">âš¡ ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸</div>
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:840:1
    |
838 |                             </ul>
839 |                         </div>
840 |                         
    | ^^^^^^^^^^^^^^^^^^^^^^^^
841 |                         <div class="issue-card">
842 |                             <div class="issue-title">ðŸ—ï¸ ÐÐ°Ñ€ÑƒÑˆÐµÐ½Ð¸Ñ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹</div>
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> scripts/tools/ai_project_analyzer.py:847:1
    |
845 |                             </ul>
846 |                         </div>
847 |                         
    | ^^^^^^^^^^^^^^^^^^^^^^^^
848 |                         <div class="issue-card">
849 |                             <div class="issue-title">ðŸ’¡ AI Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸</div>
    |
help: Remove whitespace from blank line

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_project_analyzer.py:895:34
    |
893 |         }
894 |
895 |     def analyze_project(self) -> Dict:
    |                                  ^^^^
896 |         """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"""
897 |         print("ðŸ” Ð—Ð°Ð¿ÑƒÑÐº Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°...")
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_project_analyzer.py:927:37
    |
925 |         return self._generate_report(security_issues, performance_issues, git_patterns)
926 |
927 |     def analyze_with_cache(self) -> Dict:
    |                                     ^^^^
928 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ñ ÐºÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"""
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_project_analyzer.py:933:22
    |
931 |         if self.cache_file.exists():
932 |             try:
933 |                 with open(self.cache_file, "rb") as f:
    |                      ^^^^
934 |                     cached_data = pickle.load(f)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_project_analyzer.py:949:18
    |
947 |         # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² ÐºÐµÑˆ
948 |         try:
949 |             with open(self.cache_file, "wb") as f:
    |                  ^^^^
950 |                 pickle.dump({"timestamp": time.time(), "results": results}, f)
951 |             print("ðŸ’¾ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹")
    |
help: Replace with `Path.open()`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/ai_project_analyzer.py:957:45
    |
955 |         return results
956 |
957 |     def export_for_context_manager(self) -> Dict:
    |                                             ^^^^
958 |         """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ AI Context Manager"""
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/ai_project_analyzer.py:992:22
    |
991 |             try:
992 |                 with open(py_file, "r", encoding="utf-8") as f:
    |                      ^^^^
993 |                     content = f.read()
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/tools/ai_project_analyzer.py:992:36
    |
991 |             try:
992 |                 with open(py_file, "r", encoding="utf-8") as f:
    |                                    ^^^
993 |                     content = f.read()
    |
help: Remove mode argument

B007 Loop control variable `func_hash` not used within loop body
    --> scripts/tools/ai_project_analyzer.py:1025:13
     |
1024 |         # Ð˜Ñ‰ÐµÐ¼ Ñ„Ð°Ð¹Ð»Ñ‹ Ñ Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ð¼Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑÐ¼Ð¸
1025 |         for func_hash, file_func_pairs in function_hashes.items():
     |             ^^^^^^^^^
1026 |             if len(file_func_pairs) > 1:
1027 |                 files = [pair[0] for pair in file_func_pairs]
     |
help: Rename unused `func_hash` to `_func_hash`

SIM118 Use `key in dict` instead of `key in dict.keys()`
    --> scripts/tools/ai_project_analyzer.py:1051:13
     |
1050 |         # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
1051 |         for file_path in self.metrics.keys():
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1052 |             file_stem = Path(file_path).stem
1053 |             if file_stem not in all_imports and not self._is_entry_point(file_path):
     |
help: Remove `.keys()`

SIM102 Use a single `if` statement instead of nested `if` statements
    --> scripts/tools/ai_project_analyzer.py:1053:13
     |
1051 |           for file_path in self.metrics.keys():
1052 |               file_stem = Path(file_path).stem
1053 | /             if file_stem not in all_imports and not self._is_entry_point(file_path):
1054 | |                 # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· grep
1055 | |                 if not self._is_referenced_in_project(file_stem):
     | |_________________________________________________________________^
1056 |                       self.unused_files.add(file_path)
     |
help: Combine `if` statements using `and`

SIM102 Use a single `if` statement instead of nested `if` statements
    --> scripts/tools/ai_project_analyzer.py:1065:17
     |
1063 |               # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸Ñ ÑÐ»Ð¾ÐµÐ²
1064 |               for imp in metrics.imports:
1065 | /                 if layer == "models" and "database" in imp:
1066 | |                     if not any(
1067 | |                         allowed in file_path for allowed in ["adapter", "interface"]
1068 | |                     ):
     | |______________________^
1069 |                           self.architecture_violations.append(
1070 |                               f"ðŸ—ï¸ Models layer accessing database directly: {file_path} -> {imp}"
     |
help: Combine `if` statements using `and`

UP045 [*] Use `X | None` for type annotations
    --> scripts/tools/ai_project_analyzer.py:1106:26
     |
1104 |     def _generate_report(
1105 |         self,
1106 |         security_issues: Optional[List[str]] = None,
     |                          ^^^^^^^^^^^^^^^^^^^
1107 |         performance_issues: Optional[List[str]] = None,
1108 |         git_patterns: Optional[Dict] = None,
     |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_project_analyzer.py:1106:35
     |
1104 |     def _generate_report(
1105 |         self,
1106 |         security_issues: Optional[List[str]] = None,
     |                                   ^^^^
1107 |         performance_issues: Optional[List[str]] = None,
1108 |         git_patterns: Optional[Dict] = None,
     |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
    --> scripts/tools/ai_project_analyzer.py:1107:29
     |
1105 |         self,
1106 |         security_issues: Optional[List[str]] = None,
1107 |         performance_issues: Optional[List[str]] = None,
     |                             ^^^^^^^^^^^^^^^^^^^
1108 |         git_patterns: Optional[Dict] = None,
1109 |     ) -> Dict:
     |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_project_analyzer.py:1107:38
     |
1105 |         self,
1106 |         security_issues: Optional[List[str]] = None,
1107 |         performance_issues: Optional[List[str]] = None,
     |                                      ^^^^
1108 |         git_patterns: Optional[Dict] = None,
1109 |     ) -> Dict:
     |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
    --> scripts/tools/ai_project_analyzer.py:1108:23
     |
1106 |         security_issues: Optional[List[str]] = None,
1107 |         performance_issues: Optional[List[str]] = None,
1108 |         git_patterns: Optional[Dict] = None,
     |                       ^^^^^^^^^^^^^^
1109 |     ) -> Dict:
1110 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚"""
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> scripts/tools/ai_project_analyzer.py:1108:32
     |
1106 |         security_issues: Optional[List[str]] = None,
1107 |         performance_issues: Optional[List[str]] = None,
1108 |         git_patterns: Optional[Dict] = None,
     |                                ^^^^
1109 |     ) -> Dict:
1110 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚"""
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> scripts/tools/ai_project_analyzer.py:1109:10
     |
1107 |         performance_issues: Optional[List[str]] = None,
1108 |         git_patterns: Optional[Dict] = None,
1109 |     ) -> Dict:
     |          ^^^^
1110 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚"""
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_project_analyzer.py:1149:47
     |
1147 |         }
1148 |
1149 |     def _generate_ai_recommendations(self) -> List[str]:
     |                                               ^^^^
1150 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ AI Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
1151 |         recommendations = []
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_project_analyzer.py:1197:52
     |
1195 |         return any(pattern in str(file_path) for pattern in skip_patterns)
1196 |
1197 |     def _extract_functions(self, tree: ast.AST) -> List[str]:
     |                                                    ^^^^
1198 |         """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¸Ð¼ÐµÐ½Ð° Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¹ Ð¸Ð· AST"""
1199 |         functions = []
     |
help: Replace with `list`

PERF401 Use a list comprehension to create a transformed list
    --> scripts/tools/ai_project_analyzer.py:1202:17
     |
1200 |         for node in ast.walk(tree):
1201 |             if isinstance(node, ast.FunctionDef):
1202 |                 functions.append(node.name)
     |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
1203 |         return functions
     |
help: Replace for loop with list comprehension

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_project_analyzer.py:1205:50
     |
1203 |         return functions
1204 |
1205 |     def _extract_classes(self, tree: ast.AST) -> List[str]:
     |                                                  ^^^^
1206 |         """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¸Ð¼ÐµÐ½Ð° ÐºÐ»Ð°ÑÑÐ¾Ð² Ð¸Ð· AST"""
1207 |         classes = []
     |
help: Replace with `list`

PERF401 Use a list comprehension to create a transformed list
    --> scripts/tools/ai_project_analyzer.py:1210:17
     |
1208 |         for node in ast.walk(tree):
1209 |             if isinstance(node, ast.ClassDef):
1210 |                 classes.append(node.name)
     |                 ^^^^^^^^^^^^^^^^^^^^^^^^^
1211 |         return classes
     |
help: Replace for loop with list comprehension

UP006 [*] Use `list` instead of `List` for type annotation
    --> scripts/tools/ai_project_analyzer.py:1213:50
     |
1211 |         return classes
1212 |
1213 |     def _extract_imports(self, tree: ast.AST) -> List[str]:
     |                                                  ^^^^
1214 |         """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð¸Ð· AST"""
1215 |         imports = []
     |
help: Replace with `list`

PERF401 Use `list.extend` to create a transformed list
    --> scripts/tools/ai_project_analyzer.py:1219:21
     |
1217 |             if isinstance(node, ast.Import):
1218 |                 for alias in node.names:
1219 |                     imports.append(alias.name)
     |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
1220 |             elif isinstance(node, ast.ImportFrom):
1221 |                 if node.module:
     |
help: Replace for loop with list.extend

SIM102 Use a single `if` statement instead of nested `if` statements
    --> scripts/tools/ai_project_analyzer.py:1220:13
     |
1218 |                   for alias in node.names:
1219 |                       imports.append(alias.name)
1220 | /             elif isinstance(node, ast.ImportFrom):
1221 | |                 if node.module:
     | |_______________________________^
1222 |                       imports.append(node.module)
1223 |           return imports
     |
help: Combine `if` statements using `and`

SIM114 [*] Combine `if` branches using logical `or` operator
    --> scripts/tools/ai_project_analyzer.py:1230:13
     |
1229 |           for node in ast.walk(tree):
1230 | /             if isinstance(node, (ast.If, ast.For, ast.While, ast.With)):
1231 | |                 complexity += 1
1232 | |             elif isinstance(node, ast.ExceptHandler):
1233 | |                 complexity += 1
     | |_______________________________^
1234 |
1235 |           return complexity
     |
help: Combine `if` branches

PLW1510 [*] `subprocess.run` without explicit `check` argument
    --> scripts/tools/ai_project_analyzer.py:1259:22
     |
1257 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚, ÑÑÑ‹Ð»Ð°ÐµÑ‚ÑÑ Ð»Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚ Ð½Ð° Ñ„Ð°Ð¹Ð»"""
1258 |         try:
1259 |             result = subprocess.run(
     |                      ^^^^^^^^^^^^^^
1260 |                 ["grep", "-r", file_stem, str(self.project_root)],
1261 |                 capture_output=True,
     |
help: Add explicit `check=False`

E722 Do not use bare `except`
    --> scripts/tools/ai_project_analyzer.py:1266:9
     |
1264 |             )
1265 |             return len(result.stdout.strip()) > 0
1266 |         except:
     |         ^^^^^^
1267 |             return True  # ÐÐ° Ð²ÑÑÐºÐ¸Ð¹ ÑÐ»ÑƒÑ‡Ð°Ð¹ ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼Ñ‹Ð¼
     |

PLR0912 Too many branches (19 > 12)
    --> scripts/tools/ai_project_analyzer.py:1270:5
     |
1270 | def main():
     |     ^^^^
1271 |     """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ CLI"""
1272 |     if "--analyze" in sys.argv:
     |

PLR0915 Too many statements (70 > 50)
    --> scripts/tools/ai_project_analyzer.py:1270:5
     |
1270 | def main():
     |     ^^^^
1271 |     """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ CLI"""
1272 |     if "--analyze" in sys.argv:
     |

F541 [*] f-string without any placeholders
    --> scripts/tools/ai_project_analyzer.py:1330:19
     |
1329 |         if results["ai_recommendations"]:
1330 |             print(f"\nðŸ’¡ AI Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^
1331 |             for rec in results["ai_recommendations"]:
1332 |                 print(f"  â€¢ {rec}")
     |
help: Remove extraneous `f` prefix

PTH123 `open()` should be replaced by `Path.open()`
    --> scripts/tools/ai_project_analyzer.py:1337:14
     |
1335 |         output_file = Path("results") / "project_analysis_enhanced.json"
1336 |         output_file.parent.mkdir(exist_ok=True)
1337 |         with open(output_file, "w", encoding="utf-8") as f:
     |              ^^^^
1338 |             json.dump(results, f, indent=2, ensure_ascii=False)
     |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
    --> scripts/tools/ai_project_analyzer.py:1351:18
     |
1349 |         json_file = Path("results") / "project_analysis_enhanced.json"
1350 |         if json_file.exists():
1351 |             with open(json_file, "r", encoding="utf-8") as f:
     |                  ^^^^
1352 |                 results = json.load(f)
     |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
    --> scripts/tools/ai_project_analyzer.py:1351:34
     |
1349 |         json_file = Path("results") / "project_analysis_enhanced.json"
1350 |         if json_file.exists():
1351 |             with open(json_file, "r", encoding="utf-8") as f:
     |                                  ^^^
1352 |                 results = json.load(f)
     |
help: Remove mode argument

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/tools/batch_ai_analysis.py:24:1
   |
22 |   """
23 |
24 | / import argparse
25 | | import sqlite3
26 | | import time
27 | | import logging
28 | | import sys
29 | | from typing import Optional
30 | |
31 | | # Add project root to path for imports
32 | | import sys
33 | | from pathlib import Path
   | |________________________^
34 |
35 |   project_root = Path(__file__).parent.parent.parent
   |
help: Organize imports

F811 [*] Redefinition of unused `sys` from line 28
  --> scripts/tools/batch_ai_analysis.py:32:8
   |
31 | # Add project root to path for imports
32 | import sys
   |        ^^^ `sys` redefined here
33 | from pathlib import Path
   |
  ::: scripts/tools/batch_ai_analysis.py:28:8
   |
26 | import time
27 | import logging
28 | import sys
   |        --- previous definition of `sys` here
29 | from typing import Optional
   |
help: Remove definition: `sys`

PLR0915 Too many statements (72 > 50)
  --> scripts/tools/batch_ai_analysis.py:61:5
   |
61 | def main(
   |     ^^^^
62 |     db_path: str,
63 |     batch_size: int,
   |

UP045 [*] Use `X | None` for type annotations
  --> scripts/tools/batch_ai_analysis.py:65:18
   |
63 |     batch_size: int,
64 |     sleep_sec: float,
65 |     max_batches: Optional[int],
   |                  ^^^^^^^^^^^^^
66 |     dry_run: bool,
67 | ):
   |
help: Convert to `X | None`

TRY401 Redundant exception object included in `logging.exception` call
   --> scripts/tools/batch_ai_analysis.py:177:67
    |
175 |         logger.info("\nâš ï¸  Processing interrupted by user (Ctrl+C)")
176 |     except Exception as e:
177 |         logger.exception(f"ðŸ’¥ Unexpected error during processing: {e}")
    |                                                                    ^
178 |     finally:
179 |         total_time = time.time() - start_time
    |

G003 Logging statement uses `+`
   --> scripts/tools/batch_ai_analysis.py:182:21
    |
180 |         remaining_final = count_remaining(db_path)
181 |
182 |         logger.info("\n" + "=" * 60)
    |                     ^^^^^^^^^^^^^^^
183 |         logger.info("ðŸ BATCH PROCESSING SUMMARY")
184 |         logger.info("=" * 60)
    |

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/tools/comprehensive_ai_stats.py:26:1
   |
24 |   """
25 |
26 | / import sqlite3
27 | | import json
28 | | from datetime import datetime
29 | | from collections import Counter, defaultdict
30 | | from typing import Dict, List, Any
   | |__________________________________^
   |
help: Organize imports

F401 [*] `collections.Counter` imported but unused
  --> scripts/tools/comprehensive_ai_stats.py:29:25
   |
27 | import json
28 | from datetime import datetime
29 | from collections import Counter, defaultdict
   |                         ^^^^^^^
30 | from typing import Dict, List, Any
   |
help: Remove unused import

F401 [*] `collections.defaultdict` imported but unused
  --> scripts/tools/comprehensive_ai_stats.py:29:34
   |
27 | import json
28 | from datetime import datetime
29 | from collections import Counter, defaultdict
   |                                  ^^^^^^^^^^^
30 | from typing import Dict, List, Any
   |
help: Remove unused import

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/tools/comprehensive_ai_stats.py:30:1
   |
28 | from datetime import datetime
29 | from collections import Counter, defaultdict
30 | from typing import Dict, List, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/tools/comprehensive_ai_stats.py:30:1
   |
28 | from datetime import datetime
29 | from collections import Counter, defaultdict
30 | from typing import Dict, List, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

F401 [*] `typing.List` imported but unused
  --> scripts/tools/comprehensive_ai_stats.py:30:26
   |
28 | from datetime import datetime
29 | from collections import Counter, defaultdict
30 | from typing import Dict, List, Any
   |                          ^^^^
   |
help: Remove unused import: `typing.List`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> scripts/tools/comprehensive_ai_stats.py:39:42
   |
37 |         self.db_path = db_path
38 |
39 |     def get_comprehensive_stats(self) -> Dict[str, Any]:
   |                                          ^^^^
40 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð²ÑÐµÐ¾Ð±ÑŠÐµÐ¼Ð»ÑŽÑ‰ÐµÐ¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸"""
41 |         conn = sqlite3.connect(self.db_path)
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> scripts/tools/comprehensive_ai_stats.py:73:44
   |
71 |         return stats
72 |
73 |     def _get_overview_stats(self, conn) -> Dict[str, Any]:
   |                                            ^^^^
74 |         """ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°"""
75 |         cursor = conn.cursor()
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> scripts/tools/comprehensive_ai_stats.py:97:41
   |
95 |         }
96 |
97 |     def _get_genre_stats(self, conn) -> Dict[str, Any]:
   |                                         ^^^^
98 |         """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð¶Ð°Ð½Ñ€Ð°Ð¼"""
99 |         cursor = conn.cursor()
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/comprehensive_ai_stats.py:129:40
    |
127 |         }
128 |
129 |     def _get_mood_stats(self, conn) -> Dict[str, Any]:
    |                                        ^^^^
130 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ð¹"""
131 |         cursor = conn.cursor()
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/comprehensive_ai_stats.py:169:43
    |
167 |         }
168 |
169 |     def _get_quality_stats(self, conn) -> Dict[str, Any]:
    |                                           ^^^^
170 |         """ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°"""
171 |         cursor = conn.cursor()
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/comprehensive_ai_stats.py:226:42
    |
224 |         }
225 |
226 |     def _get_artist_stats(self, conn) -> Dict[str, Any]:
    |                                          ^^^^
227 |         """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°Ð¼"""
228 |         cursor = conn.cursor()
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/comprehensive_ai_stats.py:265:46
    |
263 |         }
264 |
265 |     def _get_complexity_stats(self, conn) -> Dict[str, Any]:
    |                                              ^^^^
266 |         """ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²"""
267 |         cursor = conn.cursor()
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/comprehensive_ai_stats.py:306:46
    |
304 |         }
305 |
306 |     def _get_commercial_stats(self, conn) -> Dict[str, Any]:
    |                                              ^^^^
307 |         """ÐšÐ¾Ð¼Ð¼ÐµÑ€Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·"""
308 |         cursor = conn.cursor()
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/comprehensive_ai_stats.py:341:44
    |
339 |         }
340 |
341 |     def _get_temporal_stats(self, conn) -> Dict[str, Any]:
    |                                            ^^^^
342 |         """Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ‚Ñ€ÐµÐ½Ð´Ñ‹"""
343 |         cursor = conn.cursor()
    |
help: Replace with `dict`

RUF013 PEP 484 prohibits implicit `Optional`
   --> scripts/tools/comprehensive_ai_stats.py:371:44
    |
369 |         }
370 |
371 |     def generate_report(self, output_file: str = None) -> str:
    |                                            ^^^
372 |         """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°"""
373 |         if not output_file:
    |
help: Convert to `T | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/tools/comprehensive_ai_stats.py:374:25
    |
372 |         """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°"""
373 |         if not output_file:
374 |             timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    |                         ^^^^^^^^^^^^^^
375 |             output_file = f"results/ai_analysis_comprehensive_report_{timestamp}.json"
376 |         elif not output_file.startswith("results/"):
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/tools/comprehensive_ai_stats.py:385:29
    |
383 |         # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ
384 |         stats["metadata"] = {
385 |             "generated_at": datetime.now().isoformat(),
    |                             ^^^^^^^^^^^^^^
386 |             "database_path": self.db_path,
387 |             "generator_version": "1.0",
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/comprehensive_ai_stats.py:391:14
    |
390 |         # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² JSON
391 |         with open(output_file, "w", encoding="utf-8") as f:
    |              ^^^^
392 |             json.dump(stats, f, ensure_ascii=False, indent=2)
    |
help: Replace with `Path.open()`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/comprehensive_ai_stats.py:400:37
    |
398 |         return output_file
399 |
400 |     def _print_summary(self, stats: Dict[str, Any]):
    |                                     ^^^^
401 |         """ÐŸÐµÑ‡Ð°Ñ‚ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ð³Ð¾ Ñ€ÐµÐ·ÑŽÐ¼Ðµ"""
402 |         overview = stats["overview"]
    |
help: Replace with `dict`

F541 [*] f-string without any placeholders
   --> scripts/tools/comprehensive_ai_stats.py:417:15
    |
415 |         )
416 |
417 |         print(f"\nðŸŽ¼ Ð–Ð°Ð½Ñ€Ð¾Ð²Ð¾Ðµ Ñ€Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð¸Ðµ:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
418 |         top_genres = list(genre_stats["genre_distribution"].items())[:5]
419 |         for genre, count in top_genres:
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/comprehensive_ai_stats.py:422:15
    |
420 |             print(f"   â€¢ {genre}: {count:,} Ñ‚Ñ€ÐµÐºÐ¾Ð²")
421 |
422 |         print(f"\nðŸ˜Š Ð¢Ð¾Ð¿ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^
423 |         top_moods = list(mood_stats["mood_distribution"].items())[:5]
424 |         for mood, count in top_moods:
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/comprehensive_ai_stats.py:428:19
    |
427 |         if quality_stats["quality_averages"]["authenticity"]:
428 |             print(f"\nâ­ Ð¡Ñ€ÐµÐ´Ð½Ð¸Ðµ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
429 |             qa = quality_stats["quality_averages"]
430 |             print(f"   â€¢ ÐÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ð¾ÑÑ‚ÑŒ: {qa['authenticity']}")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
 --> scripts/tools/create_cli_showcase.py:6:1
  |
4 |   """
5 |
6 | / import sqlite3
7 | | from collections import Counter
8 | | import os
9 | | from datetime import datetime
  | |_____________________________^
  |
help: Organize imports

F401 [*] `collections.Counter` imported but unused
 --> scripts/tools/create_cli_showcase.py:7:25
  |
6 | import sqlite3
7 | from collections import Counter
  |                         ^^^^^^^
8 | import os
9 | from datetime import datetime
  |
help: Remove unused import: `collections.Counter`

F401 [*] `datetime.datetime` imported but unused
 --> scripts/tools/create_cli_showcase.py:9:22
  |
7 | from collections import Counter
8 | import os
9 | from datetime import datetime
  |                      ^^^^^^^^
  |
help: Remove unused import: `datetime.datetime`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
  --> scripts/tools/create_cli_showcase.py:16:12
   |
14 |     db_path = "data/rap_lyrics.db"
15 |
16 |     if not os.path.exists(db_path):
   |            ^^^^^^^^^^^^^^
17 |         print("âŒ Database not found")
18 |         return None
   |
help: Replace with `Path(...).exists()`

F541 [*] f-string without any placeholders
   --> scripts/tools/create_cli_showcase.py:136:11
    |
135 |       # Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÑÑ‚ÐµÐº
136 |       print(f"""
    |  ___________^
137 | | â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ðŸ› ï¸  TECH STACK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
138 | | â”‚                                                      â”‚
139 | | â”‚  ðŸ Python 3.13      ðŸ“Š Pydantic Models             â”‚
140 | | â”‚  ðŸ•·ï¸  Genius API       ðŸŽµ Spotify Web API             â”‚
141 | | â”‚  ðŸ¤– Gemma 27B        ðŸ”„ Async Processing             â”‚
142 | | â”‚  ðŸ’¾ SQLite DB        âš¡ CLI Interface                â”‚
143 | | â”‚                                                      â”‚
144 | | â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯""")
    | |___________________________________________________________^
145 |
146 |       # Pipeline ÑÑ‚Ð°Ñ‚ÑƒÑ
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/create_cli_showcase.py:147:11
    |
146 |       # Pipeline ÑÑ‚Ð°Ñ‚ÑƒÑ
147 |       print(f"""
    |  ___________^
148 | | â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âš™ï¸  ML PIPELINE STATUS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
149 | | â”‚                                                             â”‚
150 | | â”‚  âœ… Data Scraping      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%    â”‚
151 | | â”‚  ðŸŽµ Spotify Enrichment â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘  95%    â”‚
152 | | â”‚  ðŸ¤– AI Analysis        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  30%    â”‚
153 | | â”‚  ðŸ”§ Feature Engineering â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  10%    â”‚
154 | | â”‚                                                             â”‚
155 | | â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯""")
    | |__________________________________________________________________^
156 |
157 |       # Ð¢ÐµÐºÑƒÑ‰Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/create_cli_showcase.py:158:11
    |
157 |       # Ð¢ÐµÐºÑƒÑ‰Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
158 |       print(f"""
    |  ___________^
159 | | â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ðŸŽ¯ CURRENT GOALS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
160 | | â”‚                                                        â”‚
161 | | â”‚  âœ… 52K+ Tracks Collected                              â”‚
162 | | â”‚  ðŸ”„ Migrating to GPT-4o (content filtering issues)    â”‚
163 | | â”‚  ðŸ“ˆ Scaling to 100K+ tracks with monitoring           â”‚
164 | | â”‚  ðŸ¤– Conditional lyrics generation model               â”‚
165 | | â”‚  ðŸš€ Production deployment pipeline                    â”‚
166 | | â”‚                                                        â”‚
167 | | â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯""")
    | |_____________________________________________________________^
168 |
169 |       # CLI ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/create_cli_showcase.py:170:11
    |
169 |       # CLI ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹
170 |       print(f"""
    |  ___________^
171 | | â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ðŸš€ AVAILABLE COMMANDS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
172 | | â”‚                                                             â”‚
173 | | â”‚  ðŸ“Š python scripts/rap_scraper_cli.py status               â”‚
174 | | â”‚  ðŸ•·ï¸  python scripts/rap_scraper_cli.py scraping             â”‚
175 | | â”‚  ðŸŽµ python scripts/rap_scraper_cli.py spotify --continue   â”‚
176 | | â”‚  ðŸ¤– python scripts/rap_scraper_cli.py analysis --analyzer  â”‚
177 | | â”‚  ðŸ“ˆ python scripts/rap_scraper_cli.py monitoring           â”‚
178 | | â”‚                                                             â”‚
179 | | â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯""")
    | |__________________________________________________________________^
180 |
181 |       # ÐŸÐ¾Ð´Ð¿Ð¸ÑÑŒ
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/tools/database_diagnostics.py:34:1
   |
32 |   """
33 |
34 | / import psycopg2
35 | | import psycopg2.extras
36 | | import argparse
37 | | import os
38 | | from pathlib import Path
39 | | from datetime import datetime
40 | | import sys
41 | | import json
   | |___________^
42 |
43 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path Ð´Ð»Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº src Ð¼Ð¾Ð´ÑƒÐ»ÑÐ¼
   |
help: Organize imports

F401 [*] `datetime.datetime` imported but unused
  --> scripts/tools/database_diagnostics.py:39:22
   |
37 | import os
38 | from pathlib import Path
39 | from datetime import datetime
   |                      ^^^^^^^^
40 | import sys
41 | import json
   |
help: Remove unused import: `datetime.datetime`

F401 [*] `json` imported but unused
  --> scripts/tools/database_diagnostics.py:41:8
   |
39 | from datetime import datetime
40 | import sys
41 | import json
   |        ^^^^
42 |
43 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path Ð´Ð»Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº src Ð¼Ð¾Ð´ÑƒÐ»ÑÐ¼
   |
help: Remove unused import: `json`

TRY300 Consider moving this statement to an `else` block
  --> scripts/tools/database_diagnostics.py:78:13
   |
76 |             self.conn.autocommit = True
77 |             print("âœ… ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº PostgreSQL ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!")
78 |             return True
   |             ^^^^^^^^^^^
79 |         except Exception as e:
80 |             print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ðº PostgreSQL: {e}")
   |

TRY300 Consider moving this statement to an `else` block
  --> scripts/tools/database_diagnostics.py:96:21
   |
94 |                     self.db_config = alt_config
95 |                     print("âœ… ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð±ÐµÐ· Ð¿Ð°Ñ€Ð¾Ð»Ñ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!")
96 |                     return True
   |                     ^^^^^^^^^^^
97 |                 except Exception:
98 |                     pass
   |

TRY300 Consider moving this statement to an `else` block
   --> scripts/tools/database_diagnostics.py:111:21
    |
109 |                     self.db_config = alt_config
110 |                     print("âœ… ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº Ð‘Ð” 'postgres' ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!")
111 |                     return True
    |                     ^^^^^^^^^^^
112 |                 except Exception:
113 |                     pass
    |

TRY300 Consider moving this statement to an `else` block
   --> scripts/tools/database_diagnostics.py:134:21
    |
132 |                     self.db_config = alt_config
133 |                     print("âœ… ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ð¼Ð¸ Ð¸Ð· .env ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!")
134 |                     return True
    |                     ^^^^^^^^^^^
135 |                 except Exception as e2:
136 |                     print(f"   âŒ Ð¢Ð°ÐºÐ¶Ðµ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ: {e2}")
    |

PLR0912 Too many branches (16 > 12)
   --> scripts/tools/database_diagnostics.py:151:9
    |
149 |             self.conn.close()
150 |
151 |     def check_general_status(self):
    |         ^^^^^^^^^^^^^^^^^^^^
152 |         """ÐžÐ±Ñ‰Ð°Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° PostgreSQL Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
153 |         print("ðŸ” ÐžÐ‘Ð©ÐÐ¯ Ð”Ð˜ÐÐ“ÐÐžÐ¡Ð¢Ð˜ÐšÐ POSTGRESQL Ð‘ÐÐ—Ð« Ð”ÐÐÐÐ«Ð¥")
    |

PLR0915 Too many statements (65 > 50)
   --> scripts/tools/database_diagnostics.py:151:9
    |
149 |             self.conn.close()
150 |
151 |     def check_general_status(self):
    |         ^^^^^^^^^^^^^^^^^^^^
152 |         """ÐžÐ±Ñ‰Ð°Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° PostgreSQL Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
153 |         print("ðŸ” ÐžÐ‘Ð©ÐÐ¯ Ð”Ð˜ÐÐ“ÐÐžÐ¡Ð¢Ð˜ÐšÐ POSTGRESQL Ð‘ÐÐ—Ð« Ð”ÐÐÐÐ«Ð¥")
    |

F541 [*] f-string without any placeholders
   --> scripts/tools/database_diagnostics.py:180:23
    |
179 |                 # ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
180 |                 print(f"\nðŸ“Š ÐžÐ¡ÐÐžÐ’ÐÐÐ¯ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ:")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
181 |
182 |                 # Ð¢Ñ€ÐµÐºÐ¸
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/database_diagnostics.py:245:27
    |
243 |                 # Ð¢Ð¾Ð¿ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²
244 |                 if self._table_exists("tracks"):
245 |                     print(f"\nðŸ† Ð¢ÐžÐŸ-10 ÐÐ Ð¢Ð˜Ð¡Ð¢ÐžÐ’ ÐŸÐž ÐšÐžÐ›Ð˜Ð§Ð•Ð¡Ð¢Ð’Ð£ Ð¢Ð Ð•ÐšÐžÐ’:")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
246 |                     cur.execute("""
247 |                         SELECT artist, COUNT(*) as count 
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/database_diagnostics.py:260:27
    |
258 |                 # ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ðµ
259 |                 if self._table_exists("tracks"):
260 |                     print(f"\nðŸ“… ÐŸÐžÐ¡Ð›Ð•Ð”ÐÐ˜Ð• Ð”ÐžÐ‘ÐÐ’Ð›Ð•ÐÐÐ«Ð• Ð¢Ð Ð•ÐšÐ˜:")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
261 |                     cur.execute("""
262 |                         SELECT title, artist, created_at
    |
help: Remove extraneous `f` prefix

PLR0912 Too many branches (21 > 12)
   --> scripts/tools/database_diagnostics.py:379:9
    |
377 |             print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐµ ÑÑ…ÐµÐ¼Ñ‹: {e}")
378 |
379 |     def check_analysis_status(self):
    |         ^^^^^^^^^^^^^^^^^^^^^
380 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÐ° AI Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð² PostgreSQL"""
381 |         print("ðŸ¤– Ð¡Ð¢ÐÐ¢Ð£Ð¡ AI ÐÐÐÐ›Ð˜Ð—Ð")
    |

PLR0915 Too many statements (85 > 50)
   --> scripts/tools/database_diagnostics.py:379:9
    |
377 |             print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐµ ÑÑ…ÐµÐ¼Ñ‹: {e}")
378 |
379 |     def check_analysis_status(self):
    |         ^^^^^^^^^^^^^^^^^^^^^
380 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÐ° AI Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð² PostgreSQL"""
381 |         print("ðŸ¤– Ð¡Ð¢ÐÐ¢Ð£Ð¡ AI ÐÐÐÐ›Ð˜Ð—Ð")
    |

F541 [*] f-string without any placeholders
   --> scripts/tools/database_diagnostics.py:416:23
    |
414 |                     total_analyses = cur.fetchone()[0]
415 |
416 |                 print(f"ðŸ“Š ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^
417 |                 print(f"  ðŸŽµ Ð¢Ñ€ÐµÐºÐ¾Ð² Ñ Ñ‚ÐµÐºÑÑ‚Ð°Ð¼Ð¸: {total_tracks:,}")
418 |                 print(f"  ðŸ¤– ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð²: {analyzed_tracks:,}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/database_diagnostics.py:428:27
    |
426 |                 # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼ (Ð¸Ð· Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹)
427 |                 if analyzed_tracks > 0:
428 |                     print(f"\nðŸ§  Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°Ð¼:")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
429 |
430 |                     if self._table_exists("analysis_results"):
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/database_diagnostics.py:476:27
    |
474 |                 # Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
475 |                 if analyzed_tracks > 0:
476 |                     print(f"\nðŸ“… Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
477 |
478 |                     if self._table_exists("analysis_results"):
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/database_diagnostics.py:510:27
    |
508 |                 # ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ñ‹
509 |                 if analyzed_tracks > 0:
510 |                     print(f"\nðŸ• ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 5 Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð²:")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
511 |
512 |                     if self._table_exists("analysis_results"):
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/database_diagnostics.py:635:27
    |
633 |                     first_id = unanalyzed[0]["id"]
634 |                     print(f"\nðŸŽ¯ ÐŸÐµÑ€Ð²Ð°Ñ Ð½ÐµÐ°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ: ID {first_id}")
635 |                     print(f"ðŸ’¡ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÐ¼Ð°Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð° Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
636 |                     print(
637 |                         f"   python scripts/mass_qwen_analysis.py --start-id {first_id}"
    |
help: Remove extraneous `f` prefix

RET505 [*] Unnecessary `else` after `return` statement
   --> scripts/tools/database_diagnostics.py:641:17
    |
640 |                     return first_id
641 |                 else:
    |                 ^^^^
642 |                     print("  âœ… Ð’ÑÐµ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹!")
643 |                     return None
    |
help: Remove unnecessary `else`

F541 [*] f-string without any placeholders
   --> scripts/tools/database_diagnostics.py:806:15
    |
804 |                 diagnostics.find_unanalyzed(args.limit)
805 |
806 |         print(f"\nâœ… Ð”Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
807 |
808 |     except Exception as e:
    |
help: Remove extraneous `f` prefix

PLR1722 Use `sys.exit()` instead of `exit`
   --> scripts/tools/database_diagnostics.py:819:5
    |
818 | if __name__ == "__main__":
819 |     exit(main())
    |     ^^^^
    |
help: Replace `exit` with `sys.exit()`

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/tools/dependency_manager.py:22:1
   |
20 |   """
21 |
22 | / import subprocess
23 | | import shutil
24 | | import json
25 | | import re
26 | | from dataclasses import dataclass
27 | | from pathlib import Path
28 | | from typing import Dict, List, Optional, Tuple
29 | | import requests
30 | | from datetime import datetime, timedelta
   | |________________________________________^
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> scripts/tools/dependency_manager.py:28:1
   |
26 | from dataclasses import dataclass
27 | from pathlib import Path
28 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
29 | import requests
30 | from datetime import datetime, timedelta
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/tools/dependency_manager.py:28:1
   |
26 | from dataclasses import dataclass
27 | from pathlib import Path
28 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
29 | import requests
30 | from datetime import datetime, timedelta
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/tools/dependency_manager.py:28:1
   |
26 | from dataclasses import dataclass
27 | from pathlib import Path
28 | from typing import Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
29 | import requests
30 | from datetime import datetime, timedelta
   |

F401 [*] `typing.Tuple` imported but unused
  --> scripts/tools/dependency_manager.py:28:42
   |
26 | from dataclasses import dataclass
27 | from pathlib import Path
28 | from typing import Dict, List, Optional, Tuple
   |                                          ^^^^^
29 | import requests
30 | from datetime import datetime, timedelta
   |
help: Remove unused import: `typing.Tuple`

F401 [*] `requests` imported but unused
  --> scripts/tools/dependency_manager.py:29:8
   |
27 | from pathlib import Path
28 | from typing import Dict, List, Optional, Tuple
29 | import requests
   |        ^^^^^^^^
30 | from datetime import datetime, timedelta
   |
help: Remove unused import: `requests`

F401 [*] `datetime.timedelta` imported but unused
  --> scripts/tools/dependency_manager.py:30:32
   |
28 | from typing import Dict, List, Optional, Tuple
29 | import requests
30 | from datetime import datetime, timedelta
   |                                ^^^^^^^^^
   |
help: Remove unused import: `datetime.timedelta`

UP045 [*] Use `X | None` for type annotations
  --> scripts/tools/dependency_manager.py:41:20
   |
39 |     severity: str
40 |     description: str
41 |     fixed_version: Optional[str]
   |                    ^^^^^^^^^^^^^
   |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> scripts/tools/dependency_manager.py:86:41
   |
84 |         }
85 |
86 |     def get_installed_packages(self) -> Dict[str, str]:
   |                                         ^^^^
87 |         """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¿Ð°ÐºÐµÑ‚Ð¾Ð²"""
88 |         try:
   |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/dependency_manager.py:101:40
    |
 99 |             return {}
100 |
101 |     def check_vulnerabilities(self) -> List[Vulnerability]:
    |                                        ^^^^
102 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ ÑƒÑÐ·Ð²Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð² ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¿Ð°ÐºÐµÑ‚Ð°Ñ…"""
103 |         vulnerabilities = []
    |
help: Replace with `list`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/tools/dependency_manager.py:114:22
    |
113 |             # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ safety Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑƒÑÐ·Ð²Ð¸Ð¼Ð¾ÑÑ‚ÐµÐ¹
114 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
115 |                 ["safety", "check", "--json"], capture_output=True, text=True
116 |             )
    |
help: Add explicit `check=False`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/dependency_manager.py:150:42
    |
148 |         return vulnerabilities
149 |
150 |     def check_outdated_packages(self) -> List[PackageStatus]:
    |                                          ^^^^
151 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ ÑƒÑÑ‚Ð°Ñ€ÐµÐ²ÑˆÐ¸Ðµ Ð¿Ð°ÐºÐµÑ‚Ñ‹"""
152 |         outdated_packages = []
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/dependency_manager.py:181:43
    |
179 |         return outdated_packages
180 |
181 |     def generate_security_report(self) -> Dict:
    |                                           ^^^^
182 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸"""
183 |         print("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸...")
    |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/tools/dependency_manager.py:198:26
    |
197 |         report = {
198 |             "timestamp": datetime.now().isoformat(),
    |                          ^^^^^^^^^^^^^^
199 |             "summary": {
200 |                 "total_vulnerabilities": len(vulnerabilities),
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/dependency_manager.py:223:14
    |
222 |         # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ñ‚Ñ‡ÐµÑ‚ (Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð² UTF-8, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¿Ð°Ð´Ð°Ñ‚ÑŒ Ð½Ð° ÑÐ¼Ð¾Ð´Ð·Ð¸)
223 |         with open(self.security_report, "w", encoding="utf-8") as f:
    |              ^^^^
224 |             json.dump(report, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/dependency_manager.py:228:61
    |
226 |         return report
227 |
228 |     def perform_safe_updates(self, dry_run: bool = True) -> Dict:
    |                                                             ^^^^
229 |         """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ð°ÐºÐµÑ‚Ð¾Ð²"""
230 |         print(f"Ð—Ð°Ð¿ÑƒÑÐº {'ÑÐ¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ð¸' if dry_run else 'Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ…'} Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¹...")
    |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/tools/dependency_manager.py:243:26
    |
242 |         results = {
243 |             "timestamp": datetime.now().isoformat(),
    |                          ^^^^^^^^^^^^^^
244 |             "dry_run": dry_run,
245 |             "safe_updates": [],
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

F841 Local variable `result` is assigned to but never used
   --> scripts/tools/dependency_manager.py:257:21
    |
255 |             for package in safe_updates:
256 |                 try:
257 |                     result = subprocess.run(
    |                     ^^^^^^
258 |                         ["pip", "install", "--upgrade", package.name],
259 |                         capture_output=True,
    |
help: Remove assignment to unused variable `result`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/tools/dependency_manager.py:273:17
    |
271 |                       )
272 |
273 | /                 except subprocess.CalledProcessError as e:
274 | |                     results["errors"].append({"package": package.name, "error": str(e)})
    | |________________________________________________________________________________________^
275 |           else:
276 |               # Ð’ dry_run Ñ€ÐµÐ¶Ð¸Ð¼Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ñ‡Ñ‚Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/dependency_manager.py:284:46
    |
282 |         return results
283 |
284 |     def _determine_severity(self, vuln_data: Dict) -> str:
    |                                              ^^^^
285 |         """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ ÑÐµÑ€ÑŒÐµÐ·Ð½Ð¾ÑÑ‚ÑŒ ÑƒÑÐ·Ð²Ð¸Ð¼Ð¾ÑÑ‚Ð¸"""
286 |         advisory = vuln_data.get("advisory", "").lower()
    |
help: Replace with `dict`

RET505 [*] Unnecessary `elif` after `return` statement
   --> scripts/tools/dependency_manager.py:292:9
    |
290 |         ):
291 |             return "critical"
292 |         elif any(word in advisory for word in ["high", "sql injection", "xss"]):
    |         ^^^^
293 |             return "high"
294 |         elif any(word in advisory for word in ["medium", "denial of service"]):
    |
help: Remove unnecessary `elif`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/dependency_manager.py:299:49
    |
297 |             return "low"
298 |
299 |     def _extract_fixed_version(self, vuln_data: Dict) -> Optional[str]:
    |                                                 ^^^^
300 |         """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð²ÐµÑ€ÑÐ¸ÑŽ Ñ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼"""
301 |         advisory = vuln_data.get("advisory", "")
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> scripts/tools/dependency_manager.py:299:58
    |
297 |             return "low"
298 |
299 |     def _extract_fixed_version(self, vuln_data: Dict) -> Optional[str]:
    |                                                          ^^^^^^^^^^^^^
300 |         """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð²ÐµÑ€ÑÐ¸ÑŽ Ñ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼"""
301 |         advisory = vuln_data.get("advisory", "")
    |
help: Convert to `X | None`

ARG002 Unused method argument: `pkg_data`
   --> scripts/tools/dependency_manager.py:317:38
    |
315 |         return None
316 |
317 |     def _calculate_days_behind(self, pkg_data: Dict) -> int:
    |                                      ^^^^^^^^
318 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð½ÐµÐ¹ Ð¾Ñ‚ÑÑ‚Ð°Ð²Ð°Ð½Ð¸Ñ Ð¾Ñ‚ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ¹ Ð²ÐµÑ€ÑÐ¸Ð¸"""
319 |         # Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÐ° - Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð½ÑƒÐ¶ÐµÐ½ API PyPI
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/dependency_manager.py:317:48
    |
315 |         return None
316 |
317 |     def _calculate_days_behind(self, pkg_data: Dict) -> int:
    |                                                ^^^^
318 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð½ÐµÐ¹ Ð¾Ñ‚ÑÑ‚Ð°Ð²Ð°Ð½Ð¸Ñ Ð¾Ñ‚ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ¹ Ð²ÐµÑ€ÑÐ¸Ð¸"""
319 |         # Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÐ° - Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð½ÑƒÐ¶ÐµÐ½ API PyPI
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/dependency_manager.py:322:49
    |
320 |         return 30  # Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ°
321 |
322 |     def _check_breaking_changes(self, pkg_data: Dict) -> bool:
    |                                                 ^^^^
323 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ breaking changes"""
324 |         installed = pkg_data["version"]
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/dependency_manager.py:333:52
    |
331 |         return latest_major > installed_major
332 |
333 |     def _determine_update_priority(self, pkg_data: Dict) -> str:
    |                                                    ^^^^
334 |         """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ"""
335 |         pkg_name = pkg_data["name"].lower()
    |
help: Replace with `dict`

RET505 [*] Unnecessary `elif` after `return` statement
   --> scripts/tools/dependency_manager.py:339:9
    |
337 |         if pkg_name in self.critical_packages:
338 |             return "critical" if self._check_breaking_changes(pkg_data) else "high"
339 |         elif pkg_name in self.sensitive_packages:
    |         ^^^^
340 |             return "medium"
341 |         else:
    |
help: Remove unnecessary `elif`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/dependency_manager.py:344:46
    |
342 |             return "low"
343 |
344 |     def _check_dependency_conflicts(self) -> List[Dict]:
    |                                              ^^^^
345 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚Ñ‹ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹"""
346 |         conflicts = []
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/dependency_manager.py:344:51
    |
342 |             return "low"
343 |
344 |     def _check_dependency_conflicts(self) -> List[Dict]:
    |                                                   ^^^^
345 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚Ñ‹ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹"""
346 |         conflicts = []
    |
help: Replace with `dict`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> scripts/tools/dependency_manager.py:349:22
    |
348 |         try:
349 |             result = subprocess.run(["pip", "check"], capture_output=True, text=True)
    |                      ^^^^^^^^^^^^^^
350 |
351 |             if result.returncode != 0:
    |
help: Add explicit `check=False`

PERF401 Use `list.extend` to create a transformed list
   --> scripts/tools/dependency_manager.py:355:25
    |
353 |                   for line in result.stdout.split("\n"):
354 |                       if "has requirement" in line:
355 | /                         conflicts.append(
356 | |                             {"description": line.strip(), "severity": "medium"}
357 | |                         )
    | |_________________________^
358 |
359 |           except Exception as e:
    |
help: Replace for loop with list.extend

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/dependency_manager.py:364:43
    |
362 |         return conflicts
363 |
364 |     def _audit_requirements_file(self) -> List[Dict]:
    |                                           ^^^^
365 |         """ÐÑƒÐ´Ð¸Ñ‚ Ñ„Ð°Ð¹Ð»Ð° requirements.txt"""
366 |         issues = []
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/dependency_manager.py:364:48
    |
362 |         return conflicts
363 |
364 |     def _audit_requirements_file(self) -> List[Dict]:
    |                                                ^^^^
365 |         """ÐÑƒÐ´Ð¸Ñ‚ Ñ„Ð°Ð¹Ð»Ð° requirements.txt"""
366 |         issues = []
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/dependency_manager.py:374:14
    |
372 |             return issues
373 |
374 |         with open(self.requirements_file, "r") as f:
    |              ^^^^
375 |             lines = f.readlines()
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/tools/dependency_manager.py:374:43
    |
372 |             return issues
373 |
374 |         with open(self.requirements_file, "r") as f:
    |                                           ^^^
375 |             lines = f.readlines()
    |
help: Remove mode argument

PLW2901 `for` loop variable `line` overwritten by assignment target
   --> scripts/tools/dependency_manager.py:378:13
    |
377 |         for i, line in enumerate(lines, 1):
378 |             line = line.strip()
    |             ^^^^
379 |             if not line or line.startswith("#"):
380 |                 continue
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/dependency_manager.py:395:58
    |
393 |         return issues
394 |
395 |     def _calculate_security_score(self, vulnerabilities: List, outdated: List) -> float:
    |                                                          ^^^^
396 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ Ð¾Ð±Ñ‰Ð¸Ð¹ Ð±Ð°Ð»Ð» Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ (0-100)"""
397 |         score = 100
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/dependency_manager.py:395:74
    |
393 |         return issues
394 |
395 |     def _calculate_security_score(self, vulnerabilities: List, outdated: List) -> float:
    |                                                                          ^^^^
396 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ Ð¾Ð±Ñ‰Ð¸Ð¹ Ð±Ð°Ð»Ð» Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ (0-100)"""
397 |         score = 100
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/dependency_manager.py:417:32
    |
416 |     def _generate_security_recommendations(
417 |         self, vulnerabilities: List, outdated: List
    |                                ^^^^
418 |     ) -> List[str]:
419 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸"""
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/dependency_manager.py:417:48
    |
416 |     def _generate_security_recommendations(
417 |         self, vulnerabilities: List, outdated: List
    |                                                ^^^^
418 |     ) -> List[str]:
419 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸"""
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> scripts/tools/dependency_manager.py:418:10
    |
416 |     def _generate_security_recommendations(
417 |         self, vulnerabilities: List, outdated: List
418 |     ) -> List[str]:
    |          ^^^^
419 |         """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸"""
420 |         recommendations = []
    |
help: Replace with `list`

SIM103 Return the negated condition directly
   --> scripts/tools/dependency_manager.py:449:9
    |
448 |           # ÐÐµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°ÐºÐµÑ‚Ñ‹ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸
449 | /         if package.name.lower() in self.sensitive_packages:
450 | |             return False
451 | |
452 | |         return True
    | |___________________^
453 |
454 |       def _backup_requirements(self):
    |
help: Inline condition

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/tools/dependency_manager.py:459:46
    |
457 |             backup_file = (
458 |                 self.results_dir
459 |                 / f"requirements_backup_{int(datetime.now().timestamp())}.txt"
    |                                              ^^^^^^^^^^^^^^
460 |             )
461 |             # Ð§Ð¸Ñ‚Ð°Ñ‚ÑŒ/Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ð² UTF-8
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> scripts/tools/dependency_manager.py:466:44
    |
464 |             )
465 |
466 |     def _log_update_results(self, results: Dict):
    |                                            ^^^^
467 |         """Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¹"""
468 |         if self.update_log.exists():
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/dependency_manager.py:469:18
    |
467 |         """Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¹"""
468 |         if self.update_log.exists():
469 |             with open(self.update_log, "r", encoding="utf-8") as f:
    |                  ^^^^
470 |                 data = json.load(f)
471 |         else:
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/tools/dependency_manager.py:469:40
    |
467 |         """Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¹"""
468 |         if self.update_log.exists():
469 |             with open(self.update_log, "r", encoding="utf-8") as f:
    |                                        ^^^
470 |                 data = json.load(f)
471 |         else:
    |
help: Remove mode argument

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/tools/dependency_manager.py:480:14
    |
478 |             data = data[-50:]
479 |
480 |         with open(self.update_log, "w", encoding="utf-8") as f:
    |              ^^^^
481 |             json.dump(data, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/tools/monitor_qwen_progress.py:6:1
   |
 4 |   """
 5 |
 6 | / import sys
 7 | | import os
 8 | | import sqlite3
 9 | | from datetime import datetime, timedelta
10 | | import time
   | |___________^
11 |
12 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path
   |
help: Organize imports

F401 [*] `datetime.timedelta` imported but unused
  --> scripts/tools/monitor_qwen_progress.py:9:32
   |
 7 | import os
 8 | import sqlite3
 9 | from datetime import datetime, timedelta
   |                                ^^^^^^^^^
10 | import time
   |
help: Remove unused import: `datetime.timedelta`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> scripts/tools/monitor_qwen_progress.py:13:16
   |
12 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path
13 | project_root = os.path.dirname(os.path.dirname(__file__))
   |                ^^^^^^^^^^^^^^^
14 | sys.path.insert(0, project_root)
15 | sys.path.insert(0, os.path.join(project_root, "src"))
   |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> scripts/tools/monitor_qwen_progress.py:13:32
   |
12 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path
13 | project_root = os.path.dirname(os.path.dirname(__file__))
   |                                ^^^^^^^^^^^^^^^
14 | sys.path.insert(0, project_root)
15 | sys.path.insert(0, os.path.join(project_root, "src"))
   |
help: Replace with `Path(...).parent`

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
  --> scripts/tools/monitor_qwen_progress.py:15:20
   |
13 | project_root = os.path.dirname(os.path.dirname(__file__))
14 | sys.path.insert(0, project_root)
15 | sys.path.insert(0, os.path.join(project_root, "src"))
   |                    ^^^^^^^^^^^^
   |

PLR0912 Too many branches (14 > 12)
  --> scripts/tools/monitor_qwen_progress.py:18:5
   |
18 | def monitor_qwen_progress():
   |     ^^^^^^^^^^^^^^^^^^^^^
19 |     """ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Qwen"""
   |

PLR0915 Too many statements (66 > 50)
  --> scripts/tools/monitor_qwen_progress.py:18:5
   |
18 | def monitor_qwen_progress():
   |     ^^^^^^^^^^^^^^^^^^^^^
19 |     """ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Qwen"""
   |

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
  --> scripts/tools/monitor_qwen_progress.py:21:15
   |
19 |     """ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Qwen"""
20 |
21 |     db_path = os.path.join(project_root, "data", "rap_lyrics.db")
   |               ^^^^^^^^^^^^
22 |
23 |     if not os.path.exists(db_path):
   |

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
  --> scripts/tools/monitor_qwen_progress.py:23:12
   |
21 |     db_path = os.path.join(project_root, "data", "rap_lyrics.db")
22 |
23 |     if not os.path.exists(db_path):
   |            ^^^^^^^^^^^^^^
24 |         print("âŒ Ð‘Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°!")
25 |         return
   |
help: Replace with `Path(...).exists()`

F541 [*] f-string without any placeholders
  --> scripts/tools/monitor_qwen_progress.py:91:15
   |
89 |         remaining_qwen = total_records - qwen_analyzed
90 |
91 |         print(f"ðŸ“ˆ ÐžÐ±Ñ‰Ð¸Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:")
   |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
92 |         print(f"  ðŸ“Š Ð’ÑÐµÐ³Ð¾ Ð·Ð°Ð¿Ð¸ÑÐµÐ¹ Ð² Ð±Ð°Ð·Ðµ: {total_records:,}")
93 |         print(
   |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/monitor_qwen_progress.py:104:19
    |
102 |         # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼
103 |         if models_stats:
104 |             print(f"\nðŸ¤– Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
105 |             for model, count in models_stats:
106 |                 percent = (count / all_analyzed) * 100 if all_analyzed > 0 else 0
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/monitor_qwen_progress.py:122:23
    |
120 |                 )
121 |
122 |                 print(f"\nâ±ï¸  Qwen Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
123 |                 print(
124 |                     f"  ðŸš€ ÐŸÐµÑ€Ð²Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·: {first_analysis.strftime('%Y-%m-%d %H:%M:%S')}"
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/monitor_qwen_progress.py:143:19
    |
141 |         # ÐÐµÐ´Ð°Ð²Ð½ÑÑ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ
142 |         if recent_analyses:
143 |             print(f"\nðŸ• ÐÐµÐ´Ð°Ð²Ð½ÑÑ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ (Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ Ñ‡Ð°Ñ):")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
144 |             for timestamp, count in recent_analyses:
145 |                 dt = datetime.fromisoformat(timestamp)
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/monitor_qwen_progress.py:159:19
    |
158 |         if sentiments:
159 |             print(f"\nðŸ˜Š Qwen Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸ÑÐ¼:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
160 |             for sentiment, count in sentiments:
161 |                 percent = (count / qwen_analyzed) * 100 if qwen_analyzed > 0 else 0
    |
help: Remove extraneous `f` prefix

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> scripts/tools/monitor_qwen_progress.py:164:33
    |
162 |                 print(f"  {sentiment}: {count} ({percent:.1f}%)")
163 |
164 |         print(f"\nðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    |                                  ^^^^^^^^^^^^^^
165 |
166 |     except Exception as e:
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP009 [*] UTF-8 encoding declaration is unnecessary
 --> scripts/tools/precise_cleaner.py:2:1
  |
1 | #!/usr/bin/env python3
2 | # -*- coding: utf-8 -*-
  | ^^^^^^^^^^^^^^^^^^^^^^^
3 | """
4 | Precision Lyrics Cleaner - Ñ‚Ð¾Ñ‡ÐµÑ‡Ð½Ð°Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
  |
help: Remove unnecessary coding comment

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/tools/precise_cleaner.py:19:1
   |
17 |   """
18 |
19 | / import psycopg2
20 | | import re
21 | | import yaml
22 | | import logging
23 | | from pathlib import Path
   | |________________________^
24 |
25 |   logging.basicConfig(
   |
help: Organize imports

F401 [*] `pathlib.Path` imported but unused
  --> scripts/tools/precise_cleaner.py:23:21
   |
21 | import yaml
22 | import logging
23 | from pathlib import Path
   |                     ^^^^
24 |
25 | logging.basicConfig(
   |
help: Remove unused import: `pathlib.Path`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/tools/precise_cleaner.py:32:10
   |
31 | def load_config():
32 |     with open("config.yaml", "r", encoding="utf-8") as f:
   |          ^^^^
33 |         return yaml.safe_load(f)
   |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
  --> scripts/tools/precise_cleaner.py:32:30
   |
31 | def load_config():
32 |     with open("config.yaml", "r", encoding="utf-8") as f:
   |                              ^^^
33 |         return yaml.safe_load(f)
   |
help: Remove mode argument

PLW2901 `for` loop variable `line` overwritten by assignment target
  --> scripts/tools/precise_cleaner.py:92:13
   |
90 |         last_line = None
91 |         for i, line in enumerate(lines):
92 |             line = line.strip()
   |             ^^^^
93 |             if not line or len(line) < 10:
94 |                 continue
   |

W605 [*] Invalid escape sequence: `\s`
   --> scripts/tools/precise_cleaner.py:137:40
    |
135 |         WHERE lyrics IS NOT NULL 
136 |         AND (
137 |             lyrics ~ 'Contributor(?:s)?\s*(?:\w+\s*)*Lyrics' OR
    |                                        ^^
138 |             lyrics ~ '^[a-zA-Z\s]+?\s*Lyrics\s*.*\n.*Lyrics' OR
139 |             lyrics ~ '.*(Read More|â€¦)' OR
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\w`
   --> scripts/tools/precise_cleaner.py:137:46
    |
135 |         WHERE lyrics IS NOT NULL 
136 |         AND (
137 |             lyrics ~ 'Contributor(?:s)?\s*(?:\w+\s*)*Lyrics' OR
    |                                              ^^
138 |             lyrics ~ '^[a-zA-Z\s]+?\s*Lyrics\s*.*\n.*Lyrics' OR
139 |             lyrics ~ '.*(Read More|â€¦)' OR
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\s`
   --> scripts/tools/precise_cleaner.py:137:49
    |
135 |         WHERE lyrics IS NOT NULL 
136 |         AND (
137 |             lyrics ~ 'Contributor(?:s)?\s*(?:\w+\s*)*Lyrics' OR
    |                                                 ^^
138 |             lyrics ~ '^[a-zA-Z\s]+?\s*Lyrics\s*.*\n.*Lyrics' OR
139 |             lyrics ~ '.*(Read More|â€¦)' OR
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\s`
   --> scripts/tools/precise_cleaner.py:138:31
    |
136 |         AND (
137 |             lyrics ~ 'Contributor(?:s)?\s*(?:\w+\s*)*Lyrics' OR
138 |             lyrics ~ '^[a-zA-Z\s]+?\s*Lyrics\s*.*\n.*Lyrics' OR
    |                               ^^
139 |             lyrics ~ '.*(Read More|â€¦)' OR
140 |             lyrics ~ '\(.*?\;.*?\)' OR
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\s`
   --> scripts/tools/precise_cleaner.py:138:36
    |
136 |         AND (
137 |             lyrics ~ 'Contributor(?:s)?\s*(?:\w+\s*)*Lyrics' OR
138 |             lyrics ~ '^[a-zA-Z\s]+?\s*Lyrics\s*.*\n.*Lyrics' OR
    |                                    ^^
139 |             lyrics ~ '.*(Read More|â€¦)' OR
140 |             lyrics ~ '\(.*?\;.*?\)' OR
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\s`
   --> scripts/tools/precise_cleaner.py:138:45
    |
136 |         AND (
137 |             lyrics ~ 'Contributor(?:s)?\s*(?:\w+\s*)*Lyrics' OR
138 |             lyrics ~ '^[a-zA-Z\s]+?\s*Lyrics\s*.*\n.*Lyrics' OR
    |                                             ^^
139 |             lyrics ~ '.*(Read More|â€¦)' OR
140 |             lyrics ~ '\(.*?\;.*?\)' OR
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\(`
   --> scripts/tools/precise_cleaner.py:140:23
    |
138 |             lyrics ~ '^[a-zA-Z\s]+?\s*Lyrics\s*.*\n.*Lyrics' OR
139 |             lyrics ~ '.*(Read More|â€¦)' OR
140 |             lyrics ~ '\(.*?\;.*?\)' OR
    |                       ^^
141 |             lyrics ~ '^[a-zA-Z\s\-]+?\s*Lyrics\s*\n' OR
142 |             lyrics ~ '^([^\n]*\n)\1{2,}' OR  -- ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ ÑÑ‚Ñ€Ð¾Ðº (3+ Ñ€Ð°Ð·Ð°)
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\;`
   --> scripts/tools/precise_cleaner.py:140:28
    |
138 |             lyrics ~ '^[a-zA-Z\s]+?\s*Lyrics\s*.*\n.*Lyrics' OR
139 |             lyrics ~ '.*(Read More|â€¦)' OR
140 |             lyrics ~ '\(.*?\;.*?\)' OR
    |                            ^^
141 |             lyrics ~ '^[a-zA-Z\s\-]+?\s*Lyrics\s*\n' OR
142 |             lyrics ~ '^([^\n]*\n)\1{2,}' OR  -- ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ ÑÑ‚Ñ€Ð¾Ðº (3+ Ñ€Ð°Ð·Ð°)
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\)`
   --> scripts/tools/precise_cleaner.py:140:33
    |
138 |             lyrics ~ '^[a-zA-Z\s]+?\s*Lyrics\s*.*\n.*Lyrics' OR
139 |             lyrics ~ '.*(Read More|â€¦)' OR
140 |             lyrics ~ '\(.*?\;.*?\)' OR
    |                                 ^^
141 |             lyrics ~ '^[a-zA-Z\s\-]+?\s*Lyrics\s*\n' OR
142 |             lyrics ~ '^([^\n]*\n)\1{2,}' OR  -- ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ ÑÑ‚Ñ€Ð¾Ðº (3+ Ñ€Ð°Ð·Ð°)
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\s`
   --> scripts/tools/precise_cleaner.py:141:31
    |
139 |             lyrics ~ '.*(Read More|â€¦)' OR
140 |             lyrics ~ '\(.*?\;.*?\)' OR
141 |             lyrics ~ '^[a-zA-Z\s\-]+?\s*Lyrics\s*\n' OR
    |                               ^^
142 |             lyrics ~ '^([^\n]*\n)\1{2,}' OR  -- ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ ÑÑ‚Ñ€Ð¾Ðº (3+ Ñ€Ð°Ð·Ð°)
143 |             lyrics ~ 'Lyrics.*album.*\\.' OR
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\-`
   --> scripts/tools/precise_cleaner.py:141:33
    |
139 |             lyrics ~ '.*(Read More|â€¦)' OR
140 |             lyrics ~ '\(.*?\;.*?\)' OR
141 |             lyrics ~ '^[a-zA-Z\s\-]+?\s*Lyrics\s*\n' OR
    |                                 ^^
142 |             lyrics ~ '^([^\n]*\n)\1{2,}' OR  -- ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ ÑÑ‚Ñ€Ð¾Ðº (3+ Ñ€Ð°Ð·Ð°)
143 |             lyrics ~ 'Lyrics.*album.*\\.' OR
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\s`
   --> scripts/tools/precise_cleaner.py:141:38
    |
139 |             lyrics ~ '.*(Read More|â€¦)' OR
140 |             lyrics ~ '\(.*?\;.*?\)' OR
141 |             lyrics ~ '^[a-zA-Z\s\-]+?\s*Lyrics\s*\n' OR
    |                                      ^^
142 |             lyrics ~ '^([^\n]*\n)\1{2,}' OR  -- ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ ÑÑ‚Ñ€Ð¾Ðº (3+ Ñ€Ð°Ð·Ð°)
143 |             lyrics ~ 'Lyrics.*album.*\\.' OR
    |
help: Add backslash to escape sequence

W605 [*] Invalid escape sequence: `\s`
   --> scripts/tools/precise_cleaner.py:141:47
    |
139 |             lyrics ~ '.*(Read More|â€¦)' OR
140 |             lyrics ~ '\(.*?\;.*?\)' OR
141 |             lyrics ~ '^[a-zA-Z\s\-]+?\s*Lyrics\s*\n' OR
    |                                               ^^
142 |             lyrics ~ '^([^\n]*\n)\1{2,}' OR  -- ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ ÑÑ‚Ñ€Ð¾Ðº (3+ Ñ€Ð°Ð·Ð°)
143 |             lyrics ~ 'Lyrics.*album.*\\.' OR
    |
help: Add backslash to escape sequence

F541 [*] f-string without any placeholders
   --> scripts/tools/precise_cleaner.py:175:15
    |
173 |         print(f"ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ: {title}")
174 |
175 |         print(f"ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð» (Ð¿ÐµÑ€Ð²Ñ‹Ðµ 200 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²):")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
176 |         print(f"'{lyrics[:200]}...'")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/precise_cleaner.py:179:15
    |
178 |         cleaned = precision_clean_lyrics(lyrics, title)
179 |         print(f"ÐŸÐ¾ÑÐ»Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ (Ð¿ÐµÑ€Ð²Ñ‹Ðµ 200 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²):")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
180 |         print(f"'{cleaned[:200]}...'")
    |
help: Remove extraneous `f` prefix

UP009 [*] UTF-8 encoding declaration is unnecessary
 --> scripts/tools/precision_cleaner.py:2:1
  |
1 | #!/usr/bin/env python3
2 | # -*- coding: utf-8 -*-
  | ^^^^^^^^^^^^^^^^^^^^^^^
3 | """
4 | Precision Lyrics Cleaner - Ñ‚Ð¾Ñ‡ÐµÑ‡Ð½Ð°Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
  |
help: Remove unnecessary coding comment

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/tools/precision_cleaner.py:12:1
   |
10 |   """
11 |
12 | / import psycopg2
13 | | import re
14 | | import yaml
15 | | import logging
16 | | from pathlib import Path
   | |________________________^
17 |
18 |   logging.basicConfig(
   |
help: Organize imports

F401 [*] `pathlib.Path` imported but unused
  --> scripts/tools/precision_cleaner.py:16:21
   |
14 | import yaml
15 | import logging
16 | from pathlib import Path
   |                     ^^^^
17 |
18 | logging.basicConfig(
   |
help: Remove unused import: `pathlib.Path`

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/tools/precision_cleaner.py:25:10
   |
24 | def load_config():
25 |     with open("config.yaml", "r", encoding="utf-8") as f:
   |          ^^^^
26 |         return yaml.safe_load(f)
   |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
  --> scripts/tools/precision_cleaner.py:25:30
   |
24 | def load_config():
25 |     with open("config.yaml", "r", encoding="utf-8") as f:
   |                              ^^^
26 |         return yaml.safe_load(f)
   |
help: Remove mode argument

PLR0912 Too many branches (13 > 12)
  --> scripts/tools/precision_cleaner.py:42:5
   |
42 | def precision_clean_lyrics(lyrics, song_title=None):
   |     ^^^^^^^^^^^^^^^^^^^^^^
43 |     """
44 |     Ð¢Ð¾Ñ‡Ð½Ð°Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° Ñ‚ÐµÐºÑÑ‚Ð° Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð¿ÐµÑÐ½Ð¸
   |

PLW2901 `for` loop variable `line` overwritten by assignment target
  --> scripts/tools/precision_cleaner.py:88:17
   |
86 |             lines = content_part.split("\n")
87 |             for i, line in enumerate(lines):
88 |                 line = line.strip()
   |                 ^^^^
89 |                 # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿ÑƒÑÑ‚Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ
90 |                 if not line or len(line) < 10:
   |

F541 [*] f-string without any placeholders
   --> scripts/tools/precision_cleaner.py:161:15
    |
159 |         print(f"ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ: {title}")
160 |
161 |         print(f"ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð» (Ð¿ÐµÑ€Ð²Ñ‹Ðµ 200 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²):")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
162 |         print(f"'{lyrics[:200]}...'")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/tools/precision_cleaner.py:165:15
    |
164 |         cleaned = precision_clean_lyrics(lyrics, title)
165 |         print(f"ÐŸÐ¾ÑÐ»Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ (Ð¿ÐµÑ€Ð²Ñ‹Ðµ 200 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²):")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
166 |         print(f"'{cleaned[:200]}...'")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> scripts/utils/code_analyzer.py:26:1
   |
24 |   """
25 |
26 | / import os
27 | | import ast
28 | | import re
29 | | from pathlib import Path
30 | | from collections import defaultdict, Counter
31 | | import json
32 | | from datetime import datetime
   | |_____________________________^
   |
help: Organize imports

F401 [*] `os` imported but unused
  --> scripts/utils/code_analyzer.py:26:8
   |
24 | """
25 |
26 | import os
   |        ^^
27 | import ast
28 | import re
   |
help: Remove unused import: `os`

F401 [*] `ast` imported but unused
  --> scripts/utils/code_analyzer.py:27:8
   |
26 | import os
27 | import ast
   |        ^^^
28 | import re
29 | from pathlib import Path
   |
help: Remove unused import: `ast`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
  --> scripts/utils/code_analyzer.py:41:26
   |
39 |         self.project_root = Path(project_root)
40 |         self.results = {
41 |             "timestamp": datetime.now().isoformat(),
   |                          ^^^^^^^^^^^^^^
42 |             "project_root": str(self.project_root),
43 |             "file_sizes": [],
   |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/utils/code_analyzer.py:60:22
   |
59 |             try:
60 |                 with open(file_path, "r", encoding="utf-8") as f:
   |                      ^^^^
61 |                     lines = len(f.readlines())
   |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
  --> scripts/utils/code_analyzer.py:60:38
   |
59 |             try:
60 |                 with open(file_path, "r", encoding="utf-8") as f:
   |                                      ^^^
61 |                     lines = len(f.readlines())
   |
help: Remove mode argument

PTH123 `open()` should be replaced by `Path.open()`
  --> scripts/utils/code_analyzer.py:95:22
   |
94 |             try:
95 |                 with open(file_path, "r", encoding="utf-8") as f:
   |                      ^^^^
96 |                     content = f.read()
   |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
  --> scripts/utils/code_analyzer.py:95:38
   |
94 |             try:
95 |                 with open(file_path, "r", encoding="utf-8") as f:
   |                                      ^^^
96 |                     content = f.read()
   |
help: Remove mode argument

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utils/code_analyzer.py:132:22
    |
131 |             try:
132 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                      ^^^^
133 |                     content = f.read()
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> scripts/utils/code_analyzer.py:132:38
    |
131 |             try:
132 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                                      ^^^
133 |                     content = f.read()
    |
help: Remove mode argument

PERF401 Use a list comprehension to create a transformed list
   --> scripts/utils/code_analyzer.py:155:13
    |
153 |           # Large files
154 |           for large_file in self.results["large_files"]:
155 | /             opportunities.append(
156 | |                 {
157 | |                     "type": "large_file",
158 | |                     "description": f"Large file: {large_file['file']} ({large_file['lines']} lines)",
159 | |                     "recommendation": "Consider splitting into smaller modules",
160 | |                     "priority": large_file["refactor_priority"],
161 | |                     "file": large_file["file"],
162 | |                 }
163 | |             )
    | |_____________^
164 |
165 |           # Duplicate function names
    |
help: Replace for loop with list comprehension

PERF401 Use `list.extend` to create a transformed list
   --> scripts/utils/code_analyzer.py:168:17
    |
166 |           for duplicate in self.results["potential_duplicates"]:
167 |               if duplicate["count"] > 2:  # More than 2 occurrences
168 | /                 opportunities.append(
169 | |                     {
170 | |                         "type": "function_duplication",
171 | |                         "description": f"Function '{duplicate['function']}' appears in {duplicate['count']} files",
172 | |                         "recommendation": "Consider creating a shared utility function",
173 | |                         "priority": "medium",
174 | |                         "files": duplicate["files"],
175 | |                     }
176 | |                 )
    | |_________________^
177 |
178 |           # Files with many imports (high coupling)
    |
help: Replace for loop with list.extend

PLR0911 Too many return statements (7 > 6)
   --> scripts/utils/code_analyzer.py:193:9
    |
191 |         self.results["refactoring_opportunities"] = opportunities
192 |
193 |     def _categorize_file(self, file_path: str) -> str:
    |         ^^^^^^^^^^^^^^^^
194 |         """Categorize file by purpose"""
195 |         if "analyzer" in file_path:
    |

RET505 [*] Unnecessary `elif` after `return` statement
   --> scripts/utils/code_analyzer.py:197:9
    |
195 |         if "analyzer" in file_path:
196 |             return "analyzer"
197 |         elif "scraper" in file_path:
    |         ^^^^
198 |             return "scraper"
199 |         elif "enhancer" in file_path:
    |
help: Remove unnecessary `elif`

PTH123 `open()` should be replaced by `Path.open()`
   --> scripts/utils/code_analyzer.py:250:14
    |
248 |         }
249 |
250 |         with open(filename, "w", encoding="utf-8") as f:
    |              ^^^^
251 |             json.dump(results_copy, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

F541 [*] f-string without any placeholders
   --> scripts/utils/code_analyzer.py:268:15
    |
266 |         print(f"ðŸ“Š Average file size: {summary.get('average_file_size', 0)} lines")
267 |
268 |         print(f"\nðŸš¨ REFACTORING OPPORTUNITIES:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
269 |         print(f"   Large files (>500 lines): {summary.get('large_files_count', 0)}")
270 |         print(
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/utils/code_analyzer.py:278:15
    |
277 |         # Top 5 largest files
278 |         print(f"\nðŸ“ˆ TOP 5 LARGEST FILES:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
279 |         for i, file_info in enumerate(self.results["file_sizes"][:5]):
280 |             print(
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> scripts/utils/code_analyzer.py:292:19
    |
291 |         if high_priority:
292 |             print(f"\nðŸ”¥ HIGH PRIORITY REFACTORING:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
293 |             for opp in high_priority[:3]:
294 |                 print(f"   â€¢ {opp['description']}")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/__init__.py:23:1
   |
22 | # Easy imports for configuration
23 | from src.config.config_loader import get_config, Config
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 |
25 | __all__ = ["get_config", "Config"]
   |
help: Organize imports

RUF022 [*] `__all__` is not sorted
  --> src/__init__.py:25:11
   |
23 | from src.config.config_loader import get_config, Config
24 |
25 | __all__ = ["get_config", "Config"]
   |           ^^^^^^^^^^^^^^^^^^^^^^^^
   |
help: Apply an isort-style sorting to `__all__`

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/__init__.py:13:1
   |
11 |   """
12 |
13 | / from .algorithmic_analyzer import AdvancedAlgorithmicAnalyzer
14 | | from .mass_qwen_analysis import UnifiedQwenMassAnalyzer
15 | | from .ollama_analyzer import OllamaAnalyzer
16 | |
17 | | # from .hybrid_analyzer import HybridAnalyzer  # Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½
18 | | from .emotion_analyzer import EmotionAnalyzer
19 | |
20 | | # New config-integrated analyzers
21 | | from .qwen_analyzer import QwenAnalyzer  # v2.0.0 with config integration
   | |_______________________________________^
22 |
23 |   # ÐŸÑ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ð½Ð¾Ð²Ñ‹Ñ… Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð² Ð¾Ð½Ð¸ Ð±ÑƒÐ´ÑƒÑ‚ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð·Ð°Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹
   |
help: Organize imports

ERA001 Found commented-out code
  --> src/analyzers/__init__.py:17:1
   |
15 | from .ollama_analyzer import OllamaAnalyzer
16 |
17 | # from .hybrid_analyzer import HybridAnalyzer  # Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18 | from .emotion_analyzer import EmotionAnalyzer
   |
help: Remove commented-out code

RUF022 `__all__` is not sorted
  --> src/analyzers/__init__.py:26:11
   |
24 |   # Ð±Ð»Ð°Ð³Ð¾Ð´Ð°Ñ€Ñ Ð´ÐµÐºÐ¾Ñ€Ð°Ñ‚Ð¾Ñ€Ñƒ @register_analyzer
25 |
26 |   __all__ = [
   |  ___________^
27 | |     "AdvancedAlgorithmicAnalyzer",
28 | |     "UnifiedQwenMassAnalyzer",
29 | |     "OllamaAnalyzer",
30 | |     # "HybridAnalyzer",  # Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½
31 | |     "EmotionAnalyzer",
32 | |     "QwenAnalyzer",  # New v2.0.0
33 | | ]
   | |_^
   |
help: Apply an isort-style sorting to `__all__`

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/algorithmic_analyzer.py:58:1
   |
56 |   """
57 |
58 | / import re
59 | | import time
60 | | import math
61 | | import json
62 | | import logging
63 | | import asyncio
64 | | from datetime import datetime
65 | | from typing import Dict, Any, List, Set, Tuple, Optional
66 | | from collections import Counter, defaultdict
67 | | from dataclasses import dataclass, field
68 | | from pathlib import Path
69 | | import hashlib
   | |______________^
70 |
71 |   # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ñ fallback Ð´Ð»Ñ standalone Ð·Ð°Ð¿ÑƒÑÐºÐ°
   |
help: Organize imports

F401 [*] `json` imported but unused
  --> src/analyzers/algorithmic_analyzer.py:61:8
   |
59 | import time
60 | import math
61 | import json
   |        ^^^^
62 | import logging
63 | import asyncio
   |
help: Remove unused import: `json`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/analyzers/algorithmic_analyzer.py:65:1
   |
63 | import asyncio
64 | from datetime import datetime
65 | from typing import Dict, Any, List, Set, Tuple, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
66 | from collections import Counter, defaultdict
67 | from dataclasses import dataclass, field
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/analyzers/algorithmic_analyzer.py:65:1
   |
63 | import asyncio
64 | from datetime import datetime
65 | from typing import Dict, Any, List, Set, Tuple, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
66 | from collections import Counter, defaultdict
67 | from dataclasses import dataclass, field
   |

UP035 `typing.Set` is deprecated, use `set` instead
  --> src/analyzers/algorithmic_analyzer.py:65:1
   |
63 | import asyncio
64 | from datetime import datetime
65 | from typing import Dict, Any, List, Set, Tuple, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
66 | from collections import Counter, defaultdict
67 | from dataclasses import dataclass, field
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> src/analyzers/algorithmic_analyzer.py:65:1
   |
63 | import asyncio
64 | from datetime import datetime
65 | from typing import Dict, Any, List, Set, Tuple, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
66 | from collections import Counter, defaultdict
67 | from dataclasses import dataclass, field
   |

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/algorithmic_analyzer.py:73:5
   |
71 |   # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ñ fallback Ð´Ð»Ñ standalone Ð·Ð°Ð¿ÑƒÑÐºÐ°
72 |   try:
73 | /     from interfaces.analyzer_interface import (
74 | |         BaseAnalyzer,
75 | |         AnalysisResult,
76 | |         register_analyzer,
77 | |     )
   | |_____^
78 |
79 |       PROJECT_IMPORT_SUCCESS = True
   |
help: Organize imports

I001 [*] Import block is un-sorted or un-formatted
   --> src/analyzers/algorithmic_analyzer.py:95:17
    |
 93 |                   sys.path.append(str(src_path))
 94 |               try:
 95 | /                 from interfaces.analyzer_interface import (
 96 | |                     BaseAnalyzer,
 97 | |                     AnalysisResult,
 98 | |                     register_analyzer,
 99 | |                 )
    | |_________________^
100 |
101 |                   PROJECT_IMPORT_SUCCESS = True
    |
help: Organize imports

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:110:40
    |
108 |         # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ðµ ÐºÐ»Ð°ÑÑÑ‹ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ¸ Ð´Ð»Ñ standalone Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹
109 |         class BaseAnalyzer:
110 |             def __init__(self, config: Dict[str, Any] = None):
    |                                        ^^^^
111 |                 self.config = config or {}
    |
help: Replace with `dict`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src/analyzers/algorithmic_analyzer.py:110:40
    |
108 |         # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ðµ ÐºÐ»Ð°ÑÑÑ‹ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ¸ Ð´Ð»Ñ standalone Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹
109 |         class BaseAnalyzer:
110 |             def __init__(self, config: Dict[str, Any] = None):
    |                                        ^^^^^^^^^^^^^^
111 |                 self.config = config or {}
    |
help: Convert to `T | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:125:23
    |
123 |             analysis_type: str
124 |             confidence: float
125 |             metadata: Dict[str, Any]
    |                       ^^^^
126 |             raw_output: Dict[str, Any]
127 |             processing_time: float
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:126:25
    |
124 |             confidence: float
125 |             metadata: Dict[str, Any]
126 |             raw_output: Dict[str, Any]
    |                         ^^^^
127 |             processing_time: float
128 |             timestamp: str
    |
help: Replace with `dict`

ARG001 Unused function argument: `name`
   --> src/analyzers/algorithmic_analyzer.py:130:31
    |
128 |             timestamp: str
129 |
130 |         def register_analyzer(name: str):
    |                               ^^^^
131 |             def decorator(cls):
132 |                 return cls
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:146:19
    |
144 |     """Ð¤Ð¾Ð½ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ€Ð¸Ñ„Ð¼"""
145 |
146 |     vowel_sounds: Dict[str, List[str]] = field(
    |                   ^^^^
147 |         default_factory=lambda: {
148 |             "ay": ["ai", "ay", "ey", "a_e"],
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:146:29
    |
144 |     """Ð¤Ð¾Ð½ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ€Ð¸Ñ„Ð¼"""
145 |
146 |     vowel_sounds: Dict[str, List[str]] = field(
    |                             ^^^^
147 |         default_factory=lambda: {
148 |             "ay": ["ai", "ay", "ey", "a_e"],
    |
help: Replace with `list`

UP006 [*] Use `set` instead of `Set` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:159:25
    |
157 |     )
158 |
159 |     consonant_clusters: Set[str] = field(
    |                         ^^^
160 |         default_factory=lambda: {
161 |             "ch",
    |
help: Replace with `set`

B033 [*] Sets should not contain duplicate item `"corner"`
   --> src/analyzers/algorithmic_analyzer.py:272:17
    |
270 |                 "pavement",
271 |                 "alley",
272 |                 "corner",
    |                 ^^^^^^^^
273 |                 "neighborhood",
274 |             },
    |
help: Remove duplicate item

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:458:44
    |
456 |         self.phonetic_patterns = PhoneticPattern()
457 |
458 |     def analyze_flow_patterns(self, lines: List[str]) -> Dict[str, Any]:
    |                                            ^^^^
459 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð² flow"""
460 |         if not lines:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:458:58
    |
456 |         self.phonetic_patterns = PhoneticPattern()
457 |
458 |     def analyze_flow_patterns(self, lines: List[str]) -> Dict[str, Any]:
    |                                                          ^^^^
459 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð² flow"""
460 |         if not lines:
    |
help: Replace with `dict`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/analyzers/algorithmic_analyzer.py:561:9
    |
560 |           # Ð˜ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ
561 | /         if word.endswith("e") and syllable_count > 1:
562 | |             # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ silent e
563 | |             if not word.endswith(("le", "se", "me", "ne", "ve", "ze", "de", "ge")):
    | |___________________________________________________________________________________^
564 |                   syllable_count -= 1
    |
help: Combine `if` statements using `and`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:591:46
    |
589 |         return "".join(stress_pattern)
590 |
591 |     def _calculate_consistency(self, values: List[float]) -> float:
    |                                              ^^^^
592 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹"""
593 |         if len(values) < 2:
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:603:43
    |
601 |         return min(consistency, 1.0)
602 |
603 |     def _calculate_variance(self, values: List[float]) -> float:
    |                                           ^^^^
604 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð´Ð¸ÑÐ¿ÐµÑ€ÑÐ¸Ð¸"""
605 |         if len(values) < 2:
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:611:59
    |
609 |         return sum((x - mean) ** 2 for x in values) / len(values)
610 |
611 |     def _analyze_stress_regularity(self, stress_patterns: List[str]) -> float:
    |                                                           ^^^^
612 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ñ€ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ð¾ÑÑ‚Ð¸ ÑƒÐ´Ð°Ñ€ÐµÐ½Ð¸Ð¹"""
613 |         if not stress_patterns:
    |
help: Replace with `list`

RET504 Unnecessary assignment to `regularity` before `return` statement
   --> src/analyzers/algorithmic_analyzer.py:622:20
    |
620 |         if most_common:
621 |             regularity = most_common[0][1] / len(stress_patterns)
622 |             return regularity
    |                    ^^^^^^^^^^
623 |
624 |         return 0.0
    |
help: Remove unnecessary assignment

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:626:48
    |
624 |         return 0.0
625 |
626 |     def _count_flow_interruptions(self, lines: List[str]) -> int:
    |                                                ^^^^
627 |         """ÐŸÐ¾Ð´ÑÑ‡ÐµÑ‚ Ð¿Ñ€ÐµÑ€Ñ‹Ð²Ð°Ð½Ð¸Ð¹ flow"""
628 |         interruptions = 0
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:637:50
    |
635 |         return interruptions
636 |
637 |     def _calculate_rhythmic_density(self, lines: List[str]) -> float:
    |                                                  ^^^^
638 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚Ð¸"""
639 |         if not lines:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:652:37
    |
650 |         return min(density / 2.0, 1.0)  # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ðº [0, 1]
651 |
652 |     def _empty_flow_result(self) -> Dict[str, Any]:
    |                                     ^^^^
653 |         """ÐŸÑƒÑÑ‚Ð¾Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° flow"""
654 |         return {
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:672:46
    |
670 |         self.rhyme_cache = {}
671 |
672 |     def analyze_rhyme_structure(self, lines: List[str]) -> Dict[str, Any]:
    |                                              ^^^^
673 |         """ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ñ€Ð¸Ñ„Ð¼ÐµÐ½Ð½Ð¾Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹"""
674 |         if len(lines) < 2:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:672:60
    |
670 |         self.rhyme_cache = {}
671 |
672 |     def analyze_rhyme_structure(self, lines: List[str]) -> Dict[str, Any]:
    |                                                            ^^^^
673 |         """ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ñ€Ð¸Ñ„Ð¼ÐµÐ½Ð½Ð¾Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹"""
674 |         if len(lines) < 2:
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:707:44
    |
705 |         }
706 |
707 |     def _extract_line_endings(self, lines: List[str]) -> List[str]:
    |                                            ^^^^
708 |         """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð¾ÐºÐ¾Ð½Ñ‡Ð°Ð½Ð¸Ð¹ ÑÑ‚Ñ€Ð¾Ðº Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¾Ð¹"""
709 |         endings = []
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:707:58
    |
705 |         }
706 |
707 |     def _extract_line_endings(self, lines: List[str]) -> List[str]:
    |                                                          ^^^^
708 |         """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð¾ÐºÐ¾Ð½Ñ‡Ð°Ð½Ð¸Ð¹ ÑÑ‚Ñ€Ð¾Ðº Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¾Ð¹"""
709 |         endings = []
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:720:45
    |
718 |         return endings
719 |
720 |     def _find_perfect_rhymes(self, endings: List[str]) -> List[Tuple[int, int]]:
    |                                             ^^^^
721 |         """ÐŸÐ¾Ð¸ÑÐº Ñ‚Ð¾Ñ‡Ð½Ñ‹Ñ… Ñ€Ð¸Ñ„Ð¼"""
722 |         perfect_rhymes = []
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:720:59
    |
718 |         return endings
719 |
720 |     def _find_perfect_rhymes(self, endings: List[str]) -> List[Tuple[int, int]]:
    |                                                           ^^^^
721 |         """ÐŸÐ¾Ð¸ÑÐº Ñ‚Ð¾Ñ‡Ð½Ñ‹Ñ… Ñ€Ð¸Ñ„Ð¼"""
722 |         perfect_rhymes = []
    |
help: Replace with `list`

UP006 [*] Use `tuple` instead of `Tuple` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:720:64
    |
718 |         return endings
719 |
720 |     def _find_perfect_rhymes(self, endings: List[str]) -> List[Tuple[int, int]]:
    |                                                                ^^^^^
721 |         """ÐŸÐ¾Ð¸ÑÐº Ñ‚Ð¾Ñ‡Ð½Ñ‹Ñ… Ñ€Ð¸Ñ„Ð¼"""
722 |         perfect_rhymes = []
    |
help: Replace with `tuple`

PERF401 Use `list.extend` to create a transformed list
   --> src/analyzers/algorithmic_analyzer.py:727:21
    |
725 |             for j in range(i + 1, len(endings)):
726 |                 if self._is_perfect_rhyme(endings[i], endings[j]):
727 |                     perfect_rhymes.append((i, j))
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
728 |
729 |         return perfect_rhymes
    |
help: Replace for loop with list.extend

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:731:42
    |
729 |         return perfect_rhymes
730 |
731 |     def _find_near_rhymes(self, endings: List[str]) -> List[Tuple[int, int]]:
    |                                          ^^^^
732 |         """ÐŸÐ¾Ð¸ÑÐº Ð½ÐµÑ‚Ð¾Ñ‡Ð½Ñ‹Ñ… Ñ€Ð¸Ñ„Ð¼"""
733 |         near_rhymes = []
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:731:56
    |
729 |         return perfect_rhymes
730 |
731 |     def _find_near_rhymes(self, endings: List[str]) -> List[Tuple[int, int]]:
    |                                                        ^^^^
732 |         """ÐŸÐ¾Ð¸ÑÐº Ð½ÐµÑ‚Ð¾Ñ‡Ð½Ñ‹Ñ… Ñ€Ð¸Ñ„Ð¼"""
733 |         near_rhymes = []
    |
help: Replace with `list`

UP006 [*] Use `tuple` instead of `Tuple` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:731:61
    |
729 |         return perfect_rhymes
730 |
731 |     def _find_near_rhymes(self, endings: List[str]) -> List[Tuple[int, int]]:
    |                                                             ^^^^^
732 |         """ÐŸÐ¾Ð¸ÑÐº Ð½ÐµÑ‚Ð¾Ñ‡Ð½Ñ‹Ñ… Ñ€Ð¸Ñ„Ð¼"""
733 |         near_rhymes = []
    |
help: Replace with `tuple`

PERF401 Use `list.extend` to create a transformed list
   --> src/analyzers/algorithmic_analyzer.py:740:21
    |
738 |                     endings[i], endings[j]
739 |                 ) and self._is_near_rhyme(endings[i], endings[j]):
740 |                     near_rhymes.append((i, j))
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
741 |
742 |         return near_rhymes
    |
help: Replace for loop with list.extend

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:744:44
    |
742 |         return near_rhymes
743 |
744 |     def _find_internal_rhymes(self, lines: List[str]) -> List[Tuple[int, str, str]]:
    |                                            ^^^^
745 |         """ÐŸÐ¾Ð¸ÑÐº Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… Ñ€Ð¸Ñ„Ð¼"""
746 |         internal_rhymes = []
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:744:58
    |
742 |         return near_rhymes
743 |
744 |     def _find_internal_rhymes(self, lines: List[str]) -> List[Tuple[int, str, str]]:
    |                                                          ^^^^
745 |         """ÐŸÐ¾Ð¸ÑÐº Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… Ñ€Ð¸Ñ„Ð¼"""
746 |         internal_rhymes = []
    |
help: Replace with `list`

UP006 [*] Use `tuple` instead of `Tuple` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:744:63
    |
742 |         return near_rhymes
743 |
744 |     def _find_internal_rhymes(self, lines: List[str]) -> List[Tuple[int, str, str]]:
    |                                                               ^^^^^
745 |         """ÐŸÐ¾Ð¸ÑÐº Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… Ñ€Ð¸Ñ„Ð¼"""
746 |         internal_rhymes = []
    |
help: Replace with `tuple`

PERF401 Use `list.extend` to create a transformed list
   --> src/analyzers/algorithmic_analyzer.py:757:25
    |
755 |                         words[i], words[j]
756 |                     ) or self._is_near_rhyme(words[i], words[j]):
757 |                         internal_rhymes.append((line_idx, words[i], words[j]))
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
758 |
759 |         return internal_rhymes
    |
help: Replace for loop with list.extend

SIM103 Return the condition `len(set(consonants1) & set(consonants2)) >= 1` directly
   --> src/analyzers/algorithmic_analyzer.py:801:9
    |
799 |           consonants2 = [c for c in word2[-3:] if c not in "aeiou"]
800 |
801 | /         if len(set(consonants1) & set(consonants2)) >= 1:
802 | |             return True
803 | |
804 | |         return False
    | |____________________^
805 |
806 |       def _phonetic_rhyme_check(self, word1: str, word2: str) -> bool:
    |
help: Replace with `return len(set(consonants1) & set(consonants2)) >= 1`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:835:53
    |
833 |         return False
834 |
835 |     def _detect_complex_rhyme_scheme(self, endings: List[str]) -> str:
    |                                                     ^^^^
836 |         """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÐ»Ð¾Ð¶Ð½Ð¾Ð¹ ÑÑ…ÐµÐ¼Ñ‹ Ñ€Ð¸Ñ„Ð¼Ð¾Ð²ÐºÐ¸"""
837 |         if len(endings) < 4:
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:890:55
    |
888 |         return min(complexity_score, 1.0)
889 |
890 |     def _calculate_phonetic_similarity(self, endings: List[str]) -> float:
    |                                                       ^^^^
891 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ñ„Ð¾Ð½ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð°"""
892 |         if len(endings) < 2:
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:924:24
    |
923 |     def _calculate_rhyme_density(
924 |         self, endings: List[str], perfect_rhymes: List, near_rhymes: List
    |                        ^^^^
925 |     ) -> float:
926 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ñ€Ð¸Ñ„Ð¼"""
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:924:51
    |
923 |     def _calculate_rhyme_density(
924 |         self, endings: List[str], perfect_rhymes: List, near_rhymes: List
    |                                                   ^^^^
925 |     ) -> float:
926 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ñ€Ð¸Ñ„Ð¼"""
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:924:70
    |
923 |     def _calculate_rhyme_density(
924 |         self, endings: List[str], perfect_rhymes: List, near_rhymes: List
    |                                                                      ^^^^
925 |     ) -> float:
926 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ñ€Ð¸Ñ„Ð¼"""
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:943:46
    |
941 |         )
942 |
943 |     def _calculate_alliteration(self, lines: List[str]) -> float:
    |                                              ^^^^
944 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÐºÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚Ð° Ð°Ð»Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸"""
945 |         if not lines:
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:967:43
    |
965 |         return alliteration_count / max(total_word_pairs, 1)
966 |
967 |     def _calculate_assonance(self, lines: List[str]) -> float:
    |                                           ^^^^
968 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÐºÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚Ð° Ð°ÑÑÐ¾Ð½Ð°Ð½ÑÐ° (Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÐµÐ½Ð¸Ðµ Ð³Ð»Ð°ÑÐ½Ñ‹Ñ…)"""
969 |         if not lines:
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/algorithmic_analyzer.py:997:44
    |
995 |         return assonance_count / max(total_comparisons, 1)
996 |
997 |     def _calculate_consonance(self, lines: List[str]) -> float:
    |                                            ^^^^
998 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÐºÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚Ð° ÐºÐ¾Ð½ÑÐ¾Ð½Ð°Ð½ÑÐ° (Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÐµÐ½Ð¸Ðµ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ñ‹Ñ…)"""
999 |         if not lines:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1028:38
     |
1026 |         return consonance_count / max(total_comparisons, 1)
1027 |
1028 |     def _empty_rhyme_result(self) -> Dict[str, Any]:
     |                                      ^^^^
1029 |         """ÐŸÑƒÑÑ‚Ð¾Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ€Ð¸Ñ„Ð¼"""
1030 |         return {
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1047:49
     |
1045 |     """ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ñ‡Ð¸Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ñ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸"""
1046 |
1047 |     def analyze_readability(self, text: str) -> Dict[str, Any]:
     |                                                 ^^^^
1048 |         """ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ñ‡Ð¸Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
1049 |         if not text.strip():
     |
help: Replace with `dict`

RET504 Unnecessary assignment to `smog` before `return` statement
    --> src/analyzers/algorithmic_analyzer.py:1150:16
     |
1148 |         # SMOG = 3 + âˆš(complex_words * 30 / sentences)
1149 |         smog = 3 + math.sqrt(complex_words * 30 / sentences)
1150 |         return smog
     |                ^^^^
1151 |
1152 |     def _calculate_ari(self, sentences: int, words: int, text: str) -> float:
     |
help: Remove unnecessary assignment

E741 Ambiguous variable name: `l`
    --> src/analyzers/algorithmic_analyzer.py:1172:9
     |
1170 |         characters = len(re.sub(r"[^a-zA-Z]", "", text))
1171 |
1172 |         l = (characters / words) * 100  # Average letters per 100 words
     |         ^
1173 |         s = (sentences / words) * 100  # Average sentences per 100 words
     |

RET505 [*] Unnecessary `elif` after `return` statement
    --> src/analyzers/algorithmic_analyzer.py:1201:9
     |
1199 |         if avg_grade <= 6:
1200 |             return "elementary"
1201 |         elif avg_grade <= 8:
     |         ^^^^
1202 |             return "middle_school"
1203 |         elif avg_grade <= 12:
     |
help: Remove unnecessary `elif`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1210:44
     |
1208 |             return "graduate"
1209 |
1210 |     def _empty_readability_result(self) -> Dict[str, Any]:
     |                                            ^^^^
1211 |         """ÐŸÑƒÑÑ‚Ð¾Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ‡Ð¸Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
1212 |         return {
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1238:32
     |
1236 |     """
1237 |
1238 |     def __init__(self, config: Dict[str, Any] = None):
     |                                ^^^^
1239 |         super().__init__(config)
     |
help: Replace with `dict`

RUF013 PEP 484 prohibits implicit `Optional`
    --> src/analyzers/algorithmic_analyzer.py:1238:32
     |
1236 |     """
1237 |
1238 |     def __init__(self, config: Dict[str, Any] = None):
     |                                ^^^^^^^^^^^^^^
1239 |         super().__init__(config)
     |
help: Convert to `T | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/algorithmic_analyzer.py:1317:32
     |
1315 |         metadata = {
1316 |             "analyzer_version": "2.0.0",
1317 |             "processing_date": datetime.now().isoformat(),
     |                                ^^^^^^^^^^^^^^
1318 |             "lyrics_length": len(processed_lyrics),
1319 |             "word_count": len(words),
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/algorithmic_analyzer.py:1334:26
     |
1332 |             "metadata": metadata,
1333 |             "raw_output": analysis_results,
1334 |             "timestamp": datetime.now().isoformat(),
     |                          ^^^^^^^^^^^^^^
1335 |             "artist": artist,
1336 |             "title": title,
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1357:49
     |
1355 |         return hashlib.md5(content.encode()).hexdigest()
1356 |
1357 |     def _split_into_lines(self, lyrics: str) -> List[str]:
     |                                                 ^^^^
1358 |         """Ð Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ðµ Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¾Ð¹"""
1359 |         lines = [line.strip() for line in lyrics.split("\n") if line.strip()]
     |
help: Replace with `list`

PERF401 Use a list comprehension to create a transformed list
    --> src/analyzers/algorithmic_analyzer.py:1370:17
     |
1368 |                 re.IGNORECASE,
1369 |             ):
1370 |                 filtered_lines.append(line)
     |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
1371 |
1372 |         return filtered_lines
     |
help: Replace for loop with list comprehension

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1374:57
     |
1372 |         return filtered_lines
1373 |
1374 |     def _extract_meaningful_words(self, lyrics: str) -> List[str]:
     |                                                         ^^^^
1375 |         """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ñ‹Ñ… ÑÐ»Ð¾Ð²"""
1376 |         words = re.findall(r"\b[a-zA-Z]{2,}\b", lyrics.lower())
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1499:22
     |
1498 |     def _analyze_advanced_sentiment(
1499 |         self, words: List[str], full_text: str
     |                      ^^^^
1500 |     ) -> Dict[str, Any]:
1501 |         """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ Ñ Ð³Ñ€Ð°Ð´Ð°Ñ†Ð¸ÐµÐ¹"""
     |
help: Replace with `list`

ARG002 Unused method argument: `full_text`
    --> src/analyzers/algorithmic_analyzer.py:1499:33
     |
1498 |     def _analyze_advanced_sentiment(
1499 |         self, words: List[str], full_text: str
     |                                 ^^^^^^^^^
1500 |     ) -> Dict[str, Any]:
1501 |         """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ Ñ Ð³Ñ€Ð°Ð´Ð°Ñ†Ð¸ÐµÐ¹"""
     |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1500:10
     |
1498 |     def _analyze_advanced_sentiment(
1499 |         self, words: List[str], full_text: str
1500 |     ) -> Dict[str, Any]:
     |          ^^^^
1501 |         """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ Ñ Ð³Ñ€Ð°Ð´Ð°Ñ†Ð¸ÐµÐ¹"""
1502 |         if not words:
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1564:47
     |
1562 |         }
1563 |
1564 |     def _analyze_themes_advanced(self, words: List[str]) -> Dict[str, Any]:
     |                                               ^^^^
1565 |         """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·"""
1566 |         if not words:
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1564:61
     |
1562 |         }
1563 |
1564 |     def _analyze_themes_advanced(self, words: List[str]) -> Dict[str, Any]:
     |                                                             ^^^^
1565 |         """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·"""
1566 |         if not words:
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1615:35
     |
1614 |     def _analyze_literary_devices(
1615 |         self, lyrics: str, words: List[str]
     |                                   ^^^^
1616 |     ) -> Dict[str, Any]:
1617 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð½Ñ‹Ñ… Ð¿Ñ€Ð¸ÐµÐ¼Ð¾Ð²"""
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1616:10
     |
1614 |     def _analyze_literary_devices(
1615 |         self, lyrics: str, words: List[str]
1616 |     ) -> Dict[str, Any]:
     |          ^^^^
1617 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð½Ñ‹Ñ… Ð¿Ñ€Ð¸ÐµÐ¼Ð¾Ð²"""
1618 |         if not lyrics or not words:
     |
help: Replace with `dict`

ERA001 Found commented-out code
    --> src/analyzers/algorithmic_analyzer.py:1647:9
     |
1645 |         line_repetitions = self._analyze_repetitions(lyrics)
1646 |
1647 |         # ÐŸÐµÑ€ÑÐ¾Ð½Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ (ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð¾)
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1648 |         personification_indicators = [
1649 |             "speaks",
     |
help: Remove commented-out code

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1674:52
     |
1672 |         }
1673 |
1674 |     def _analyze_repetitions(self, lyrics: str) -> Dict[str, Any]:
     |                                                    ^^^^
1675 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¾Ð² Ð² Ñ‚ÐµÐºÑÑ‚Ðµ"""
1676 |         lines = [line.strip().lower() for line in lyrics.split("\n") if line.strip()]
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1712:57
     |
1710 |         }
1711 |
1712 |     def _analyze_vocabulary_sophistication(self, words: List[str]) -> Dict[str, Any]:
     |                                                         ^^^^
1713 |         """ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ ÑÐ»Ð¾Ð²Ð°Ñ€Ñ"""
1714 |         if not words:
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1712:71
     |
1710 |         }
1711 |
1712 |     def _analyze_vocabulary_sophistication(self, words: List[str]) -> Dict[str, Any]:
     |                                                                       ^^^^
1713 |         """ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ ÑÐ»Ð¾Ð²Ð°Ñ€Ñ"""
1714 |         if not words:
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1790:22
     |
1789 |     def _analyze_structure_advanced(
1790 |         self, lines: List[str], full_text: str
     |                      ^^^^
1791 |     ) -> Dict[str, Any]:
1792 |         """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·"""
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1791:10
     |
1789 |     def _analyze_structure_advanced(
1790 |         self, lines: List[str], full_text: str
1791 |     ) -> Dict[str, Any]:
     |          ^^^^
1792 |         """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·"""
1793 |         if not lines:
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1824:50
     |
1822 |         }
1823 |
1824 |     def _analyze_punctuation(self, text: str) -> Dict[str, int]:
     |                                                  ^^^^
1825 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿ÑƒÐ½ÐºÑ‚ÑƒÐ°Ñ†Ð¸Ð¸"""
1826 |         punctuation_counts = {
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1844:47
     |
1842 |         return punctuation_counts
1843 |
1844 |     def _find_structure_patterns(self, lines: List[str]) -> Dict[str, Any]:
     |                                               ^^^^
1845 |         """ÐŸÐ¾Ð¸ÑÐº ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð½Ñ‹Ñ… Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð²"""
1846 |         if len(lines) < 4:
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1844:61
     |
1842 |         return punctuation_counts
1843 |
1844 |     def _find_structure_patterns(self, lines: List[str]) -> Dict[str, Any]:
     |                                                             ^^^^
1845 |         """ÐŸÐ¾Ð¸ÑÐº ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð½Ñ‹Ñ… Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð²"""
1846 |         if len(lines) < 4:
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1871:47
     |
1869 |         }
1870 |
1871 |     def _identify_stanzas(self, text: str) -> Dict[str, Any]:
     |                                               ^^^^
1872 |         """ÐÐ½Ð°Ð»Ð¸Ð· ÑÑ‚Ñ€Ð¾Ñ„Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹"""
1873 |         # Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð¿Ð¾ Ð´Ð²Ð¾Ð¹Ð½Ñ‹Ð¼ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ°Ð¼ ÑÑ‚Ñ€Ð¾Ðº
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1895:35
     |
1894 |     def _analyze_creativity_advanced(
1895 |         self, lyrics: str, words: List[str], lines: List[str]
     |                                   ^^^^
1896 |     ) -> Dict[str, Any]:
1897 |         """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸"""
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1895:53
     |
1894 |     def _analyze_creativity_advanced(
1895 |         self, lyrics: str, words: List[str], lines: List[str]
     |                                                     ^^^^
1896 |     ) -> Dict[str, Any]:
1897 |         """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸"""
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1896:10
     |
1894 |     def _analyze_creativity_advanced(
1895 |         self, lyrics: str, words: List[str], lines: List[str]
1896 |     ) -> Dict[str, Any]:
     |          ^^^^
1897 |         """ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸"""
1898 |         if not words or not lines:
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1932:41
     |
1930 |         }
1931 |
1932 |     def _detect_neologisms(self, words: List[str]) -> List[str]:
     |                                         ^^^^
1933 |         """ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ Ð½ÐµÐ¾Ð»Ð¾Ð³Ð¸Ð·Ð¼Ð¾Ð² Ð¸ Ð½ÐµÐ¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ñ… ÑÐ»Ð¾Ð²"""
1934 |         # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ ÑÐ²Ñ€Ð¸ÑÑ‚Ð¸ÐºÐ° Ð´Ð»Ñ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ñ… Ð½ÐµÐ¾Ð»Ð¾Ð³Ð¸Ð·Ð¼Ð¾Ð²
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1932:55
     |
1930 |         }
1931 |
1932 |     def _detect_neologisms(self, words: List[str]) -> List[str]:
     |                                                       ^^^^
1933 |         """ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ Ð½ÐµÐ¾Ð»Ð¾Ð³Ð¸Ð·Ð¼Ð¾Ð² Ð¸ Ð½ÐµÐ¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ñ… ÑÐ»Ð¾Ð²"""
1934 |         # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ ÑÐ²Ñ€Ð¸ÑÑ‚Ð¸ÐºÐ° Ð´Ð»Ñ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ñ… Ð½ÐµÐ¾Ð»Ð¾Ð³Ð¸Ð·Ð¼Ð¾Ð²
     |
help: Replace with `list`

PIE810 Call `endswith` once with a `tuple`
    --> src/analyzers/algorithmic_analyzer.py:1940:17
     |
1938 |               # Ð¡Ð»Ð¾Ð²Ð° Ñ Ð½ÐµÐ¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¼Ð¸ ÑÑƒÑ„Ñ„Ð¸ÐºÑÐ°Ð¼Ð¸ Ð¸Ð»Ð¸ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑÐ°Ð¼Ð¸
1939 |               if len(word) > 6 and (
1940 | /                 word.endswith("ness")
1941 | |                 or word.endswith("tion")
1942 | |                 or word.endswith("ism")
1943 | |                 or word.startswith("un")
1944 | |                 or word.startswith("pre")
1945 | |                 or word.startswith("over")
     | |__________________________________________^
1946 |               ):
1947 |                   potential_neologisms.append(word)
     |
help: Merge into a single `endswith` call

PIE810 Call `startswith` once with a `tuple`
    --> src/analyzers/algorithmic_analyzer.py:1940:17
     |
1938 |               # Ð¡Ð»Ð¾Ð²Ð° Ñ Ð½ÐµÐ¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¼Ð¸ ÑÑƒÑ„Ñ„Ð¸ÐºÑÐ°Ð¼Ð¸ Ð¸Ð»Ð¸ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑÐ°Ð¼Ð¸
1939 |               if len(word) > 6 and (
1940 | /                 word.endswith("ness")
1941 | |                 or word.endswith("tion")
1942 | |                 or word.endswith("ism")
1943 | |                 or word.startswith("un")
1944 | |                 or word.startswith("pre")
1945 | |                 or word.startswith("over")
     | |__________________________________________^
1946 |               ):
1947 |                   potential_neologisms.append(word)
     |
help: Merge into a single `startswith` call

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1959:43
     |
1957 |         ]  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
1958 |
1959 |     def _find_unique_phrases(self, lines: List[str]) -> List[str]:
     |                                           ^^^^
1960 |         """ÐŸÐ¾Ð¸ÑÐº ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ñ„Ñ€Ð°Ð·Ð¾Ð²Ñ‹Ñ… ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¹"""
1961 |         unique_phrases = []
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1959:57
     |
1957 |         ]  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
1958 |
1959 |     def _find_unique_phrases(self, lines: List[str]) -> List[str]:
     |                                                         ^^^^
1960 |         """ÐŸÐ¾Ð¸ÑÐº ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ñ„Ñ€Ð°Ð·Ð¾Ð²Ñ‹Ñ… ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¹"""
1961 |         unique_phrases = []
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1992:35
     |
1991 |     def _analyze_advanced_wordplay(
1992 |         self, lyrics: str, words: List[str]
     |                                   ^^^^
1993 |     ) -> Dict[str, Any]:
1994 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ñ… Ð¿Ñ€Ð¸ÐµÐ¼Ð¾Ð² Ð¸Ð³Ñ€Ñ‹ ÑÐ»Ð¾Ð²"""
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:1993:10
     |
1991 |     def _analyze_advanced_wordplay(
1992 |         self, lyrics: str, words: List[str]
1993 |     ) -> Dict[str, Any]:
     |          ^^^^
1994 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ñ… Ð¿Ñ€Ð¸ÐµÐ¼Ð¾Ð² Ð¸Ð³Ñ€Ñ‹ ÑÐ»Ð¾Ð²"""
1995 |         wordplay_score = 0
     |
help: Replace with `dict`

SIM102 Use a single `if` statement instead of nested `if` statements
    --> src/analyzers/algorithmic_analyzer.py:2001:13
     |
1999 |           double_meanings = []
2000 |           for word in set(words):
2001 | /             if len(word) > 4:
2002 | |                 # ÐŸÐ¾Ð¸ÑÐº ÑÐ»Ð¾Ð², ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¼Ð¾Ð³ÑƒÑ‚ Ð¸Ð¼ÐµÑ‚ÑŒ Ð´Ð²Ð¾Ð¹Ð½Ð¾Ð¹ ÑÐ¼Ñ‹ÑÐ»
2003 | |                 if any(
2004 | |                     other in word for other in words if other != word and len(other) > 2
2005 | |                 ):
     | |__________________^
2006 |                       double_meanings.append(word)
     |
help: Combine `if` statements using `and`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2053:48
     |
2051 |         }
2052 |
2053 |     def _analyze_rhyme_innovation(self, lines: List[str]) -> Dict[str, Any]:
     |                                                ^^^^
2054 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð½Ð½Ð¾Ð²Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð¾ÑÑ‚Ð¸ Ñ€Ð¸Ñ„Ð¼"""
2055 |         if len(lines) < 4:
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2053:62
     |
2051 |         }
2052 |
2053 |     def _analyze_rhyme_innovation(self, lines: List[str]) -> Dict[str, Any]:
     |                                                              ^^^^
2054 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð½Ð½Ð¾Ð²Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð¾ÑÑ‚Ð¸ Ñ€Ð¸Ñ„Ð¼"""
2055 |         if len(lines) < 4:
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2118:33
     |
2117 |     def _calculate_advanced_composite_scores(
2118 |         self, analysis_results: Dict[str, Any]
     |                                 ^^^^
2119 |     ) -> Dict[str, Any]:
2120 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ñ… ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ‚Ð½Ñ‹Ñ… Ð¾Ñ†ÐµÐ½Ð¾Ðº"""
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2119:10
     |
2117 |     def _calculate_advanced_composite_scores(
2118 |         self, analysis_results: Dict[str, Any]
2119 |     ) -> Dict[str, Any]:
     |          ^^^^
2120 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ñ… ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ‚Ð½Ñ‹Ñ… Ð¾Ñ†ÐµÐ½Ð¾Ðº"""
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2176:33
     |
2175 |     def _calculate_advanced_confidence(
2176 |         self, analysis_results: Dict[str, Any], lines: List[str], words: List[str]
     |                                 ^^^^
2177 |     ) -> float:
2178 |         """Ð Ð°ÑÑ‡ÐµÑ‚ Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸"""
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2176:56
     |
2175 |     def _calculate_advanced_confidence(
2176 |         self, analysis_results: Dict[str, Any], lines: List[str], words: List[str]
     |                                                        ^^^^
2177 |     ) -> float:
2178 |         """Ð Ð°ÑÑ‡ÐµÑ‚ Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸"""
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2176:74
     |
2175 |     def _calculate_advanced_confidence(
2176 |         self, analysis_results: Dict[str, Any], lines: List[str], words: List[str]
     |                                                                          ^^^^
2177 |     ) -> float:
2178 |         """Ð Ð°ÑÑ‡ÐµÑ‚ Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸"""
     |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2218:52
     |
2216 |         )
2217 |
2218 |     def _calculate_consistency_score(self, values: List[float]) -> float:
     |                                                    ^^^^
2219 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹"""
2220 |         if len(values) < 2:
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2290:36
     |
2288 |         }
2289 |
2290 |     def get_analyzer_info(self) -> Dict[str, Any]:
     |                                    ^^^^
2291 |         """Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾Ð± Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ðµ"""
2292 |         return {
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2325:37
     |
2324 |     @property
2325 |     def supported_features(self) -> List[str]:
     |                                     ^^^^
2326 |         """ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
2327 |         return [
     |
help: Replace with `list`

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2381:15
     |
2379 |         )
2380 |
2381 |         print(f"\nðŸ“Š Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« ÐÐÐÐ›Ð˜Ð—Ð:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2382 |         print(f"ðŸŽ¯ Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {result['confidence']:.3f}")
2383 |         print(f"âš¡ Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {result['processing_time']:.3f}s")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2387:15
     |
2385 |         # Ð Ð¸Ñ„Ð¼Ñ‹ Ð¸ Ð·Ð²ÑƒÑ‡Ð°Ð½Ð¸Ðµ
2386 |         rhyme_analysis = result["raw_output"].get("rhyme_analysis", {})
2387 |         print(f"\nðŸŽµ Ð Ð˜Ð¤ÐœÐ« Ð˜ Ð—Ð’Ð£Ð§ÐÐÐ˜Ð•:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^
2388 |         print(f"  Ð¡Ñ…ÐµÐ¼Ð° Ñ€Ð¸Ñ„Ð¼Ð¾Ð²ÐºÐ¸: {rhyme_analysis.get('rhyme_scheme', 'N/A')}")
2389 |         print(f"  ÐŸÐ»Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ñ€Ð¸Ñ„Ð¼: {rhyme_analysis.get('rhyme_density', 0):.3f}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2395:15
     |
2393 |         # Flow Ð°Ð½Ð°Ð»Ð¸Ð·
2394 |         flow_analysis = result["raw_output"].get("flow_analysis", {})
2395 |         print(f"\nðŸŒŠ FLOW Ð˜ Ð Ð˜Ð¢Ðœ:")
     |               ^^^^^^^^^^^^^^^^^^^^
2396 |         print(
2397 |             f"  ÐšÐ¾Ð½ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð³Ð¾Ð²: {flow_analysis.get('syllable_consistency', 0):.3f}"
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2408:15
     |
2406 |         # Ð§Ð¸Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ
2407 |         readability = result["raw_output"].get("readability_metrics", {})
2408 |         print(f"\nðŸ“š Ð§Ð˜Ð¢ÐÐ‘Ð•Ð›Ð¬ÐÐžÐ¡Ð¢Ð¬:")
     |               ^^^^^^^^^^^^^^^^^^^^^^
2409 |         print(f"  Flesch Reading Ease: {readability.get('flesch_reading_ease', 0):.1f}")
2410 |         print(f"  SMOG Index: {readability.get('smog_index', 0):.1f}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2415:15
     |
2413 |         # ÐšÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ‚Ð½Ñ‹Ðµ Ð¾Ñ†ÐµÐ½ÐºÐ¸
2414 |         composite = result["raw_output"].get("composite_scores", {})
2415 |         print(f"\nðŸ† ÐšÐžÐœÐŸÐžÐ—Ð˜Ð¢ÐÐ«Ð• ÐžÐ¦Ð•ÐÐšÐ˜:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2416 |         print(f"  Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¼Ð°ÑÑ‚ÐµÑ€ÑÑ‚Ð²Ð¾: {composite.get('technical_mastery', 0):.3f}")
2417 |         print(
     |
help: Remove extraneous `f` prefix

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2446:34
     |
2444 |         self.db_config = self._load_db_config()
2445 |
2446 |     def _load_db_config(self) -> Dict[str, Any]:
     |                                  ^^^^
2447 |         """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð‘Ð”"""
2448 |         try:
     |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
    --> src/analyzers/algorithmic_analyzer.py:2454:22
     |
2453 |             if config_path.exists():
2454 |                 with open(config_path, "r", encoding="utf-8") as f:
     |                      ^^^^
2455 |                     config = yaml.safe_load(f)
2456 |                     return config.get("database", {})
     |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
    --> src/analyzers/algorithmic_analyzer.py:2454:40
     |
2453 |             if config_path.exists():
2454 |                 with open(config_path, "r", encoding="utf-8") as f:
     |                                        ^^^
2455 |                     config = yaml.safe_load(f)
2456 |                     return config.get("database", {})
     |
help: Remove mode argument

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2472:43
     |
2470 |             return {}
2471 |
2472 |     async def get_database_stats(self) -> Dict[str, Any]:
     |                                           ^^^^
2473 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
2474 |         try:
     |
help: Replace with `dict`

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2528:23
     |
2526 |                 }
2527 |
2528 |                 print(f"ðŸ“Š ÐŸÐžÐ›ÐÐÐ¯ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ Ð‘ÐÐ—Ð« Ð”ÐÐÐÐ«Ð¥:")
     |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2529 |                 print(f"=" * 50)
2530 |                 print(f"  ðŸ“€ Ð’ÑÐµÐ³Ð¾ Ð·Ð°Ð¿Ð¸ÑÐµÐ¹ Ð² Ð‘Ð”: {stats['total_songs']:,}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2529:23
     |
2528 |                 print(f"ðŸ“Š ÐŸÐžÐ›ÐÐÐ¯ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ Ð‘ÐÐ—Ð« Ð”ÐÐÐÐ«Ð¥:")
2529 |                 print(f"=" * 50)
     |                       ^^^^
2530 |                 print(f"  ðŸ“€ Ð’ÑÐµÐ³Ð¾ Ð·Ð°Ð¿Ð¸ÑÐµÐ¹ Ð² Ð‘Ð”: {stats['total_songs']:,}")
2531 |                 print(f"  ðŸŽ¤ Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¸ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÐµÐ¹: {stats['unique_artists']:,}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2539:23
     |
2537 |                     f"  âŒ ÐÐµÐ¿Ñ€Ð¸Ð³Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {stats['non_analyzable_songs']:,}"
2538 |                 )
2539 |                 print(f"")
     |                       ^^^
2540 |                 print(f"ðŸ“ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ ÐŸÐž Ð”Ð›Ð˜ÐÐ• Ð¢Ð•ÐšÐ¡Ð¢ÐžÐ’:")
2541 |                 print(f"  Ð¡Ñ€ÐµÐ´Ð½ÑÑ Ð´Ð»Ð¸Ð½Ð°: {stats['avg_lyrics_length']:.0f} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2540:23
     |
2538 |                 )
2539 |                 print(f"")
2540 |                 print(f"ðŸ“ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ ÐŸÐž Ð”Ð›Ð˜ÐÐ• Ð¢Ð•ÐšÐ¡Ð¢ÐžÐ’:")
     |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2541 |                 print(f"  Ð¡Ñ€ÐµÐ´Ð½ÑÑ Ð´Ð»Ð¸Ð½Ð°: {stats['avg_lyrics_length']:.0f} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²")
2542 |                 print(
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2557:27
     |
2555 |                         stats["analyzable_songs"] / stats["total_songs"]
2556 |                     ) * 100
2557 |                     print(f"")
     |                           ^^^
2558 |                     print(f"ðŸ“Š ÐŸÐ ÐžÐ¦Ð•ÐÐ¢ÐÐ«Ð• Ð¡ÐžÐžÐ¢ÐÐžÐ¨Ð•ÐÐ˜Ð¯:")
2559 |                     print(f"  ÐŸÐµÑÐµÐ½ Ñ Ñ‚ÐµÐºÑÑ‚Ð°Ð¼Ð¸: {lyrics_percent:.1f}%")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2558:27
     |
2556 |                     ) * 100
2557 |                     print(f"")
2558 |                     print(f"ðŸ“Š ÐŸÐ ÐžÐ¦Ð•ÐÐ¢ÐÐ«Ð• Ð¡ÐžÐžÐ¢ÐÐžÐ¨Ð•ÐÐ˜Ð¯:")
     |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2559 |                     print(f"  ÐŸÐµÑÐµÐ½ Ñ Ñ‚ÐµÐºÑÑ‚Ð°Ð¼Ð¸: {lyrics_percent:.1f}%")
2560 |                     print(f"  ÐŸÑ€Ð¸Ð³Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {analyzable_percent:.1f}%")
     |
help: Remove extraneous `f` prefix

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/algorithmic_analyzer.py:2572:22
     |
2571 |     async def analyze_all_songs(
2572 |         self, limit: Optional[int] = None, batch_size: int = 100
     |                      ^^^^^^^^^^^^^
2573 |     ) -> Dict[str, Any]:
2574 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð²ÑÐµÑ… Ð¿ÐµÑÐµÐ½ Ð² Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2573:10
     |
2571 |     async def analyze_all_songs(
2572 |         self, limit: Optional[int] = None, batch_size: int = 100
2573 |     ) -> Dict[str, Any]:
     |          ^^^^
2574 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð²ÑÐµÑ… Ð¿ÐµÑÐµÐ½ Ð² Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
2575 |         try:
     |
help: Replace with `dict`

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/analyzers/algorithmic_analyzer.py:2634:25
     |
2632 |                               processed += 1
2633 |
2634 | /                         except Exception as e:
2635 | |                             print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿ÐµÑÐ½Ð¸ {song['id']}: {e}")
     | |______________________________________________________________________________^
2636 |
2637 |                       results.extend(batch_results)
     |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2660:60
     |
2658 |             return {}
2659 |
2660 |     async def analyze_single_track(self, track_id: int) -> Dict[str, Any]:
     |                                                            ^^^^
2661 |         """ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð¹ Ð¿ÐµÑÐ½Ð¸ Ð¿Ð¾ ID"""
2662 |         try:
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2712:49
     |
2710 |             return {}
2711 |
2712 |     def _calculate_summary_stats(self, results: List[Dict]) -> Dict[str, Any]:
     |                                                 ^^^^
2713 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑÐ²Ð¾Ð´Ð½Ð¾Ð¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸"""
2714 |         if not results:
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2712:54
     |
2710 |             return {}
2711 |
2712 |     def _calculate_summary_stats(self, results: List[Dict]) -> Dict[str, Any]:
     |                                                      ^^^^
2713 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑÐ²Ð¾Ð´Ð½Ð¾Ð¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸"""
2714 |         if not results:
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2712:64
     |
2710 |             return {}
2711 |
2712 |     def _calculate_summary_stats(self, results: List[Dict]) -> Dict[str, Any]:
     |                                                                ^^^^
2713 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑÐ²Ð¾Ð´Ð½Ð¾Ð¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸"""
2714 |         if not results:
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/algorithmic_analyzer.py:2743:47
     |
2741 |         }
2742 |
2743 |     def _print_analysis_results(self, result: Dict[str, Any]):
     |                                               ^^^^
2744 |         """ÐšÑ€Ð°ÑÐ¸Ð²Ñ‹Ð¹ Ð²Ñ‹Ð²Ð¾Ð´ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
2745 |         print(f"\nðŸ“Š Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« ÐÐÐÐ›Ð˜Ð—Ð:")
     |
help: Replace with `dict`

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2745:15
     |
2743 |     def _print_analysis_results(self, result: Dict[str, Any]):
2744 |         """ÐšÑ€Ð°ÑÐ¸Ð²Ñ‹Ð¹ Ð²Ñ‹Ð²Ð¾Ð´ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
2745 |         print(f"\nðŸ“Š Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« ÐÐÐÐ›Ð˜Ð—Ð:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2746 |         print(f"ðŸŽ¯ Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {result['confidence']:.3f}")
2747 |         print(f"âš¡ Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {result['processing_time']:.3f}s")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2752:19
     |
2750 |         rhyme_analysis = result["raw_output"].get("rhyme_analysis", {})
2751 |         if rhyme_analysis:
2752 |             print(f"\nðŸŽµ Ð Ð˜Ð¤ÐœÐ« Ð˜ Ð—Ð’Ð£Ð§ÐÐÐ˜Ð•:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^
2753 |             print(f"  Ð¡Ñ…ÐµÐ¼Ð° Ñ€Ð¸Ñ„Ð¼Ð¾Ð²ÐºÐ¸: {rhyme_analysis.get('rhyme_scheme', 'N/A')}")
2754 |             print(f"  ÐŸÐ»Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ñ€Ð¸Ñ„Ð¼: {rhyme_analysis.get('rhyme_density', 0):.3f}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2761:19
     |
2759 |         flow_analysis = result["raw_output"].get("flow_analysis", {})
2760 |         if flow_analysis:
2761 |             print(f"\nðŸŒŠ FLOW Ð˜ Ð Ð˜Ð¢Ðœ:")
     |                   ^^^^^^^^^^^^^^^^^^^^
2762 |             print(
2763 |                 f"  ÐšÐ¾Ð½ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ»Ð¾Ð³Ð¾Ð²: {flow_analysis.get('syllable_consistency', 0):.3f}"
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2775:19
     |
2773 |         composite = result["raw_output"].get("composite_scores", {})
2774 |         if composite:
2775 |             print(f"\nðŸ† ÐšÐžÐœÐŸÐžÐ—Ð˜Ð¢ÐÐ«Ð• ÐžÐ¦Ð•ÐÐšÐ˜:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2776 |             print(
2777 |                 f"  Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¼Ð°ÑÑ‚ÐµÑ€ÑÑ‚Ð²Ð¾: {composite.get('technical_mastery', 0):.3f}"
     |
help: Remove extraneous `f` prefix

PLR0915 Too many statements (69 > 50)
    --> src/analyzers/algorithmic_analyzer.py:2786:11
     |
2786 | async def main():
     |           ^^^^
2787 |     """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ PostgreSQL"""
2788 |     import argparse
     |

F541 [*] f-string without any placeholders
    --> src/analyzers/algorithmic_analyzer.py:2889:27
     |
2887 |                 if results:
2888 |                     summary = results.get("summary_stats", {})
2889 |                     print(f"\nðŸ“ˆ Ð¡Ð’ÐžÐ”ÐÐÐ¯ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ:")
     |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2890 |                     print(f"  ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ Ñ‚Ñ€ÐµÐºÐ¾Ð²: {summary.get('total_results', 0):,}")
2891 |                     print(
     |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/create_visual_analysis.py:6:1
   |
 4 |   """
 5 |
 6 | / import sqlite3
 7 | | import pandas as pd
 8 | | import matplotlib.pyplot as plt
 9 | | import seaborn as sns
10 | | from collections import Counter
11 | | import numpy as np
12 | | from datetime import datetime
13 | | import os
   | |_________^
14 |
15 |   # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÑÑ‚Ð¸Ð»Ñ
   |
help: Organize imports

F401 [*] `pandas` imported but unused
 --> src/analyzers/create_visual_analysis.py:7:18
  |
6 | import sqlite3
7 | import pandas as pd
  |                  ^^
8 | import matplotlib.pyplot as plt
9 | import seaborn as sns
  |
help: Remove unused import: `pandas`

F401 [*] `collections.Counter` imported but unused
  --> src/analyzers/create_visual_analysis.py:10:25
   |
 8 | import matplotlib.pyplot as plt
 9 | import seaborn as sns
10 | from collections import Counter
   |                         ^^^^^^^
11 | import numpy as np
12 | from datetime import datetime
   |
help: Remove unused import: `collections.Counter`

F401 [*] `datetime.datetime` imported but unused
  --> src/analyzers/create_visual_analysis.py:12:22
   |
10 | from collections import Counter
11 | import numpy as np
12 | from datetime import datetime
   |                      ^^^^^^^^
13 | import os
   |
help: Remove unused import: `datetime.datetime`

F401 [*] `os` imported but unused
  --> src/analyzers/create_visual_analysis.py:13:8
   |
11 | import numpy as np
12 | from datetime import datetime
13 | import os
   |        ^^
14 |
15 | # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÑÑ‚Ð¸Ð»Ñ
   |
help: Remove unused import: `os`

PLR0915 Too many statements (88 > 50)
  --> src/analyzers/create_visual_analysis.py:81:5
   |
81 | def create_dashboard():
   |     ^^^^^^^^^^^^^^^^
82 |     """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÐºÑ€Ð°ÑÐ¸Ð²Ð¾Ð³Ð¾ Ð´Ð°ÑˆÐ±Ð¾Ñ€Ð´Ð°"""
83 |     stats = get_database_stats()
   |

F841 Local variable `values` is assigned to but never used
   --> src/analyzers/create_visual_analysis.py:116:5
    |
115 |     y_pos = np.arange(len(metrics))
116 |     values = [
    |     ^^^^^^
117 |         stats["total_tracks"],
118 |         stats["total_artists"],
    |
help: Remove assignment to unused variable `values`

B007 Loop control variable `i` not used within loop body
   --> src/analyzers/create_visual_analysis.py:142:9
    |
141 |     # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð½Ð° ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹
142 |     for i, bar in enumerate(bars):
    |         ^
143 |         height = bar.get_height()
144 |         ax2.text(
    |
help: Rename unused `i` to `_i`

RUF059 Unpacked variable `wedges` is never used
   --> src/analyzers/create_visual_analysis.py:159:9
    |
157 |         genre_counts = [g[1] for g in stats["genres"][:6]]
158 |
159 |         wedges, texts, autotexts = ax3.pie(
    |         ^^^^^^
160 |             genre_counts,
161 |             labels=genre_names,
    |
help: Prefix it with an underscore or any other dummy variable pattern

RUF059 Unpacked variable `texts` is never used
   --> src/analyzers/create_visual_analysis.py:159:17
    |
157 |         genre_counts = [g[1] for g in stats["genres"][:6]]
158 |
159 |         wedges, texts, autotexts = ax3.pie(
    |                 ^^^^^
160 |             genre_counts,
161 |             labels=genre_names,
    |
help: Prefix it with an underscore or any other dummy variable pattern

RUF059 Unpacked variable `autotexts` is never used
   --> src/analyzers/create_visual_analysis.py:159:24
    |
157 |         genre_counts = [g[1] for g in stats["genres"][:6]]
158 |
159 |         wedges, texts, autotexts = ax3.pie(
    |                        ^^^^^^^^^
160 |             genre_counts,
161 |             labels=genre_names,
    |
help: Prefix it with an underscore or any other dummy variable pattern

C408 Unnecessary `dict()` call (rewrite as a literal)
   --> src/analyzers/create_visual_analysis.py:217:18
    |
215 |               fontsize=10,
216 |               fontweight="bold",
217 |               bbox=dict(
    |  __________________^
218 | |                 boxstyle="round,pad=0.3", facecolor=colors[i % len(colors)], alpha=0.7
219 | |             ),
    | |_____________^
220 |               color="white",
221 |           )
    |
help: Rewrite as a literal

B007 Loop control variable `i` not used within loop body
   --> src/analyzers/create_visual_analysis.py:244:9
    |
242 |     ax6.set_ylabel("Completion %")
243 |
244 |     for i, bar in enumerate(bars):
    |         ^
245 |         height = bar.get_height()
246 |         ax6.text(
    |
help: Rename unused `i` to `_i`

F541 [*] f-string without any placeholders
   --> src/analyzers/create_visual_analysis.py:342:11
    |
340 |     print("ðŸŽ¤ RAP SCRAPER PROJECT - CLI SHOWCASE")
341 |     print("=" * 80)
342 |     print(f"ðŸ“Š Production ML Pipeline Status:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
343 |     print(f"   ðŸŽµ Total Tracks: 52,124")
344 |     print(f"   ðŸ‘¤ Artists: 314")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/create_visual_analysis.py:343:11
    |
341 |     print("=" * 80)
342 |     print(f"ðŸ“Š Production ML Pipeline Status:")
343 |     print(f"   ðŸŽµ Total Tracks: 52,124")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
344 |     print(f"   ðŸ‘¤ Artists: 314")
345 |     print(f"   ðŸ¤– AI Analyses: 14,434")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/create_visual_analysis.py:344:11
    |
342 |     print(f"ðŸ“Š Production ML Pipeline Status:")
343 |     print(f"   ðŸŽµ Total Tracks: 52,124")
344 |     print(f"   ðŸ‘¤ Artists: 314")
    |           ^^^^^^^^^^^^^^^^^^^^^
345 |     print(f"   ðŸ¤– AI Analyses: 14,434")
346 |     print(f"   ðŸ’¾ Database Size: 200.68 MB")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/create_visual_analysis.py:345:11
    |
343 |     print(f"   ðŸŽµ Total Tracks: 52,124")
344 |     print(f"   ðŸ‘¤ Artists: 314")
345 |     print(f"   ðŸ¤– AI Analyses: 14,434")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
346 |     print(f"   ðŸ’¾ Database Size: 200.68 MB")
347 |     print(f"   ðŸ”¥ Success Rate: 89.7%")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/create_visual_analysis.py:346:11
    |
344 |     print(f"   ðŸ‘¤ Artists: 314")
345 |     print(f"   ðŸ¤– AI Analyses: 14,434")
346 |     print(f"   ðŸ’¾ Database Size: 200.68 MB")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
347 |     print(f"   ðŸ”¥ Success Rate: 89.7%")
348 |     print()
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/create_visual_analysis.py:347:11
    |
345 |     print(f"   ðŸ¤– AI Analyses: 14,434")
346 |     print(f"   ðŸ’¾ Database Size: 200.68 MB")
347 |     print(f"   ðŸ”¥ Success Rate: 89.7%")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
348 |     print()
349 |     print("ðŸš€ Available Commands:")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/emotion_analyzer.py:28:1
   |
26 |   """
27 |
28 | / import sys
29 | | import os
30 | | from pathlib import Path
   | |________________________^
31 |
32 |   # Add project root to Python path for imports
   |
help: Organize imports

F401 [*] `os` imported but unused
  --> src/analyzers/emotion_analyzer.py:29:8
   |
28 | import sys
29 | import os
   |        ^^
30 | from pathlib import Path
   |
help: Remove unused import: `os`

E402 Module level import not at top of file
  --> src/analyzers/emotion_analyzer.py:36:1
   |
34 | sys.path.insert(0, str(project_root))
35 |
36 | import logging
   | ^^^^^^^^^^^^^^
37 | import asyncio
38 | import numpy as np
   |

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/emotion_analyzer.py:36:1
   |
34 |   sys.path.insert(0, str(project_root))
35 |
36 | / import logging
37 | | import asyncio
38 | | import numpy as np
39 | | from typing import Dict, Any, Optional, List, Tuple, Union
40 | | from datetime import datetime, timedelta
41 | | from dataclasses import dataclass, field
42 | | from contextlib import asynccontextmanager
43 | | import functools
44 | | import json
45 | | import re
   | |_________^
46 |
47 |   # Conditional imports Ð´Ð»Ñ graceful degradation
   |
help: Organize imports

E402 Module level import not at top of file
  --> src/analyzers/emotion_analyzer.py:37:1
   |
36 | import logging
37 | import asyncio
   | ^^^^^^^^^^^^^^
38 | import numpy as np
39 | from typing import Dict, Any, Optional, List, Tuple, Union
   |

E402 Module level import not at top of file
  --> src/analyzers/emotion_analyzer.py:38:1
   |
36 | import logging
37 | import asyncio
38 | import numpy as np
   | ^^^^^^^^^^^^^^^^^^
39 | from typing import Dict, Any, Optional, List, Tuple, Union
40 | from datetime import datetime, timedelta
   |

F401 [*] `numpy` imported but unused
  --> src/analyzers/emotion_analyzer.py:38:17
   |
36 | import logging
37 | import asyncio
38 | import numpy as np
   |                 ^^
39 | from typing import Dict, Any, Optional, List, Tuple, Union
40 | from datetime import datetime, timedelta
   |
help: Remove unused import: `numpy`

E402 Module level import not at top of file
  --> src/analyzers/emotion_analyzer.py:39:1
   |
37 | import asyncio
38 | import numpy as np
39 | from typing import Dict, Any, Optional, List, Tuple, Union
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
40 | from datetime import datetime, timedelta
41 | from dataclasses import dataclass, field
   |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/analyzers/emotion_analyzer.py:39:1
   |
37 | import asyncio
38 | import numpy as np
39 | from typing import Dict, Any, Optional, List, Tuple, Union
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
40 | from datetime import datetime, timedelta
41 | from dataclasses import dataclass, field
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/analyzers/emotion_analyzer.py:39:1
   |
37 | import asyncio
38 | import numpy as np
39 | from typing import Dict, Any, Optional, List, Tuple, Union
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
40 | from datetime import datetime, timedelta
41 | from dataclasses import dataclass, field
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> src/analyzers/emotion_analyzer.py:39:1
   |
37 | import asyncio
38 | import numpy as np
39 | from typing import Dict, Any, Optional, List, Tuple, Union
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
40 | from datetime import datetime, timedelta
41 | from dataclasses import dataclass, field
   |

F401 [*] `typing.Tuple` imported but unused
  --> src/analyzers/emotion_analyzer.py:39:47
   |
37 | import asyncio
38 | import numpy as np
39 | from typing import Dict, Any, Optional, List, Tuple, Union
   |                                               ^^^^^
40 | from datetime import datetime, timedelta
41 | from dataclasses import dataclass, field
   |
help: Remove unused import

F401 [*] `typing.Union` imported but unused
  --> src/analyzers/emotion_analyzer.py:39:54
   |
37 | import asyncio
38 | import numpy as np
39 | from typing import Dict, Any, Optional, List, Tuple, Union
   |                                                      ^^^^^
40 | from datetime import datetime, timedelta
41 | from dataclasses import dataclass, field
   |
help: Remove unused import

E402 Module level import not at top of file
  --> src/analyzers/emotion_analyzer.py:40:1
   |
38 | import numpy as np
39 | from typing import Dict, Any, Optional, List, Tuple, Union
40 | from datetime import datetime, timedelta
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
41 | from dataclasses import dataclass, field
42 | from contextlib import asynccontextmanager
   |

F401 [*] `datetime.timedelta` imported but unused
  --> src/analyzers/emotion_analyzer.py:40:32
   |
38 | import numpy as np
39 | from typing import Dict, Any, Optional, List, Tuple, Union
40 | from datetime import datetime, timedelta
   |                                ^^^^^^^^^
41 | from dataclasses import dataclass, field
42 | from contextlib import asynccontextmanager
   |
help: Remove unused import: `datetime.timedelta`

E402 Module level import not at top of file
  --> src/analyzers/emotion_analyzer.py:41:1
   |
39 | from typing import Dict, Any, Optional, List, Tuple, Union
40 | from datetime import datetime, timedelta
41 | from dataclasses import dataclass, field
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
42 | from contextlib import asynccontextmanager
43 | import functools
   |

E402 Module level import not at top of file
  --> src/analyzers/emotion_analyzer.py:42:1
   |
40 | from datetime import datetime, timedelta
41 | from dataclasses import dataclass, field
42 | from contextlib import asynccontextmanager
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43 | import functools
44 | import json
   |

F401 [*] `contextlib.asynccontextmanager` imported but unused
  --> src/analyzers/emotion_analyzer.py:42:24
   |
40 | from datetime import datetime, timedelta
41 | from dataclasses import dataclass, field
42 | from contextlib import asynccontextmanager
   |                        ^^^^^^^^^^^^^^^^^^^
43 | import functools
44 | import json
   |
help: Remove unused import: `contextlib.asynccontextmanager`

E402 Module level import not at top of file
  --> src/analyzers/emotion_analyzer.py:43:1
   |
41 | from dataclasses import dataclass, field
42 | from contextlib import asynccontextmanager
43 | import functools
   | ^^^^^^^^^^^^^^^^
44 | import json
45 | import re
   |

E402 Module level import not at top of file
  --> src/analyzers/emotion_analyzer.py:44:1
   |
42 | from contextlib import asynccontextmanager
43 | import functools
44 | import json
   | ^^^^^^^^^^^
45 | import re
   |

F401 [*] `json` imported but unused
  --> src/analyzers/emotion_analyzer.py:44:8
   |
42 | from contextlib import asynccontextmanager
43 | import functools
44 | import json
   |        ^^^^
45 | import re
   |
help: Remove unused import: `json`

E402 Module level import not at top of file
  --> src/analyzers/emotion_analyzer.py:45:1
   |
43 | import functools
44 | import json
45 | import re
   | ^^^^^^^^^
46 |
47 | # Conditional imports Ð´Ð»Ñ graceful degradation
   |

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/emotion_analyzer.py:49:5
   |
47 |   # Conditional imports Ð´Ð»Ñ graceful degradation
48 |   try:
49 | /     import torch
50 | |     from transformers import (
51 | |         AutoTokenizer,
52 | |         AutoModelForSequenceClassification,
53 | |         pipeline,
54 | |         AutoConfig,
55 | |     )
   | |_____^
56 |
57 |       HAS_TRANSFORMERS = True
   |
help: Organize imports

F401 `transformers.AutoTokenizer` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> src/analyzers/emotion_analyzer.py:51:9
   |
49 |     import torch
50 |     from transformers import (
51 |         AutoTokenizer,
   |         ^^^^^^^^^^^^^
52 |         AutoModelForSequenceClassification,
53 |         pipeline,
   |
help: Remove unused import

F401 `transformers.AutoModelForSequenceClassification` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> src/analyzers/emotion_analyzer.py:52:9
   |
50 |     from transformers import (
51 |         AutoTokenizer,
52 |         AutoModelForSequenceClassification,
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
53 |         pipeline,
54 |         AutoConfig,
   |
help: Remove unused import

F401 `transformers.AutoConfig` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> src/analyzers/emotion_analyzer.py:54:9
   |
52 |         AutoModelForSequenceClassification,
53 |         pipeline,
54 |         AutoConfig,
   |         ^^^^^^^^^^
55 |     )
   |
help: Remove unused import

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/emotion_analyzer.py:63:5
   |
62 |   try:
63 | /     from interfaces.analyzer_interface import (
64 | |         BaseAnalyzer,
65 | |         AnalysisResult,
66 | |         register_analyzer,
67 | |     )
   | |_____^
68 |
69 |       HAS_INTERFACE = True
   |
help: Organize imports

ARG001 Unused function argument: `name`
  --> src/analyzers/emotion_analyzer.py:79:27
   |
77 |             self.name = "emotion_analyzer"
78 |
79 |     def register_analyzer(name):
   |                           ^^^^
80 |         def decorator(cls):
81 |             return cls
   |

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/analyzers/emotion_analyzer.py:91:19
   |
89 |         analysis_type: str
90 |         confidence: float
91 |         metadata: Dict[str, Any]
   |                   ^^^^
92 |         raw_output: Dict[str, Any]
93 |         processing_time: float
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/analyzers/emotion_analyzer.py:92:21
   |
90 |         confidence: float
91 |         metadata: Dict[str, Any]
92 |         raw_output: Dict[str, Any]
   |                     ^^^^
93 |         processing_time: float
94 |         timestamp: str
   |
help: Replace with `dict`

I001 [*] Import block is un-sorted or un-formatted
   --> src/analyzers/emotion_analyzer.py:99:5
    |
 97 | # PostgreSQL integration
 98 | try:
 99 |     from src.database.postgres_adapter import PostgreSQLManager, DatabaseConfig
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
100 |
101 |     HAS_POSTGRES = True
    |
help: Organize imports

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:117:21
    |
115 |     confidence: float
116 |     dominant_emotion: str
117 |     emotion_scores: Dict[str, float]
    |                     ^^^^
118 |     genre_prediction: str
119 |     intensity: float  # Overall emotional intensity
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:121:15
    |
119 |     intensity: float  # Overall emotional intensity
120 |     analysis_time: float
121 |     metadata: Dict[str, Any] = field(default_factory=dict)
    |               ^^^^
122 |
123 |     # Rap-specific metrics
    |
help: Replace with `dict`

SIM114 [*] Combine `if` branches using logical `or` operator
   --> src/analyzers/emotion_analyzer.py:163:9
    |
161 |           """Create new model instance"""
162 |           # Determine optimal device
163 | /         if device == "auto":
164 | |             device_id = 0 if torch.cuda.is_available() else -1
165 | |         elif device == "cuda":
166 | |             device_id = 0 if torch.cuda.is_available() else -1
    | |______________________________________________________________^
167 |           else:
168 |               device_id = -1
    |
help: Combine `if` branches

RET504 Unnecessary assignment to `classifier` before `return` statement
   --> src/analyzers/emotion_analyzer.py:184:16
    |
182 |         )
183 |
184 |         return classifier
    |                ^^^^^^^^^^
    |
help: Remove unnecessary assignment

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> src/analyzers/emotion_analyzer.py:205:28
    |
204 |       # Rap-specific emotion mappings
205 |       RAP_EMOTION_PATTERNS = {
    |  ____________________________^
206 | |         "aggression": ["anger", "dominance", "power"],
207 | |         "authenticity": ["sadness", "pain", "struggle"],
208 | |         "celebration": ["joy", "pride", "success"],
209 | |         "romance": ["love", "desire", "attraction"],
210 | |         "reflection": ["contemplation", "wisdom", "growth"],
211 | |         "energy": ["excitement", "hype", "motivation"],
212 | |     }
    | |_____^
213 |
214 |       # Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ðµ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð´Ð»Ñ Ñ€ÑÐ¿-Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
    |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> src/analyzers/emotion_analyzer.py:215:20
    |
214 |       # Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ðµ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð´Ð»Ñ Ñ€ÑÐ¿-Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
215 |       RAP_KEYWORDS = {
    |  ____________________^
216 | |         "aggression": {
217 | |             "high": ["fuck", "shit", "damn", "bitch", "kill", "murder", "war", "fight"],
218 | |             "medium": ["mad", "angry", "hate", "rage", "wild", "crazy", "beast"],
219 | |             "low": ["tough", "hard", "strong", "power", "boss", "king"],
220 | |         },
221 | |         "authenticity": {
222 | |             "high": ["struggle", "pain", "real", "truth", "hood", "street", "broke"],
223 | |             "medium": ["life", "story", "journey", "hustle", "grind", "survive"],
224 | |             "low": ["experience", "learn", "grow", "change", "move"],
225 | |         },
226 | |         "success": {
227 | |             "high": [
228 | |                 "money",
229 | |                 "cash",
230 | |                 "rich",
231 | |                 "millionaire",
232 | |                 "gold",
233 | |                 "diamond",
234 | |                 "luxury",
235 | |             ],
236 | |             "medium": ["success", "win", "top", "best", "champion", "star"],
237 | |             "low": ["good", "great", "nice", "cool", "awesome", "amazing"],
238 | |         },
239 | |     }
    | |_____^
240 |
241 |       def __init__(self, config: Optional[Dict[str, Any]] = None):
    |

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/emotion_analyzer.py:241:32
    |
239 |     }
240 |
241 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^
242 |         """Initialize enhanced emotion analyzer"""
243 |         super().__init__(config)
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:241:41
    |
239 |     }
240 |
241 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
    |                                         ^^^^
242 |         """Initialize enhanced emotion analyzer"""
243 |         super().__init__(config)
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/emotion_analyzer.py:285:13
    |
283 |         try:
284 |             await self._init_task
285 |             return self._is_available
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^
286 |         except Exception as e:
287 |             logger.error(f"Failed to initialize EmotionAnalyzer: {e}")
    |

F541 [*] f-string without any placeholders
   --> src/analyzers/emotion_analyzer.py:324:28
    |
322 |                 self.db_manager = None
323 |         else:
324 |             logger.warning(f"PostgreSQL not enabled or dependencies missing")
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
325 |
326 |         # Initialize transformer model
    |
help: Remove extraneous `f` prefix

TRY301 Abstract `raise` to an inner function
   --> src/analyzers/emotion_analyzer.py:349:17
    |
347 |                 await self._warmup_model()
348 |             else:
349 |                 raise Exception("Failed to create classifier")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
350 |
351 |         except Exception as e:
    |

TRY002 Create your own exception
   --> src/analyzers/emotion_analyzer.py:349:23
    |
347 |                 await self._warmup_model()
348 |             else:
349 |                 raise Exception("Failed to create classifier")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
350 |
351 |         except Exception as e:
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/emotion_analyzer.py:411:22
    |
409 |     async def _analyze_emotion_enhanced(self, text: str) -> EmotionAnalysisResult:
410 |         """Enhanced emotion analysis with rap-specific features"""
411 |         start_time = datetime.now()
    |                      ^^^^^^^^^^^^^^
412 |
413 |         try:
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/emotion_analyzer.py:438:30
    |
436 |             genre_prediction = self._predict_rap_subgenre(emotion_scores, rap_metrics)
437 |
438 |             analysis_time = (datetime.now() - start_time).total_seconds()
    |                              ^^^^^^^^^^^^^^
439 |
440 |             # Update session statistics
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/emotion_analyzer.py:465:34
    |
463 |                     "rap_analysis": self.rap_analysis_enabled,
464 |                     "session_id": id(self),
465 |                     "timestamp": datetime.now().isoformat(),
    |                                  ^^^^^^^^^^^^^^
466 |                 },
467 |             )
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/emotion_analyzer.py:469:13
    |
467 |             )
468 |
469 |             return result
    |             ^^^^^^^^^^^^^
470 |
471 |         except Exception as e:
    |

RET504 Unnecessary assignment to `result` before `return` statement
   --> src/analyzers/emotion_analyzer.py:469:20
    |
467 |             )
468 |
469 |             return result
    |                    ^^^^^^
470 |
471 |         except Exception as e:
    |
help: Remove unnecessary assignment

PLR5501 [*] Use `elif` instead of `else` then `if`, to reduce indentation
   --> src/analyzers/emotion_analyzer.py:513:9
    |
511 |                   if len(text) > self.max_length * 2.5:  # Reduced multiplier
512 |                       text = text[: int(self.max_length * 2.5)]
513 | /         else:
514 | |             # More aggressive fallback truncation if tokenizer not available
515 | |             if len(text) > self.max_length * 2.5:
    | |____________^
516 |                   text = text[: int(self.max_length * 2.5)]
    |
help: Convert to `elif`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:520:55
    |
518 |         return text.strip()
519 |
520 |     async def _analyze_with_model(self, text: str) -> Dict[str, float]:
    |                                                       ^^^^
521 |         """Model-based emotion analysis with proper error handling"""
522 |         try:
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/emotion_analyzer.py:532:13
    |
530 |                     emotion_scores[emotion_name] = score
531 |
532 |             return emotion_scores
    |             ^^^^^^^^^^^^^^^^^^^^^
533 |
534 |         except Exception as e:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:538:56
    |
536 |             raise
537 |
538 |     def _fallback_emotion_analysis(self, text: str) -> Dict[str, float]:
    |                                                        ^^^^
539 |         """Enhanced fallback analysis with rap-specific patterns"""
540 |         text_lower = text.lower()
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:657:51
    |
655 |         return final_scores
656 |
657 |     def _analyze_rap_patterns(self, text: str) -> Dict[str, float]:
    |                                                   ^^^^
658 |         """Analyze rap-specific patterns and themes"""
659 |         text_lower = text.lower()
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:720:31
    |
719 |     def _calculate_enhanced_sentiment(
720 |         self, emotion_scores: Dict[str, float], rap_metrics: Dict[str, float]
    |                               ^^^^
721 |     ) -> float:
722 |         """Enhanced sentiment calculation with rap context"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:720:62
    |
719 |     def _calculate_enhanced_sentiment(
720 |         self, emotion_scores: Dict[str, float], rap_metrics: Dict[str, float]
    |                                                              ^^^^
721 |     ) -> float:
722 |         """Enhanced sentiment calculation with rap context"""
    |
help: Replace with `dict`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/emotion_analyzer.py:750:9
    |
748 |         if total_score > 0:
749 |             return positive_score / total_score
750 |         else:
    |         ^^^^
751 |             return 0.5
    |
help: Remove unnecessary `else`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:753:62
    |
751 |             return 0.5
752 |
753 |     def _calculate_emotional_intensity(self, emotion_scores: Dict[str, float]) -> float:
    |                                                              ^^^^
754 |         """Calculate overall emotional intensity"""
755 |         return (
    |
help: Replace with `dict`

PLR0911 Too many return statements (7 > 6)
   --> src/analyzers/emotion_analyzer.py:761:9
    |
759 |         )
760 |
761 |     def _predict_rap_subgenre(
    |         ^^^^^^^^^^^^^^^^^^^^^
762 |         self, emotion_scores: Dict[str, float], rap_metrics: Dict[str, float]
763 |     ) -> str:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:762:31
    |
761 |     def _predict_rap_subgenre(
762 |         self, emotion_scores: Dict[str, float], rap_metrics: Dict[str, float]
    |                               ^^^^
763 |     ) -> str:
764 |         """Predict rap subgenre based on emotional patterns"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:762:62
    |
761 |     def _predict_rap_subgenre(
762 |         self, emotion_scores: Dict[str, float], rap_metrics: Dict[str, float]
    |                                                              ^^^^
763 |     ) -> str:
764 |         """Predict rap subgenre based on emotional patterns"""
    |
help: Replace with `dict`

RET505 [*] Unnecessary `elif` after `return` statement
   --> src/analyzers/emotion_analyzer.py:777:9
    |
775 |         if aggression > 0.7 and anger > 0.6:
776 |             return "hardcore_rap"
777 |         elif love > 0.5 or (joy > 0.4 and energy < 0.3):
    |         ^^^^
778 |             return "r&b_rap"
779 |         elif authenticity > 0.6 and sadness > 0.4:
    |
help: Remove unnecessary `elif`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/emotion_analyzer.py:814:36
    |
812 |             "metadata": {
813 |                 "analyzer_version": "2.0.0",
814 |                 "processing_date": datetime.now().isoformat(),
    |                                    ^^^^^^^^^^^^^^
815 |                 "dominant_emotion": emotion_result.dominant_emotion,
816 |                 "emotion_scores": emotion_result.emotion_scores,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/emotion_analyzer.py:830:26
    |
828 |             },
829 |             "raw_output": raw_output,
830 |             "timestamp": datetime.now().isoformat(),
    |                          ^^^^^^^^^^^^^^
831 |         }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/emotion_analyzer.py:849:36
    |
847 |                 "error": error,
848 |                 "analyzer_version": "2.0.0",
849 |                 "processing_date": datetime.now().isoformat(),
    |                                    ^^^^^^^^^^^^^^
850 |                 "available": self._is_available,
851 |                 "initialization_error": self._initialization_error,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/emotion_analyzer.py:854:26
    |
852 |             },
853 |             "raw_output": {"error": error},
854 |             "timestamp": datetime.now().isoformat(),
    |                          ^^^^^^^^^^^^^^
855 |         }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:863:15
    |
861 |     def _build_compatible_analysis_result(
862 |         self,
863 |         base: Dict[str, Any],
    |               ^^^^
864 |         analyzer_type_value: str,
865 |         analysis_data_value: Dict[str, Any],
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/emotion_analyzer.py:865:30
    |
863 |         base: Dict[str, Any],
864 |         analyzer_type_value: str,
865 |         analysis_data_value: Dict[str, Any],
    |                              ^^^^
866 |     ) -> AnalysisResult:
867 |         """Build AnalysisResult compatible with either current interface or fallback definition.
    |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/emotion_analyzer.py:905:26
    |
903 |     ) -> EmotionAnalysisResult:
904 |         """Create error emotion result"""
905 |         analysis_time = (datetime.now() - start_time).total_seconds()
    |                          ^^^^^^^^^^^^^^
906 |
907 |         return EmotionAnalysisResult(
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/emotion_analyzer.py:920:28
    |
919 |     async def batch_analyze(
920 |         self, lyrics_list: List[str], **kwargs
    |                            ^^^^
921 |     ) -> List[EmotionAnalysisResult]:
922 |         """Optimized batch analysis"""
    |
help: Replace with `list`

ARG002 Unused method argument: `kwargs`
   --> src/analyzers/emotion_analyzer.py:920:41
    |
919 |     async def batch_analyze(
920 |         self, lyrics_list: List[str], **kwargs
    |                                         ^^^^^^
921 |     ) -> List[EmotionAnalysisResult]:
922 |         """Optimized batch analysis"""
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/emotion_analyzer.py:921:10
    |
919 |     async def batch_analyze(
920 |         self, lyrics_list: List[str], **kwargs
921 |     ) -> List[EmotionAnalysisResult]:
    |          ^^^^
922 |         """Optimized batch analysis"""
923 |         if not await self.initialize():
    |
help: Replace with `list`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/emotion_analyzer.py:926:29
    |
924 |             return [
925 |                 self._create_error_emotion_result(
926 |                     lyrics, datetime.now(), "Analyzer not available"
    |                             ^^^^^^^^^^^^^^
927 |                 )
928 |                 for lyrics in lyrics_list
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/emotion_analyzer.py:942:29
    |
940 |                 if isinstance(result, Exception):
941 |                     error_result = self._create_error_emotion_result(
942 |                         "", datetime.now(), str(result)
    |                             ^^^^^^^^^^^^^^
943 |                     )
944 |                     results.append(error_result)
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/emotion_analyzer.py:952:10
    |
950 |     async def analyze_from_database(
951 |         self, limit: int = 100, analyzer_type: str = "emotion_analyzer_v2"
952 |     ) -> List[AnalysisResult]:
    |          ^^^^
953 |         """
954 |         Analyze songs from PostgreSQL database that haven't been analyzed yet
    |
help: Replace with `list`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/analyzers/emotion_analyzer.py:990:17
    |
988 |                       results.append(result)
989 |
990 | /                 except Exception as e:
991 | |                     logger.error(f"Failed to analyze track {track['id']}: {e}")
992 | |                     continue
    | |____________________________^
993 |
994 |               logger.info(f"Successfully analyzed {len(results)} tracks")
    |

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/emotion_analyzer.py:995:13
    |
994 |             logger.info(f"Successfully analyzed {len(results)} tracks")
995 |             return results
    |             ^^^^^^^^^^^^^^
996 |
997 |         except Exception as e:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/emotion_analyzer.py:1038:10
     |
1036 |     async def batch_analyze_from_database(
1037 |         self, batch_size: int = 50, max_batches: int = 10
1038 |     ) -> Dict[str, Any]:
     |          ^^^^
1039 |         """
1040 |         Perform batch analysis of songs from database
     |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/emotion_analyzer.py:1059:27
     |
1057 |             "batches_processed": 0,
1058 |             "errors": 0,
1059 |             "start_time": datetime.now(),
     |                           ^^^^^^^^^^^^^^
1060 |         }
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/analyzers/emotion_analyzer.py:1097:21
     |
1095 |                           stats["total_analyzed"] += 1
1096 |
1097 | /                     except Exception as e:
1098 | |                         logger.error(f"Failed to analyze track {track['id']}: {e}")
1099 | |                         stats["errors"] += 1
1100 | |                         continue
     | |________________________________^
1101 |
1102 |                   # Save batch results
     |

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/analyzers/emotion_analyzer.py:1108:21
     |
1106 |                           await self._save_analysis_to_database(track_id, result)
1107 |                           saved_count += 1
1108 | /                     except Exception as e:
1109 | |                         logger.error(f"Failed to save result for track {track_id}: {e}")
     | |________________________________________________________________________________________^
1110 |
1111 |                   stats["total_saved"] += saved_count
     |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/emotion_analyzer.py:1123:33
     |
1121 |                 await asyncio.sleep(0.1)
1122 |
1123 |             stats["end_time"] = datetime.now()
     |                                 ^^^^^^^^^^^^^^
1124 |             stats["duration"] = (
1125 |                 stats["end_time"] - stats["start_time"]
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

TRY300 Consider moving this statement to an `else` block
    --> src/analyzers/emotion_analyzer.py:1129:13
     |
1128 |             logger.info(f"Batch analysis completed: {stats}")
1129 |             return stats
     |             ^^^^^^^^^^^^
1130 |
1131 |         except Exception as e:
     |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/emotion_analyzer.py:1140:36
     |
1138 |         return self._is_available
1139 |
1140 |     def get_session_stats(self) -> Dict[str, Any]:
     |                                    ^^^^
1141 |         """Get current session statistics"""
1142 |         stats = self.session_stats.copy()
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/emotion_analyzer.py:1148:43
     |
1146 |         return stats
1147 |
1148 |     async def get_database_stats(self) -> Dict[str, Any]:
     |                                           ^^^^
1149 |         """Get analysis statistics from PostgreSQL database"""
1150 |         if not self.db_manager:
     |
help: Replace with `dict`

ARG002 Unused method argument: `limit`
    --> src/analyzers/emotion_analyzer.py:1159:42
     |
1157 |             return {"error": str(e)}
1158 |
1159 |     async def get_analysis_summary(self, limit: int = 100) -> Dict[str, Any]:
     |                                          ^^^^^
1160 |         """Get summary of recent analysis results"""
1161 |         if not self.db_manager:
     |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/emotion_analyzer.py:1159:63
     |
1157 |             return {"error": str(e)}
1158 |
1159 |     async def get_analysis_summary(self, limit: int = 100) -> Dict[str, Any]:
     |                                                               ^^^^
1160 |         """Get summary of recent analysis results"""
1161 |         if not self.db_manager:
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/emotion_analyzer.py:1207:36
     |
1205 |         logger.info("EmotionAnalyzer cleanup completed")
1206 |
1207 |     def get_analyzer_info(self) -> Dict[str, Any]:
     |                                    ^^^^
1208 |         """Get comprehensive analyzer information"""
1209 |         return {
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/emotion_analyzer.py:1274:37
     |
1273 |     @property
1274 |     def supported_features(self) -> List[str]:
     |                                     ^^^^
1275 |         """Return comprehensive feature list"""
1276 |         return [
     |
help: Replace with `list`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/emotion_analyzer.py:1302:22
     |
1300 |     @functools.wraps(func)
1301 |     async def wrapper(self, *args, **kwargs):
1302 |         start_time = datetime.now()
     |                      ^^^^^^^^^^^^^^
1303 |         try:
1304 |             result = await func(self, *args, **kwargs)
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/emotion_analyzer.py:1311:31
     |
1309 |             raise
1310 |         finally:
1311 |             execution_time = (datetime.now() - start_time).total_seconds()
     |                               ^^^^^^^^^^^^^^
1312 |             logger.debug(
1313 |                 f"{func.__name__} executed in {execution_time:.3f}s, success: {success}"
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1394:19
     |
1392 |             )
1393 |
1394 |             print(f"   âœ… Analysis completed")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
1395 |             print(f"   ðŸ“ˆ Sentiment: {result.metadata.get('sentiment_score', 0):.3f}")
1396 |             print(f"   ðŸŽ¯ Confidence: {result.confidence:.3f}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1418:11
     |
1417 |     # Session statistics
1418 |     print(f"\nðŸ“Š Session Statistics:")
     |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
1419 |     stats = analyzer.get_session_stats()
1420 |     for key, value in stats.items():
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1424:11
     |
1423 |     # Analyzer info
1424 |     print(f"\nðŸ” Analyzer Information:")
     |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1425 |     info = analyzer.get_analyzer_info()
1426 |     print(f"   Version: {info['version']}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1433:11
     |
1431 |     # Cleanup
1432 |     await analyzer.cleanup()
1433 |     print(f"\nâœ… Testing completed successfully!")
     |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
     |
help: Remove extraneous `f` prefix

F841 Local variable `result` is assigned to but never used
    --> src/analyzers/emotion_analyzer.py:1457:17
     |
1455 |             analyzer = EmotionAnalyzer()
1456 |             if await analyzer.initialize():
1457 |                 result = await analyzer.analyze_song(
     |                 ^^^^^^
1458 |                     "Test Artist",
1459 |                     "Test Song",
     |
help: Remove assignment to unused variable `result`

ERA001 Found commented-out code
    --> src/analyzers/emotion_analyzer.py:1464:17
     |
1463 |                 # Here you would store the result to PostgreSQL
1464 |                 # await db_manager.store_analysis_result(result)
     |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1465 |                 print("   âœ… Analysis result ready for PostgreSQL storage")
     |
help: Remove commented-out code

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/emotion_analyzer.py:1503:18
     |
1501 |     print(f"   Processing {len(lyrics_batch)} texts in batch...")
1502 |
1503 |     start_time = datetime.now()
     |                  ^^^^^^^^^^^^^^
1504 |     results = await analyzer.batch_analyze(lyrics_batch)
1505 |     batch_time = (datetime.now() - start_time).total_seconds()
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/emotion_analyzer.py:1505:19
     |
1503 |     start_time = datetime.now()
1504 |     results = await analyzer.batch_analyze(lyrics_batch)
1505 |     batch_time = (datetime.now() - start_time).total_seconds()
     |                   ^^^^^^^^^^^^^^
1506 |
1507 |     print(f"   âœ… Batch completed in {batch_time:.3f}s")
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

RET505 [*] Unnecessary `elif` after `return` statement
    --> src/analyzers/emotion_analyzer.py:1542:13
     |
1540 |                 print("ðŸ‘‹ Ð”Ð¾ ÑÐ²Ð¸Ð´Ð°Ð½Ð¸Ñ!")
1541 |                 return
1542 |             elif choice == "1":
     |             ^^^^
1543 |                 await test_analyzer_comprehensive()
1544 |                 await pause_for_user()
     |
help: Remove unnecessary `elif`

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1699:15
     |
1698 |         # Ð—Ð°Ð¿ÑƒÑÐº Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ progress bar
1699 |         print(f"\nðŸš€ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð¼Ð°ÑÑÐ¾Ð²Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·...")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1700 |         stats = await analyzer.batch_analyze_from_database(
1701 |             batch_size=20,  # Ð£Ð¼ÐµÐ½ÑŒÑˆÐµÐ½Ð½Ñ‹Ð¹ batch size Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ Ñ‡Ð°ÑÑ‚Ñ‹Ñ… Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¹
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1706:15
     |
1705 |         # ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
1706 |         print(f"\nðŸ“Š Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« ÐœÐÐ¡Ð¡ÐžÐ’ÐžÐ“Ðž ÐÐÐÐ›Ð˜Ð—Ð:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1707 |         print(f"   Ð’ÑÐµÐ³Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾: {stats.get('total_processed', 0)}")
1708 |         print(f"   Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {stats.get('total_analyzed', 0)}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1797:15
     |
1796 | â€¦     # ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
1797 | â€¦     print(f"\nðŸ“Š Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« ÐÐÐÐ›Ð˜Ð—Ð:")
     |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
1798 | â€¦     print(
1799 | â€¦         f"   ðŸ“ˆ ÐÐ°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ: {result.metadata.get('sentiment_score', 0):.3f} (0=Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ðµ, 1=Ð¿Ð¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½Ð¾Ðµ)"
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1813:19
     |
1811 |         rap_metrics = result.metadata.get("rap_metrics", {})
1812 |         if rap_metrics:
1813 |             print(f"\nðŸŽ¤ RAP-Ð¡ÐŸÐ•Ð¦Ð˜Ð¤Ð˜Ð§ÐÐ«Ð• ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1814 |             print(f"   ðŸ”¥ ÐÐ³Ñ€ÐµÑÑÐ¸Ð²Ð½Ð¾ÑÑ‚ÑŒ: {rap_metrics.get('aggression_level', 0):.3f}")
1815 |             print(f"   âš¡ Ð­Ð½ÐµÑ€Ð³Ð¸Ñ: {rap_metrics.get('energy_level', 0):.3f}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1824:19
     |
1822 |         emotion_scores = result.metadata.get("emotion_scores", {})
1823 |         if emotion_scores:
1824 |             print(f"\nðŸŽ­ Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ«Ð™ ÐÐÐÐ›Ð˜Ð— Ð­ÐœÐžÐ¦Ð˜Ð™:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1825 |             for emotion, score in sorted(
1826 |                 emotion_scores.items(), key=lambda x: x[1], reverse=True
     |
help: Remove extraneous `f` prefix

F841 Local variable `summary` is assigned to but never used
    --> src/analyzers/emotion_analyzer.py:1857:9
     |
1855 |         # ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
1856 |         stats = await analyzer.get_database_stats()
1857 |         summary = await analyzer.get_analysis_summary()
     |         ^^^^^^^
1858 |
1859 |         print("ðŸ—„ï¸ ÐžÐ¡ÐÐžÐ’ÐÐÐ¯ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ:")
     |
help: Remove assignment to unused variable `summary`

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1868:19
     |
1866 |         analyzer_stats = await get_analyzer_stats(analyzer.db_manager)
1867 |         if analyzer_stats:
1868 |             print(f"\nðŸ¤– Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ ÐŸÐž ÐÐÐÐ›Ð˜Ð—ÐÐ¢ÐžÐ ÐÐœ:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1869 |             for analyzer_type, count in analyzer_stats.items():
1870 |                 print(f"   {analyzer_type}: {count} Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð²")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1874:15
     |
1872 |         # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð½ÐµÐ°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð²
1873 |         unanalyzed_stats = await get_unanalyzed_tracks_count(analyzer.db_manager)
1874 |         print(f"\nðŸŽ¯ ÐŸÐžÐ¢Ð Ð•Ð‘ÐÐžÐ¡Ð¢Ð¬ Ð’ ÐÐÐÐ›Ð˜Ð—Ð•:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1875 |         print(f"   Ð’ÑÐµÐ³Ð¾ Ñ‚Ñ€ÐµÐºÐ¾Ð²: {unanalyzed_stats.get('total_tracks', 0)}")
1876 |         print(
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1883:15
     |
1881 |         # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÑÐµÑÑÐ¸Ð¸
1882 |         session_stats = analyzer.get_session_stats()
1883 |         print(f"\nðŸ“ˆ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ Ð¢Ð•ÐšÐ£Ð©Ð•Ð™ Ð¡Ð•Ð¡Ð¡Ð˜Ð˜:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1884 |         for key, value in session_stats.items():
1885 |             print(f"   {key}: {value}")
     |
help: Remove extraneous `f` prefix

TRY300 Consider moving this statement to an `else` block
    --> src/analyzers/emotion_analyzer.py:1902:9
     |
1900 |         if result:
1901 |             return dict(result[0])
1902 |         return None
     |         ^^^^^^^^^^^
1903 |     except Exception as e:
1904 |         print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ñ‚Ñ€ÐµÐºÐ°: {e}")
     |

TRY300 Consider moving this statement to an `else` block
    --> src/analyzers/emotion_analyzer.py:1953:9
     |
1951 |         if result:
1952 |             return dict(result[0])
1953 |         return None
     |         ^^^^^^^^^^^
1954 |     except Exception as e:
1955 |         print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ð¾Ð³Ð¾ Ñ‚Ñ€ÐµÐºÐ°: {e}")
     |

RET505 [*] Unnecessary `else` after `return` statement
    --> src/analyzers/emotion_analyzer.py:1978:13
     |
1976 |             if 0 <= index < len(tracks):
1977 |                 return tracks[index]
1978 |             else:
     |             ^^^^
1979 |                 print("âŒ ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð½Ð¾Ð¼ÐµÑ€")
1980 |         except ValueError:
     |
help: Remove unnecessary `else`

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/analyzers/emotion_analyzer.py:1980:9
     |
1978 |               else:
1979 |                   print("âŒ ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð½Ð¾Ð¼ÐµÑ€")
1980 | /         except ValueError:
1981 | |             print("âŒ Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ñ‡Ð¸ÑÐ»Ð¾")
     | |_____________________________________^
     |

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:1986:11
     |
1984 | async def display_analysis_result(result, track):
1985 |     """ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð·Ð¸Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
1986 |     print(f"\nðŸ“Š Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« ÐÐÐÐ›Ð˜Ð—Ð:")
     |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
1987 |     print(f"   ðŸŽµ Ð¢Ñ€ÐµÐº: {track['artist']} - {track['title']}")
1988 |     print(f"   ðŸ“ˆ ÐÐ°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ: {result.metadata.get('sentiment_score', 0):.3f}")
     |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
    --> src/analyzers/emotion_analyzer.py:2052:5
     |
2050 |   # Main execution
2051 |   if __name__ == "__main__":
2052 | /     import sys
2053 | |     import argparse
     | |___________________^
2054 |
2055 |       # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
     |
help: Organize imports

PLR0912 Too many branches (17 > 12)
    --> src/analyzers/emotion_analyzer.py:2093:15
     |
2091 |     args = parser.parse_args()
2092 |
2093 |     async def main():
     |               ^^^^
2094 |         """Main execution function"""
2095 |         # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¸Ð»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½ --menu, Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ
     |

F841 Local variable `limit` is assigned to but never used
    --> src/analyzers/emotion_analyzer.py:2111:13
     |
2109 |         if args.analyze_db:
2110 |             # Determine limit: use --all for unlimited, otherwise use --limit
2111 |             limit = None if args.all else args.limit
     |             ^^^^^
2112 |             limit_text = "all unanalyzed tracks" if args.all else f"limit: {args.limit}"
     |
help: Remove assignment to unused variable `limit`

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:2130:19
     |
2129 |         if args.batch_db:
2130 |             print(f"\nâš¡ Running batch analysis from database...")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2131 |             analyzer = EmotionAnalyzer({"postgres_enabled": True})
2132 |             if await analyzer.initialize():
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:2142:19
     |
2141 |         if args.db_stats:
2142 |             print(f"\nðŸ“Š Database Statistics:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2143 |             analyzer = EmotionAnalyzer({"postgres_enabled": True})
2144 |             if await analyzer.initialize():
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/emotion_analyzer.py:2154:19
     |
2153 |         if args.text:
2154 |             print(f"\nðŸ“ Analyzing custom text...")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2155 |             analyzer = EmotionAnalyzer()
2156 |             if await analyzer.initialize():
     |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/mass_qwen_analysis.py:22:1
   |
20 |   """
21 |
22 | / import sys
23 | | import os
24 | | import asyncio
25 | | import time
26 | | import json
27 | | import argparse
28 | | import logging
29 | | from pathlib import Path
30 | | from datetime import datetime, timedelta
31 | | from typing import List, Dict, Any, Optional, Tuple
32 | | from dataclasses import dataclass
33 | | from dotenv import load_dotenv
   | |______________________________^
34 |
35 |   # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
   |
help: Organize imports

UP035 `typing.List` is deprecated, use `list` instead
  --> src/analyzers/mass_qwen_analysis.py:31:1
   |
29 | from pathlib import Path
30 | from datetime import datetime, timedelta
31 | from typing import List, Dict, Any, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
32 | from dataclasses import dataclass
33 | from dotenv import load_dotenv
   |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/analyzers/mass_qwen_analysis.py:31:1
   |
29 | from pathlib import Path
30 | from datetime import datetime, timedelta
31 | from typing import List, Dict, Any, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
32 | from dataclasses import dataclass
33 | from dotenv import load_dotenv
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> src/analyzers/mass_qwen_analysis.py:31:1
   |
29 | from pathlib import Path
30 | from datetime import datetime, timedelta
31 | from typing import List, Dict, Any, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
32 | from dataclasses import dataclass
33 | from dotenv import load_dotenv
   |

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/analyzers/mass_qwen_analysis.py:39:16
   |
38 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path
39 | project_root = os.path.dirname(
   |                ^^^^^^^^^^^^^^^
40 |     os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
41 | )
   |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/analyzers/mass_qwen_analysis.py:40:5
   |
38 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path
39 | project_root = os.path.dirname(
40 |     os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
   |     ^^^^^^^^^^^^^^^
41 | )
42 | sys.path.insert(0, project_root)
   |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/analyzers/mass_qwen_analysis.py:40:21
   |
38 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path
39 | project_root = os.path.dirname(
40 |     os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
   |                     ^^^^^^^^^^^^^^^
41 | )
42 | sys.path.insert(0, project_root)
   |
help: Replace with `Path(...).parent`

PTH100 `os.path.abspath()` should be replaced by `Path.resolve()`
  --> src/analyzers/mass_qwen_analysis.py:40:37
   |
38 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path
39 | project_root = os.path.dirname(
40 |     os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
   |                                     ^^^^^^^^^^^^^^^
41 | )
42 | sys.path.insert(0, project_root)
   |
help: Replace with `Path(...).resolve()`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/analyzers/mass_qwen_analysis.py:76:15
   |
74 |     analyzer_type: str
75 |     confidence: float
76 |     metadata: Dict[str, Any]
   |               ^^^^
77 |     raw_output: Dict[str, Any]
78 |     processing_time: float
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/analyzers/mass_qwen_analysis.py:77:17
   |
75 |     confidence: float
76 |     metadata: Dict[str, Any]
77 |     raw_output: Dict[str, Any]
   |                 ^^^^
78 |     processing_time: float
79 |     timestamp: str
   |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
  --> src/analyzers/mass_qwen_analysis.py:87:32
   |
85 |     """
86 |
87 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
   |                                ^^^^^^^^^^^^^^^^^^^^^^^^
88 |         """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ð¾Ð³Ð¾ Qwen Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
89 |         self.config = config or {}
   |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/analyzers/mass_qwen_analysis.py:87:41
   |
85 |     """
86 |
87 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
   |                                         ^^^^
88 |         """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ð¾Ð³Ð¾ Qwen Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
89 |         self.config = config or {}
   |
help: Replace with `dict`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/mass_qwen_analysis.py:143:13
    |
141 |                 logger.info("âœ… Novita AI Qwen API ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¿Ñ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½")
142 |                 return True
143 |             else:
    |             ^^^^
144 |                 logger.error("âŒ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Qwen API")
145 |                 return False
    |
help: Remove unnecessary `else`

SIM103 Return the condition `not len(lyrics.strip()) < 10` directly
   --> src/analyzers/mass_qwen_analysis.py:155:9
    |
153 |           if not all([artist, title, lyrics]):
154 |               return False
155 | /         if len(lyrics.strip()) < 10:
156 | |             return False
157 | |         return True
    | |___________________^
158 |
159 |       def preprocess_lyrics(self, lyrics: str) -> str:
    |
help: Replace with `return not len(lyrics.strip()) < 10`

TRY301 Abstract `raise` to an inner function
   --> src/analyzers/mass_qwen_analysis.py:214:17
    |
213 |             if not response.choices or not response.choices[0].message.content:
214 |                 raise RuntimeError("Empty response from Qwen model")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
215 |
216 |             # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/mass_qwen_analysis.py:232:40
    |
230 |                     "model_name": self.model_name,
231 |                     "model_version": "qwen3-4b-fp8",
232 |                     "processing_date": datetime.now().isoformat(),
    |                                        ^^^^^^^^^^^^^^
233 |                     "lyrics_length": len(processed_lyrics),
234 |                     "temperature": self.temperature,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/mass_qwen_analysis.py:251:27
    |
249 |                 raw_output=analysis_data,
250 |                 processing_time=processing_time,
251 |                 timestamp=datetime.now().isoformat(),
    |                           ^^^^^^^^^^^^^^
252 |             )
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/analyzers/mass_qwen_analysis.py:258:32
    |
256 |                 f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ð¾Ð³Ð¾ Qwen Ð´Ð»Ñ {artist} - {title}: {e}"
257 |             )
258 |             raise RuntimeError(f"Qwen analysis failed: {e}") from e
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
259 |
260 |     def _create_analysis_prompts(
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:327:54
    |
325 |         return system_prompt, user_prompt
326 |
327 |     def _parse_response(self, response_text: str) -> Dict[str, Any]:
    |                                                      ^^^^
328 |         """ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Qwen Ð¼Ð¾Ð´ÐµÐ»Ð¸"""
329 |         try:
    |
help: Replace with `dict`

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:357:38
    |
355 |                         logger.debug("âœ… JSON parsing successful after fixes")
356 |                     except json.JSONDecodeError:
357 |                         logger.error(f"JSON still invalid after fixes")
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
358 |                         analysis_data = self._create_fallback_analysis()
359 |             else:
    |
help: Remove extraneous `f` prefix

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/mass_qwen_analysis.py:381:13
    |
379 |             self._validate_analysis_structure(analysis_data)
380 |
381 |             return analysis_data
    |             ^^^^^^^^^^^^^^^^^^^^
382 |
383 |         except json.JSONDecodeError as e:
    |

RET504 Unnecessary assignment to `json_str` before `return` statement
   --> src/analyzers/mass_qwen_analysis.py:405:16
    |
403 |         json_str = json_str.strip()
404 |
405 |         return json_str
    |                ^^^^^^^^
406 |
407 |     def _validate_analysis_structure(self, data: Dict[str, Any]) -> None:
    |
help: Remove unnecessary assignment

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:407:50
    |
405 |         return json_str
406 |
407 |     def _validate_analysis_structure(self, data: Dict[str, Any]) -> None:
    |                                                  ^^^^
408 |         """Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
409 |         required_sections = [
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:438:52
    |
436 |                     logger.warning(f"Invalid metric value for {metric}: {value}")
437 |
438 |     def _calculate_confidence(self, analysis_data: Dict[str, Any]) -> float:
    |                                                    ^^^^
439 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ñ… Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
440 |         confidence_factors = []
    |
help: Replace with `dict`

RUF019 [*] Unnecessary key check before dictionary access
   --> src/analyzers/mass_qwen_analysis.py:454:16
    |
452 |             "cultural_context",
453 |         ]:
454 |             if section_name in analysis_data and analysis_data[section_name]:
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
455 |                 sections_completed += 1
    |
help: Replace with `dict.get`

PERF401 Use a list comprehension to create a transformed list
   --> src/analyzers/mass_qwen_analysis.py:477:21
    |
475 |             for metric_value in quality_metrics.values():
476 |                 if isinstance(metric_value, (int, float)) and 0 <= metric_value <= 1:
477 |                     valid_metrics.append(metric_value)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
478 |
479 |             if valid_metrics:
    |
help: Replace for loop with list comprehension

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/mass_qwen_analysis.py:486:9
    |
484 |         if confidence_factors:
485 |             return sum(confidence_factors) / len(confidence_factors)
486 |         else:
    |         ^^^^
487 |             return 0.5  # Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…
    |
help: Remove unnecessary `else`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:489:44
    |
487 |             return 0.5  # Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…
488 |
489 |     def _create_fallback_analysis(self) -> Dict[str, Any]:
    |                                            ^^^^
490 |         """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð² ÑÐ»ÑƒÑ‡Ð°Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð°"""
491 |         return {
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/mass_qwen_analysis.py:548:17
    |
546 |     errors: int = 0
547 |     skipped: int = 0
548 |     start_time: Optional[datetime] = None
    |                 ^^^^^^^^^^^^^^^^^^
549 |     current_batch: int = 0
550 |     total_batches: int = 0
    |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/mass_qwen_analysis.py:562:20
    |
560 |         if not self.start_time:
561 |             return 0.0
562 |         elapsed = (datetime.now() - self.start_time).total_seconds()
    |                    ^^^^^^^^^^^^^^
563 |         return (self.processed / max(elapsed, 1)) * 60
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/mass_qwen_analysis.py:609:13
    |
608 |             print("âœ… PostgreSQL Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾")
609 |             return True
    |             ^^^^^^^^^^^
610 |
611 |         except Exception as e:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:615:43
    |
613 |             return False
614 |
615 |     async def get_database_stats(self) -> Dict[str, Any]:
    |                                           ^^^^
616 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
617 |         try:
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/analyzers/mass_qwen_analysis.py:644:18
    |
642 |                 return False
643 |
644 |             with open(self.checkpoint_file, "r", encoding="utf-8") as f:
    |                  ^^^^
645 |                 data = json.load(f)
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> src/analyzers/mass_qwen_analysis.py:644:45
    |
642 |                 return False
643 |
644 |             with open(self.checkpoint_file, "r", encoding="utf-8") as f:
    |                                             ^^^
645 |                 data = json.load(f)
    |
help: Remove mode argument

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/mass_qwen_analysis.py:651:13
    |
649 |                 f"ðŸ“ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½ Ñ‡ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚: Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑÑ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ð°Ñ Ð·Ð°Ð¿Ð¸ÑÑŒ ID {self.last_processed_id}"
650 |             )
651 |             return True
    |             ^^^^^^^^^^^
652 |
653 |         except Exception as e:
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/mass_qwen_analysis.py:665:30
    |
663 |             data = {
664 |                 "last_processed_id": self.last_processed_id,
665 |                 "timestamp": datetime.now().isoformat(),
    |                              ^^^^^^^^^^^^^^
666 |                 "processed": self.stats.processed,
667 |                 "errors": self.stats.errors,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> src/analyzers/mass_qwen_analysis.py:670:18
    |
668 |             }
669 |
670 |             with open(self.checkpoint_file, "w", encoding="utf-8") as f:
    |                  ^^^^
671 |                 json.dump(data, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/mass_qwen_analysis.py:677:22
    |
676 |     async def get_unanalyzed_records(
677 |         self, limit: Optional[int] = None, resume: bool = False
    |                      ^^^^^^^^^^^^^
678 |     ) -> List[Dict[str, Any]]:
679 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½ÐµÐ°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ð¸ÑÐµÐ¹"""
    |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:678:10
    |
676 |     async def get_unanalyzed_records(
677 |         self, limit: Optional[int] = None, resume: bool = False
678 |     ) -> List[Dict[str, Any]]:
    |          ^^^^
679 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½ÐµÐ°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ð¸ÑÐµÐ¹"""
680 |         try:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:678:15
    |
676 |     async def get_unanalyzed_records(
677 |         self, limit: Optional[int] = None, resume: bool = False
678 |     ) -> List[Dict[str, Any]]:
    |               ^^^^
679 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½ÐµÐ°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ð¸ÑÐµÐ¹"""
680 |         try:
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:712:51
    |
710 |             return []
711 |
712 |     async def analyze_single_record(self, record: Dict[str, Any]) -> bool:
    |                                                   ^^^^
713 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¾Ð´Ð½Ð¾Ð¹ Ð·Ð°Ð¿Ð¸ÑÐ¸"""
714 |         track_id = record["id"]
    |
help: Replace with `dict`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/mass_qwen_analysis.py:745:13
    |
743 |                 self.last_processed_id = track_id
744 |                 return True
745 |             else:
    |             ^^^^
746 |                 return False
    |
help: Remove unnecessary `else`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:752:63
    |
750 |             return False
751 |
752 |     async def _save_analysis_to_database(self, analysis_data: Dict[str, Any]) -> bool:
    |                                                               ^^^^
753 |         """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð² Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
754 |         try:
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/mass_qwen_analysis.py:802:13
    |
800 |                 mood_analysis = result.raw_output.get("mood_analysis", {})
801 |                 return mood_analysis.get("primary_mood", "neutral")
802 |             return "neutral"
    |             ^^^^^^^^^^^^^^^^
803 |         except:
804 |             return "neutral"
    |

E722 Do not use bare `except`
   --> src/analyzers/mass_qwen_analysis.py:803:9
    |
801 |                 return mood_analysis.get("primary_mood", "neutral")
802 |             return "neutral"
803 |         except:
    |         ^^^^^^
804 |             return "neutral"
    |

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/mass_qwen_analysis.py:812:13
    |
810 |                 quality_metrics = result.raw_output.get("quality_metrics", {})
811 |                 return float(quality_metrics.get("overall_quality", 0.5)) * 5.0
812 |             return 3.0
    |             ^^^^^^^^^^
813 |         except:
814 |             return 3.0
    |

E722 Do not use bare `except`
   --> src/analyzers/mass_qwen_analysis.py:813:9
    |
811 |                 return float(quality_metrics.get("overall_quality", 0.5)) * 5.0
812 |             return 3.0
813 |         except:
    |         ^^^^^^
814 |             return 3.0
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:816:42
    |
814 |             return 3.0
815 |
816 |     def _extract_themes(self, result) -> List[str]:
    |                                          ^^^^
817 |         """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐ¼ Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
818 |         try:
    |
help: Replace with `list`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/mass_qwen_analysis.py:822:13
    |
820 |                 content_analysis = result.raw_output.get("content_analysis", {})
821 |                 return content_analysis.get("main_themes", ["general"])
822 |             return ["general"]
    |             ^^^^^^^^^^^^^^^^^^
823 |         except:
824 |             return ["general"]
    |

E722 Do not use bare `except`
   --> src/analyzers/mass_qwen_analysis.py:823:9
    |
821 |                 return content_analysis.get("main_themes", ["general"])
822 |             return ["general"]
823 |         except:
    |         ^^^^^^
824 |             return ["general"]
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:826:42
    |
824 |             return ["general"]
825 |
826 |     async def process_batch(self, batch: List[Dict[str, Any]]) -> Tuple[int, int]:
    |                                          ^^^^
827 |         """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð±Ð°Ñ‚Ñ‡Ð° Ð·Ð°Ð¿Ð¸ÑÐµÐ¹"""
828 |         processed = 0
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:826:47
    |
824 |             return ["general"]
825 |
826 |     async def process_batch(self, batch: List[Dict[str, Any]]) -> Tuple[int, int]:
    |                                               ^^^^
827 |         """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð±Ð°Ñ‚Ñ‡Ð° Ð·Ð°Ð¿Ð¸ÑÐµÐ¹"""
828 |         processed = 0
    |
help: Replace with `dict`

UP006 [*] Use `tuple` instead of `Tuple` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:826:67
    |
824 |             return ["general"]
825 |
826 |     async def process_batch(self, batch: List[Dict[str, Any]]) -> Tuple[int, int]:
    |                                                                   ^^^^^
827 |         """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð±Ð°Ñ‚Ñ‡Ð° Ð·Ð°Ð¿Ð¸ÑÐµÐ¹"""
828 |         processed = 0
    |
help: Replace with `tuple`

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:842:27
    |
840 |                 if await self.analyze_single_record(record):
841 |                     processed += 1
842 |                     print(f"    âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
843 |                 else:
844 |                     errors += 1
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:845:27
    |
843 |                 else:
844 |                     errors += 1
845 |                     print(f"    âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^
846 |
847 |                 # ÐŸÐ°ÑƒÐ·Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´Ð¾Ñ‚Ð²Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ñ rate limiting
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:858:15
    |
856 |     def print_progress(self):
857 |         """Ð’Ñ‹Ð²Ð¾Ð´ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ°"""
858 |         print(f"\nðŸ“Š ÐŸÐ ÐžÐ“Ð Ð•Ð¡Ð¡:")
    |               ^^^^^^^^^^^^^^^^^
859 |         print(f"  ðŸ“ˆ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾: {self.stats.processed}/{self.stats.total_records}")
860 |         print(f"  âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚ÑŒ: {self.stats.success_rate:.1f}%")
    |
help: Remove extraneous `f` prefix

PLR0915 Too many statements (66 > 50)
   --> src/analyzers/mass_qwen_analysis.py:865:15
    |
863 |         print(f"  ðŸ“¦ Ð‘Ð°Ñ‚Ñ‡: {self.stats.current_batch}/{self.stats.total_batches}")
864 |
865 |     async def run_analysis(
    |               ^^^^^^^^^^^^
866 |         self,
867 |         batch_size: int = 100,
    |

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/mass_qwen_analysis.py:868:22
    |
866 |         self,
867 |         batch_size: int = 100,
868 |         max_records: Optional[int] = None,
    |                      ^^^^^^^^^^^^^
869 |         resume: bool = False,
870 |         test_mode: bool = False,
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:871:10
    |
869 |         resume: bool = False,
870 |         test_mode: bool = False,
871 |     ) -> Dict[str, Any]:
    |          ^^^^
872 |         """Ð—Ð°Ð¿ÑƒÑÐº Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
    |
help: Replace with `dict`

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:883:15
    |
881 |         # ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð±Ð°Ð·Ñ‹
882 |         db_stats = await self.get_database_stats()
883 |         print(f"ðŸ“Š Ð‘Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…:")
    |               ^^^^^^^^^^^^^^^^^^
884 |         print(f"  ðŸ“ Ð’ÑÐµÐ³Ð¾ Ñ‚Ñ€ÐµÐºÐ¾Ð²: {db_stats.get('total_tracks', 0)}")
885 |         print(f"  ðŸ“ Ð¡ Ñ‚ÐµÐºÑÑ‚Ð°Ð¼Ð¸: {db_stats.get('tracks_with_lyrics', 0)}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:896:15
    |
895 |         # ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ð¸ÑÐµÐ¹ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
896 |         print(f"\nðŸ” Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÐµÐ¹ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°...")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
897 |         records = await self.get_unanalyzed_records(limit=max_records, resume=resume)
    |
help: Remove extraneous `f` prefix

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/mass_qwen_analysis.py:905:33
    |
903 |         # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸
904 |         self.stats.total_records = len(records)
905 |         self.stats.start_time = datetime.now()
    |                                 ^^^^^^^^^^^^^^
906 |         self.stats.total_batches = (len(records) + batch_size - 1) // batch_size
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:908:15
    |
906 |         self.stats.total_batches = (len(records) + batch_size - 1) // batch_size
907 |
908 |         print(f"\nðŸŽ¯ ÐŸÐ»Ð°Ð½ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:")
    |               ^^^^^^^^^^^^^^^^^^^^^
909 |         print(f"  ðŸ“Š Ð—Ð°Ð¿Ð¸ÑÐµÐ¹ Ðº Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ: {len(records)}")
910 |         print(f"  ðŸ“¦ Ð Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ñ‚Ñ‡Ð°: {batch_size}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:913:15
    |
911 |         print(f"  ðŸ”¢ ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð±Ð°Ñ‚Ñ‡ÐµÐ¹: {self.stats.total_batches}")
912 |         print(f"  â±ï¸  ÐŸÑ€Ð¸Ð¼ÐµÑ€Ð½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ: {(len(records) * 15) // 60} Ð¼Ð¸Ð½ÑƒÑ‚")
913 |         print(f"  ðŸ†“ Ð‘ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Qwen Ñ‡ÐµÑ€ÐµÐ· Novita AI - Ð±ÐµÐ· Ð·Ð°Ñ‚Ñ€Ð°Ñ‚!")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
914 |
915 |         if not test_mode:
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:916:19
    |
915 |         if not test_mode:
916 |             print(f"\nâ³ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ñ‡ÐµÑ€ÐµÐ· 3 ÑÐµÐºÑƒÐ½Ð´Ñ‹...")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
917 |             await asyncio.sleep(3)
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:920:15
    |
919 |         # ÐœÐ°ÑÑÐ¾Ð²Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð¾ Ð±Ð°Ñ‚Ñ‡Ð°Ð¼
920 |         print(f"\nðŸš€ ÐÐÐ§Ð˜ÐÐÐ•Ðœ ÐœÐÐ¡Ð¡ÐžÐ’Ð«Ð™ ÐÐÐÐ›Ð˜Ð—")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
921 |         print("=" * 50)
    |
help: Remove extraneous `f` prefix

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/mass_qwen_analysis.py:958:23
    |
957 |         # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
958 |         total_time = (datetime.now() - self.stats.start_time).total_seconds()
    |                       ^^^^^^^^^^^^^^
959 |
960 |         print(f"\nðŸ† ÐÐÐÐ›Ð˜Ð— Ð—ÐÐ’Ð•Ð Ð¨Ð•Ð!")
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:960:15
    |
958 |         total_time = (datetime.now() - self.stats.start_time).total_seconds()
959 |
960 |         print(f"\nðŸ† ÐÐÐÐ›Ð˜Ð— Ð—ÐÐ’Ð•Ð Ð¨Ð•Ð!")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^
961 |         print("=" * 50)
962 |         print(f"âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {self.stats.processed}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/mass_qwen_analysis.py:971:15
    |
969 |         # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð±Ð°Ð·Ñ‹
970 |         final_db_stats = await self.get_database_stats()
971 |         print(f"\nðŸ“ˆ ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð±Ð°Ð·Ñ‹:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
972 |         print(f"  ðŸ¤– Qwen Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {final_db_stats.get('qwen_analyzed', 0)}")
973 |         print(f"  â³ ÐžÑÑ‚Ð°Ð»Ð¾ÑÑŒ: {final_db_stats.get('unanalyzed', 0)}")
    |
help: Remove extraneous `f` prefix

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/mass_qwen_analysis.py:989:40
    |
987 |         }
988 |
989 |     async def show_stats_only(self) -> Dict[str, Any]:
    |                                        ^^^^
990 |         """ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð±ÐµÐ· Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
991 |         print("ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð½Ð¾Ð³Ð¾ Qwen Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
    --> src/analyzers/mass_qwen_analysis.py:1010:22
     |
1008 |         if self.checkpoint_file.exists():
1009 |             try:
1010 |                 with open(self.checkpoint_file, "r") as f:
     |                      ^^^^
1011 |                     checkpoint = json.load(f)
1012 |                 print(f"\nðŸ“ ÐÐ°Ð¹Ð´ÐµÐ½ Ñ‡ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚:")
     |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
    --> src/analyzers/mass_qwen_analysis.py:1010:49
     |
1008 |         if self.checkpoint_file.exists():
1009 |             try:
1010 |                 with open(self.checkpoint_file, "r") as f:
     |                                                 ^^^
1011 |                     checkpoint = json.load(f)
1012 |                 print(f"\nðŸ“ ÐÐ°Ð¹Ð´ÐµÐ½ Ñ‡ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚:")
     |
help: Remove mode argument

F541 [*] f-string without any placeholders
    --> src/analyzers/mass_qwen_analysis.py:1012:23
     |
1010 |                 with open(self.checkpoint_file, "r") as f:
1011 |                     checkpoint = json.load(f)
1012 |                 print(f"\nðŸ“ ÐÐ°Ð¹Ð´ÐµÐ½ Ñ‡ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚:")
     |                       ^^^^^^^^^^^^^^^^^^^^^^^^
1013 |                 print(
1014 |                     f"  ðŸ“„ ÐŸÐ¾ÑÐ»ÐµÐ´Ð½ÑÑ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ð°Ñ Ð·Ð°Ð¿Ð¸ÑÑŒ: {checkpoint.get('last_processed_id', 0)}"
     |
help: Remove extraneous `f` prefix

E722 Do not use bare `except`
    --> src/analyzers/mass_qwen_analysis.py:1019:13
     |
1017 |                 print(f"  âœ… ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ Ð² ÑÐµÑÑÐ¸Ð¸: {checkpoint.get('processed', 0)}")
1018 |                 print(f"  âŒ ÐžÑˆÐ¸Ð±Ð¾Ðº Ð² ÑÐµÑÑÐ¸Ð¸: {checkpoint.get('errors', 0)}")
1019 |             except:
     |             ^^^^^^
1020 |                 print(f"\nâš ï¸ ÐÐ°Ð¹Ð´ÐµÐ½ Ð¿Ð¾Ð²Ñ€ÐµÐ¶Ð´ÐµÐ½Ð½Ñ‹Ð¹ Ñ‡ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚")
     |

F541 [*] f-string without any placeholders
    --> src/analyzers/mass_qwen_analysis.py:1020:23
     |
1018 |                 print(f"  âŒ ÐžÑˆÐ¸Ð±Ð¾Ðº Ð² ÑÐµÑÑÐ¸Ð¸: {checkpoint.get('errors', 0)}")
1019 |             except:
1020 |                 print(f"\nâš ï¸ ÐÐ°Ð¹Ð´ÐµÐ½ Ð¿Ð¾Ð²Ñ€ÐµÐ¶Ð´ÐµÐ½Ð½Ñ‹Ð¹ Ñ‡ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚")
     |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1021 |
1022 |         return db_stats
     |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
   --> src/analyzers/multi_model_analyzer.py:91:1
    |
 89 |   """
 90 |
 91 | / import json
 92 | | import time
 93 | | import logging
 94 | | import requests
 95 | | import os
 96 | | import re
 97 | | from typing import Dict, List, Optional, Union, Tuple
 98 | | from pydantic import BaseModel, Field
 99 | | from dotenv import load_dotenv
100 | | import asyncpg
101 | | import psycopg2
102 | | from psycopg2.extras import RealDictCursor
103 | | from datetime import datetime
104 | | from collections import Counter
105 | | import asyncio
    | |______________^
106 |
107 |   # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
    |
help: Organize imports

F401 [*] `time` imported but unused
  --> src/analyzers/multi_model_analyzer.py:92:8
   |
91 | import json
92 | import time
   |        ^^^^
93 | import logging
94 | import requests
   |
help: Remove unused import: `time`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/analyzers/multi_model_analyzer.py:97:1
   |
95 | import os
96 | import re
97 | from typing import Dict, List, Optional, Union, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
98 | from pydantic import BaseModel, Field
99 | from dotenv import load_dotenv
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/analyzers/multi_model_analyzer.py:97:1
   |
95 | import os
96 | import re
97 | from typing import Dict, List, Optional, Union, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
98 | from pydantic import BaseModel, Field
99 | from dotenv import load_dotenv
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> src/analyzers/multi_model_analyzer.py:97:1
   |
95 | import os
96 | import re
97 | from typing import Dict, List, Optional, Union, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
98 | from pydantic import BaseModel, Field
99 | from dotenv import load_dotenv
   |

F401 [*] `typing.Union` imported but unused
  --> src/analyzers/multi_model_analyzer.py:97:42
   |
95 | import os
96 | import re
97 | from typing import Dict, List, Optional, Union, Tuple
   |                                          ^^^^^
98 | from pydantic import BaseModel, Field
99 | from dotenv import load_dotenv
   |
help: Remove unused import

F401 [*] `typing.Tuple` imported but unused
  --> src/analyzers/multi_model_analyzer.py:97:49
   |
95 | import os
96 | import re
97 | from typing import Dict, List, Optional, Union, Tuple
   |                                                 ^^^^^
98 | from pydantic import BaseModel, Field
99 | from dotenv import load_dotenv
   |
help: Remove unused import

F401 [*] `collections.Counter` imported but unused
   --> src/analyzers/multi_model_analyzer.py:104:25
    |
102 | from psycopg2.extras import RealDictCursor
103 | from datetime import datetime
104 | from collections import Counter
    |                         ^^^^^^^
105 | import asyncio
    |
help: Remove unused import: `collections.Counter`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/multi_model_analyzer.py:151:18
    |
149 |     rhyme_scheme: str = Field(default="unknown")
150 |     complexity_level: str = Field(default="intermediate")
151 |     main_themes: List[str] = Field(default_factory=list)
    |                  ^^^^
152 |     emotional_tone: str = Field(default="neutral")
153 |     storytelling_type: str = Field(default="conversational")
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/multi_model_analyzer.py:184:18
    |
183 |     analysis: EnhancedSongData
184 |     explanation: Dict[str, List[str]]
    |                  ^^^^
185 |     confidence: float
186 |     decision_factors: Dict[str, float]
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/multi_model_analyzer.py:184:28
    |
183 |     analysis: EnhancedSongData
184 |     explanation: Dict[str, List[str]]
    |                            ^^^^
185 |     confidence: float
186 |     decision_factors: Dict[str, float]
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/multi_model_analyzer.py:186:23
    |
184 |     explanation: Dict[str, List[str]]
185 |     confidence: float
186 |     decision_factors: Dict[str, float]
    |                       ^^^^
187 |     influential_phrases: Dict[str, List[str]]
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/multi_model_analyzer.py:187:26
    |
185 |     confidence: float
186 |     decision_factors: Dict[str, float]
187 |     influential_phrases: Dict[str, List[str]]
    |                          ^^^^
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/multi_model_analyzer.py:187:36
    |
185 |     confidence: float
186 |     decision_factors: Dict[str, float]
187 |     influential_phrases: Dict[str, List[str]]
    |                                    ^^^^
    |
help: Replace with `list`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/multi_model_analyzer.py:222:13
    |
221 |             self.logger.info("âœ… PostgreSQL connection pool initialized successfully")
222 |             return True
    |             ^^^^^^^^^^^
223 |
224 |         except Exception as e:
    |

PLR0912 Too many branches (13 > 12)
   --> src/analyzers/multi_model_analyzer.py:492:9
    |
490 |         }
491 |
492 |     def detect_hallucinations(self, lyrics: str, analysis: dict) -> float:
    |         ^^^^^^^^^^^^^^^^^^^^^
493 |         """Ð”ÐµÑ‚ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¸ Ð² AI Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ"""
494 |         hallucination_score = 0.0
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/analyzers/multi_model_analyzer.py:536:13
    |
534 |           if "authenticity_score" in analysis:
535 |               auth_score = analysis["authenticity_score"]
536 | /             if isinstance(auth_score, (int, float)):
537 | |                 if (
538 | |                     auth_score > 0.9 and len(lyrics.split()) < 50
539 | |                 ):  # Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾Ð¼ Ñ‚ÐµÐºÑÑ‚Ðµ
    | |__________________^
540 |                       hallucination_score += 0.1
    |
help: Combine `if` statements using `and`

SIM103 Return the condition directly
   --> src/analyzers/multi_model_analyzer.py:569:9
    |
567 |           ):
568 |               return True
569 | /         if "love" in theme_lower and any(
570 | |             word in lyrics_lower
571 | |             for word in ["love", "girl", "relationship", "girlfriend", "romance"]
572 | |         ):
573 | |             return True
574 | |
575 | |         return False
    | |____________________^
576 |
577 |       def mood_supported_by_lyrics(self, mood: str, lyrics_lower: str) -> bool:
    |
help: Inline condition

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/analyzers/multi_model_analyzer.py:630:13
    |
628 |   â€¦     auth = analysis["authenticity_score"]
629 |   â€¦     commercial = analysis["commercial_appeal"]
630 | / â€¦     if isinstance(auth, (int, float)) and isinstance(commercial, (int, float)):
631 | | â€¦         # ÐžÑ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð˜ Ð¾Ñ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¹ ÐºÐ¾Ð¼Ð¼ÐµÑ€Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð¿Ð¿ÐµÐ°Ð» - Ñ€ÐµÐ´ÐºÐ¾
632 | | â€¦         if auth > 0.9 and commercial > 0.9:
    | |_____________________________________________^
633 |   â€¦             consistency_score -= 0.2
    |
help: Combine `if` statements using `and`

F841 Local variable `lyrics_lower` is assigned to but never used
   --> src/analyzers/multi_model_analyzer.py:649:9
    |
647 |         """Ð’Ð°Ð»Ð¸Ð´Ð¸Ñ€ÑƒÐµÑ‚ Ñ„Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ"""
648 |         factual_score = 1.0
649 |         lyrics_lower = lyrics.lower()
    |         ^^^^^^^^^^^^
650 |
651 |         # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ
    |
help: Remove assignment to unused variable `lyrics_lower`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/analyzers/multi_model_analyzer.py:667:13
    |
665 |               # Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ€Ð¸Ñ„Ð¼
666 |               lines = [line.strip() for line in lyrics.split("\n") if line.strip()]
667 | /             if len(lines) >= 4:
668 | |                 # Ð•ÑÐ»Ð¸ Ð·Ð°ÑÐ²Ð»ÐµÐ½Ð° ÑÐ»Ð¾Ð¶Ð½Ð°Ñ ÑÑ…ÐµÐ¼Ð°, Ð½Ð¾ Ñ‚ÐµÐºÑÑ‚ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹
669 | |                 if (
670 | |                     "complex" in rhyme_scheme
671 | |                     and len(set(line.split()[-1] for line in lines[:4] if line.split()))
672 | |                     == 1
673 | |                 ):
    | |__________________^
674 |                       factual_score -= 0.1
    |
help: Combine `if` statements using `and`

C401 Unnecessary generator (rewrite as a set comprehension)
   --> src/analyzers/multi_model_analyzer.py:671:29
    |
669 |                 if (
670 |                     "complex" in rhyme_scheme
671 |                     and len(set(line.split()[-1] for line in lines[:4] if line.split()))
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
672 |                     == 1
673 |                 ):
    |
help: Rewrite as a set comprehension

RUF019 [*] Unnecessary key check before dictionary access
   --> src/analyzers/multi_model_analyzer.py:700:20
    |
698 |                 1
699 |                 for key in ["main_themes", "structure", "rhyme_scheme"]
700 |                 if key in analysis and analysis[key]
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
701 |             )
702 |             if detailed_fields > 2:
    |
help: Replace with `dict.get`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/multi_model_analyzer.py:766:9
    |
764 |         if is_reliable:
765 |             return f"âœ… ÐÐ½Ð°Ð»Ð¸Ð· Ð½Ð°Ð´ÐµÐ¶ÐµÐ½ (Ñ€Ð¸ÑÐº Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹: {hallucination_risk:.2f})"
766 |         else:
    |         ^^^^
767 |             issues = []
768 |             if hallucination_risk > 0.4:  # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³
    |
help: Remove unnecessary `else`

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/multi_model_analyzer.py:822:10
    |
820 |     def analyze_with_explanation(
821 |         self, artist: str, title: str, lyrics: str
822 |     ) -> Optional[ExplainableAnalysisResult]:
    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
823 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ñ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸ÐµÐ¼ Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹"""
824 |         try:
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/multi_model_analyzer.py:850:10
    |
848 |     def explain_decision(
849 |         self, lyrics: str, result: EnhancedSongData
850 |     ) -> Dict[str, List[str]]:
    |          ^^^^
851 |         """ÐžÐ±ÑŠÑÑÐ½ÑÐµÑ‚, Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‡ÐµÐ³Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ñ€Ð¸Ð½ÑÐ»Ð° Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ"""
852 |         lyrics_lower = lyrics.lower()
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/multi_model_analyzer.py:850:20
    |
848 |     def explain_decision(
849 |         self, lyrics: str, result: EnhancedSongData
850 |     ) -> Dict[str, List[str]]:
    |                    ^^^^
851 |         """ÐžÐ±ÑŠÑÑÐ½ÑÐµÑ‚, Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‡ÐµÐ³Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ñ€Ð¸Ð½ÑÐ»Ð° Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ"""
852 |         lyrics_lower = lyrics.lower()
    |
help: Replace with `list`

RET504 Unnecessary assignment to `consistency` before `return` statement
   --> src/analyzers/multi_model_analyzer.py:981:16
    |
979 |         # ÐÐ¸Ð·ÐºÐ¾Ðµ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ðµ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ðµ = Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ ÐºÐ¾Ð½ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ
980 |         consistency = max(0, 1 - (std_dev * 2))  # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼
981 |         return consistency
    |                ^^^^^^^^^^^
982 |
983 |     def _calculate_detail_factor(self, lyrics: str) -> float:
    |
help: Remove unnecessary assignment

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/multi_model_analyzer.py:1004:10
     |
1002 |     def extract_key_factors(
1003 |         self, lyrics: str, result: EnhancedSongData
1004 |     ) -> Dict[str, float]:
     |          ^^^^
1005 |         """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ñ‹, Ð²Ð»Ð¸ÑÑŽÑ‰Ð¸Ðµ Ð½Ð° Ð°Ð½Ð°Ð»Ð¸Ð·"""
1006 |         factors = {}
     |
help: Replace with `dict`

PLR0912 Too many branches (19 > 12)
    --> src/analyzers/multi_model_analyzer.py:1029:9
     |
1027 |         return factors
1028 |
1029 |     def find_influential_phrases(
     |         ^^^^^^^^^^^^^^^^^^^^^^^^
1030 |         self, lyrics: str, result: EnhancedSongData
1031 |     ) -> Dict[str, List[str]]:
     |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/multi_model_analyzer.py:1031:10
     |
1029 |     def find_influential_phrases(
1030 |         self, lyrics: str, result: EnhancedSongData
1031 |     ) -> Dict[str, List[str]]:
     |          ^^^^
1032 |         """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ñ„Ñ€Ð°Ð·Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ð¾Ð²Ð»Ð¸ÑÐ»Ð¸ Ð½Ð° Ð¾Ñ†ÐµÐ½ÐºÑƒ"""
1033 |         influential = {
     |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/multi_model_analyzer.py:1031:20
     |
1029 |     def find_influential_phrases(
1030 |         self, lyrics: str, result: EnhancedSongData
1031 |     ) -> Dict[str, List[str]]:
     |                    ^^^^
1032 |         """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ñ„Ñ€Ð°Ð·Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ð¾Ð²Ð»Ð¸ÑÐ»Ð¸ Ð½Ð° Ð¾Ñ†ÐµÐ½ÐºÑƒ"""
1033 |         influential = {
     |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer.py:1106:10
     |
1104 |     def analyze_song(
1105 |         self, artist: str, title: str, lyrics: str
1106 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1107 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸"""
1108 |         raise NotImplementedError
     |
help: Convert to `X | None`

RET505 [*] Unnecessary `else` after `return` statement
    --> src/analyzers/multi_model_analyzer.py:1140:17
     |
1138 |                     logger.info(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model_name} Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
1139 |                     return True
1140 |                 else:
     |                 ^^^^
1141 |                     logger.warning(
1142 |                         f"âš ï¸ ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model_name} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°. ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸..."
     |
help: Remove unnecessary `else`

TRY300 Consider moving this statement to an `else` block
    --> src/analyzers/multi_model_analyzer.py:1145:13
     |
1143 |                     )
1144 |                     return self._pull_model()
1145 |             return False
     |             ^^^^^^^^^^^^
1146 |         except requests.exceptions.RequestException as e:
1147 |             logger.warning(f"âŒ› Ollama Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½: {e}")
     |

RET505 [*] Unnecessary `else` after `return` statement
    --> src/analyzers/multi_model_analyzer.py:1163:13
     |
1161 |                 logger.info(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model_name} Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°")
1162 |                 return True
1163 |             else:
     |             ^^^^
1164 |                 logger.error(f"âŒ› ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: {response.text}")
1165 |                 return False
     |
help: Remove unnecessary `else`

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer.py:1172:10
     |
1170 |     def analyze_song(
1171 |         self, artist: str, title: str, lyrics: str
1172 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1173 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ‡ÐµÑ€ÐµÐ· Ollama"""
1174 |         if not self.available:
     |
help: Convert to `X | None`

RET505 [*] Unnecessary `else` after `return` statement
    --> src/analyzers/multi_model_analyzer.py:1200:13
     |
1198 |                 analysis_text = result.get("response", "")
1199 |                 return self._parse_analysis(analysis_text, artist, title)
1200 |             else:
     |             ^^^^
1201 |                 logger.error(
1202 |                     f"âŒ› Ollama Ð¾ÑˆÐ¸Ð±ÐºÐ°: {response.status_code} - {response.text}"
     |
help: Remove unnecessary `else`

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer.py:1257:10
     |
1255 |     def _parse_analysis(
1256 |         self, analysis_text: str, artist: str, title: str
1257 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1258 |         """ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
1259 |         try:
     |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/multi_model_analyzer.py:1303:31
     |
1301 |                 quality_metrics=quality_metrics,
1302 |                 model_used="gemma-2-27b-it",
1303 |                 analysis_date=datetime.now().isoformat(),
     |                               ^^^^^^^^^^^^^^
1304 |             )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

PLR0912 Too many branches (24 > 12)
    --> src/analyzers/multi_model_analyzer.py:1328:9
     |
1326 |         return True
1327 |
1328 |     def analyze_song(
     |         ^^^^^^^^^^^^
1329 |         self, artist: str, title: str, lyrics: str
1330 |     ) -> Optional[EnhancedSongData]:
     |

PLR0915 Too many statements (81 > 50)
    --> src/analyzers/multi_model_analyzer.py:1328:9
     |
1326 |         return True
1327 |
1328 |     def analyze_song(
     |         ^^^^^^^^^^^^
1329 |         self, artist: str, title: str, lyrics: str
1330 |     ) -> Optional[EnhancedSongData]:
     |

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer.py:1330:10
     |
1328 |     def analyze_song(
1329 |         self, artist: str, title: str, lyrics: str
1330 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1331 |         """Mock Ð°Ð½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ ÑƒÐ¼Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸"""
1332 |         try:
     |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/multi_model_analyzer.py:1513:31
     |
1511 |                 quality_metrics=quality_metrics,
1512 |                 model_used="mock_analyzer_v1",
1513 |                 analysis_date=datetime.now().isoformat(),
     |                               ^^^^^^^^^^^^^^
1514 |             )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

F401 `google.generativeai` imported but unused; consider using `importlib.util.find_spec` to test for availability
    --> src/analyzers/multi_model_analyzer.py:1537:43
     |
1536 |         try:
1537 |             import google.generativeai as genai
     |                                           ^^^^^
1538 |             from google.generativeai.client import configure
1539 |             from google.generativeai.generative_models import GenerativeModel
     |
help: Remove unused import: `google.generativeai`

F401 `google.generativeai.generative_models.GenerativeModel` imported but unused; consider using `importlib.util.find_spec` to test for availability
    --> src/analyzers/multi_model_analyzer.py:1539:63
     |
1537 |             import google.generativeai as genai
1538 |             from google.generativeai.client import configure
1539 |             from google.generativeai.generative_models import GenerativeModel
     |                                                               ^^^^^^^^^^^^^^^
1540 |
1541 |             configure(api_key=self.api_key)
     |
help: Remove unused import: `google.generativeai.generative_models.GenerativeModel`

TRY300 Consider moving this statement to an `else` block
    --> src/analyzers/multi_model_analyzer.py:1543:13
     |
1541 |             configure(api_key=self.api_key)
1542 |             logger.info("âœ… Google Gemma API Ð³Ð¾Ñ‚Ð¾Ð² Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÑŽ")
1543 |             return True
     |             ^^^^^^^^^^^
1544 |         except ImportError:
1545 |             logger.warning("âŒ› google-generativeai Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½")
     |

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer.py:1553:10
     |
1551 |     def analyze_song(
1552 |         self, artist: str, title: str, lyrics: str
1553 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1554 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ‡ÐµÑ€ÐµÐ· Google Gemma"""
1555 |         if not self.available:
     |
help: Convert to `X | None`

F401 [*] `google.generativeai` imported but unused
    --> src/analyzers/multi_model_analyzer.py:1559:43
     |
1558 |         try:
1559 |             import google.generativeai as genai
     |                                           ^^^^^
1560 |             from google.generativeai.client import configure
1561 |             from google.generativeai.generative_models import GenerativeModel
     |
help: Remove unused import: `google.generativeai`

F401 [*] `google.generativeai.client.configure` imported but unused
    --> src/analyzers/multi_model_analyzer.py:1560:52
     |
1558 |         try:
1559 |             import google.generativeai as genai
1560 |             from google.generativeai.client import configure
     |                                                    ^^^^^^^^^
1561 |             from google.generativeai.generative_models import GenerativeModel
     |
help: Remove unused import: `google.generativeai.client.configure`

RET505 [*] Unnecessary `else` after `return` statement
    --> src/analyzers/multi_model_analyzer.py:1576:13
     |
1574 |             if response.text:
1575 |                 return self._parse_analysis(response.text, artist, title)
1576 |             else:
     |             ^^^^
1577 |                 logger.error("âŒ› Gemma: Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚")
1578 |                 return None
     |
help: Remove unnecessary `else`

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer.py:1625:10
     |
1623 |     def _parse_analysis(
1624 |         self, analysis_text: str, artist: str, title: str
1625 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1626 |         """ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
1627 |         try:
     |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/multi_model_analyzer.py:1671:31
     |
1669 |                 quality_metrics=quality_metrics,
1670 |                 model_used="gemma-2-27b-it",
1671 |                 analysis_date=datetime.now().isoformat(),
     |                               ^^^^^^^^^^^^^^
1672 |             )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer.py:1717:10
     |
1715 |     def analyze_with_explanations(
1716 |         self, artist: str, title: str, lyrics: str
1717 |     ) -> Optional[ExplainableAnalysisResult]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1718 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ñ Ð¿Ð¾Ð»Ð½Ñ‹Ð¼Ð¸ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸ÑÐ¼Ð¸ Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹ AI"""
1719 |         return self.interpretable_analyzer.analyze_with_explanation(
     |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer.py:1723:65
     |
1721 |         )
1722 |
1723 |     async def explain_existing_analysis(self, track_id: int) -> Optional[Dict]:
     |                                                                 ^^^^^^^^^^^^^^
1724 |         """ÐžÐ±ÑŠÑÑÐ½ÑÐµÑ‚ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
1725 |         try:
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/multi_model_analyzer.py:1723:74
     |
1721 |         )
1722 |
1723 |     async def explain_existing_analysis(self, track_id: int) -> Optional[Dict]:
     |                                                                          ^^^^
1724 |         """ÐžÐ±ÑŠÑÑÐ½ÑÐµÑ‚ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
1725 |         try:
     |
help: Replace with `dict`

TRY002 Create your own exception
    --> src/analyzers/multi_model_analyzer.py:1868:19
     |
1866 |         if not self.providers:
1867 |             logger.error("âŒ› ÐÐ¸ Ð¾Ð´Ð¸Ð½ AI Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½!")
1868 |             raise Exception("No AI providers available")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1869 |
1870 |         self.current_provider = self.providers[0]
     |

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer.py:1875:10
     |
1873 |     def analyze_song(
1874 |         self, artist: str, title: str, lyrics: str
1875 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1876 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ fallback Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð°Ð¼Ð¸"""
     |
help: Convert to `X | None`

RET505 [*] Unnecessary `else` after `return` statement
    --> src/analyzers/multi_model_analyzer.py:1896:17
     |
1894 |                     logger.info(f"âœ… ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ Ñ‡ÐµÑ€ÐµÐ· {provider.name}")
1895 |                     return result
1896 |                 else:
     |                 ^^^^
1897 |                     logger.warning(f"âš ï¸ {provider.name} Ð½Ðµ ÑÐ¼Ð¾Ð³ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ")
     |
help: Remove unnecessary `else`

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/analyzers/multi_model_analyzer.py:1899:13
     |
1897 |                       logger.warning(f"âš ï¸ {provider.name} Ð½Ðµ ÑÐ¼Ð¾Ð³ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ")
1898 |
1899 | /             except Exception as e:
1900 | |                 logger.error(f"âŒ› ÐžÑˆÐ¸Ð±ÐºÐ° {provider.name}: {e}")
1901 | |                 continue
     | |________________________^
1902 |
1903 |           logger.error(
     |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/multi_model_analyzer.py:1908:28
     |
1906 |         return None
1907 |
1908 |     def get_stats(self) -> Dict:
     |                            ^^^^
1909 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ"""
1910 |         return {
     |
help: Replace with `dict`

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:1961:44
     |
1959 |                         else:
1960 |                             failed += 1
1961 |                             logger.warning(f"âŒ› ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ")
     |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1962 |
1963 |                         # ÐŸÐ°ÑƒÐ·Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸
     |
help: Remove extraneous `f` prefix

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/analyzers/multi_model_analyzer.py:1967:21
     |
1965 |                               await asyncio.sleep(2)  # 2 ÑÐµÐºÑƒÐ½Ð´Ñ‹ Ð¼ÐµÐ¶Ð´Ñƒ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ð¼Ð¸
1966 |
1967 | /                     except Exception as e:
1968 | |                         failed += 1
1969 | |                         logger.error(f"âŒ› ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿ÐµÑÐ½Ð¸ {row['id']}: {e}")
1970 | |                         continue
     | |________________________________^
1971 |
1972 |                   logger.info(f"""
     |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/multi_model_analyzer.py:2015:17
     |
2013 |                 1000.0,  # placeholder processing time
2014 |                 analysis.model_used,
2015 |                 datetime.now(),
     |                 ^^^^^^^^^^^^^^
2016 |             )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer.py:2024:10
     |
2022 |     def analyze_song_with_safety(
2023 |         self, artist: str, title: str, lyrics: str
2024 |     ) -> Optional[Dict]:
     |          ^^^^^^^^^^^^^^
2025 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ Ð¸ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸ÐµÐ¹ Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹"""
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/multi_model_analyzer.py:2024:19
     |
2022 |     def analyze_song_with_safety(
2023 |         self, artist: str, title: str, lyrics: str
2024 |     ) -> Optional[Dict]:
     |                   ^^^^
2025 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ Ð¸ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸ÐµÐ¹ Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹"""
     |
help: Replace with `dict`

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2033:26
     |
2032 |         if not analysis_result:
2033 |             logger.error(f"âŒ› ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð· Ð´Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸")
     |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2034 |             return None
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2065:28
     |
2064 |         if not validation_result["is_reliable"]:
2065 |             logger.warning(f"âš ï¸ Ð’ÐÐ˜ÐœÐÐÐ˜Ð•: ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¸Ð·Ð½Ð°Ð½ Ð½ÐµÐ½Ð°Ð´ÐµÐ¶Ð½Ñ‹Ð¼!")
     |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2066 |             logger.warning(
2067 |                 f"   â€¢ Ð Ð¸ÑÐº Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹: {validation_result['hallucination_risk']:.3f}"
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2081:25
     |
2079 |                 )
2080 |         else:
2081 |             logger.info(f"âœ… ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¾ÑˆÐµÐ» Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÑŽ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸")
     |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2082 |             logger.info(
2083 |                 f"   â€¢ ÐÐ°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚ÑŒ: {validation_result['reliability_score']:.3f}"
     |
help: Remove extraneous `f` prefix

PLR0912 Too many branches (14 > 12)
    --> src/analyzers/multi_model_analyzer.py:2097:11
     |
2097 | async def main():
     |           ^^^^
2098 |     """Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð½Ð¾Ð³Ð¾Ð¼Ð¾Ð´ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð° Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð¸Ñ€ÑƒÐµÐ¼Ð¾ÑÑ‚ÑŒÑŽ"""
     |

PLR0915 Too many statements (75 > 50)
    --> src/analyzers/multi_model_analyzer.py:2097:11
     |
2097 | async def main():
     |           ^^^^
2098 |     """Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð½Ð¾Ð³Ð¾Ð¼Ð¾Ð´ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð° Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð¸Ñ€ÑƒÐµÐ¼Ð¾ÑÑ‚ÑŒÑŽ"""
     |

W293 Blank line contains whitespace
    --> src/analyzers/multi_model_analyzer.py:2125:1
     |
2123 |         ÐœÐ¾Ð»Ð¾Ð´Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¾ÑˆÐ»Ð° Ð² Ð´Ñ‹Ð¼Ñƒ Ð¸ Ð´Ñ€Ð°ÐºÐ°Ñ…
2124 |         Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ñ‡Ð¸Ñ‚Ð°ÑŽ Ð¿Ñ€Ð°Ð²Ð´Ñƒ Ð² ÑÑ‚Ð¸Ñ… ÑÑ‚Ñ€Ð¾ÐºÐ°Ñ…
2125 |         
     | ^^^^^^^^
2126 |         Ð”ÐµÐ½ÑŒÐ³Ð¸, ÑÐ»Ð°Ð²Ð° - Ð²ÑÐµ ÑÑ‚Ð¾ Ð¿ÑƒÑÑ‚Ð¾Ñ‚Ð°
2127 |         Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¾ÑÑ‚Ð°Ñ‚ÑŒÑÑ ÑÐ¾Ð±Ð¾Ð¹ Ð´Ð¾ ÐºÐ¾Ð½Ñ†Ð°
     |
help: Remove whitespace from blank line

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2150:19
     |
2149 |             # ÐžÐ±ÑŠÑÑÐ½ÐµÐ½Ð¸Ñ
2150 |             print(f"\nðŸ’¡ ÐžÐ‘ÐªÐ¯Ð¡ÐÐ•ÐÐ˜Ð¯ Ð Ð•Ð¨Ð•ÐÐ˜Ð™:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2151 |             for category, explanations in explainable_result.explanation.items():
2152 |                 if explanations:
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2158:19
     |
2157 |             # Ð’Ð»Ð¸ÑÑ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ„Ñ€Ð°Ð·Ñ‹
2158 |             print(f"\nðŸ” Ð’Ð›Ð˜Ð¯Ð¢Ð•Ð›Ð¬ÐÐ«Ð• Ð¤Ð ÐÐ—Ð«:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
2159 |             for category, phrases in explainable_result.influential_phrases.items():
2160 |                 if phrases:
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2166:19
     |
2165 |             # ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ñ‹
2166 |             print(f"\nðŸ“Š ÐšÐ›Ð®Ð§Ð•Ð’Ð«Ð• Ð¤ÐÐšÐ¢ÐžÐ Ð« (Ñ‚Ð¾Ð¿-5):")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2167 |             top_factors = sorted(
2168 |                 explainable_result.decision_factors.items(),
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2188:19
     |
2187 |         if safe_result:
2188 |             print(f"\nðŸ›¡ï¸ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ Ð‘Ð•Ð—ÐžÐŸÐÐ¡ÐÐžÐ“Ðž ÐÐÐÐ›Ð˜Ð—Ð:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2189 |             print("-" * 50)
2190 |             print(
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2197:23
     |
2196 |             if safe_result["warnings"]:
2197 |                 print(f"âš ï¸ ÐŸÑ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ:")
     |                       ^^^^^^^^^^^^^^^^^^^^
2198 |                 for warning in safe_result["warnings"]:
2199 |                     print(f"   â€¢ {warning}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2203:19
     |
2201 |             # Ð”ÐµÑ‚Ð°Ð»Ð¸ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸
2202 |             validation = safe_result["validation"]
2203 |             print(f"\nðŸ“Š Ð”Ð•Ð¢ÐÐ›Ð˜ Ð’ÐÐ›Ð˜Ð”ÐÐ¦Ð˜Ð˜:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^
2204 |             print(f"   â€¢ Ð Ð¸ÑÐº Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹: {validation['hallucination_risk']:.3f}")
2205 |             print(f"   â€¢ ÐšÐ¾Ð½ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ: {validation['consistency_score']:.3f}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2210:15
     |
2209 |         # Ð¢ÐµÑÑ‚ Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼
2210 |         print(f"\nðŸ“„ Ð¢ÐµÑÑ‚ Ñ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼...")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2211 |         normal_safe_result = analyzer.analyze_song_with_safety(
2212 |             "Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð°Ñ€Ñ‚Ð¸ÑÑ‚", "ÐšÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ñ‚Ñ€ÐµÐº", test_lyrics
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2224:15
     |
2222 |         # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
2223 |         stats = analyzer.get_stats()
2224 |         print(f"\nðŸ“ˆ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ:")
     |               ^^^^^^^^^^^^^^^^^^^
2225 |         print(f"  â€¢ Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {stats['total_analyzed']}")
2226 |         print(f"  â€¢ Ollama Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½: {stats['ollama_used']} Ñ€Ð°Ð·")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2231:15
     |
2229 |         print(f"  â€¢ ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ: ${stats['total_cost']:.4f}")
2230 |
2231 |         print(f"\nâœ… AI Safety & Hallucination Detection - Ð“ÐžÐ¢ÐžÐ’Ðž!")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2232 |         print(f"ðŸ›¡ï¸ Ð¢ÐµÐ¿ÐµÑ€ÑŒ AI Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:")
2233 |         print(f"   â€¢ Interpretability & Model Understanding")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2232:15
     |
2231 |         print(f"\nâœ… AI Safety & Hallucination Detection - Ð“ÐžÐ¢ÐžÐ’Ðž!")
2232 |         print(f"ðŸ›¡ï¸ Ð¢ÐµÐ¿ÐµÑ€ÑŒ AI Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2233 |         print(f"   â€¢ Interpretability & Model Understanding")
2234 |         print(f"   â€¢ Safety & Hallucination Detection")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2233:15
     |
2231 |         print(f"\nâœ… AI Safety & Hallucination Detection - Ð“ÐžÐ¢ÐžÐ’Ðž!")
2232 |         print(f"ðŸ›¡ï¸ Ð¢ÐµÐ¿ÐµÑ€ÑŒ AI Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:")
2233 |         print(f"   â€¢ Interpretability & Model Understanding")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2234 |         print(f"   â€¢ Safety & Hallucination Detection")
2235 |         print(f"   â€¢ Consistency Validation")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2234:15
     |
2232 |         print(f"ðŸ›¡ï¸ Ð¢ÐµÐ¿ÐµÑ€ÑŒ AI Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:")
2233 |         print(f"   â€¢ Interpretability & Model Understanding")
2234 |         print(f"   â€¢ Safety & Hallucination Detection")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2235 |         print(f"   â€¢ Consistency Validation")
2236 |         print(f"   â€¢ Factual Accuracy Checking")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2235:15
     |
2233 |         print(f"   â€¢ Interpretability & Model Understanding")
2234 |         print(f"   â€¢ Safety & Hallucination Detection")
2235 |         print(f"   â€¢ Consistency Validation")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2236 |         print(f"   â€¢ Factual Accuracy Checking")
2237 |         print(f"ðŸŽ¯ ÐŸÑ€Ð¾Ð´ÑƒÐºÑ†Ð¸Ð¾Ð½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹ Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸!")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2236:15
     |
2234 |         print(f"   â€¢ Safety & Hallucination Detection")
2235 |         print(f"   â€¢ Consistency Validation")
2236 |         print(f"   â€¢ Factual Accuracy Checking")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2237 |         print(f"ðŸŽ¯ ÐŸÑ€Ð¾Ð´ÑƒÐºÑ†Ð¸Ð¾Ð½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹ Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸!")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer.py:2237:15
     |
2235 |         print(f"   â€¢ Consistency Validation")
2236 |         print(f"   â€¢ Factual Accuracy Checking")
2237 |         print(f"ðŸŽ¯ ÐŸÑ€Ð¾Ð´ÑƒÐºÑ†Ð¸Ð¾Ð½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹ Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸!")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2238 |
2239 |         # Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ
     |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/multi_model_analyzer_backup.py:44:1
   |
42 |   """
43 |
44 | / import json
45 | | import time
46 | | import logging
47 | | import requests
48 | | import os
49 | | import re
50 | | from typing import Dict, List, Optional, Union, Tuple
51 | | from pydantic import BaseModel, Field
52 | | from dotenv import load_dotenv
53 | | import sqlite3
54 | | from datetime import datetime
55 | | from collections import Counter
   | |_______________________________^
56 |
57 |   # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/analyzers/multi_model_analyzer_backup.py:50:1
   |
48 | import os
49 | import re
50 | from typing import Dict, List, Optional, Union, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
51 | from pydantic import BaseModel, Field
52 | from dotenv import load_dotenv
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/analyzers/multi_model_analyzer_backup.py:50:1
   |
48 | import os
49 | import re
50 | from typing import Dict, List, Optional, Union, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
51 | from pydantic import BaseModel, Field
52 | from dotenv import load_dotenv
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> src/analyzers/multi_model_analyzer_backup.py:50:1
   |
48 | import os
49 | import re
50 | from typing import Dict, List, Optional, Union, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
51 | from pydantic import BaseModel, Field
52 | from dotenv import load_dotenv
   |

F401 [*] `typing.Union` imported but unused
  --> src/analyzers/multi_model_analyzer_backup.py:50:42
   |
48 | import os
49 | import re
50 | from typing import Dict, List, Optional, Union, Tuple
   |                                          ^^^^^
51 | from pydantic import BaseModel, Field
52 | from dotenv import load_dotenv
   |
help: Remove unused import

F401 [*] `typing.Tuple` imported but unused
  --> src/analyzers/multi_model_analyzer_backup.py:50:49
   |
48 | import os
49 | import re
50 | from typing import Dict, List, Optional, Union, Tuple
   |                                                 ^^^^^
51 | from pydantic import BaseModel, Field
52 | from dotenv import load_dotenv
   |
help: Remove unused import

F401 [*] `pydantic.Field` imported but unused
  --> src/analyzers/multi_model_analyzer_backup.py:51:33
   |
49 | import re
50 | from typing import Dict, List, Optional, Union, Tuple
51 | from pydantic import BaseModel, Field
   |                                 ^^^^^
52 | from dotenv import load_dotenv
53 | import sqlite3
   |
help: Remove unused import: `pydantic.Field`

F401 [*] `collections.Counter` imported but unused
  --> src/analyzers/multi_model_analyzer_backup.py:55:25
   |
53 | import sqlite3
54 | from datetime import datetime
55 | from collections import Counter
   |                         ^^^^^^^
56 |
57 | # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
   |
help: Remove unused import: `collections.Counter`

E402 Module level import not at top of file
  --> src/analyzers/multi_model_analyzer_backup.py:72:1
   |
71 | # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
72 | from ..models.models import SongMetadata, LyricsAnalysis, QualityMetrics
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/multi_model_analyzer_backup.py:72:1
   |
71 | # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
72 | from ..models.models import SongMetadata, LyricsAnalysis, QualityMetrics
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
help: Organize imports

PLR0912 Too many branches (13 > 12)
   --> src/analyzers/multi_model_analyzer_backup.py:315:9
    |
313 |         }
314 |
315 |     def detect_hallucinations(self, lyrics: str, analysis: dict) -> float:
    |         ^^^^^^^^^^^^^^^^^^^^^
316 |         """Ð”ÐµÑ‚ÐµÐºÑ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¸ Ð² AI Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ"""
317 |         hallucination_score = 0.0
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/analyzers/multi_model_analyzer_backup.py:359:13
    |
357 |           if "authenticity_score" in analysis:
358 |               auth_score = analysis["authenticity_score"]
359 | /             if isinstance(auth_score, (int, float)):
360 | |                 if (
361 | |                     auth_score > 0.9 and len(lyrics.split()) < 50
362 | |                 ):  # Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾Ð¼ Ñ‚ÐµÐºÑÑ‚Ðµ
    | |__________________^
363 |                       hallucination_score += 0.1
    |
help: Combine `if` statements using `and`

SIM103 Return the condition directly
   --> src/analyzers/multi_model_analyzer_backup.py:392:9
    |
390 |           ):
391 |               return True
392 | /         if "love" in theme_lower and any(
393 | |             word in lyrics_lower
394 | |             for word in ["love", "girl", "relationship", "girlfriend", "romance"]
395 | |         ):
396 | |             return True
397 | |
398 | |         return False
    | |____________________^
399 |
400 |       def mood_supported_by_lyrics(self, mood: str, lyrics_lower: str) -> bool:
    |
help: Inline condition

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/analyzers/multi_model_analyzer_backup.py:453:13
    |
451 |   â€¦     auth = analysis["authenticity_score"]
452 |   â€¦     commercial = analysis["commercial_appeal"]
453 | / â€¦     if isinstance(auth, (int, float)) and isinstance(commercial, (int, float)):
454 | | â€¦         # ÐžÑ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð˜ Ð¾Ñ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¹ ÐºÐ¾Ð¼Ð¼ÐµÑ€Ñ‡ÐµÑÐºÐ¸Ð¹ Ð°Ð¿Ð¿ÐµÐ°Ð» - Ñ€ÐµÐ´ÐºÐ¾
455 | | â€¦         if auth > 0.9 and commercial > 0.9:
    | |_____________________________________________^
456 |   â€¦             consistency_score -= 0.2
    |
help: Combine `if` statements using `and`

F841 Local variable `lyrics_lower` is assigned to but never used
   --> src/analyzers/multi_model_analyzer_backup.py:472:9
    |
470 |         """Ð’Ð°Ð»Ð¸Ð´Ð¸Ñ€ÑƒÐµÑ‚ Ñ„Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ"""
471 |         factual_score = 1.0
472 |         lyrics_lower = lyrics.lower()
    |         ^^^^^^^^^^^^
473 |
474 |         # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ
    |
help: Remove assignment to unused variable `lyrics_lower`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/analyzers/multi_model_analyzer_backup.py:490:13
    |
488 |               # Ð£Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ€Ð¸Ñ„Ð¼
489 |               lines = [line.strip() for line in lyrics.split("\n") if line.strip()]
490 | /             if len(lines) >= 4:
491 | |                 # Ð•ÑÐ»Ð¸ Ð·Ð°ÑÐ²Ð»ÐµÐ½Ð° ÑÐ»Ð¾Ð¶Ð½Ð°Ñ ÑÑ…ÐµÐ¼Ð°, Ð½Ð¾ Ñ‚ÐµÐºÑÑ‚ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹
492 | |                 if (
493 | |                     "complex" in rhyme_scheme
494 | |                     and len(set(line.split()[-1] for line in lines[:4] if line.split()))
495 | |                     == 1
496 | |                 ):
    | |__________________^
497 |                       factual_score -= 0.1
    |
help: Combine `if` statements using `and`

C401 Unnecessary generator (rewrite as a set comprehension)
   --> src/analyzers/multi_model_analyzer_backup.py:494:29
    |
492 |                 if (
493 |                     "complex" in rhyme_scheme
494 |                     and len(set(line.split()[-1] for line in lines[:4] if line.split()))
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
495 |                     == 1
496 |                 ):
    |
help: Rewrite as a set comprehension

RUF019 [*] Unnecessary key check before dictionary access
   --> src/analyzers/multi_model_analyzer_backup.py:523:20
    |
521 |                 1
522 |                 for key in ["main_themes", "structure", "rhyme_scheme"]
523 |                 if key in analysis and analysis[key]
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
524 |             )
525 |             if detailed_fields > 2:
    |
help: Replace with `dict.get`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/multi_model_analyzer_backup.py:589:9
    |
587 |         if is_reliable:
588 |             return f"âœ… ÐÐ½Ð°Ð»Ð¸Ð· Ð½Ð°Ð´ÐµÐ¶ÐµÐ½ (Ñ€Ð¸ÑÐº Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹: {hallucination_risk:.2f})"
589 |         else:
    |         ^^^^
590 |             issues = []
591 |             if hallucination_risk > 0.4:  # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³
    |
help: Remove unnecessary `else`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/multi_model_analyzer_backup.py:618:18
    |
617 |     analysis: EnhancedSongData
618 |     explanation: Dict[str, List[str]]
    |                  ^^^^
619 |     confidence: float
620 |     decision_factors: Dict[str, float]
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/multi_model_analyzer_backup.py:618:28
    |
617 |     analysis: EnhancedSongData
618 |     explanation: Dict[str, List[str]]
    |                            ^^^^
619 |     confidence: float
620 |     decision_factors: Dict[str, float]
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/multi_model_analyzer_backup.py:620:23
    |
618 |     explanation: Dict[str, List[str]]
619 |     confidence: float
620 |     decision_factors: Dict[str, float]
    |                       ^^^^
621 |     influential_phrases: Dict[str, List[str]]
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/multi_model_analyzer_backup.py:621:26
    |
619 |     confidence: float
620 |     decision_factors: Dict[str, float]
621 |     influential_phrases: Dict[str, List[str]]
    |                          ^^^^
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/multi_model_analyzer_backup.py:621:36
    |
619 |     confidence: float
620 |     decision_factors: Dict[str, float]
621 |     influential_phrases: Dict[str, List[str]]
    |                                    ^^^^
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/multi_model_analyzer_backup.py:668:10
    |
666 |     def analyze_with_explanation(
667 |         self, artist: str, title: str, lyrics: str
668 |     ) -> Optional[ExplainableAnalysisResult]:
    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
669 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ñ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸ÐµÐ¼ Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹"""
670 |         try:
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/multi_model_analyzer_backup.py:696:10
    |
694 |     def explain_decision(
695 |         self, lyrics: str, result: EnhancedSongData
696 |     ) -> Dict[str, List[str]]:
    |          ^^^^
697 |         """ÐžÐ±ÑŠÑÑÐ½ÑÐµÑ‚, Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‡ÐµÐ³Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ñ€Ð¸Ð½ÑÐ»Ð° Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ"""
698 |         lyrics_lower = lyrics.lower()
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/multi_model_analyzer_backup.py:696:20
    |
694 |     def explain_decision(
695 |         self, lyrics: str, result: EnhancedSongData
696 |     ) -> Dict[str, List[str]]:
    |                    ^^^^
697 |         """ÐžÐ±ÑŠÑÑÐ½ÑÐµÑ‚, Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‡ÐµÐ³Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ñ€Ð¸Ð½ÑÐ»Ð° Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ"""
698 |         lyrics_lower = lyrics.lower()
    |
help: Replace with `list`

RET504 Unnecessary assignment to `consistency` before `return` statement
   --> src/analyzers/multi_model_analyzer_backup.py:827:16
    |
825 |         # ÐÐ¸Ð·ÐºÐ¾Ðµ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ðµ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ðµ = Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ ÐºÐ¾Ð½ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ
826 |         consistency = max(0, 1 - (std_dev * 2))  # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼
827 |         return consistency
    |                ^^^^^^^^^^^
828 |
829 |     def _calculate_detail_factor(self, lyrics: str) -> float:
    |
help: Remove unnecessary assignment

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/multi_model_analyzer_backup.py:850:10
    |
848 |     def extract_key_factors(
849 |         self, lyrics: str, result: EnhancedSongData
850 |     ) -> Dict[str, float]:
    |          ^^^^
851 |         """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ñ‹, Ð²Ð»Ð¸ÑÑŽÑ‰Ð¸Ðµ Ð½Ð° Ð°Ð½Ð°Ð»Ð¸Ð·"""
852 |         factors = {}
    |
help: Replace with `dict`

PLR0912 Too many branches (19 > 12)
   --> src/analyzers/multi_model_analyzer_backup.py:875:9
    |
873 |         return factors
874 |
875 |     def find_influential_phrases(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^
876 |         self, lyrics: str, result: EnhancedSongData
877 |     ) -> Dict[str, List[str]]:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/multi_model_analyzer_backup.py:877:10
    |
875 |     def find_influential_phrases(
876 |         self, lyrics: str, result: EnhancedSongData
877 |     ) -> Dict[str, List[str]]:
    |          ^^^^
878 |         """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ñ„Ñ€Ð°Ð·Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ð¾Ð²Ð»Ð¸ÑÐ»Ð¸ Ð½Ð° Ð¾Ñ†ÐµÐ½ÐºÑƒ"""
879 |         influential = {
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/multi_model_analyzer_backup.py:877:20
    |
875 |     def find_influential_phrases(
876 |         self, lyrics: str, result: EnhancedSongData
877 |     ) -> Dict[str, List[str]]:
    |                    ^^^^
878 |         """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ñ„Ñ€Ð°Ð·Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ð¾Ð²Ð»Ð¸ÑÐ»Ð¸ Ð½Ð° Ð¾Ñ†ÐµÐ½ÐºÑƒ"""
879 |         influential = {
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/multi_model_analyzer_backup.py:952:10
    |
950 |     def analyze_song(
951 |         self, artist: str, title: str, lyrics: str
952 |     ) -> Optional[EnhancedSongData]:
    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
953 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸"""
954 |         raise NotImplementedError
    |
help: Convert to `X | None`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/multi_model_analyzer_backup.py:986:17
    |
984 |                     logger.info(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model_name} Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
985 |                     return True
986 |                 else:
    |                 ^^^^
987 |                     logger.warning(
988 |                         f"âš ï¸ ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model_name} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°. ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸..."
    |
help: Remove unnecessary `else`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/multi_model_analyzer_backup.py:991:13
    |
989 |                     )
990 |                     return self._pull_model()
991 |             return False
    |             ^^^^^^^^^^^^
992 |         except requests.exceptions.RequestException as e:
993 |             logger.warning(f"âŒ Ollama Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½: {e}")
    |

RET505 [*] Unnecessary `else` after `return` statement
    --> src/analyzers/multi_model_analyzer_backup.py:1009:13
     |
1007 |                 logger.info(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model_name} Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°")
1008 |                 return True
1009 |             else:
     |             ^^^^
1010 |                 logger.error(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: {response.text}")
1011 |                 return False
     |
help: Remove unnecessary `else`

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer_backup.py:1018:10
     |
1016 |     def analyze_song(
1017 |         self, artist: str, title: str, lyrics: str
1018 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1019 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ‡ÐµÑ€ÐµÐ· Ollama"""
1020 |         if not self.available:
     |
help: Convert to `X | None`

RET505 [*] Unnecessary `else` after `return` statement
    --> src/analyzers/multi_model_analyzer_backup.py:1046:13
     |
1044 |                 analysis_text = result.get("response", "")
1045 |                 return self._parse_analysis(analysis_text, artist, title)
1046 |             else:
     |             ^^^^
1047 |                 logger.error(
1048 |                     f"âŒ Ollama Ð¾ÑˆÐ¸Ð±ÐºÐ°: {response.status_code} - {response.text}"
     |
help: Remove unnecessary `else`

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer_backup.py:1103:10
     |
1101 |     def _parse_analysis(
1102 |         self, analysis_text: str, artist: str, title: str
1103 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1104 |         """ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
1105 |         try:
     |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/multi_model_analyzer_backup.py:1149:31
     |
1147 |                 quality_metrics=quality_metrics,
1148 |                 model_used=f"ollama:{self.model_name}",
1149 |                 analysis_date=datetime.now().isoformat(),
     |                               ^^^^^^^^^^^^^^
1150 |             )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

PLR0912 Too many branches (24 > 12)
    --> src/analyzers/multi_model_analyzer_backup.py:1174:9
     |
1172 |         return True
1173 |
1174 |     def analyze_song(
     |         ^^^^^^^^^^^^
1175 |         self, artist: str, title: str, lyrics: str
1176 |     ) -> Optional[EnhancedSongData]:
     |

PLR0915 Too many statements (81 > 50)
    --> src/analyzers/multi_model_analyzer_backup.py:1174:9
     |
1172 |         return True
1173 |
1174 |     def analyze_song(
     |         ^^^^^^^^^^^^
1175 |         self, artist: str, title: str, lyrics: str
1176 |     ) -> Optional[EnhancedSongData]:
     |

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer_backup.py:1176:10
     |
1174 |     def analyze_song(
1175 |         self, artist: str, title: str, lyrics: str
1176 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1177 |         """Mock Ð°Ð½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ ÑƒÐ¼Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸ÑÐ¼Ð¸"""
1178 |         try:
     |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/multi_model_analyzer_backup.py:1359:31
     |
1357 |                 quality_metrics=quality_metrics,
1358 |                 model_used="mock_analyzer_v1",
1359 |                 analysis_date=datetime.now().isoformat(),
     |                               ^^^^^^^^^^^^^^
1360 |             )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

F401 `google.generativeai` imported but unused; consider using `importlib.util.find_spec` to test for availability
    --> src/analyzers/multi_model_analyzer_backup.py:1383:43
     |
1382 |         try:
1383 |             import google.generativeai as genai
     |                                           ^^^^^
1384 |             from google.generativeai.client import configure
1385 |             from google.generativeai.generative_models import GenerativeModel
     |
help: Remove unused import: `google.generativeai`

F401 `google.generativeai.generative_models.GenerativeModel` imported but unused; consider using `importlib.util.find_spec` to test for availability
    --> src/analyzers/multi_model_analyzer_backup.py:1385:63
     |
1383 |             import google.generativeai as genai
1384 |             from google.generativeai.client import configure
1385 |             from google.generativeai.generative_models import GenerativeModel
     |                                                               ^^^^^^^^^^^^^^^
1386 |
1387 |             configure(api_key=self.api_key)
     |
help: Remove unused import: `google.generativeai.generative_models.GenerativeModel`

TRY300 Consider moving this statement to an `else` block
    --> src/analyzers/multi_model_analyzer_backup.py:1389:13
     |
1387 |             configure(api_key=self.api_key)
1388 |             logger.info("âœ… Google Gemma API Ð³Ð¾Ñ‚Ð¾Ð² Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÑŽ")
1389 |             return True
     |             ^^^^^^^^^^^
1390 |         except ImportError:
1391 |             logger.warning("âŒ google-generativeai Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½")
     |

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer_backup.py:1399:10
     |
1397 |     def analyze_song(
1398 |         self, artist: str, title: str, lyrics: str
1399 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1400 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ‡ÐµÑ€ÐµÐ· Google Gemma"""
1401 |         if not self.available:
     |
help: Convert to `X | None`

F401 [*] `google.generativeai` imported but unused
    --> src/analyzers/multi_model_analyzer_backup.py:1405:43
     |
1404 |         try:
1405 |             import google.generativeai as genai
     |                                           ^^^^^
1406 |             from google.generativeai.client import configure
1407 |             from google.generativeai.generative_models import GenerativeModel
     |
help: Remove unused import: `google.generativeai`

F401 [*] `google.generativeai.client.configure` imported but unused
    --> src/analyzers/multi_model_analyzer_backup.py:1406:52
     |
1404 |         try:
1405 |             import google.generativeai as genai
1406 |             from google.generativeai.client import configure
     |                                                    ^^^^^^^^^
1407 |             from google.generativeai.generative_models import GenerativeModel
     |
help: Remove unused import: `google.generativeai.client.configure`

RET505 [*] Unnecessary `else` after `return` statement
    --> src/analyzers/multi_model_analyzer_backup.py:1422:13
     |
1420 |             if response.text:
1421 |                 return self._parse_analysis(response.text, artist, title)
1422 |             else:
     |             ^^^^
1423 |                 logger.error("âŒ Gemma: Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚")
1424 |                 return None
     |
help: Remove unnecessary `else`

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer_backup.py:1471:10
     |
1469 |     def _parse_analysis(
1470 |         self, analysis_text: str, artist: str, title: str
1471 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1472 |         """ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
1473 |         try:
     |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/multi_model_analyzer_backup.py:1517:31
     |
1515 |                 quality_metrics=quality_metrics,
1516 |                 model_used="gemma-2-27b-it",
1517 |                 analysis_date=datetime.now().isoformat(),
     |                               ^^^^^^^^^^^^^^
1518 |             )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer_backup.py:1554:10
     |
1552 |     def analyze_with_explanations(
1553 |         self, artist: str, title: str, lyrics: str
1554 |     ) -> Optional[ExplainableAnalysisResult]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1555 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ñ Ð¿Ð¾Ð»Ð½Ñ‹Ð¼Ð¸ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸ÑÐ¼Ð¸ Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹ AI"""
1556 |         return self.interpretable_analyzer.analyze_with_explanation(
     |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer_backup.py:1562:10
     |
1560 |     def explain_existing_analysis(
1561 |         self, song_id: int, db_path: str = "rap_lyrics.db"
1562 |     ) -> Optional[Dict]:
     |          ^^^^^^^^^^^^^^
1563 |         """ÐžÐ±ÑŠÑÑÐ½ÑÐµÑ‚ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
1564 |         try:
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/multi_model_analyzer_backup.py:1562:19
     |
1560 |     def explain_existing_analysis(
1561 |         self, song_id: int, db_path: str = "rap_lyrics.db"
1562 |     ) -> Optional[Dict]:
     |                   ^^^^
1563 |         """ÐžÐ±ÑŠÑÑÐ½ÑÐµÑ‚ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
1564 |         try:
     |
help: Replace with `dict`

TRY002 Create your own exception
    --> src/analyzers/multi_model_analyzer_backup.py:1681:19
     |
1679 |         if not self.providers:
1680 |             logger.error("âŒ ÐÐ¸ Ð¾Ð´Ð¸Ð½ AI Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½!")
1681 |             raise Exception("No AI providers available")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1682 |
1683 |         self.current_provider = self.providers[0]
     |

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer_backup.py:1688:10
     |
1686 |     def analyze_song(
1687 |         self, artist: str, title: str, lyrics: str
1688 |     ) -> Optional[EnhancedSongData]:
     |          ^^^^^^^^^^^^^^^^^^^^^^^^^^
1689 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ fallback Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð°Ð¼Ð¸"""
     |
help: Convert to `X | None`

RET505 [*] Unnecessary `else` after `return` statement
    --> src/analyzers/multi_model_analyzer_backup.py:1709:17
     |
1707 |                     logger.info(f"âœ… ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ Ñ‡ÐµÑ€ÐµÐ· {provider.name}")
1708 |                     return result
1709 |                 else:
     |                 ^^^^
1710 |                     logger.warning(f"âš ï¸ {provider.name} Ð½Ðµ ÑÐ¼Ð¾Ð³ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ")
     |
help: Remove unnecessary `else`

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/analyzers/multi_model_analyzer_backup.py:1712:13
     |
1710 |                       logger.warning(f"âš ï¸ {provider.name} Ð½Ðµ ÑÐ¼Ð¾Ð³ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ")
1711 |
1712 | /             except Exception as e:
1713 | |                 logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° {provider.name}: {e}")
1714 | |                 continue
     | |________________________^
1715 |
1716 |           logger.error(
     |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/multi_model_analyzer_backup.py:1721:28
     |
1719 |         return None
1720 |
1721 |     def get_stats(self) -> Dict:
     |                            ^^^^
1722 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ"""
1723 |         return {
     |
help: Replace with `dict`

B007 Loop control variable `track` not used within loop body
    --> src/analyzers/multi_model_analyzer_backup.py:1760:20
     |
1758 |             failed = 0
1759 |
1760 |             for i, track in enumerate(tracks, 1):
     |                    ^^^^^
1761 |                 try:
1762 |                     logger.info(
     |
help: Rename unused `track` to `_track`

F821 Undefined name `song`
    --> src/analyzers/multi_model_analyzer_backup.py:1763:60
     |
1761 |                 try:
1762 |                     logger.info(
1763 |                         f"ðŸ“ˆ ÐŸÑ€Ð¾Ð³Ñ€ÐµÑÑ: {i}/{len(tracks)} - {song['artist']} - {song['title']}"
     |                                                             ^^^^
1764 |                     )
     |

F821 Undefined name `song`
    --> src/analyzers/multi_model_analyzer_backup.py:1763:79
     |
1761 |                 try:
1762 |                     logger.info(
1763 |                         f"ðŸ“ˆ ÐŸÑ€Ð¾Ð³Ñ€ÐµÑÑ: {i}/{len(tracks)} - {song['artist']} - {song['title']}"
     |                                                                                ^^^^
1764 |                     )
     |

F821 Undefined name `song`
    --> src/analyzers/multi_model_analyzer_backup.py:1767:25
     |
1766 |                     analysis = self.analyze_song(
1767 |                         song["artist"], song["title"], song["lyrics"]
     |                         ^^^^
1768 |                     )
     |

F821 Undefined name `song`
    --> src/analyzers/multi_model_analyzer_backup.py:1767:41
     |
1766 |                     analysis = self.analyze_song(
1767 |                         song["artist"], song["title"], song["lyrics"]
     |                                         ^^^^
1768 |                     )
     |

F821 Undefined name `song`
    --> src/analyzers/multi_model_analyzer_backup.py:1767:56
     |
1766 |                     analysis = self.analyze_song(
1767 |                         song["artist"], song["title"], song["lyrics"]
     |                                                        ^^^^
1768 |                     )
     |

F821 Undefined name `song`
    --> src/analyzers/multi_model_analyzer_backup.py:1772:57
     |
1770 |                     if analysis:
1771 |                         # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² Ð‘Ð”
1772 |                         self._save_analysis_to_db(conn, song["id"], analysis)
     |                                                         ^^^^
1773 |                         successful += 1
1774 |                         logger.info(f"âœ… Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½ Ð°Ð½Ð°Ð»Ð¸Ð· #{successful}")
     |

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:1777:40
     |
1775 |                     else:
1776 |                         failed += 1
1777 |                         logger.warning(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ")
     |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1778 |
1779 |                     # ÐŸÐ°ÑƒÐ·Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸
     |
help: Remove extraneous `f` prefix

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/analyzers/multi_model_analyzer_backup.py:1783:17
     |
1781 |                           time.sleep(2)  # 2 ÑÐµÐºÑƒÐ½Ð´Ñ‹ Ð¼ÐµÐ¶Ð´Ñƒ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ð¼Ð¸
1782 |
1783 | /                 except Exception as e:
1784 | |                     failed += 1
1785 | |                     logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿ÐµÑÐ½Ð¸ {song['id']}: {e}")
1786 | |                     continue
     | |____________________________^
1787 |
1788 |               conn.close()
     |

F821 Undefined name `song`
    --> src/analyzers/multi_model_analyzer_backup.py:1785:60
     |
1783 |                 except Exception as e:
1784 |                     failed += 1
1785 |                     logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¿ÐµÑÐ½Ð¸ {song['id']}: {e}")
     |                                                             ^^^^
1786 |                     continue
     |

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/multi_model_analyzer_backup.py:1842:10
     |
1840 |     def analyze_song_with_safety(
1841 |         self, artist: str, title: str, lyrics: str
1842 |     ) -> Optional[Dict]:
     |          ^^^^^^^^^^^^^^
1843 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ Ð¸ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸ÐµÐ¹ Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹"""
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/multi_model_analyzer_backup.py:1842:19
     |
1840 |     def analyze_song_with_safety(
1841 |         self, artist: str, title: str, lyrics: str
1842 |     ) -> Optional[Dict]:
     |                   ^^^^
1843 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¿ÐµÑÐ½Ð¸ Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸ Ð¸ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸ÐµÐ¹ Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹"""
     |
help: Replace with `dict`

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:1851:26
     |
1850 |         if not analysis_result:
1851 |             logger.error(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð· Ð´Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸")
     |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1852 |             return None
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:1883:28
     |
1882 |         if not validation_result["is_reliable"]:
1883 |             logger.warning(f"âš ï¸ Ð’ÐÐ˜ÐœÐÐÐ˜Ð•: ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¸Ð·Ð½Ð°Ð½ Ð½ÐµÐ½Ð°Ð´ÐµÐ¶Ð½Ñ‹Ð¼!")
     |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1884 |             logger.warning(
1885 |                 f"   â€¢ Ð Ð¸ÑÐº Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹: {validation_result['hallucination_risk']:.3f}"
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:1899:25
     |
1897 |                 )
1898 |         else:
1899 |             logger.info(f"âœ… ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¾ÑˆÐµÐ» Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÑŽ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸")
     |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1900 |             logger.info(
1901 |                 f"   â€¢ ÐÐ°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚ÑŒ: {validation_result['reliability_score']:.3f}"
     |
help: Remove extraneous `f` prefix

PLR0912 Too many branches (14 > 12)
    --> src/analyzers/multi_model_analyzer_backup.py:1915:5
     |
1915 | def main():
     |     ^^^^
1916 |     """Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð½Ð¾Ð³Ð¾Ð¼Ð¾Ð´ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð° Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð¸Ñ€ÑƒÐµÐ¼Ð¾ÑÑ‚ÑŒÑŽ"""
     |

PLR0915 Too many statements (76 > 50)
    --> src/analyzers/multi_model_analyzer_backup.py:1915:5
     |
1915 | def main():
     |     ^^^^
1916 |     """Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð½Ð¾Ð³Ð¾Ð¼Ð¾Ð´ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð° Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð¸Ñ€ÑƒÐµÐ¼Ð¾ÑÑ‚ÑŒÑŽ"""
     |

W293 Blank line contains whitespace
    --> src/analyzers/multi_model_analyzer_backup.py:1938:1
     |
1936 |         ÐœÐ¾Ð»Ð¾Ð´Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¾ÑˆÐ»Ð° Ð² Ð´Ñ‹Ð¼Ñƒ Ð¸ Ð´Ñ€Ð°ÐºÐ°Ñ…
1937 |         Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ñ‡Ð¸Ñ‚Ð°ÑŽ Ð¿Ñ€Ð°Ð²Ð´Ñƒ Ð² ÑÑ‚Ð¸Ñ… ÑÑ‚Ñ€Ð¾ÐºÐ°Ñ…
1938 |         
     | ^^^^^^^^
1939 |         Ð”ÐµÐ½ÑŒÐ³Ð¸, ÑÐ»Ð°Ð²Ð° - Ð²ÑÐµ ÑÑ‚Ð¾ Ð¿ÑƒÑÑ‚Ð¾Ñ‚Ð°
1940 |         Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¾ÑÑ‚Ð°Ñ‚ÑŒÑÑ ÑÐ¾Ð±Ð¾Ð¹ Ð´Ð¾ ÐºÐ¾Ð½Ñ†Ð°
     |
help: Remove whitespace from blank line

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:1963:19
     |
1962 |             # ÐžÐ±ÑŠÑÑÐ½ÐµÐ½Ð¸Ñ
1963 |             print(f"\nðŸ’¡ ÐžÐ‘ÐªÐ¯Ð¡ÐÐ•ÐÐ˜Ð¯ Ð Ð•Ð¨Ð•ÐÐ˜Ð™:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
1964 |             for category, explanations in explainable_result.explanation.items():
1965 |                 if explanations:
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:1971:19
     |
1970 |             # Ð’Ð»Ð¸ÑÑ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ„Ñ€Ð°Ð·Ñ‹
1971 |             print(f"\nðŸ“ Ð’Ð›Ð˜Ð¯Ð¢Ð•Ð›Ð¬ÐÐ«Ð• Ð¤Ð ÐÐ—Ð«:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
1972 |             for category, phrases in explainable_result.influential_phrases.items():
1973 |                 if phrases:
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:1979:19
     |
1978 |             # ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ñ‹
1979 |             print(f"\nðŸ“Š ÐšÐ›Ð®Ð§Ð•Ð’Ð«Ð• Ð¤ÐÐšÐ¢ÐžÐ Ð« (Ñ‚Ð¾Ð¿-5):")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1980 |             top_factors = sorted(
1981 |                 explainable_result.decision_factors.items(),
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2015:19
     |
2014 |         if safe_result:
2015 |             print(f"\nðŸ›¡ï¸ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ Ð‘Ð•Ð—ÐžÐŸÐÐ¡ÐÐžÐ“Ðž ÐÐÐÐ›Ð˜Ð—Ð:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2016 |             print("-" * 50)
2017 |             print(
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2024:23
     |
2023 |             if safe_result["warnings"]:
2024 |                 print(f"âš ï¸ ÐŸÑ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ:")
     |                       ^^^^^^^^^^^^^^^^^^^^
2025 |                 for warning in safe_result["warnings"]:
2026 |                     print(f"   â€¢ {warning}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2030:19
     |
2028 |             # Ð”ÐµÑ‚Ð°Ð»Ð¸ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸
2029 |             validation = safe_result["validation"]
2030 |             print(f"\nðŸ“Š Ð”Ð•Ð¢ÐÐ›Ð˜ Ð’ÐÐ›Ð˜Ð”ÐÐ¦Ð˜Ð˜:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^
2031 |             print(f"   â€¢ Ð Ð¸ÑÐº Ð³Ð°Ð»Ð»ÑŽÑ†Ð¸Ð½Ð°Ñ†Ð¸Ð¹: {validation['hallucination_risk']:.3f}")
2032 |             print(f"   â€¢ ÐšÐ¾Ð½ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ: {validation['consistency_score']:.3f}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2037:15
     |
2036 |         # Ð¢ÐµÑÑ‚ Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼
2037 |         print(f"\nðŸ”„ Ð¢ÐµÑÑ‚ Ñ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼...")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2038 |         normal_safe_result = analyzer.analyze_song_with_safety(
2039 |             "Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð°Ñ€Ñ‚Ð¸ÑÑ‚", "ÐšÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ñ‚Ñ€ÐµÐº", test_lyrics
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2051:15
     |
2049 |         # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
2050 |         stats = analyzer.get_stats()
2051 |         print(f"\nðŸ“ˆ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ:")
     |               ^^^^^^^^^^^^^^^^^^^
2052 |         print(f"  â€¢ Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {stats['total_analyzed']}")
2053 |         print(f"  â€¢ Ollama Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½: {stats['ollama_used']} Ñ€Ð°Ð·")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2058:15
     |
2056 |         print(f"  â€¢ ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ: ${stats['total_cost']:.4f}")
2057 |
2058 |         print(f"\nâœ… AI Safety & Hallucination Detection - Ð“ÐžÐ¢ÐžÐ’Ðž!")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2059 |         print(f"ðŸ›¡ï¸ Ð¢ÐµÐ¿ÐµÑ€ÑŒ AI Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:")
2060 |         print(f"   â€¢ Interpretability & Model Understanding")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2059:15
     |
2058 |         print(f"\nâœ… AI Safety & Hallucination Detection - Ð“ÐžÐ¢ÐžÐ’Ðž!")
2059 |         print(f"ðŸ›¡ï¸ Ð¢ÐµÐ¿ÐµÑ€ÑŒ AI Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2060 |         print(f"   â€¢ Interpretability & Model Understanding")
2061 |         print(f"   â€¢ Safety & Hallucination Detection")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2060:15
     |
2058 |         print(f"\nâœ… AI Safety & Hallucination Detection - Ð“ÐžÐ¢ÐžÐ’Ðž!")
2059 |         print(f"ðŸ›¡ï¸ Ð¢ÐµÐ¿ÐµÑ€ÑŒ AI Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:")
2060 |         print(f"   â€¢ Interpretability & Model Understanding")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2061 |         print(f"   â€¢ Safety & Hallucination Detection")
2062 |         print(f"   â€¢ Consistency Validation")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2061:15
     |
2059 |         print(f"ðŸ›¡ï¸ Ð¢ÐµÐ¿ÐµÑ€ÑŒ AI Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚:")
2060 |         print(f"   â€¢ Interpretability & Model Understanding")
2061 |         print(f"   â€¢ Safety & Hallucination Detection")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2062 |         print(f"   â€¢ Consistency Validation")
2063 |         print(f"   â€¢ Factual Accuracy Checking")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2062:15
     |
2060 |         print(f"   â€¢ Interpretability & Model Understanding")
2061 |         print(f"   â€¢ Safety & Hallucination Detection")
2062 |         print(f"   â€¢ Consistency Validation")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2063 |         print(f"   â€¢ Factual Accuracy Checking")
2064 |         print(f"ðŸŽ¯ ÐŸÑ€Ð¾Ð´ÑƒÐºÑ†Ð¸Ð¾Ð½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹ Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸!")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2063:15
     |
2061 |         print(f"   â€¢ Safety & Hallucination Detection")
2062 |         print(f"   â€¢ Consistency Validation")
2063 |         print(f"   â€¢ Factual Accuracy Checking")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2064 |         print(f"ðŸŽ¯ ÐŸÑ€Ð¾Ð´ÑƒÐºÑ†Ð¸Ð¾Ð½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹ Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸!")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/multi_model_analyzer_backup.py:2064:15
     |
2062 |         print(f"   â€¢ Consistency Validation")
2063 |         print(f"   â€¢ Factual Accuracy Checking")
2064 |         print(f"ðŸŽ¯ ÐŸÑ€Ð¾Ð´ÑƒÐºÑ†Ð¸Ð¾Ð½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÐµÐ¹ Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸!")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2065 |
2066 |     except Exception as e:
     |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/ollama_analyzer.py:25:1
   |
23 |   """
24 |
25 | / import json
26 | | import time
27 | | import logging
28 | | import requests
29 | | from typing import Dict, Any, List, Optional
30 | | from datetime import datetime
31 | |
32 | | from interfaces.analyzer_interface import (
33 | |     BaseAnalyzer,
34 | |     AnalysisResult,
35 | |     register_analyzer,
36 | | )
   | |_^
37 |
38 |   logger = logging.getLogger(__name__)
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/analyzers/ollama_analyzer.py:29:1
   |
27 | import logging
28 | import requests
29 | from typing import Dict, Any, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30 | from datetime import datetime
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/analyzers/ollama_analyzer.py:29:1
   |
27 | import logging
28 | import requests
29 | from typing import Dict, Any, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30 | from datetime import datetime
   |

UP045 [*] Use `X | None` for type annotations
  --> src/analyzers/ollama_analyzer.py:53:32
   |
51 |     """
52 |
53 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
   |                                ^^^^^^^^^^^^^^^^^^^^^^^^
54 |         """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ollama Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
55 |         super().__init__(config)
   |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/analyzers/ollama_analyzer.py:53:41
   |
51 |     """
52 |
53 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
   |                                         ^^^^
54 |         """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ollama Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
55 |         super().__init__(config)
   |
help: Replace with `dict`

RET505 [*] Unnecessary `else` after `return` statement
  --> src/analyzers/ollama_analyzer.py:90:17
   |
88 |                     logger.info(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model_name} Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
89 |                     return True
90 |                 else:
   |                 ^^^^
91 |                     logger.warning(f"âš ï¸ ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model_name} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
92 |                     # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
   |
help: Remove unnecessary `else`

TRY300 Consider moving this statement to an `else` block
  --> src/analyzers/ollama_analyzer.py:95:13
   |
93 |                     return self._pull_model()
94 |
95 |             return False
   |             ^^^^^^^^^^^^
96 |
97 |         except requests.exceptions.RequestException as e:
   |

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/ollama_analyzer.py:117:13
    |
115 |                 logger.info(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model_name} ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°")
116 |                 return True
117 |             else:
    |             ^^^^
118 |                 logger.error(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: {response.text}")
119 |                 return False
    |
help: Remove unnecessary `else`

TRY301 Abstract `raise` to an inner function
   --> src/analyzers/ollama_analyzer.py:174:17
    |
173 |               if response.status_code != 200:
174 | /                 raise RuntimeError(
175 | |                     f"Ollama request failed: {response.status_code} - {response.text}"
176 | |                 )
    | |_________________^
177 |
178 |               result = response.json()
    |

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/analyzers/ollama_analyzer.py:175:21
    |
173 |             if response.status_code != 200:
174 |                 raise RuntimeError(
175 |                     f"Ollama request failed: {response.status_code} - {response.text}"
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
176 |                 )
    |
help: Assign to variable; remove f-string literal

TRY301 Abstract `raise` to an inner function
   --> src/analyzers/ollama_analyzer.py:182:17
    |
181 |             if not analysis_text:
182 |                 raise RuntimeError("Empty response from Ollama model")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
183 |
184 |             # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/ollama_analyzer.py:200:40
    |
198 |                     "model_name": self.model_name,
199 |                     "base_url": self.base_url,
200 |                     "processing_date": datetime.now().isoformat(),
    |                                        ^^^^^^^^^^^^^^
201 |                     "lyrics_length": len(processed_lyrics),
202 |                     "temperature": self.temperature,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/ollama_analyzer.py:207:27
    |
205 |                 raw_output=analysis_data,
206 |                 processing_time=processing_time,
207 |                 timestamp=datetime.now().isoformat(),
    |                           ^^^^^^^^^^^^^^
208 |             )
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/analyzers/ollama_analyzer.py:212:32
    |
210 |         except requests.exceptions.RequestException as e:
211 |             logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ðº Ollama: {e}")
212 |             raise RuntimeError(f"Ollama connection failed: {e}") from e
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
213 |
214 |         except Exception as e:
    |
help: Assign to variable; remove f-string literal

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/analyzers/ollama_analyzer.py:216:32
    |
214 |         except Exception as e:
215 |             logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ollama Ð´Ð»Ñ {artist} - {title}: {e}")
216 |             raise RuntimeError(f"Ollama analysis failed: {e}") from e
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
217 |
218 |     def _create_analysis_prompt(self, artist: str, title: str, lyrics: str) -> str:
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/ollama_analyzer.py:266:54
    |
264 | Respond with ONLY the JSON object, no additional text!"""
265 |
266 |     def _parse_response(self, response_text: str) -> Dict[str, Any]:
    |                                                      ^^^^
267 |         """ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ollama Ð¼Ð¾Ð´ÐµÐ»Ð¸"""
268 |         try:
    |
help: Replace with `dict`

TRY301 Abstract `raise` to an inner function
   --> src/analyzers/ollama_analyzer.py:274:17
    |
273 |             if json_start == -1 or json_end == 0:
274 |                 raise ValueError("No JSON found in response")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
275 |
276 |             json_str = response_text[json_start:json_end]
    |

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/ollama_analyzer.py:288:13
    |
286 |             self._validate_analysis_structure(analysis_data)
287 |
288 |             return analysis_data
    |             ^^^^^^^^^^^^^^^^^^^^
289 |
290 |         except json.JSONDecodeError as e:
    |

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/analyzers/ollama_analyzer.py:299:30
    |
297 |         except Exception as e:
298 |             logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ollama: {e}")
299 |             raise ValueError(f"Ollama response parsing failed: {e}") from e
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
300 |
301 |     def _extract_basic_info(self, response_text: str) -> Dict[str, Any]:
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/ollama_analyzer.py:301:58
    |
299 |             raise ValueError(f"Ollama response parsing failed: {e}") from e
300 |
301 |     def _extract_basic_info(self, response_text: str) -> Dict[str, Any]:
    |                                                          ^^^^
302 |         """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° JSON"""
303 |         logger.warning("âš ï¸ Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¸Ð· Ð½ÐµÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°")
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/ollama_analyzer.py:361:50
    |
359 |         }
360 |
361 |     def _validate_analysis_structure(self, data: Dict[str, Any]) -> None:
    |                                                  ^^^^
362 |         """Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
363 |         required_sections = [
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/ollama_analyzer.py:388:52
    |
386 |                     logger.warning(f"âš ï¸ ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ {metric}: {value}")
387 |
388 |     def _calculate_confidence(self, analysis_data: Dict[str, Any]) -> float:
    |                                                    ^^^^
389 |         """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ñ… Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
390 |         confidence_factors = []
    |
help: Replace with `dict`

RUF019 [*] Unnecessary key check before dictionary access
   --> src/analyzers/ollama_analyzer.py:403:16
    |
401 |             "experimental_features",
402 |         ]:
403 |             if section_name in analysis_data and analysis_data[section_name]:
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
404 |                 completed_sections += 1
    |
help: Replace with `dict.get`

PERF401 Use a list comprehension to create a transformed list
   --> src/analyzers/ollama_analyzer.py:415:21
    |
413 |             for metric_value in quality_assessment.values():
414 |                 if isinstance(metric_value, (int, float)) and 0 <= metric_value <= 1:
415 |                     valid_metrics.append(metric_value)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
416 |
417 |             if valid_metrics:
    |
help: Replace for loop with list comprehension

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/ollama_analyzer.py:431:9
    |
429 |             # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÑˆÑ‚Ñ€Ð°Ñ„ Ð´Ð»Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ (Ð¾Ð½Ð¸ Ð¼ÐµÐ½ÐµÐµ Ñ‚Ð¾Ñ‡Ð½Ñ‹)
430 |             return base_confidence * 0.8
431 |         else:
    |         ^^^^
432 |             return 0.4  # ÐÐ¸Ð·ÐºÐ°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
    |
help: Remove unnecessary `else`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/ollama_analyzer.py:434:36
    |
432 |             return 0.4  # ÐÐ¸Ð·ÐºÐ°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
433 |
434 |     def get_analyzer_info(self) -> Dict[str, Any]:
    |                                    ^^^^
435 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾Ð± Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ðµ"""
436 |         return {
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/ollama_analyzer.py:472:37
    |
471 |     @property
472 |     def supported_features(self) -> List[str]:
    |                                     ^^^^
473 |         """ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
474 |         return [
    |
help: Replace with `list`

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/optimized_ollama_analyzer.py:20:1
   |
18 |   """
19 |
20 | / import json
21 | | import time
22 | | import logging
23 | | import requests
24 | | import psutil
25 | | import threading
26 | | from typing import Dict, Any, List, Optional
27 | | from datetime import datetime
28 | |
29 | | from interfaces.analyzer_interface import (
30 | |     BaseAnalyzer,
31 | |     AnalysisResult,
32 | |     register_analyzer,
33 | | )
   | |_^
34 |
35 |   logger = logging.getLogger(__name__)
   |
help: Organize imports

F401 [*] `threading` imported but unused
  --> src/analyzers/optimized_ollama_analyzer.py:25:8
   |
23 | import requests
24 | import psutil
25 | import threading
   |        ^^^^^^^^^
26 | from typing import Dict, Any, List, Optional
27 | from datetime import datetime
   |
help: Remove unused import: `threading`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/analyzers/optimized_ollama_analyzer.py:26:1
   |
24 | import psutil
25 | import threading
26 | from typing import Dict, Any, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
27 | from datetime import datetime
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/analyzers/optimized_ollama_analyzer.py:26:1
   |
24 | import psutil
25 | import threading
26 | from typing import Dict, Any, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
27 | from datetime import datetime
   |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> src/analyzers/optimized_ollama_analyzer.py:51:26
   |
50 |       # Ð›ÐµÐ³ÐºÐ¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ð¾ Ð¿Ð¾Ñ€ÑÐ´ÐºÑƒ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸Ñ (Ð¾Ñ‚ ÑÐ°Ð¼Ð¾Ð¹ Ð»ÐµÐ³ÐºÐ¾Ð¹ Ðº Ð±Ð¾Ð»ÐµÐµ Ñ‚ÑÐ¶ÐµÐ»Ð¾Ð¹)
51 |       LIGHTWEIGHT_MODELS = [
   |  __________________________^
52 | |         "qwen2.5:1.5b",  # Ð¡Ð°Ð¼Ð°Ñ Ð»ÐµÐ³ÐºÐ°Ñ, Ð½Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ
53 | |         "phi3:mini",  # Microsoft, Ð¾Ñ‡ÐµÐ½ÑŒ Ð±Ñ‹ÑÑ‚Ñ€Ð°Ñ
54 | |         "llama3.2:1b",  # Ð£Ð»ÑŒÑ‚Ñ€Ð°-Ð»ÐµÐ³ÐºÐ°Ñ Meta
55 | |         "gemma2:2b",  # Google, ÐºÐ¾Ð¼Ð¿Ð°ÐºÑ‚Ð½Ð°Ñ
56 | |         "llama3.2:3b",  # Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸Ð· Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»Ð°
57 | |     ]
   | |_____^
58 |
59 |       def __init__(self, config: Optional[Dict[str, Any]] = None):
   |

UP045 [*] Use `X | None` for type annotations
  --> src/analyzers/optimized_ollama_analyzer.py:59:32
   |
57 |     ]
58 |
59 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
   |                                ^^^^^^^^^^^^^^^^^^^^^^^^
60 |         """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ollama Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
61 |         super().__init__(config)
   |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/analyzers/optimized_ollama_analyzer.py:59:41
   |
57 |     ]
58 |
59 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
   |                                         ^^^^
60 |         """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ollama Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
61 |         super().__init__(config)
   |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/optimized_ollama_analyzer.py:135:13
    |
133 |                 proxies={"http": "", "https": ""},
134 |             )
135 |             return response.status_code == 200
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
136 |         except:
137 |             logger.warning("âŒ Ollama ÑÐµÑ€Ð²ÐµÑ€ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ: ollama serve")
    |

E722 Do not use bare `except`
   --> src/analyzers/optimized_ollama_analyzer.py:136:9
    |
134 |             )
135 |             return response.status_code == 200
136 |         except:
    |         ^^^^^^
137 |             logger.warning("âŒ Ollama ÑÐµÑ€Ð²ÐµÑ€ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ: ollama serve")
138 |             return False
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/optimized_ollama_analyzer.py:140:36
    |
138 |             return False
139 |
140 |     def _get_system_specs(self) -> Dict[str, Any]:
    |                                    ^^^^
141 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"""
142 |         try:
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/optimized_ollama_analyzer.py:166:40
    |
164 |             return {"ram_gb": 8, "cpu_percent": 50, "cpu_cores": 4, "max_freq": 2000}
165 |
166 |     def _get_installed_models(self) -> List[str]:
    |                                        ^^^^
167 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¸ÑÐºÐ° ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹"""
168 |         try:
    |
help: Replace with `list`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/optimized_ollama_analyzer.py:179:13
    |
177 |                 return [model["name"] for model in models_data]
178 |
179 |             return []
    |             ^^^^^^^^^
180 |         except Exception as e:
181 |             logger.warning(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: {e}")
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/optimized_ollama_analyzer.py:185:28
    |
184 |     def _select_optimal_model(
185 |         self, system_info: Dict, installed_models: List[str]
    |                            ^^^^
186 |     ) -> Optional[str]:
187 |         """Ð’Ñ‹Ð±Ð¾Ñ€ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"""
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/optimized_ollama_analyzer.py:185:52
    |
184 |     def _select_optimal_model(
185 |         self, system_info: Dict, installed_models: List[str]
    |                                                    ^^^^
186 |     ) -> Optional[str]:
187 |         """Ð’Ñ‹Ð±Ð¾Ñ€ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"""
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/optimized_ollama_analyzer.py:186:10
    |
184 |     def _select_optimal_model(
185 |         self, system_info: Dict, installed_models: List[str]
186 |     ) -> Optional[str]:
    |          ^^^^^^^^^^^^^
187 |         """Ð’Ñ‹Ð±Ð¾Ñ€ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"""
188 |         ram_gb = system_info["ram_gb"]
    |
help: Convert to `X | None`

RUF005 Consider iterable unpacking instead of concatenation
   --> src/analyzers/optimized_ollama_analyzer.py:207:32
    |
205 |         else:
206 |             # ÐœÐ¾Ñ‰Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° - Ð¼Ð¾Ð¶Ð½Ð¾ Ð²ÑÐµ Ð»ÐµÐ³ÐºÐ¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ + Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ð¼ Ð±Ð¾Ð»ÐµÐµ Ñ‚ÑÐ¶ÐµÐ»Ñ‹Ðµ
207 |             preferred_models = self.LIGHTWEIGHT_MODELS + ["llama3.2:7b", "qwen2.5:7b"]
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
208 |
209 |         # Ð˜Ñ‰ÐµÐ¼ Ð¿ÐµÑ€Ð²ÑƒÑŽ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸Ð· Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ñ…
    |
help: Replace with iterable unpacking

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/optimized_ollama_analyzer.py:226:72
    |
224 |         return None
225 |
226 |     def _adjust_settings_for_model(self, model_name: str, system_info: Dict):
    |                                                                        ^^^^
227 |         """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð¿Ð¾Ð´ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ"""
228 |         ram_gb = system_info["ram_gb"]
    |
help: Replace with `dict`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/optimized_ollama_analyzer.py:299:13
    |
297 |                 )
298 |                 return True
299 |             else:
    |             ^^^^
300 |                 logger.warning(
301 |                     f"âš ï¸ ÐœÐ¾Ð´ÐµÐ»ÑŒ {self.model_name} Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾ ({test_time:.1f}Ñ)"
    |
help: Remove unnecessary `else`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/optimized_ollama_analyzer.py:331:13
    |
329 |                 logger.info(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ {target_model} ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð°")
330 |                 return True
331 |             else:
    |             ^^^^
332 |                 logger.error(
333 |                     f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ {target_model}: {response.text}"
    |
help: Remove unnecessary `else`

F541 [*] f-string without any placeholders
   --> src/analyzers/optimized_ollama_analyzer.py:354:28
    |
352 |         # ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ñ… Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²
353 |         if self.resource_monitor.is_system_overloaded(self.max_cpu_usage):
354 |             logger.warning(f"âš ï¸ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿ÐµÑ€ÐµÐ³Ñ€ÑƒÐ¶ÐµÐ½Ð°, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸Ñ‡Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼")
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
355 |             self._switch_to_economy_mode()
    |
help: Remove extraneous `f` prefix

TRY301 Abstract `raise` to an inner function
   --> src/analyzers/optimized_ollama_analyzer.py:385:17
    |
384 |             if response.status_code != 200:
385 |                 raise RuntimeError(f"Ollama request failed: {response.status_code}")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
386 |
387 |             result = response.json()
    |

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/analyzers/optimized_ollama_analyzer.py:385:36
    |
384 |             if response.status_code != 200:
385 |                 raise RuntimeError(f"Ollama request failed: {response.status_code}")
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
386 |
387 |             result = response.json()
    |
help: Assign to variable; remove f-string literal

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/optimized_ollama_analyzer.py:410:40
    |
408 |                     "max_tokens": self.max_tokens,
409 |                     "system_load": self.resource_monitor.get_current_load(),
410 |                     "processing_date": datetime.now().isoformat(),
    |                                        ^^^^^^^^^^^^^^
411 |                 },
412 |                 raw_output=analysis_data,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/optimized_ollama_analyzer.py:414:27
    |
412 |                 raw_output=analysis_data,
413 |                 processing_time=processing_time,
414 |                 timestamp=datetime.now().isoformat(),
    |                           ^^^^^^^^^^^^^^
415 |             )
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/analyzers/optimized_ollama_analyzer.py:421:32
    |
419 |                 f"âŒ ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ðµ ÑƒÐ´Ð°Ð»ÑÑ Ð´Ð»Ñ {artist} - {title}: {e}"
420 |             )
421 |             raise RuntimeError(f"Optimized analysis failed: {e}") from e
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
422 |
423 |     def _preprocess_lyrics_optimized(self, lyrics: str) -> str:
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/optimized_ollama_analyzer.py:457:59
    |
455 | Only JSON, no text!"""
456 |
457 |     def _parse_response_fast(self, response_text: str) -> Dict[str, Any]:
    |                                                           ^^^^
458 |         """Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ Ñ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ð¼ fallback"""
459 |         try:
    |
help: Replace with `dict`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/analyzers/optimized_ollama_analyzer.py:467:13
    |
465 |                 json_str = response_text[start:end]
466 |                 return json.loads(json_str)
467 |             else:
    |             ^^^^
468 |                 raise ValueError("No JSON found")
    |
help: Remove unnecessary `else`

E722 Do not use bare `except`
   --> src/analyzers/optimized_ollama_analyzer.py:470:9
    |
468 |                 raise ValueError("No JSON found")
469 |
470 |         except:
    |         ^^^^^^
471 |             # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ fallback Ð±ÐµÐ· ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ð¹
472 |             return {
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/optimized_ollama_analyzer.py:481:62
    |
479 |             }
480 |
481 |     def _calculate_confidence_optimized(self, analysis_data: Dict[str, Any]) -> float:
    |                                                              ^^^^
482 |         """Ð‘Ñ‹ÑÑ‚Ñ€Ð¾Ðµ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸"""
483 |         if "_fallback" in analysis_data:
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/optimized_ollama_analyzer.py:500:36
    |
498 |         logger.info("ðŸ”‹ ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ð»Ð¸ÑÑŒ Ð² ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸Ñ‡Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼")
499 |
500 |     def get_analyzer_info(self) -> Dict[str, Any]:
    |                                    ^^^^
501 |         """Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾Ð± Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ðµ"""
502 |         system_specs = self._get_system_specs()
    |
help: Replace with `dict`

SIM103 Return the condition `memory.percent > 85` directly
   --> src/analyzers/optimized_ollama_analyzer.py:547:13
    |
546 |               # ÐŸÐ°Ð¼ÑÑ‚ÑŒ Ð¿Ð¾Ñ‡Ñ‚Ð¸ Ð·Ð°ÐºÐ¾Ð½Ñ‡Ð¸Ð»Ð°ÑÑŒ
547 | /             if memory.percent > 85:
548 | |                 return True
549 | |
550 | |             return False
    | |________________________^
551 |
552 |           except:
    |
help: Replace with `return memory.percent > 85`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/optimized_ollama_analyzer.py:550:13
    |
548 |                 return True
549 |
550 |             return False
    |             ^^^^^^^^^^^^
551 |
552 |         except:
    |

E722 Do not use bare `except`
   --> src/analyzers/optimized_ollama_analyzer.py:552:9
    |
550 |             return False
551 |
552 |         except:
    |         ^^^^^^
553 |             return False
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/optimized_ollama_analyzer.py:555:35
    |
553 |             return False
554 |
555 |     def get_current_load(self) -> Dict[str, float]:
    |                                   ^^^^
556 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"""
557 |         try:
    |
help: Replace with `dict`

E722 Do not use bare `except`
   --> src/analyzers/optimized_ollama_analyzer.py:563:9
    |
561 |                 "available_memory_gb": psutil.virtual_memory().available / (1024**3),
562 |             }
563 |         except:
    |         ^^^^^^
564 |             return {"cpu_percent": 0, "memory_percent": 0, "available_memory_gb": 0}
    |

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/qwen_analyzer.py:16:1
   |
14 |   """
15 |
16 | / import logging
17 | | from typing import Dict, List, Optional, Any
18 | | from openai import OpenAI
19 | | import time
20 | |
21 | | from src.config.config_loader import get_config
22 | | from src.cache.redis_client import redis_cache
   | |______________________________________________^
23 |
24 |   logger = logging.getLogger(__name__)
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/analyzers/qwen_analyzer.py:17:1
   |
16 | import logging
17 | from typing import Dict, List, Optional, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18 | from openai import OpenAI
19 | import time
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/analyzers/qwen_analyzer.py:17:1
   |
16 | import logging
17 | from typing import Dict, List, Optional, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18 | from openai import OpenAI
19 | import time
   |

F401 [*] `typing.List` imported but unused
  --> src/analyzers/qwen_analyzer.py:17:26
   |
16 | import logging
17 | from typing import Dict, List, Optional, Any
   |                          ^^^^
18 | from openai import OpenAI
19 | import time
   |
help: Remove unused import: `typing.List`

F541 [*] f-string without any placeholders
  --> src/analyzers/qwen_analyzer.py:44:21
   |
42 |         self.qwen_config = config.analyzers.get_qwen()
43 |
44 |         logger.info(f"ðŸ¤– Initializing QWEN Analyzer...")
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
45 |         logger.info(f"   Model: {self.qwen_config.model_name}")
46 |         logger.info(f"   Base URL: {self.qwen_config.base_url}")
   |
help: Remove extraneous `f` prefix

UP045 [*] Use `X | None` for type annotations
  --> src/analyzers/qwen_analyzer.py:65:22
   |
63 |         self,
64 |         lyrics: str,
65 |         temperature: Optional[float] = None,
   |                      ^^^^^^^^^^^^^^^
66 |         max_tokens: Optional[int] = None,
67 |         use_cache: bool = True,
   |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
  --> src/analyzers/qwen_analyzer.py:66:21
   |
64 |         lyrics: str,
65 |         temperature: Optional[float] = None,
66 |         max_tokens: Optional[int] = None,
   |                     ^^^^^^^^^^^^^
67 |         use_cache: bool = True,
68 |     ) -> Dict[str, Any]:
   |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/analyzers/qwen_analyzer.py:68:10
   |
66 |         max_tokens: Optional[int] = None,
67 |         use_cache: bool = True,
68 |     ) -> Dict[str, Any]:
   |          ^^^^
69 |         """
70 |         Analyze rap lyrics using QWEN model
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/qwen_analyzer.py:123:10
    |
121 |     def _analyze_with_retry(
122 |         self, prompt: str, temperature: float, max_tokens: int
123 |     ) -> Dict[str, Any]:
    |          ^^^^
124 |         """
125 |         Analyze with automatic retry on failure
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/qwen_analyzer.py:181:17
    |
179 |                     f"âœ… QWEN analysis successful (tokens: {result.get('tokens_used', 'N/A')})"
180 |                 )
181 |                 return result
    |                 ^^^^^^^^^^^^^
182 |
183 |             except Exception as e:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/analyzers/qwen_analyzer.py:183:13
    |
181 |                   return result
182 |
183 | /             except Exception as e:
184 | |                 last_error = e
185 | |                 logger.warning(f"âš ï¸ QWEN attempt {attempt} failed: {e}")
186 | |
187 | |                 if attempt < self.qwen_config.retry_attempts:
188 | |                     wait_time = attempt * 2  # Exponential backoff
189 | |                     logger.info(f"   Retrying in {wait_time}s...")
190 | |                     time.sleep(wait_time)
    | |_________________________________________^
191 |
192 |           # All attempts failed
    |

F541 [*] f-string without any placeholders
   --> src/analyzers/qwen_analyzer.py:219:25
    |
217 |             )
218 |
219 |             logger.info(f"âœ… QWEN API connection successful!")
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
220 |             logger.info(f"   Model: {self.qwen_config.model_name}")
221 |             logger.info(f"   Response: {response.choices[0].message.content}")
    |
help: Remove extraneous `f` prefix

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/qwen_analyzer.py:222:13
    |
220 |             logger.info(f"   Model: {self.qwen_config.model_name}")
221 |             logger.info(f"   Response: {response.choices[0].message.content}")
222 |             return True
    |             ^^^^^^^^^^^
223 |
224 |         except Exception as e:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/qwen_analyzer.py:228:34
    |
226 |             return False
227 |
228 |     def get_config_info(self) -> Dict[str, Any]:
    |                                  ^^^^
229 |         """Get current configuration info"""
230 |         return {
    |
help: Replace with `dict`

F541 [*] f-string without any placeholders
   --> src/analyzers/qwen_analyzer.py:252:15
    |
251 |         # Show config
252 |         print(f"\nðŸ“Š Configuration:")
    |               ^^^^^^^^^^^^^^^^^^^^^^
253 |         config_info = analyzer.get_config_info()
254 |         for key, value in config_info.items():
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/qwen_analyzer.py:258:15
    |
257 |         # Test connection
258 |         print(f"\nðŸ”Œ Testing API connection...")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
259 |         if analyzer.test_api_connection():
260 |             print("âœ… Connection test passed!")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/qwen_analyzer.py:263:19
    |
262 |             # Test lyrics analysis
263 |             print(f"\nðŸŽ¤ Testing lyrics analysis...")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
264 |             test_lyrics = """
265 |             Started from the bottom now we're here
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/analyzers/qwen_analyzer.py:274:23
    |
272 |                 print(f"âŒ Analysis failed: {result['error']}")
273 |             else:
274 |                 print(f"âœ… Analysis successful!")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
275 |                 print(f"   Model: {result.get('model')}")
276 |                 print(f"   Tokens: {result.get('tokens_used')}")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/analyzers/simplified_feature_analyzer.py:30:1
   |
28 |   """
29 |
30 | / import asyncio
31 | | import json
32 | | import logging
33 | | import os
34 | | import signal
35 | | import sys
36 | | import time
37 | | import traceback
38 | | from contextlib import asynccontextmanager
39 | | from dataclasses import dataclass, asdict
40 | | from datetime import datetime, timedelta
41 | | from pathlib import Path
42 | | from typing import Dict, List, Optional, Tuple, Any, AsyncGenerator
43 | | import argparse
44 | |
45 | | # Core analysis imports
46 | | import re
47 | | import math
48 | | from collections import Counter, defaultdict
49 | | from pydantic import BaseModel, Field, field_validator
   | |______________________________________________________^
50 |
51 |   # PostgreSQL imports with fallback
   |
help: Organize imports

UP035 [*] Import from `collections.abc` instead: `AsyncGenerator`
  --> src/analyzers/simplified_feature_analyzer.py:42:1
   |
40 | from datetime import datetime, timedelta
41 | from pathlib import Path
42 | from typing import Dict, List, Optional, Tuple, Any, AsyncGenerator
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43 | import argparse
   |
help: Import from `collections.abc`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/analyzers/simplified_feature_analyzer.py:42:1
   |
40 | from datetime import datetime, timedelta
41 | from pathlib import Path
42 | from typing import Dict, List, Optional, Tuple, Any, AsyncGenerator
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43 | import argparse
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/analyzers/simplified_feature_analyzer.py:42:1
   |
40 | from datetime import datetime, timedelta
41 | from pathlib import Path
42 | from typing import Dict, List, Optional, Tuple, Any, AsyncGenerator
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43 | import argparse
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> src/analyzers/simplified_feature_analyzer.py:42:1
   |
40 | from datetime import datetime, timedelta
41 | from pathlib import Path
42 | from typing import Dict, List, Optional, Tuple, Any, AsyncGenerator
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43 | import argparse
   |

F401 [*] `typing.Tuple` imported but unused
  --> src/analyzers/simplified_feature_analyzer.py:42:42
   |
40 | from datetime import datetime, timedelta
41 | from pathlib import Path
42 | from typing import Dict, List, Optional, Tuple, Any, AsyncGenerator
   |                                          ^^^^^
43 | import argparse
   |
help: Remove unused import

F401 [*] `typing.Any` imported but unused
  --> src/analyzers/simplified_feature_analyzer.py:42:49
   |
40 | from datetime import datetime, timedelta
41 | from pathlib import Path
42 | from typing import Dict, List, Optional, Tuple, Any, AsyncGenerator
   |                                                 ^^^
43 | import argparse
   |
help: Remove unused import

F401 [*] `math` imported but unused
  --> src/analyzers/simplified_feature_analyzer.py:47:8
   |
45 | # Core analysis imports
46 | import re
47 | import math
   |        ^^^^
48 | from collections import Counter, defaultdict
49 | from pydantic import BaseModel, Field, field_validator
   |
help: Remove unused import: `math`

F401 [*] `collections.Counter` imported but unused
  --> src/analyzers/simplified_feature_analyzer.py:48:25
   |
46 | import re
47 | import math
48 | from collections import Counter, defaultdict
   |                         ^^^^^^^
49 | from pydantic import BaseModel, Field, field_validator
   |
help: Remove unused import

F401 [*] `collections.defaultdict` imported but unused
  --> src/analyzers/simplified_feature_analyzer.py:48:34
   |
46 | import re
47 | import math
48 | from collections import Counter, defaultdict
   |                                  ^^^^^^^^^^^
49 | from pydantic import BaseModel, Field, field_validator
   |
help: Remove unused import

F401 `psycopg2` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> src/analyzers/simplified_feature_analyzer.py:54:12
   |
52 | try:
53 |     import asyncpg
54 |     import psycopg2
   |            ^^^^^^^^
55 |     from psycopg2.extras import RealDictCursor
   |
help: Remove unused import: `psycopg2`

F401 `psycopg2.extras.RealDictCursor` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> src/analyzers/simplified_feature_analyzer.py:55:33
   |
53 |     import asyncpg
54 |     import psycopg2
55 |     from psycopg2.extras import RealDictCursor
   |                                 ^^^^^^^^^^^^^^
56 |
57 |     POSTGRES_AVAILABLE = True
   |
help: Remove unused import: `psycopg2.extras.RealDictCursor`

UP006 [*] Use `list` instead of `List` for type annotation
  --> src/analyzers/simplified_feature_analyzer.py:96:27
   |
94 |         )
95 |
96 |     def validate(self) -> List[str]:
   |                           ^^^^
97 |         """Validate configuration parameters"""
98 |         errors = []
   |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/simplified_feature_analyzer.py:123:27
    |
121 |     last_update: str = ""
122 |     processing_rate: float = 0.0  # tracks per second
123 |     estimated_completion: Optional[str] = None
    |                           ^^^^^^^^^^^^^
124 |     error_details: List[Dict] = None
125 |     batch_statistics: Dict = None
    |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:124:20
    |
122 |     processing_rate: float = 0.0  # tracks per second
123 |     estimated_completion: Optional[str] = None
124 |     error_details: List[Dict] = None
    |                    ^^^^
125 |     batch_statistics: Dict = None
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:124:25
    |
122 |     processing_rate: float = 0.0  # tracks per second
123 |     estimated_completion: Optional[str] = None
124 |     error_details: List[Dict] = None
    |                         ^^^^
125 |     batch_statistics: Dict = None
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:125:23
    |
123 |     estimated_completion: Optional[str] = None
124 |     error_details: List[Dict] = None
125 |     batch_statistics: Dict = None
    |                       ^^^^
126 |
127 |     def __post_init__(self):
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:133:26
    |
131 |             self.batch_statistics = {"successful_batches": 0, "failed_batches": 0}
132 |
133 |     def to_dict(self) -> Dict:
    |                          ^^^^
134 |         """Convert to dictionary for JSON serialization"""
135 |         return asdict(self)
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:138:30
    |
137 |     @classmethod
138 |     def from_dict(cls, data: Dict) -> "AnalysisProgress":
    |                              ^^^^
139 |         """Create from dictionary"""
140 |         return cls(**data)
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/simplified_feature_analyzer.py:142:55
    |
140 |         return cls(**data)
141 |
142 |     def calculate_eta(self, remaining_tracks: int) -> Optional[datetime]:
    |                                                       ^^^^^^^^^^^^^^^^^^
143 |         """Calculate estimated time of completion"""
144 |         if self.processing_rate <= 0 or remaining_tracks <= 0:
    |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/simplified_feature_analyzer.py:148:16
    |
147 |         eta_seconds = remaining_tracks / self.processing_rate
148 |         return datetime.now() + timedelta(seconds=eta_seconds)
    |                ^^^^^^^^^^^^^^
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/simplified_feature_analyzer.py:160:26
    |
158 |         # Create structured log entry
159 |         log_entry = {
160 |             "timestamp": datetime.now().isoformat() + "Z",
    |                          ^^^^^^^^^^^^^^
161 |             "level": record.levelname,
162 |             "logger": record.name,
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/simplified_feature_analyzer.py:204:40
    |
203 | def setup_logging(
204 |     log_level: str = "INFO", log_file: Optional[str] = None
    |                                        ^^^^^^^^^^^^^
205 | ) -> logging.Logger:
206 |     """Configure production-grade logging"""
    |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/analyzers/simplified_feature_analyzer.py:228:42
    |
226 |     if not log_file:
227 |         log_file = (
228 |             log_dir / f"lyrics_analyzer_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    |                                          ^^^^^^^^^^^^^^
229 |         )
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/simplified_feature_analyzer.py:425:46
    |
423 |         }
424 |
425 |     def analyze(self, lyrics: str, track_id: Optional[int] = None) -> LyricsFeatures:
    |                                              ^^^^^^^^^^^^^
426 |         """Perform comprehensive lyrics analysis with timing"""
427 |         start_time = time.time()
    |
help: Convert to `X | None`

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/simplified_feature_analyzer.py:473:13
    |
471 |             )
472 |
473 |             return features
    |             ^^^^^^^^^^^^^^^
474 |
475 |         except Exception as e:
    |

G201 Logging `.exception(...)` should be used instead of `.error(..., exc_info=True)`
   --> src/analyzers/simplified_feature_analyzer.py:477:25
    |
475 |         except Exception as e:
476 |             processing_time = (time.time() - start_time) * 1000
477 |             self.logger.error(
    |                         ^^^^^
478 |                 "Analysis failed",
479 |                 extra={
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:488:50
    |
486 |             raise
487 |
488 |     def _preprocess_lyrics(self, lyrics: str) -> List[str]:
    |                                                  ^^^^
489 |         """Clean and prepare lyrics for analysis"""
490 |         # Remove excessive whitespace and empty lines
    |
help: Replace with `list`

PERF401 Use a list comprehension to create a transformed list
   --> src/analyzers/simplified_feature_analyzer.py:502:17
    |
500 |                 re.IGNORECASE,
501 |             ):
502 |                 cleaned_lines.append(line)
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
503 |
504 |         return cleaned_lines
    |
help: Replace for loop with list comprehension

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:506:48
    |
504 |         return cleaned_lines
505 |
506 |     def _tokenize_lyrics(self, lyrics: str) -> List[str]:
    |                                                ^^^^
507 |         """Advanced tokenization with stop word removal"""
508 |         # Extract words using improved regex
    |
help: Replace with `list`

RET504 Unnecessary assignment to `meaningful_words` before `return` statement
   --> src/analyzers/simplified_feature_analyzer.py:516:16
    |
514 |         ]
515 |
516 |         return meaningful_words
    |                ^^^^^^^^^^^^^^^^
517 |
518 |     def _analyze_rhymes(self, lines: List[str], words: List[str]) -> Dict:
    |
help: Remove unnecessary assignment

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:518:38
    |
516 |         return meaningful_words
517 |
518 |     def _analyze_rhymes(self, lines: List[str], words: List[str]) -> Dict:
    |                                      ^^^^
519 |         """Comprehensive rhyme analysis"""
520 |         if len(lines) < 2:
    |
help: Replace with `list`

ARG002 Unused method argument: `words`
   --> src/analyzers/simplified_feature_analyzer.py:518:49
    |
516 |         return meaningful_words
517 |
518 |     def _analyze_rhymes(self, lines: List[str], words: List[str]) -> Dict:
    |                                                 ^^^^^
519 |         """Comprehensive rhyme analysis"""
520 |         if len(lines) < 2:
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:518:56
    |
516 |         return meaningful_words
517 |
518 |     def _analyze_rhymes(self, lines: List[str], words: List[str]) -> Dict:
    |                                                        ^^^^
519 |         """Comprehensive rhyme analysis"""
520 |         if len(lines) < 2:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:518:70
    |
516 |         return meaningful_words
517 |
518 |     def _analyze_rhymes(self, lines: List[str], words: List[str]) -> Dict:
    |                                                                      ^^^^
519 |         """Comprehensive rhyme analysis"""
520 |         if len(lines) < 2:
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:557:45
    |
555 |         }
556 |
557 |     def _detect_rhyme_scheme(self, endings: List[str]) -> str:
    |                                             ^^^^
558 |         """Detect rhyme scheme pattern with improved accuracy"""
559 |         if len(endings) < 4:
    |
help: Replace with `list`

SIM103 Return the condition directly
   --> src/analyzers/simplified_feature_analyzer.py:601:9
    |
599 |           word2_vowels = [c for c in word2[-3:] if c in vowels]
600 |
601 | /         if word1_vowels and word2_vowels and word1_vowels[-1] == word2_vowels[-1]:
602 | |             return True
603 | |
604 | |         return False
    | |____________________^
605 |
606 |       def _count_perfect_rhymes(self, endings: List[str]) -> int:
    |
help: Inline condition

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:606:46
    |
604 |         return False
605 |
606 |     def _count_perfect_rhymes(self, endings: List[str]) -> int:
    |                                              ^^^^
607 |         """Count perfect rhyming pairs"""
608 |         rhyme_count = 0
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:615:45
    |
613 |         return rhyme_count
614 |
615 |     def _count_internal_rhymes(self, lines: List[str]) -> int:
    |                                             ^^^^
616 |         """Count internal rhymes within lines"""
617 |         internal_count = 0
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:633:46
    |
631 |         return internal_count
632 |
633 |     def _calculate_alliteration(self, lines: List[str]) -> float:
    |                                              ^^^^
634 |         """Calculate alliteration score"""
635 |         alliteration_count = 0
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:656:42
    |
654 |         return alliteration_count / max(total_word_pairs, 1)
655 |
656 |     def _analyze_vocabulary(self, words: List[str]) -> Dict:
    |                                          ^^^^
657 |         """Comprehensive vocabulary analysis"""
658 |         if not words:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:656:56
    |
654 |         return alliteration_count / max(total_word_pairs, 1)
655 |
656 |     def _analyze_vocabulary(self, words: List[str]) -> Dict:
    |                                                        ^^^^
657 |         """Comprehensive vocabulary analysis"""
658 |         if not words:
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:702:55
    |
700 |         return syllable_count >= 3 or len(word) > 7
701 |
702 |     def _analyze_creativity(self, lyrics: str, words: List[str]) -> Dict:
    |                                                       ^^^^
703 |         """Analyze creative elements like metaphors and wordplay"""
704 |         if not words:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:702:69
    |
700 |         return syllable_count >= 3 or len(word) > 7
701 |
702 |     def _analyze_creativity(self, lyrics: str, words: List[str]) -> Dict:
    |                                                                     ^^^^
703 |         """Analyze creative elements like metaphors and wordplay"""
704 |         if not words:
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:736:36
    |
734 |         }
735 |
736 |     def _analyze_flow(self, lines: List[str], words: List[str]) -> Dict:
    |                                    ^^^^
737 |         """Analyze flow and rhythm characteristics"""
738 |         if not lines:
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:736:54
    |
734 |         }
735 |
736 |     def _analyze_flow(self, lines: List[str], words: List[str]) -> Dict:
    |                                                      ^^^^
737 |         """Analyze flow and rhythm characteristics"""
738 |         if not lines:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:736:68
    |
734 |         }
735 |
736 |     def _analyze_flow(self, lines: List[str], words: List[str]) -> Dict:
    |                                                                    ^^^^
737 |         """Analyze flow and rhythm characteristics"""
738 |         if not lines:
    |
help: Replace with `dict`

C416 Unnecessary list comprehension (rewrite using `list()`)
   --> src/analyzers/simplified_feature_analyzer.py:755:26
    |
753 |         line_syllable_counts = []
754 |         for line in lines:
755 |             line_words = [word for word in re.findall(r"\b\w+\b", line.lower())]
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
756 |             line_syllables = sum(self._count_syllables(word) for word in line_words)
757 |             line_syllable_counts.append(line_syllables)
    |
help: Rewrite using `list()`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:813:25
    |
811 |     def _calculate_composite_scores(
812 |         self,
813 |         rhyme_features: Dict,
    |                         ^^^^
814 |         vocabulary_features: Dict,
815 |         creativity_features: Dict,
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:814:30
    |
812 |         self,
813 |         rhyme_features: Dict,
814 |         vocabulary_features: Dict,
    |                              ^^^^
815 |         creativity_features: Dict,
816 |         flow_features: Dict,
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:815:30
    |
813 |         rhyme_features: Dict,
814 |         vocabulary_features: Dict,
815 |         creativity_features: Dict,
    |                              ^^^^
816 |         flow_features: Dict,
817 |     ) -> Dict:
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:816:24
    |
814 |         vocabulary_features: Dict,
815 |         creativity_features: Dict,
816 |         flow_features: Dict,
    |                        ^^^^
817 |     ) -> Dict:
818 |         """Calculate composite sophistication scores"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:817:10
    |
815 |         creativity_features: Dict,
816 |         flow_features: Dict,
817 |     ) -> Dict:
    |          ^^^^
818 |         """Calculate composite sophistication scores"""
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:856:44
    |
854 |         }
855 |
856 |     def _calculate_confidence(self, lines: List[str], words: List[str]) -> float:
    |                                            ^^^^
857 |         """Calculate confidence in analysis results"""
858 |         confidence_factors = []
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/analyzers/simplified_feature_analyzer.py:856:62
    |
854 |         }
855 |
856 |     def _calculate_confidence(self, lines: List[str], words: List[str]) -> float:
    |                                                              ^^^^
857 |         """Calculate confidence in analysis results"""
858 |         confidence_factors = []
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/simplified_feature_analyzer.py:885:32
    |
883 |     """Professional PostgreSQL connection manager with comprehensive error handling"""
884 |
885 |     def __init__(self, config: Optional[DatabaseConfig] = None):
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^
886 |         self.config = config or DatabaseConfig.from_env()
887 |         self.logger = logging.getLogger(f"{__name__}.PostgreSQLManager")
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/analyzers/simplified_feature_analyzer.py:888:31
    |
886 |         self.config = config or DatabaseConfig.from_env()
887 |         self.logger = logging.getLogger(f"{__name__}.PostgreSQLManager")
888 |         self.connection_pool: Optional[asyncpg.Pool] = None
    |                               ^^^^^^^^^^^^^^^^^^^^^^
889 |         self._shutdown_event = asyncio.Event()
    |
help: Convert to `X | None`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/analyzers/simplified_feature_analyzer.py:895:17
    |
893 |         if config_errors:
894 |             raise ValueError(
895 |                 f"Database configuration errors: {', '.join(config_errors)}"
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
896 |             )
    |
help: Assign to variable; remove f-string literal

TRY300 Consider moving this statement to an `else` block
   --> src/analyzers/simplified_feature_analyzer.py:937:13
    |
935 |             )
936 |
937 |             return True
    |             ^^^^^^^^^^^
938 |
939 |         except Exception as e:
    |

G201 Logging `.exception(...)` should be used instead of `.error(..., exc_info=True)`
   --> src/analyzers/simplified_feature_analyzer.py:940:25
    |
939 |         except Exception as e:
940 |             self.logger.error(
    |                         ^^^^^
941 |                 "Failed to initialize PostgreSQL connection pool",
942 |                 extra={
    |

G201 Logging `.exception(...)` should be used instead of `.error(..., exc_info=True)`
   --> src/analyzers/simplified_feature_analyzer.py:995:25
    |
993 |         except Exception as e:
994 |             execution_time = (time.time() - start_time) * 1000
995 |             self.logger.error(
    |                         ^^^^^
996 |                 "Query execution failed",
997 |                 extra={
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/simplified_feature_analyzer.py:1007:43
     |
1005 |             raise
1006 |
1007 |     async def get_database_stats(self) -> Dict:
     |                                           ^^^^
1008 |         """Get comprehensive database statistics"""
1009 |         try:
     |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
    --> src/analyzers/simplified_feature_analyzer.py:1033:13
     |
1031 |                 return stats
1032 |
1033 |             return {}
     |             ^^^^^^^^^
1034 |
1035 |         except Exception as e:
     |

F841 [*] Local variable `e` is assigned to but never used
    --> src/analyzers/simplified_feature_analyzer.py:1035:29
     |
1033 |             return {}
1034 |
1035 |         except Exception as e:
     |                             ^
1036 |             self.logger.error("Failed to get database statistics", exc_info=True)
1037 |             return {}
     |
help: Remove assignment to unused variable `e`

G201 Logging `.exception(...)` should be used instead of `.error(..., exc_info=True)`
    --> src/analyzers/simplified_feature_analyzer.py:1036:25
     |
1035 |         except Exception as e:
1036 |             self.logger.error("Failed to get database statistics", exc_info=True)
     |                         ^^^^^
1037 |             return {}
     |

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/simplified_feature_analyzer.py:1054:32
     |
1052 |     """Main analysis engine with progress tracking and error recovery"""
1053 |
1054 |     def __init__(self, config: Optional[DatabaseConfig] = None):
     |                                ^^^^^^^^^^^^^^^^^^^^^^^^
1055 |         self.db_manager = PostgreSQLManager(config)
1056 |         self.analyzer = LyricsAnalyzer()
     |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/simplified_feature_analyzer.py:1061:32
     |
1059 |         # Progress tracking
1060 |         self.progress_file = Path("results/analysis_progress_v2.json")
1061 |         self.current_progress: Optional[AnalysisProgress] = None
     |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^
1062 |
1063 |         # Statistics tracking
     |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1065:27
     |
1063 |         # Statistics tracking
1064 |         self.session_stats = {
1065 |             "start_time": datetime.now(),
     |                           ^^^^^^^^^^^^^^
1066 |             "tracks_processed": 0,
1067 |             "tracks_failed": 0,
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

ARG001 Unused function argument: `frame`
    --> src/analyzers/simplified_feature_analyzer.py:1080:36
     |
1078 |         """Setup graceful shutdown signal handlers"""
1079 |
1080 |         def signal_handler(signum, frame):
     |                                    ^^^^^
1081 |             self.logger.info(
1082 |                 f"Received shutdown signal {signum}, initiating graceful shutdown"
     |

PTH123 `open()` should be replaced by `Path.open()`
    --> src/analyzers/simplified_feature_analyzer.py:1120:22
     |
1118 |         try:
1119 |             if self.progress_file.exists():
1120 |                 with open(self.progress_file, "r", encoding="utf-8") as f:
     |                      ^^^^
1121 |                     data = json.load(f)
     |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
    --> src/analyzers/simplified_feature_analyzer.py:1120:47
     |
1118 |         try:
1119 |             if self.progress_file.exists():
1120 |                 with open(self.progress_file, "r", encoding="utf-8") as f:
     |                                               ^^^
1121 |                     data = json.load(f)
     |
help: Remove mode argument

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1127:20
     |
1125 |                 # Check if we should start a new session
1126 |                 last_update = datetime.fromisoformat(progress.last_update)
1127 |                 if datetime.now() - last_update > timedelta(hours=24):
     |                    ^^^^^^^^^^^^^^
1128 |                     self.logger.info(
1129 |                         "Starting new session (previous session > 24h old)"
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1151:33
     |
1149 |     def _create_new_progress(self) -> AnalysisProgress:
1150 |         """Create new progress session"""
1151 |         session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
     |                                 ^^^^^^^^^^^^^^
1152 |         progress = AnalysisProgress(
1153 |             session_id=session_id,
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1154:27
     |
1152 |         progress = AnalysisProgress(
1153 |             session_id=session_id,
1154 |             session_start=datetime.now().isoformat(),
     |                           ^^^^^^^^^^^^^^
1155 |             last_update=datetime.now().isoformat(),
1156 |         )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1155:25
     |
1153 |             session_id=session_id,
1154 |             session_start=datetime.now().isoformat(),
1155 |             last_update=datetime.now().isoformat(),
     |                         ^^^^^^^^^^^^^^
1156 |         )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1166:49
     |
1164 |         """Save progress to file with atomic write"""
1165 |         try:
1166 |             self.current_progress.last_update = datetime.now().isoformat()
     |                                                 ^^^^^^^^^^^^^^
1167 |
1168 |             # Calculate processing rate
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1173:36
     |
1171 |                     self.current_progress.session_start
1172 |                 )
1173 |                 elapsed_seconds = (datetime.now() - session_start).total_seconds()
     |                                    ^^^^^^^^^^^^^^
1174 |                 self.current_progress.processing_rate = (
1175 |                     self.current_progress.total_processed / max(elapsed_seconds, 1)
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
    --> src/analyzers/simplified_feature_analyzer.py:1180:18
     |
1178 |             # Atomic write using temporary file
1179 |             temp_file = self.progress_file.with_suffix(".tmp")
1180 |             with open(temp_file, "w", encoding="utf-8") as f:
     |                  ^^^^
1181 |                 json.dump(
1182 |                     self.current_progress.to_dict(), f, indent=2, ensure_ascii=False
     |
help: Replace with `Path.open()`

G201 Logging `.exception(...)` should be used instead of `.error(..., exc_info=True)`
    --> src/analyzers/simplified_feature_analyzer.py:1198:25
     |
1197 |         except Exception as e:
1198 |             self.logger.error(f"Failed to save progress: {e}", exc_info=True)
     |                         ^^^^^
1199 |
1200 |     async def analyze_all_tracks(
     |

UP045 [*] Use `X | None` for type annotations
    --> src/analyzers/simplified_feature_analyzer.py:1201:49
     |
1200 |     async def analyze_all_tracks(
1201 |         self, batch_size: int = 50, max_tracks: Optional[int] = None
     |                                                 ^^^^^^^^^^^^^
1202 |     ) -> Dict:
1203 |         """Analyze all unprocessed tracks with comprehensive progress tracking"""
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/simplified_feature_analyzer.py:1202:10
     |
1200 |     async def analyze_all_tracks(
1201 |         self, batch_size: int = 50, max_tracks: Optional[int] = None
1202 |     ) -> Dict:
     |          ^^^^
1203 |         """Analyze all unprocessed tracks with comprehensive progress tracking"""
     |
help: Replace with `dict`

F841 [*] Local variable `e` is assigned to but never used
    --> src/analyzers/simplified_feature_analyzer.py:1283:29
     |
1281 |                     await asyncio.sleep(0.1)
1282 |
1283 |         except Exception as e:
     |                             ^
1284 |             self.logger.error("Analysis loop failed", exc_info=True)
1285 |             raise
     |
help: Remove assignment to unused variable `e`

G201 Logging `.exception(...)` should be used instead of `.error(..., exc_info=True)`
    --> src/analyzers/simplified_feature_analyzer.py:1284:25
     |
1283 |         except Exception as e:
1284 |             self.logger.error("Analysis loop failed", exc_info=True)
     |                         ^^^^^
1285 |             raise
     |

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/simplified_feature_analyzer.py:1304:57
     |
1302 |         return results
1303 |
1304 |     async def _get_next_batch(self, batch_size: int) -> List[Dict]:
     |                                                         ^^^^
1305 |         """Get next batch of unprocessed tracks"""
1306 |         query = """
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/simplified_feature_analyzer.py:1304:62
     |
1302 |         return results
1303 |
1304 |     async def _get_next_batch(self, batch_size: int) -> List[Dict]:
     |                                                              ^^^^
1305 |         """Get next batch of unprocessed tracks"""
1306 |         query = """
     |
help: Replace with `dict`

F841 [*] Local variable `e` is assigned to but never used
    --> src/analyzers/simplified_feature_analyzer.py:1329:29
     |
1327 |             return [dict(row) for row in result] if result else []
1328 |
1329 |         except Exception as e:
     |                             ^
1330 |             self.logger.error(
1331 |                 "Failed to get next batch",
     |
help: Remove assignment to unused variable `e`

G201 Logging `.exception(...)` should be used instead of `.error(..., exc_info=True)`
    --> src/analyzers/simplified_feature_analyzer.py:1330:25
     |
1329 |         except Exception as e:
1330 |             self.logger.error(
     |                         ^^^^^
1331 |                 "Failed to get next batch",
1332 |                 extra={
     |

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/analyzers/simplified_feature_analyzer.py:1340:44
     |
1338 |             return []
1339 |
1340 |     async def _process_batch(self, tracks: List[Dict]) -> Dict[str, int]:
     |                                            ^^^^
1341 |         """Process a batch of tracks with comprehensive error handling"""
1342 |         processed = 0
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/simplified_feature_analyzer.py:1340:49
     |
1338 |             return []
1339 |
1340 |     async def _process_batch(self, tracks: List[Dict]) -> Dict[str, int]:
     |                                                 ^^^^
1341 |         """Process a batch of tracks with comprehensive error handling"""
1342 |         processed = 0
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/simplified_feature_analyzer.py:1340:59
     |
1338 |             return []
1339 |
1340 |     async def _process_batch(self, tracks: List[Dict]) -> Dict[str, int]:
     |                                                           ^^^^
1341 |         """Process a batch of tracks with comprehensive error handling"""
1342 |         processed = 0
     |
help: Replace with `dict`

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
    --> src/analyzers/simplified_feature_analyzer.py:1347:13
     |
1346 |           try:
1347 | /             async with self.db_manager.get_connection() as conn:
1348 | |                 async with conn.transaction():
     | |______________________________________________^
1349 |                       for track in tracks:
1350 |                           if self._shutdown_requested:
     |
help: Combine `with` statements

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1379:46
     |
1377 | â€¦                         "title": track.get("title", "Unknown"),
1378 | â€¦                         "error": str(e),
1379 | â€¦                         "timestamp": datetime.now().isoformat(),
     |                                        ^^^^^^^^^^^^^^
1380 | â€¦                     }
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

F841 [*] Local variable `e` is assigned to but never used
    --> src/analyzers/simplified_feature_analyzer.py:1389:29
     |
1387 |                             )
1388 |
1389 |         except Exception as e:
     |                             ^
1390 |             self.logger.error(
1391 |                 "Batch processing failed",
     |
help: Remove assignment to unused variable `e`

G201 Logging `.exception(...)` should be used instead of `.error(..., exc_info=True)`
    --> src/analyzers/simplified_feature_analyzer.py:1390:25
     |
1389 |         except Exception as e:
1390 |             self.logger.error(
     |                         ^^^^^
1391 |                 "Batch processing failed",
1392 |                 extra={
     |

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/analyzers/simplified_feature_analyzer.py:1417:48
     |
1416 |     async def _save_analysis_result(
1417 |         self, conn: asyncpg.Connection, track: Dict, features: LyricsFeatures
     |                                                ^^^^
1418 |     ):
1419 |         """Save analysis results to database"""
     |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1432:39
     |
1430 |             "metadata": {
1431 |                 "analyzer_version": features.analyzer_version,
1432 |                 "analysis_timestamp": datetime.now().isoformat(),
     |                                       ^^^^^^^^^^^^^^
1433 |                 "track_info": {
1434 |                     "artist": track.get("artist"),
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1451:13
     |
1449 |             features.processing_time_ms,  # processing_time_ms
1450 |             features.analyzer_version,  # model_version
1451 |             datetime.now(),  # created_at
     |             ^^^^^^^^^^^^^^
1452 |         )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/analyzers/simplified_feature_analyzer.py:1466:28
     |
1465 |         # Log session summary
1466 |         session_duration = datetime.now() - self.session_stats["start_time"]
     |                            ^^^^^^^^^^^^^^
1467 |         self.logger.info(
1468 |             "Analysis engine shutdown complete",
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

F541 [*] f-string without any placeholders
    --> src/analyzers/simplified_feature_analyzer.py:1581:15
     |
1579 |         print(f"  Alliteration Score: {features.alliteration_score:.3f}")
1580 |
1581 |         print(f"\nðŸ“š VOCABULARY:")
     |               ^^^^^^^^^^^^^^^^^^^
1582 |         print(f"  TTR Score: {features.ttr_score:.3f}")
1583 |         print(f"  Unique Words: {features.unique_words}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/simplified_feature_analyzer.py:1588:15
     |
1586 |         print(f"  Complex Words: {features.complex_words_ratio:.3f}")
1587 |
1588 |         print(f"\nðŸŽ¨ CREATIVITY:")
     |               ^^^^^^^^^^^^^^^^^^^
1589 |         print(f"  Metaphor Count: {features.metaphor_count}")
1590 |         print(f"  Wordplay Instances: {features.wordplay_instances}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/simplified_feature_analyzer.py:1593:15
     |
1591 |         print(f"  Creativity Score: {features.creativity_score:.3f}")
1592 |
1593 |         print(f"\nðŸŽ¯ FLOW:")
     |               ^^^^^^^^^^^^^
1594 |         print(f"  Syllable Count: {features.syllable_count}")
1595 |         print(f"  Avg Syllables/Line: {features.average_syllables_per_line:.1f}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/simplified_feature_analyzer.py:1599:15
     |
1597 |         print(f"  Flow Breaks: {features.flow_breaks}")
1598 |
1599 |         print(f"\nðŸ“Š COMPOSITE SCORES:")
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^
1600 |         print(f"  Overall Complexity: {features.overall_complexity:.3f}")
1601 |         print(f"  Artistic Sophistication: {features.artistic_sophistication:.3f}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/simplified_feature_analyzer.py:1605:15
     |
1603 |         print(f"  Innovation Score: {features.innovation_score:.3f}")
1604 |
1605 |         print(f"\nâš¡ PERFORMANCE:")
     |               ^^^^^^^^^^^^^^^^^^^^
1606 |         print(f"  Processing Time: {features.processing_time_ms:.1f}ms")
1607 |         print(f"  Confidence Score: {features.confidence_score:.3f}")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/simplified_feature_analyzer.py:1677:23
     |
1676 |             if results.get("shutdown_requested"):
1677 |                 print(f"  Status: Gracefully shutdown (SIGINT/SIGTERM)")
     |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1678 |             else:
1679 |                 print(f"  Status: Completed successfully")
     |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
    --> src/analyzers/simplified_feature_analyzer.py:1679:23
     |
1677 |                 print(f"  Status: Gracefully shutdown (SIGINT/SIGTERM)")
1678 |             else:
1679 |                 print(f"  Status: Completed successfully")
     |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1680 |
1681 |             print("=" * 60)
     |
help: Remove extraneous `f` prefix

G201 Logging `.exception(...)` should be used instead of `.error(..., exc_info=True)`
    --> src/analyzers/simplified_feature_analyzer.py:1691:16
     |
1690 |     except Exception as e:
1691 |         logger.error("Application failed", exc_info=True)
     |                ^^^^^
1692 |         print(f"Application failed: {e}")
1693 |         sys.exit(1)
     |

I001 [*] Import block is un-sorted or un-formatted
  --> src/api/ml_api_service_v2.py:16:1
   |
14 |   """
15 |
16 | / from fastapi import FastAPI, HTTPException, Depends, Request
17 | | from fastapi.middleware.cors import CORSMiddleware
18 | | from fastapi.responses import JSONResponse
19 | | from pydantic import BaseModel, Field
20 | | from typing import List, Dict, Optional
21 | | import logging
22 | | import time
23 | | from datetime import datetime
24 | |
25 | | from src.config import get_config
26 | | from src.analyzers.qwen_analyzer import QwenAnalyzer
27 | | from src.cache.redis_client import redis_cache, test_redis_connection
28 | | from src.database.connection import test_connection as test_db_connection
   | |_________________________________________________________________________^
29 |
30 |   logger = logging.getLogger(__name__)
   |
help: Organize imports

F401 [*] `fastapi.Depends` imported but unused
  --> src/api/ml_api_service_v2.py:16:45
   |
14 | """
15 |
16 | from fastapi import FastAPI, HTTPException, Depends, Request
   |                                             ^^^^^^^
17 | from fastapi.middleware.cors import CORSMiddleware
18 | from fastapi.responses import JSONResponse
   |
help: Remove unused import: `fastapi.Depends`

UP035 `typing.List` is deprecated, use `list` instead
  --> src/api/ml_api_service_v2.py:20:1
   |
18 | from fastapi.responses import JSONResponse
19 | from pydantic import BaseModel, Field
20 | from typing import List, Dict, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
21 | import logging
22 | import time
   |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/api/ml_api_service_v2.py:20:1
   |
18 | from fastapi.responses import JSONResponse
19 | from pydantic import BaseModel, Field
20 | from typing import List, Dict, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
21 | import logging
22 | import time
   |

F401 [*] `typing.List` imported but unused
  --> src/api/ml_api_service_v2.py:20:20
   |
18 | from fastapi.responses import JSONResponse
19 | from pydantic import BaseModel, Field
20 | from typing import List, Dict, Optional
   |                    ^^^^
21 | import logging
22 | import time
   |
help: Remove unused import: `typing.List`

PLW0603 Using the global statement to update `qwen_analyzer` is discouraged
  --> src/api/ml_api_service_v2.py:61:12
   |
59 | async def startup_event():
60 |     """Initialize services on startup"""
61 |     global qwen_analyzer
   |            ^^^^^^^^^^^^^
62 |
63 |     logger.info("ðŸš€ Starting ML API Service v2.0.0...")
   |

PLW0603 Using the global statement to update `qwen_analyzer` is discouraged
  --> src/api/ml_api_service_v2.py:61:12
   |
59 | async def startup_event():
60 |     """Initialize services on startup"""
61 |     global qwen_analyzer
   |            ^^^^^^^^^^^^^
62 |
63 |     logger.info("ðŸš€ Starting ML API Service v2.0.0...")
   |

UP045 [*] Use `X | None` for type annotations
   --> src/api/ml_api_service_v2.py:100:18
    |
 98 |     lyrics: str = Field(..., description="Lyrics text to analyze")
 99 |     use_cache: bool = Field(True, description="Use Redis cache if available")
100 |     temperature: Optional[float] = Field(
    |                  ^^^^^^^^^^^^^^^
101 |         None, description="Override config temperature"
102 |     )
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/api/ml_api_service_v2.py:112:17
    |
110 |     environment: str
111 |     timestamp: str
112 |     components: Dict[str, str]
    |                 ^^^^
    |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/api/ml_api_service_v2.py:131:22
    |
129 |         else "disabled",
130 |         "status": "running",
131 |         "timestamp": datetime.now().isoformat(),
    |                      ^^^^^^^^^^^^^^
132 |     }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

RUF010 [*] Use explicit conversion flag
   --> src/api/ml_api_service_v2.py:149:44
    |
147 |         components["database"] = "healthy" if db_ok else "unavailable"
148 |     except Exception as e:
149 |         components["database"] = f"error: {str(e)}"
    |                                            ^^^^^^
150 |
151 |     # Check Redis
    |
help: Replace with conversion flag

RUF010 [*] Use explicit conversion flag
   --> src/api/ml_api_service_v2.py:156:41
    |
154 |         components["redis"] = "healthy" if redis_ok else "unavailable"
155 |     except Exception as e:
156 |         components["redis"] = f"error: {str(e)}"
    |                                         ^^^^^^
157 |
158 |     # Check QWEN
    |
help: Replace with conversion flag

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/api/ml_api_service_v2.py:172:19
    |
170 |         version=config.application.version,
171 |         environment=config.application.environment,
172 |         timestamp=datetime.now().isoformat(),
    |                   ^^^^^^^^^^^^^^
173 |         components=components,
174 |     )
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

TRY301 Abstract `raise` to an inner function
   --> src/api/ml_api_service_v2.py:232:13
    |
231 |           if "error" in result:
232 | /             raise HTTPException(
233 | |                 status_code=500, detail=f"Analysis failed: {result['error']}"
234 | |             )
    | |_____________^
235 |
236 |           return {
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/api/ml_api_service_v2.py:241:26
    |
239 |             "cached": "timestamp" not in result
240 |             or time.time() - result.get("timestamp", 0) > 60,
241 |             "timestamp": datetime.now().isoformat(),
    |                          ^^^^^^^^^^^^^^
242 |         }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src/api/ml_api_service_v2.py:248:9
    |
246 |     except Exception as e:
247 |         logger.error(f"âŒ Analysis error: {e}")
248 |         raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

RUF010 [*] Use explicit conversion flag
   --> src/api/ml_api_service_v2.py:248:73
    |
246 |     except Exception as e:
247 |         logger.error(f"âŒ Analysis error: {e}")
248 |         raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")
    |                                                                         ^^^^^^
    |
help: Replace with conversion flag

RET504 Unnecessary assignment to `info` before `return` statement
   --> src/api/ml_api_service_v2.py:288:12
    |
286 |     }
287 |
288 |     return info
    |            ^^^^
    |
help: Remove unnecessary assignment

ARG001 Unused function argument: `exc`
   --> src/api/ml_api_service_v2.py:297:47
    |
296 | @app.exception_handler(404)
297 | async def not_found_handler(request: Request, exc):
    |                                               ^^^
298 |     """Custom 404 handler"""
299 |     return JSONResponse(
    |

ARG001 Unused function argument: `request`
   --> src/api/ml_api_service_v2.py:310:32
    |
309 | @app.exception_handler(500)
310 | async def server_error_handler(request: Request, exc):
    |                                ^^^^^^^
311 |     """Custom 500 handler"""
312 |     logger.error(f"Internal server error: {exc}")
    |

I001 [*] Import block is un-sorted or un-formatted
  --> src/cli/analyzer_cli.py:27:1
   |
25 |   """
26 |
27 | / import argparse
28 | | import asyncio
29 | | import json
30 | | import sys
31 | | import time
32 | | from pathlib import Path
33 | | from typing import Dict, Any, Optional
   | |______________________________________^
34 |
35 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/cli/analyzer_cli.py:33:1
   |
31 | import time
32 | from pathlib import Path
33 | from typing import Dict, Any, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
34 |
35 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |

F401 [*] `interfaces.analyzer_interface.AnalyzerType` imported but unused
  --> src/cli/analyzer_cli.py:39:43
   |
38 | from core.app import Application
39 | from interfaces.analyzer_interface import AnalyzerType
   |                                           ^^^^^^^^^^^^
   |
help: Remove unused import: `interfaces.analyzer_interface.AnalyzerType`

ARG002 Unused method argument: `output_format`
  --> src/cli/analyzer_cli.py:52:9
   |
50 |         text: str,
51 |         analyzer_type: str,
52 |         output_format: str = "json",
   |         ^^^^^^^^^^^^^
53 |         save_to_db: bool = False,
54 |     ) -> Dict[str, Any]:
   |

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/cli/analyzer_cli.py:54:10
   |
52 |         output_format: str = "json",
53 |         save_to_db: bool = False,
54 |     ) -> Dict[str, Any]:
   |          ^^^^
55 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð¼"""
   |
help: Replace with `dict`

EM102 Exception must not use an f-string literal, assign to variable first
  --> src/cli/analyzer_cli.py:62:17
   |
60 |             available = self.app.list_analyzers()
61 |             raise ValueError(
62 |                 f"Unknown analyzer type: {analyzer_type}. Available: {available}"
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
63 |             )
   |
help: Assign to variable; remove f-string literal

EM102 Exception must not use an f-string literal, assign to variable first
  --> src/cli/analyzer_cli.py:85:32
   |
83 |             }
84 |         else:
85 |             raise RuntimeError(f"Analyzer {analyzer_type} has no analyze method")
   |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
86 |
87 |         analysis_time = time.time() - start_time
   |
help: Assign to variable; remove f-string literal

UP045 [*] Use `X | None` for type annotations
   --> src/cli/analyzer_cli.py:108:22
    |
106 |         input_file: str,
107 |         analyzer_type: str,
108 |         output_file: Optional[str] = None,
    |                      ^^^^^^^^^^^^^
109 |         save_to_db: bool = False,
110 |     ) -> None:
    |
help: Convert to `X | None`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/cli/analyzer_cli.py:115:37
    |
113 |         input_path = Path(input_file)
114 |         if not input_path.exists():
115 |             raise FileNotFoundError(f"Input file not found: {input_file}")
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
116 |
117 |         # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    |
help: Assign to variable; remove f-string literal

PTH123 `open()` should be replaced by `Path.open()`
   --> src/cli/analyzer_cli.py:118:14
    |
117 |         # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
118 |         with open(input_path, "r", encoding="utf-8") as f:
    |              ^^^^
119 |             if input_path.suffix == ".json":
120 |                 data = json.load(f)
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> src/cli/analyzer_cli.py:118:31
    |
117 |         # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
118 |         with open(input_path, "r", encoding="utf-8") as f:
    |                               ^^^
119 |             if input_path.suffix == ".json":
120 |                 data = json.load(f)
    |
help: Remove mode argument

PTH123 `open()` should be replaced by `Path.open()`
   --> src/cli/analyzer_cli.py:153:18
    |
151 |             output_path.parent.mkdir(parents=True, exist_ok=True)
152 |
153 |             with open(output_path, "w", encoding="utf-8") as f:
    |                  ^^^^
154 |                 json.dump(results, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

UP045 [*] Use `X | None` for type annotations
   --> src/cli/analyzer_cli.py:163:20
    |
161 |         self,
162 |         text: str,
163 |         analyzers: Optional[list] = None,
    |                    ^^^^^^^^^^^^^^
164 |         output_file: Optional[str] = None,
165 |     ) -> Dict[str, Any]:
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/cli/analyzer_cli.py:164:22
    |
162 |         text: str,
163 |         analyzers: Optional[list] = None,
164 |         output_file: Optional[str] = None,
    |                      ^^^^^^^^^^^^^
165 |     ) -> Dict[str, Any]:
166 |         """Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð²"""
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/analyzer_cli.py:165:10
    |
163 |         analyzers: Optional[list] = None,
164 |         output_file: Optional[str] = None,
165 |     ) -> Dict[str, Any]:
    |          ^^^^
166 |         """Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð²"""
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/cli/analyzer_cli.py:209:18
    |
207 |             output_path.parent.mkdir(parents=True, exist_ok=True)
208 |
209 |             with open(output_path, "w", encoding="utf-8") as f:
    |                  ^^^^
210 |                 json.dump(comparison_results, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

ARG002 Unused method argument: `text`
   --> src/cli/analyzer_cli.py:217:15
    |
216 |     async def _save_to_database(
217 |         self, text: str, analysis_result: Dict[str, Any]
    |               ^^^^
218 |     ) -> None:
219 |         """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð² Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/analyzer_cli.py:217:43
    |
216 |     async def _save_to_database(
217 |         self, text: str, analysis_result: Dict[str, Any]
    |                                           ^^^^
218 |     ) -> None:
219 |         """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð² Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/analyzer_cli.py:228:35
    |
227 |     def _analyze_differences(
228 |         self, comparison_results: Dict[str, Any]
    |                                   ^^^^
229 |     ) -> Dict[str, Any]:
230 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð¸Ð¹ Ð¼ÐµÐ¶Ð´Ñƒ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/analyzer_cli.py:229:10
    |
227 |     def _analyze_differences(
228 |         self, comparison_results: Dict[str, Any]
229 |     ) -> Dict[str, Any]:
    |          ^^^^
230 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð¸Ð¹ Ð¼ÐµÐ¶Ð´Ñƒ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸"""
231 |         summary = {"performance": {}, "consensus": {}, "differences": []}
    |
help: Replace with `dict`

RET502 [*] Do not implicitly `return None` in function able to return non-`None` value
   --> src/cli/analyzer_cli.py:328:9
    |
326 |     if not args.command:
327 |         parser.print_help()
328 |         return
    |         ^^^^^^
329 |
330 |     # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ CLI Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ
    |
help: Add explicit `None` return value

PTH123 `open()` should be replaced by `Path.open()`
   --> src/cli/analyzer_cli.py:340:22
    |
339 |             if args.output:
340 |                 with open(args.output, "w", encoding="utf-8") as f:
    |                      ^^^^
341 |                     json.dump(result, f, indent=2, ensure_ascii=False)
342 |                 print(f"âœ… Result saved to: {args.output}")
    |
help: Replace with `Path.open()`

PLR1722 Use `sys.exit()` instead of `exit`
   --> src/cli/analyzer_cli.py:367:5
    |
366 | if __name__ == "__main__":
367 |     exit(main())
    |     ^^^^
    |
help: Replace `exit` with `sys.exit()`

I001 [*] Import block is un-sorted or un-formatted
  --> src/cli/batch_processor.py:26:1
   |
24 |   """
25 |
26 | / import asyncio
27 | | import json
28 | | import time
29 | | import sys
30 | | from pathlib import Path
31 | | from typing import Dict, List, Any, Optional
32 | | from concurrent.futures import ThreadPoolExecutor, as_completed
33 | | from dataclasses import dataclass, asdict
34 | | import logging
   | |______________^
35 |
36 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/cli/batch_processor.py:31:1
   |
29 | import sys
30 | from pathlib import Path
31 | from typing import Dict, List, Any, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
32 | from concurrent.futures import ThreadPoolExecutor, as_completed
33 | from dataclasses import dataclass, asdict
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/cli/batch_processor.py:31:1
   |
29 | import sys
30 | from pathlib import Path
31 | from typing import Dict, List, Any, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
32 | from concurrent.futures import ThreadPoolExecutor, as_completed
33 | from dataclasses import dataclass, asdict
   |

F401 [*] `concurrent.futures.ThreadPoolExecutor` imported but unused
  --> src/cli/batch_processor.py:32:32
   |
30 | from pathlib import Path
31 | from typing import Dict, List, Any, Optional
32 | from concurrent.futures import ThreadPoolExecutor, as_completed
   |                                ^^^^^^^^^^^^^^^^^^
33 | from dataclasses import dataclass, asdict
34 | import logging
   |
help: Remove unused import

F401 [*] `concurrent.futures.as_completed` imported but unused
  --> src/cli/batch_processor.py:32:52
   |
30 | from pathlib import Path
31 | from typing import Dict, List, Any, Optional
32 | from concurrent.futures import ThreadPoolExecutor, as_completed
   |                                                    ^^^^^^^^^^^^
33 | from dataclasses import dataclass, asdict
34 | import logging
   |
help: Remove unused import

F401 [*] `interfaces.analyzer_interface.AnalyzerType` imported but unused
  --> src/cli/batch_processor.py:40:43
   |
39 | from core.app import Application
40 | from interfaces.analyzer_interface import AnalyzerType
   |                                           ^^^^^^^^^^^^
   |
help: Remove unused import: `interfaces.analyzer_interface.AnalyzerType`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/cli/batch_processor.py:69:26
   |
67 |         return avg_time_per_item * remaining_items
68 |
69 |     def to_dict(self) -> Dict[str, Any]:
   |                          ^^^^
70 |         return {
71 |             **asdict(self),
   |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
  --> src/cli/batch_processor.py:89:16
   |
87 |     async def process_batch(
88 |         self,
89 |         texts: List[str],
   |                ^^^^
90 |         analyzer_type: str,
91 |         output_file: Optional[str] = None,
   |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
  --> src/cli/batch_processor.py:91:22
   |
89 |         texts: List[str],
90 |         analyzer_type: str,
91 |         output_file: Optional[str] = None,
   |                      ^^^^^^^^^^^^^
92 |         checkpoint_file: Optional[str] = None,
93 |         resume_from_checkpoint: bool = False,
   |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
  --> src/cli/batch_processor.py:92:26
   |
90 |         analyzer_type: str,
91 |         output_file: Optional[str] = None,
92 |         checkpoint_file: Optional[str] = None,
   |                          ^^^^^^^^^^^^^
93 |         resume_from_checkpoint: bool = False,
94 |     ) -> List[Dict[str, Any]]:
   |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
  --> src/cli/batch_processor.py:94:10
   |
92 |         checkpoint_file: Optional[str] = None,
93 |         resume_from_checkpoint: bool = False,
94 |     ) -> List[Dict[str, Any]]:
   |          ^^^^
95 |         """
96 |         ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð°ÐºÐµÑ‚Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð² Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹ checkpoint'Ð¾Ð²
   |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/cli/batch_processor.py:94:15
   |
92 |         checkpoint_file: Optional[str] = None,
93 |         resume_from_checkpoint: bool = False,
94 |     ) -> List[Dict[str, Any]]:
   |               ^^^^
95 |         """
96 |         ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð°ÐºÐµÑ‚Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð² Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹ checkpoint'Ð¾Ð²
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/cli/batch_processor.py:116:18
    |
114 |         ):
115 |             self.logger.info(f"Resuming from checkpoint: {checkpoint_file}")
116 |             with open(checkpoint_file, "r", encoding="utf-8") as f:
    |                  ^^^^
117 |                 checkpoint_data = json.load(f)
118 |                 existing_results = checkpoint_data.get("results", [])
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> src/cli/batch_processor.py:116:40
    |
114 |         ):
115 |             self.logger.info(f"Resuming from checkpoint: {checkpoint_file}")
116 |             with open(checkpoint_file, "r", encoding="utf-8") as f:
    |                                        ^^^
117 |                 checkpoint_data = json.load(f)
118 |                 existing_results = checkpoint_data.get("results", [])
    |
help: Remove mode argument

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/cli/batch_processor.py:136:17
    |
134 |             available = self.app.list_analyzers()
135 |             raise ValueError(
136 |                 f"Unknown analyzer type: {analyzer_type}. Available: {available}"
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
137 |             )
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/cli/batch_processor.py:191:22
    |
190 |     async def _process_batch_async(
191 |         self, texts: List[str], analyzer, start_index: int
    |                      ^^^^
192 |     ) -> List[Dict[str, Any]]:
193 |         """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð°ÐºÐµÑ‚Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²"""
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/cli/batch_processor.py:192:10
    |
190 |     async def _process_batch_async(
191 |         self, texts: List[str], analyzer, start_index: int
192 |     ) -> List[Dict[str, Any]]:
    |          ^^^^
193 |         """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð°ÐºÐµÑ‚Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²"""
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/batch_processor.py:192:15
    |
190 |     async def _process_batch_async(
191 |         self, texts: List[str], analyzer, start_index: int
192 |     ) -> List[Dict[str, Any]]:
    |               ^^^^
193 |         """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð°ÐºÐµÑ‚Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/batch_processor.py:223:10
    |
221 |     async def _analyze_single_text(
222 |         self, text: str, analyzer, index: int
223 |     ) -> Dict[str, Any]:
    |          ^^^^
224 |         """ÐÐ½Ð°Ð»Ð¸Ð· Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°"""
225 |         try:
    |
help: Replace with `dict`

TRY301 Abstract `raise` to an inner function
   --> src/cli/batch_processor.py:247:17
    |
245 |                 }
246 |             else:
247 |                 raise RuntimeError(f"Analyzer has no analyze method")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
248 |
249 |             analysis_time = time.time() - start_time
    |

F541 [*] f-string without any placeholders
   --> src/cli/batch_processor.py:247:36
    |
245 |                 }
246 |             else:
247 |                 raise RuntimeError(f"Analyzer has no analyze method")
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
248 |
249 |             analysis_time = time.time() - start_time
    |
help: Remove extraneous `f` prefix

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/cli/batch_processor.py:247:36
    |
245 |                 }
246 |             else:
247 |                 raise RuntimeError(f"Analyzer has no analyze method")
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
248 |
249 |             analysis_time = time.time() - start_time
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/cli/batch_processor.py:268:18
    |
266 |         self,
267 |         checkpoint_file: str,
268 |         results: List[Dict[str, Any]],
    |                  ^^^^
269 |         progress: BatchProgress,
270 |     ) -> None:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/batch_processor.py:268:23
    |
266 |         self,
267 |         checkpoint_file: str,
268 |         results: List[Dict[str, Any]],
    |                       ^^^^
269 |         progress: BatchProgress,
270 |     ) -> None:
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/cli/batch_processor.py:282:18
    |
280 |             checkpoint_path.parent.mkdir(parents=True, exist_ok=True)
281 |
282 |             with open(checkpoint_path, "w", encoding="utf-8") as f:
    |                  ^^^^
283 |                 json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/cli/batch_processor.py:289:42
    |
288 |     async def _save_results(
289 |         self, output_file: str, results: List[Dict[str, Any]], progress: BatchProgress
    |                                          ^^^^
290 |     ) -> None:
291 |         """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"""
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/batch_processor.py:289:47
    |
288 |     async def _save_results(
289 |         self, output_file: str, results: List[Dict[str, Any]], progress: BatchProgress
    |                                               ^^^^
290 |     ) -> None:
291 |         """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"""
    |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/cli/batch_processor.py:309:14
    |
307 |         output_path.parent.mkdir(parents=True, exist_ok=True)
308 |
309 |         with open(output_path, "w", encoding="utf-8") as f:
    |              ^^^^
310 |             json.dump(output_data, f, indent=2, ensure_ascii=False)
    |
help: Replace with `Path.open()`

F541 [*] f-string without any placeholders
   --> src/cli/batch_processor.py:318:19
    |
317 |         if final:
318 |             print(f"\nðŸŽ‰ Batch processing completed!")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
319 |         else:
320 |             print(
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/cli/performance_monitor.py:46:1
   |
44 |   """
45 |
46 | / import asyncio
47 | | import json
48 | | import time
49 | | import sys
50 | | import psutil
51 | | import statistics
52 | | import subprocess
53 | | import tempfile
54 | | import argparse
55 | | import functools
56 | | from pathlib import Path
57 | | from typing import Dict, List, Any, Optional
58 | | from dataclasses import dataclass, asdict
59 | | import logging
60 | | import cProfile
61 | | import pstats
62 | | from io import StringIO
63 | | from datetime import datetime
   | |_____________________________^
64 |
65 |   # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð¸Ð· .env
   |
help: Organize imports

F401 [*] `functools` imported but unused
  --> src/cli/performance_monitor.py:55:8
   |
53 | import tempfile
54 | import argparse
55 | import functools
   |        ^^^^^^^^^
56 | from pathlib import Path
57 | from typing import Dict, List, Any, Optional
   |
help: Remove unused import: `functools`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/cli/performance_monitor.py:57:1
   |
55 | import functools
56 | from pathlib import Path
57 | from typing import Dict, List, Any, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
58 | from dataclasses import dataclass, asdict
59 | import logging
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/cli/performance_monitor.py:57:1
   |
55 | import functools
56 | from pathlib import Path
57 | from typing import Dict, List, Any, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
58 | from dataclasses import dataclass, asdict
59 | import logging
   |

F401 [*] `interfaces.analyzer_interface.AnalyzerType` imported but unused
  --> src/cli/performance_monitor.py:78:43
   |
77 | from core.app import Application
78 | from interfaces.analyzer_interface import AnalyzerType
   |                                           ^^^^^^^^^^^^
79 |
80 | # ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ñ… Ñ„Ð¸Ñ‡
   |
help: Remove unused import: `interfaces.analyzer_interface.AnalyzerType`

I001 [*] Import block is un-sorted or un-formatted
  --> src/cli/performance_monitor.py:82:5
   |
80 | # ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ñ… Ñ„Ð¸Ñ‡
81 | try:
82 |     from prometheus_client import Counter, Histogram, Gauge, start_http_server, REGISTRY
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
83 |
84 |     PROMETHEUS_AVAILABLE = True
   |
help: Organize imports

F401 `prometheus_client.REGISTRY` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> src/cli/performance_monitor.py:82:81
   |
80 | # ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ñ… Ñ„Ð¸Ñ‡
81 | try:
82 |     from prometheus_client import Counter, Histogram, Gauge, start_http_server, REGISTRY
   |                                                                                 ^^^^^^^^
83 |
84 |     PROMETHEUS_AVAILABLE = True
   |
help: Remove unused import: `prometheus_client.REGISTRY`

F401 `memory_profiler.profile` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> src/cli/performance_monitor.py:89:44
   |
88 | try:
89 |     from memory_profiler import profile as memory_profile
   |                                            ^^^^^^^^^^^^^^
90 |
91 |     MEMORY_PROFILER_AVAILABLE = True
   |
help: Remove unused import: `memory_profiler.profile`

F401 `pytest` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> src/cli/performance_monitor.py:96:12
   |
95 | try:
96 |     import pytest
   |            ^^^^^^
97 |
98 |     PYTEST_AVAILABLE = True
   |
help: Remove unused import: `pytest`

I001 [*] Import block is un-sorted or un-formatted
   --> src/cli/performance_monitor.py:104:5
    |
102 |   # Rich Ð´Ð»Ñ ÐºÑ€Ð°ÑÐ¸Ð²Ð¾Ð³Ð¾ Ð²Ñ‹Ð²Ð¾Ð´Ð°
103 |   try:
104 | /     from rich.console import Console
105 | |     from rich.table import Table
106 | |     from rich.progress import Progress, TaskID, track
107 | |     from rich.panel import Panel
108 | |     from rich.text import Text
109 | |     from rich import box
110 | |     from rich.layout import Layout
111 | |     from rich.live import Live
    | |______________________________^
112 |
113 |       RICH_AVAILABLE = True
    |
help: Organize imports

F401 `rich.progress.Progress` imported but unused; consider using `importlib.util.find_spec` to test for availability
   --> src/cli/performance_monitor.py:106:31
    |
104 |     from rich.console import Console
105 |     from rich.table import Table
106 |     from rich.progress import Progress, TaskID, track
    |                               ^^^^^^^^
107 |     from rich.panel import Panel
108 |     from rich.text import Text
    |
help: Remove unused import

F401 `rich.progress.TaskID` imported but unused; consider using `importlib.util.find_spec` to test for availability
   --> src/cli/performance_monitor.py:106:41
    |
104 |     from rich.console import Console
105 |     from rich.table import Table
106 |     from rich.progress import Progress, TaskID, track
    |                                         ^^^^^^
107 |     from rich.panel import Panel
108 |     from rich.text import Text
    |
help: Remove unused import

F401 `rich.progress.track` imported but unused; consider using `importlib.util.find_spec` to test for availability
   --> src/cli/performance_monitor.py:106:49
    |
104 |     from rich.console import Console
105 |     from rich.table import Table
106 |     from rich.progress import Progress, TaskID, track
    |                                                 ^^^^^
107 |     from rich.panel import Panel
108 |     from rich.text import Text
    |
help: Remove unused import

F401 `rich.layout.Layout` imported but unused; consider using `importlib.util.find_spec` to test for availability
   --> src/cli/performance_monitor.py:110:29
    |
108 |     from rich.text import Text
109 |     from rich import box
110 |     from rich.layout import Layout
    |                             ^^^^^^
111 |     from rich.live import Live
    |
help: Remove unused import: `rich.layout.Layout`

F401 `rich.live.Live` imported but unused; consider using `importlib.util.find_spec` to test for availability
   --> src/cli/performance_monitor.py:111:27
    |
109 |     from rich import box
110 |     from rich.layout import Layout
111 |     from rich.live import Live
    |                           ^^^^
112 |
113 |     RICH_AVAILABLE = True
    |
help: Remove unused import: `rich.live.Live`

F401 `tabulate.tabulate` imported but unused; consider using `importlib.util.find_spec` to test for availability
   --> src/cli/performance_monitor.py:121:26
    |
119 | # Tabulate Ð´Ð»Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†
120 | try:
121 |     from tabulate import tabulate
    |                          ^^^^^^^^
122 |
123 |     TABULATE_AVAILABLE = True
    |
help: Remove unused import: `tabulate.tabulate`

F401 `click` imported but unused; consider using `importlib.util.find_spec` to test for availability
   --> src/cli/performance_monitor.py:129:12
    |
127 | # Click Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ð³Ð¾ CLI
128 | try:
129 |     import click
    |            ^^^^^
130 |
131 |     CLICK_AVAILABLE = True
    |
help: Remove unused import: `click`

UP045 [*] Use `X | None` for type annotations
   --> src/cli/performance_monitor.py:168:19
    |
166 |     # ÐŸÑ€Ð¾Ñ„Ð¸Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
167 |     hottest_function: str = ""
168 |     profile_data: Optional[Dict] = None
    |                   ^^^^^^^^^^^^^^
169 |
170 |     def to_dict(self) -> Dict[str, Any]:
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/performance_monitor.py:168:28
    |
166 |     # ÐŸÑ€Ð¾Ñ„Ð¸Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
167 |     hottest_function: str = ""
168 |     profile_data: Optional[Dict] = None
    |                            ^^^^
169 |
170 |     def to_dict(self) -> Dict[str, Any]:
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/performance_monitor.py:170:26
    |
168 |     profile_data: Optional[Dict] = None
169 |
170 |     def to_dict(self) -> Dict[str, Any]:
    |                          ^^^^
171 |         return asdict(self)
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/cli/performance_monitor.py:182:47
    |
181 |     def generate_benchmark_test(
182 |         self, analyzer_type: str, test_texts: List[str], output_file: str
    |                                               ^^^^
183 |     ):
184 |         """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ pytest benchmark Ñ‚ÐµÑÑ‚Ð¾Ð²"""
    |
help: Replace with `list`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/cli/performance_monitor.py:196:18
    |
194 | ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€: {analyzer_type}
195 | Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ñ‚ÐµÐºÑÑ‚Ñ‹: {len(test_texts)}
196 | Ð”Ð°Ñ‚Ð° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸: {datetime.now().isoformat()}
    |                  ^^^^^^^^^^^^^^
197 | """
198 | import pytest
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:210:1
    |
208 | class TestAnalyzerPerformance:
209 |     """Benchmark Ñ‚ÐµÑÑ‚Ñ‹ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð° {analyzer_type}"""
210 |     
    | ^^^^
211 |     @pytest.fixture(scope="class")
212 |     def analyzer(self):
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:216:1
    |
214 |         app = Application()
215 |         return app.get_analyzer("{analyzer_type}")
216 |     
    | ^^^^
217 |     @pytest.fixture(scope="class") 
218 |     def test_texts(self):
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:221:1
    |
219 |         """Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ñ‚ÐµÐºÑÑ‚Ñ‹"""
220 |         return {test_texts[:10]}  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ñ… Ñ‚ÐµÑÑ‚Ð¾Ð²
221 |     
    | ^^^^
222 |     def test_single_analysis_benchmark(self, benchmark, analyzer, test_texts):
223 |         """Benchmark Ð¾Ð´Ð¸Ð½Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:227:1
    |
225 |             text = test_texts[0]
226 |             return asyncio.run(analyzer.analyze_song("Test Artist", "Test Song", text))
227 |         
    | ^^^^^^^^
228 |         result = benchmark(run_analysis)
229 |         assert result is not None
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:231:1
    |
229 |         assert result is not None
230 |         assert hasattr(result, 'confidence')
231 |     
    | ^^^^
232 |     def test_batch_analysis_benchmark(self, benchmark, analyzer, test_texts):
233 |         """Benchmark Ð±Ð°Ñ‚Ñ‡ÐµÐ²Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:240:1
    |
238 |                 results.append(result)
239 |             return results
240 |         
    | ^^^^^^^^
241 |         def run_batch():
242 |             return asyncio.run(batch_analysis())
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:243:1
    |
241 |         def run_batch():
242 |             return asyncio.run(batch_analysis())
243 |         
    | ^^^^^^^^
244 |         results = benchmark(run_batch)
245 |         assert len(results) == len(test_texts)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:247:1
    |
245 |         assert len(results) == len(test_texts)
246 |         assert all(hasattr(r, 'confidence') for r in results)
247 |     
    | ^^^^
248 |     @pytest.mark.parametrize("text_length", [50, 200, 500, 1000])
249 |     def test_text_length_scaling_benchmark(self, benchmark, analyzer, text_length):
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:252:1
    |
250 |         """Benchmark Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð¾ Ð´Ð»Ð¸Ð½Ðµ Ñ‚ÐµÐºÑÑ‚Ð°"""
251 |         test_text = "word " * (text_length // 5)  # ÐŸÑ€Ð¸Ð¼ÐµÑ€Ð½Ð¾ text_length ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
252 |         
    | ^^^^^^^^
253 |         def run_analysis():
254 |             return asyncio.run(analyzer.analyze_song("Test Artist", "Test Song", test_text))
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:255:1
    |
253 |         def run_analysis():
254 |             return asyncio.run(analyzer.analyze_song("Test Artist", "Test Song", test_text))
255 |         
    | ^^^^^^^^
256 |         result = benchmark(run_analysis)
257 |         assert result is not None
    |
help: Remove whitespace from blank line

PTH123 `open()` should be replaced by `Path.open()`
   --> src/cli/performance_monitor.py:268:18
    |
267 |         try:
268 |             with open(output_file, "w", encoding="utf-8") as f:
    |                  ^^^^
269 |                 f.write(test_content)
    |
help: Replace with `Path.open()`

UP045 [*] Use `X | None` for type annotations
   --> src/cli/performance_monitor.py:282:44
    |
281 |     def run_benchmark_tests(
282 |         self, test_file: str, json_output: Optional[str] = None
    |                                            ^^^^^^^^^^^^^
283 |     ) -> Optional[Dict]:
284 |         """Ð—Ð°Ð¿ÑƒÑÐº pytest benchmark Ñ‚ÐµÑÑ‚Ð¾Ð²"""
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/cli/performance_monitor.py:283:10
    |
281 |     def run_benchmark_tests(
282 |         self, test_file: str, json_output: Optional[str] = None
283 |     ) -> Optional[Dict]:
    |          ^^^^^^^^^^^^^^
284 |         """Ð—Ð°Ð¿ÑƒÑÐº pytest benchmark Ñ‚ÐµÑÑ‚Ð¾Ð²"""
285 |         if not self.available:
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/performance_monitor.py:283:19
    |
281 |     def run_benchmark_tests(
282 |         self, test_file: str, json_output: Optional[str] = None
283 |     ) -> Optional[Dict]:
    |                   ^^^^
284 |         """Ð—Ð°Ð¿ÑƒÑÐº pytest benchmark Ñ‚ÐµÑÑ‚Ð¾Ð²"""
285 |         if not self.available:
    |
help: Replace with `dict`

PLW1510 [*] `subprocess.run` without explicit `check` argument
   --> src/cli/performance_monitor.py:308:22
    |
306 |             )
307 |
308 |             result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
    |                      ^^^^^^^^^^^^^^
309 |
310 |             if result.returncode == 0:
    |
help: Add explicit `check=False`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/cli/performance_monitor.py:316:30
    |
314 |                 if json_output:
315 |                     try:
316 |                         with open(json_output, "r", encoding="utf-8") as f:
    |                              ^^^^
317 |                             return json.load(f)
318 |                     except Exception as e:
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> src/cli/performance_monitor.py:316:48
    |
314 |                 if json_output:
315 |                     try:
316 |                         with open(json_output, "r", encoding="utf-8") as f:
    |                                                ^^^
317 |                             return json.load(f)
318 |                     except Exception as e:
    |
help: Remove mode argument

RET505 [*] Unnecessary `else` after `return` statement
   --> src/cli/performance_monitor.py:324:13
    |
323 |                 return {"status": "success", "output": result.stdout}
324 |             else:
    |             ^^^^
325 |                 self.monitor.display.print_error(
326 |                     f"Benchmark Ñ‚ÐµÑÑ‚Ñ‹ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð»Ð¸ÑÑŒ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹: {result.stderr}"
    |
help: Remove unnecessary `else`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/performance_monitor.py:338:25
    |
337 |     def compare_benchmark_results(
338 |         self, results1: Dict, results2: Dict, analyzer1: str, analyzer2: str
    |                         ^^^^
339 |     ):
340 |         """Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² benchmark Ñ‚ÐµÑÑ‚Ð¾Ð²"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/performance_monitor.py:338:41
    |
337 |     def compare_benchmark_results(
338 |         self, results1: Dict, results2: Dict, analyzer1: str, analyzer2: str
    |                                         ^^^^
339 |     ):
340 |         """Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² benchmark Ñ‚ÐµÑÑ‚Ð¾Ð²"""
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/cli/performance_monitor.py:400:50
    |
398 |         self.use_rich = RICH_AVAILABLE and console is not None
399 |
400 |     def print_header(self, title: str, subtitle: Optional[str] = None):
    |                                                  ^^^^^^^^^^^^^
401 |         """ÐšÑ€Ð°ÑÐ¸Ð²Ñ‹Ð¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº"""
402 |         if self.use_rich and self.console:
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/performance_monitor.py:495:48
    |
493 |                 print(f"ðŸ”¥ Hottest function: {metrics.hottest_function}")
494 |
495 |     def print_load_test_results(self, results: Dict[str, Any]):
    |                                                ^^^^
496 |         """Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð½Ð°Ð³Ñ€ÑƒÐ·Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ"""
497 |         if self.use_rich and self.console:
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/performance_monitor.py:531:51
    |
529 |             print(f"ðŸ’¾ Memory usage: {results['avg_memory_mb']:.1f} MB")
530 |
531 |     def print_hyperfine_comparison(self, results: Dict):
    |                                                   ^^^^
532 |         """Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Hyperfine"""
533 |         if self.use_rich and self.console and results:
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/cli/performance_monitor.py:560:38
    |
559 |     def print_progress_info(
560 |         self, message: str, current: Optional[int] = None, total: Optional[int] = None
    |                                      ^^^^^^^^^^^^^
561 |     ):
562 |         """Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐµ"""
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/cli/performance_monitor.py:560:67
    |
559 |     def print_progress_info(
560 |         self, message: str, current: Optional[int] = None, total: Optional[int] = None
    |                                                                   ^^^^^^^^^^^^^
561 |     ):
562 |         """Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐµ"""
    |
help: Convert to `X | None`

PLR5501 [*] Use `elif` instead of `else` then `if`, to reduce indentation
   --> src/cli/performance_monitor.py:570:9
    |
569 |               self.console.print(f"ðŸ”„ {progress_text}", style="bright_blue")
570 | /         else:
571 | |             if current is not None and total is not None:
    | |____________^
572 |                   print(f"ðŸ”„ {message} [{current}/{total}]")
573 |               else:
    |
help: Convert to `elif`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/performance_monitor.py:597:61
    |
595 |             print(f"âš ï¸  {message}")
596 |
597 |     def print_analyzer_comparison(self, comparison_results: Dict[str, Dict]):
    |                                                             ^^^^
598 |         """Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð²"""
599 |         if not comparison_results or len(comparison_results) < 2:
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/cli/performance_monitor.py:597:71
    |
595 |             print(f"âš ï¸  {message}")
596 |
597 |     def print_analyzer_comparison(self, comparison_results: Dict[str, Dict]):
    |                                                                       ^^^^
598 |         """Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð²"""
599 |         if not comparison_results or len(comparison_results) < 2:
    |
help: Replace with `dict`

PLR0912 Too many branches (20 > 12)
   --> src/cli/performance_monitor.py:751:15
    |
749 |         self.is_monitoring = False
750 |
751 |     async def benchmark_with_profiling(
    |               ^^^^^^^^^^^^^^^^^^^^^^^^
752 |         self,
753 |         analyzer_type: str,
    |

PLR0915 Too many statements (94 > 50)
   --> src/cli/performance_monitor.py:751:15
    |
749 |         self.is_monitoring = False
750 |
751 |     async def benchmark_with_profiling(
    |               ^^^^^^^^^^^^^^^^^^^^^^^^
752 |         self,
753 |         analyzer_type: str,
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/cli/performance_monitor.py:754:21
    |
752 |         self,
753 |         analyzer_type: str,
754 |         test_texts: List[str],
    |                     ^^^^
755 |         enable_profiling: bool = True,
756 |         enable_memory_profiling: bool = True,
    |
help: Replace with `list`

ARG002 Unused method argument: `enable_memory_profiling`
   --> src/cli/performance_monitor.py:756:9
    |
754 |         test_texts: List[str],
755 |         enable_profiling: bool = True,
756 |         enable_memory_profiling: bool = True,
    |         ^^^^^^^^^^^^^^^^^^^^^^^
757 |         timeout_per_text: float = 30.0,  # Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð½Ð° Ð¾Ð´Ð¸Ð½ Ñ‚ÐµÐºÑÑ‚
758 |     ) -> EnhancedMetrics:
    |

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/cli/performance_monitor.py:765:17
    |
763 |             available = self.app.list_analyzers()
764 |             raise ValueError(
765 |                 f"Unknown analyzer type: {analyzer_type}. Available: {available}"
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
766 |             )
    |
help: Assign to variable; remove f-string literal

I001 [*] Import block is un-sorted or un-formatted
   --> src/cli/performance_monitor.py:796:17
    |
794 |               try:
795 |                   # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ Ð¼ÐµÑ‚Ð¾Ð´ async
796 | /                 import inspect
797 | |                 import functools
    | |________________________________^
798 |
799 |                   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð´Ð»Ñ Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð²
    |
help: Organize imports

F841 Local variable `result` is assigned to but never used
   --> src/cli/performance_monitor.py:812:21
    |
810 |                         analyzer.analyze_song, "Unknown", f"Test_{i}", text
811 |                     )
812 |                     result = await asyncio.wait_for(
    |                     ^^^^^^
813 |                         loop.run_in_executor(None, sync_call), timeout=timeout_per_text
814 |                     )
    |
help: Remove assignment to unused variable `result`

F841 Local variable `success` is assigned to but never used
   --> src/cli/performance_monitor.py:818:17
    |
816 |                 text_time = time.time() - text_start_time
817 |                 execution_times.append(text_time)
818 |                 success = True
    |                 ^^^^^^^
819 |
820 |                 # Prometheus Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
    |
help: Remove assignment to unused variable `success`

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> src/cli/performance_monitor.py:863:9
    |
861 |           # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³
862 |           self.is_monitoring = False
863 | /         try:
864 | |             await monitoring_task
865 | |         except asyncio.CancelledError:
866 | |             pass
    | |________________^
867 |
868 |           # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/cli/performance_monitor.py:966:47
    |
965 |     async def py_spy_analysis(
966 |         self, analyzer_type: str, test_texts: List[str], duration: int = 30
    |                                               ^^^^
967 |     ) -> Optional[str]:
968 |         """ÐŸÑ€Ð¾Ñ„Ð¸Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ py-spy"""
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/cli/performance_monitor.py:967:10
    |
965 |     async def py_spy_analysis(
966 |         self, analyzer_type: str, test_texts: List[str], duration: int = 30
967 |     ) -> Optional[str]:
    |          ^^^^^^^^^^^^^
968 |         """ÐŸÑ€Ð¾Ñ„Ð¸Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ py-spy"""
    |
help: Convert to `X | None`

W293 Blank line contains whitespace
   --> src/cli/performance_monitor.py:985:1
    |
983 |     analyzer = app.get_analyzer("{analyzer_type}")
984 |     texts = {test_texts[:10]}  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð»Ñ py-spy
985 |     
    | ^^^^
986 |     for i in range(100):  # ÐœÐ½Ð¾Ð³Ð¾ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¹ Ð´Ð»Ñ py-spy
987 |         for j, text in enumerate(texts):
    |
help: Remove whitespace from blank line

PLW1510 [*] `subprocess.run` without explicit `check` argument
    --> src/cli/performance_monitor.py:1023:26
     |
1022 |             try:
1023 |                 result = subprocess.run(
     |                          ^^^^^^^^^^^^^^
1024 |                     cmd, capture_output=True, text=True, timeout=duration + 10
1025 |                 )
     |
help: Add explicit `check=False`

RET505 [*] Unnecessary `else` after `return` statement
    --> src/cli/performance_monitor.py:1029:17
     |
1027 |                     self.logger.info(f"ðŸ“Š py-spy profile saved to: {output_file}")
1028 |                     return output_file
1029 |                 else:
     |                 ^^^^
1030 |                     self.logger.warning(f"py-spy failed: {result.stderr}")
1031 |                     return None
     |
help: Remove unnecessary `else`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/cli/performance_monitor.py:1048:31
     |
1047 |     def hyperfine_comparison(
1048 |         self, analyzer_types: List[str], test_text: str = "Test text for hyperfine"
     |                               ^^^^
1049 |     ) -> Optional[Dict]:
1050 |         """Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ hyperfine"""
     |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
    --> src/cli/performance_monitor.py:1049:10
     |
1047 |     def hyperfine_comparison(
1048 |         self, analyzer_types: List[str], test_text: str = "Test text for hyperfine"
1049 |     ) -> Optional[Dict]:
     |          ^^^^^^^^^^^^^^
1050 |         """Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ hyperfine"""
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/cli/performance_monitor.py:1049:19
     |
1047 |     def hyperfine_comparison(
1048 |         self, analyzer_types: List[str], test_text: str = "Test text for hyperfine"
1049 |     ) -> Optional[Dict]:
     |                   ^^^^
1050 |         """Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ hyperfine"""
     |
help: Replace with `dict`

W293 Blank line contains whitespace
    --> src/cli/performance_monitor.py:1068:1
     |
1066 |     analyzer = app.get_analyzer("{analyzer_type}")
1067 |     text = "{test_text}"
1068 |     
     | ^^^^
1069 |     try:
1070 |         import inspect
     |
help: Remove whitespace from blank line

RUF005 Consider iterable unpacking instead of concatenation
    --> src/cli/performance_monitor.py:1089:19
     |
1087 |         try:
1088 |             # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ hyperfine
1089 |             cmd = ["hyperfine", "--export-json", "hyperfine_results.json"] + commands
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1090 |
1091 |             self.logger.info("ðŸƒ Running hyperfine comparison...")
     |
help: Replace with iterable unpacking

PLW1510 [*] `subprocess.run` without explicit `check` argument
    --> src/cli/performance_monitor.py:1094:26
     |
1093 |             try:
1094 |                 result = subprocess.run(
     |                          ^^^^^^^^^^^^^^
1095 |                     cmd, capture_output=True, text=True, timeout=120
1096 |                 )
     |
help: Add explicit `check=False`

PTH123 `open()` should be replaced by `Path.open()`
    --> src/cli/performance_monitor.py:1100:30
     |
1098 |                     # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
1099 |                     try:
1100 |                         with open("hyperfine_results.json", "r") as f:
     |                              ^^^^
1101 |                             hyperfine_data = json.load(f)
     |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
    --> src/cli/performance_monitor.py:1100:61
     |
1098 |                     # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
1099 |                     try:
1100 |                         with open("hyperfine_results.json", "r") as f:
     |                                                             ^^^
1101 |                             hyperfine_data = json.load(f)
     |
help: Remove mode argument

TRY300 Consider moving this statement to an `else` block
    --> src/cli/performance_monitor.py:1104:25
     |
1103 |                         self.logger.info("âš¡ Hyperfine comparison completed")
1104 |                         return hyperfine_data
     |                         ^^^^^^^^^^^^^^^^^^^^^
1105 |                     except FileNotFoundError:
1106 |                         self.logger.warning("Hyperfine results file not found")
     |

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/cli/performance_monitor.py:1130:21
     |
1128 |         self,
1129 |         analyzer_type: str,
1130 |         test_texts: List[str],
     |                     ^^^^
1131 |         concurrent_users: int = 10,
1132 |         duration_seconds: int = 60,
     |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/cli/performance_monitor.py:1133:10
     |
1131 |         concurrent_users: int = 10,
1132 |         duration_seconds: int = 60,
1133 |     ) -> Dict[str, Any]:
     |          ^^^^
1134 |         """ÐÐ°Ð³Ñ€ÑƒÐ·Ð¾Ñ‡Ð½Ð¾Ðµ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ"""
     |
help: Replace with `dict`

EM102 Exception must not use an f-string literal, assign to variable first
    --> src/cli/performance_monitor.py:1138:30
     |
1136 |         analyzer = self.app.get_analyzer(analyzer_type)
1137 |         if not analyzer:
1138 |             raise ValueError(f"Unknown analyzer type: {analyzer_type}")
     |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1139 |
1140 |         self.logger.info(
     |
help: Assign to variable; remove f-string literal

F841 Local variable `result` is assigned to but never used
    --> src/cli/performance_monitor.py:1166:25
     |
1164 |                         )
1165 |                     else:
1166 |                         result = analyzer.analyze_song(
     |                         ^^^^^^
1167 |                             "Unknown", f"Worker_{worker_id}", text
1168 |                         )
     |
help: Remove assignment to unused variable `result`

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
    --> src/cli/performance_monitor.py:1190:9
     |
1189 |           self.is_monitoring = False
1190 | /         try:
1191 | |             await monitoring_task
1192 | |         except asyncio.CancelledError:
1193 | |             pass
     | |________________^
1194 |
1195 |           total_time = time.time() - start_time
     |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/cli/performance_monitor.py:1245:13
     |
1243 |                   await asyncio.sleep(self.monitoring_interval)
1244 |
1245 | /             except asyncio.CancelledError:
1246 | |                 break
     | |_____________________^
1247 |               except Exception:
1248 |                   pass
     |

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/cli/performance_monitor.py:1253:45
     |
1253 | def generate_test_texts(count: int = 50) -> List[str]:
     |                                             ^^^^
1254 |     """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ñ‚ÐµÐºÑÑ‚Ð¾Ð²"""
1255 |     base_texts = [
     |
help: Replace with `list`

PLR0912 Too many branches (20 > 12)
    --> src/cli/performance_monitor.py:1278:11
     |
1278 | async def main():
     |           ^^^^
1279 |     """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ñ CLI Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸"""
1280 |     parser = argparse.ArgumentParser(description="ðŸš€ Enhanced Performance Monitor")
     |

PLR0915 Too many statements (91 > 50)
    --> src/cli/performance_monitor.py:1278:11
     |
1278 | async def main():
     |           ^^^^
1279 |     """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ñ CLI Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸"""
1280 |     parser = argparse.ArgumentParser(description="ðŸš€ Enhanced Performance Monitor")
     |

PTH123 `open()` should be replaced by `Path.open()`
    --> src/cli/performance_monitor.py:1345:22
     |
1343 |             # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
1344 |             if args.output:
1345 |                 with open(args.output, "w", encoding="utf-8") as f:
     |                      ^^^^
1346 |                     json.dump(metrics.to_dict(), f, indent=2, ensure_ascii=False)
1347 |                 monitor.display.print_success(f"Results saved to: {args.output}")
     |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
    --> src/cli/performance_monitor.py:1382:22
     |
1380 |             # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
1381 |             if args.output:
1382 |                 with open(args.output, "w", encoding="utf-8") as f:
     |                      ^^^^
1383 |                     json.dump(results, f, indent=2, ensure_ascii=False)
1384 |                 monitor.display.print_success(
     |
help: Replace with `Path.open()`

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/cli/performance_monitor.py:1418:17
     |
1416 |                       comparison_results[analyzer_type] = metrics.to_dict()
1417 |
1418 | /                 except Exception as e:
1419 | |                     monitor.display.print_warning(
1420 | |                         f"Failed to benchmark {analyzer_type}: {e}"
1421 | |                     )
1422 | |                     comparison_results[analyzer_type] = {"error": str(e)}
     | |_________________________________________________________________________^
1423 |
1424 |               # ÐšÑ€Ð°ÑÐ¸Ð²Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ
     |

PTH123 `open()` should be replaced by `Path.open()`
    --> src/cli/performance_monitor.py:1467:22
     |
1465 |                     "hyperfine_results": hyperfine_results,
1466 |                 }
1467 |                 with open(args.output, "w", encoding="utf-8") as f:
     |                      ^^^^
1468 |                     json.dump(full_results, f, indent=2, ensure_ascii=False)
1469 |                 monitor.display.print_success(
     |
help: Replace with `Path.open()`

I001 [*] Import block is un-sorted or un-formatted
  --> src/config/__init__.py:12:1
   |
10 |   """
11 |
12 | / from src.config.config_loader import (
13 | |     get_config,
14 | |     Config,
15 | |     load_config,
16 | |     get_environment,
17 | |     # Individual config classes for type hints
18 | |     ApplicationConfig,
19 | |     DatabaseConfig,
20 | |     VectorSearchConfig,
21 | |     LoggingConfig,
22 | |     AnalyzersConfig,
23 | |     APIConfig,
24 | |     RedisConfig,
25 | |     MonitoringConfig,
26 | |     CICDConfig,
27 | | )
   | |_^
28 |
29 |   __all__ = [
   |
help: Organize imports

RUF022 [*] `__all__` is not sorted
  --> src/config/__init__.py:29:11
   |
27 |   )
28 |
29 |   __all__ = [
   |  ___________^
30 | |     "get_config",
31 | |     "Config",
32 | |     "load_config",
33 | |     "get_environment",
34 | |     "ApplicationConfig",
35 | |     "DatabaseConfig",
36 | |     "VectorSearchConfig",
37 | |     "LoggingConfig",
38 | |     "AnalyzersConfig",
39 | |     "APIConfig",
40 | |     "RedisConfig",
41 | |     "MonitoringConfig",
42 | |     "CICDConfig",
43 | | ]
   | |_^
   |
help: Apply an isort-style sorting to `__all__`

I001 [*] Import block is un-sorted or un-formatted
  --> src/config/config_loader.py:17:1
   |
15 |   """
16 |
17 | / import os
18 | | from pathlib import Path
19 | | from typing import Dict, List, Optional, Any, Literal
20 | | from functools import lru_cache
21 | |
22 | | import yaml
23 | | from pydantic import BaseModel, Field, field_validator, model_validator
24 | | from pydantic_settings import BaseSettings
   | |__________________________________________^
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/config/config_loader.py:19:1
   |
17 | import os
18 | from pathlib import Path
19 | from typing import Dict, List, Optional, Any, Literal
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
20 | from functools import lru_cache
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/config/config_loader.py:19:1
   |
17 | import os
18 | from pathlib import Path
19 | from typing import Dict, List, Optional, Any, Literal
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
20 | from functools import lru_cache
   |

F401 [*] `pydantic.Field` imported but unused
  --> src/config/config_loader.py:23:33
   |
22 | import yaml
23 | from pydantic import BaseModel, Field, field_validator, model_validator
   |                                 ^^^^^
24 | from pydantic_settings import BaseSettings
   |
help: Remove unused import

F401 [*] `pydantic.model_validator` imported but unused
  --> src/config/config_loader.py:23:57
   |
22 | import yaml
23 | from pydantic import BaseModel, Field, field_validator, model_validator
   |                                                         ^^^^^^^^^^^^^^^
24 | from pydantic_settings import BaseSettings
   |
help: Remove unused import

F401 [*] `pydantic_settings.BaseSettings` imported but unused
  --> src/config/config_loader.py:24:31
   |
22 | import yaml
23 | from pydantic import BaseModel, Field, field_validator, model_validator
24 | from pydantic_settings import BaseSettings
   |                               ^^^^^^^^^^^^
   |
help: Remove unused import: `pydantic_settings.BaseSettings`

UP045 [*] Use `X | None` for type annotations
  --> src/config/config_loader.py:72:13
   |
70 |     pool_pre_ping: bool = True
71 |     echo: bool = False
72 |     sqlite: Optional[SQLiteConfig] = None
   |             ^^^^^^^^^^^^^^^^^^^^^^
73 |
74 |     @property
   |
help: Convert to `X | None`

EM102 Exception must not use an f-string literal, assign to variable first
  --> src/config/config_loader.py:94:30
   |
92 |         password = os.getenv(self.password_env)
93 |         if not password:
94 |             raise ValueError(f"Environment variable {self.password_env} not set!")
   |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
95 |         return password
   |
help: Assign to variable; remove f-string literal

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/config/config_loader.py:131:30
    |
129 |         valid_dimensions = [384, 512, 768, 1536, 3072]
130 |         if v not in valid_dimensions:
131 |             raise ValueError(f"Dimension must be one of {valid_dimensions}")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
132 |         return v
    |
help: Assign to variable; remove f-string literal

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/config/config_loader.py:157:30
    |
155 |         valid_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
156 |         if v.upper() not in valid_levels:
157 |             raise ValueError(f"Log level must be one of {valid_levels}")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
158 |         return v.upper()
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/config/config_loader.py:170:25
    |
169 |     sentiment_threshold: float = 0.5
170 |     complexity_weights: Dict[str, float] = {
    |                         ^^^^
171 |         "vocabulary": 0.3,
172 |         "structure": 0.3,
    |
help: Replace with `dict`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/config/config_loader.py:194:30
    |
192 |         api_key = os.getenv(self.api_key_env)
193 |         if self.validate_api_key and not api_key:
194 |             raise ValueError(f"Environment variable {self.api_key_env} not set!")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
195 |         return api_key or ""
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/config/config_loader.py:216:17
    |
214 |     """Hybrid analyzer configuration"""
215 |
216 |     algorithms: List[str] = ["algorithmic_basic", "qwen"]
    |                 ^^^^
217 |     consensus_threshold: float = 0.7
218 |     fallback_analyzer: str = "algorithmic_basic"
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/config/config_loader.py:237:24
    |
235 |     """All analyzers configuration"""
236 |
237 |     algorithmic_basic: Dict[str, Any]
    |                        ^^^^
238 |     qwen: Dict[str, Any]
239 |     ollama: Dict[str, Any]
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/config/config_loader.py:238:11
    |
237 |     algorithmic_basic: Dict[str, Any]
238 |     qwen: Dict[str, Any]
    |           ^^^^
239 |     ollama: Dict[str, Any]
240 |     hybrid: Dict[str, Any]
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/config/config_loader.py:239:13
    |
237 |     algorithmic_basic: Dict[str, Any]
238 |     qwen: Dict[str, Any]
239 |     ollama: Dict[str, Any]
    |             ^^^^
240 |     hybrid: Dict[str, Any]
241 |     emotion_analyzer: Dict[str, Any]
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/config/config_loader.py:240:13
    |
238 |     qwen: Dict[str, Any]
239 |     ollama: Dict[str, Any]
240 |     hybrid: Dict[str, Any]
    |             ^^^^
241 |     emotion_analyzer: Dict[str, Any]
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/config/config_loader.py:241:23
    |
239 |     ollama: Dict[str, Any]
240 |     hybrid: Dict[str, Any]
241 |     emotion_analyzer: Dict[str, Any]
    |                       ^^^^
242 |
243 |     def get_algorithmic_basic(self) -> AlgorithmicBasicConfig:
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/config/config_loader.py:268:14
    |
267 |     enabled: bool = True
268 |     origins: List[str] = ["http://localhost:3000"]
    |              ^^^^
269 |     allow_credentials: bool = True
270 |     allow_methods: List[str] = ["*"]
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/config/config_loader.py:270:20
    |
268 |     origins: List[str] = ["http://localhost:3000"]
269 |     allow_credentials: bool = True
270 |     allow_methods: List[str] = ["*"]
    |                    ^^^^
271 |     allow_headers: List[str] = ["*"]
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/config/config_loader.py:271:20
    |
269 |     allow_credentials: bool = True
270 |     allow_methods: List[str] = ["*"]
271 |     allow_headers: List[str] = ["*"]
    |                    ^^^^
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/config/config_loader.py:338:27
    |
337 |     @property
338 |     def password(self) -> Optional[str]:
    |                           ^^^^^^^^^^^^^
339 |         """Get Redis password from environment"""
340 |         return os.getenv(self.password_env)
    |
help: Convert to `X | None`

RET504 Unnecessary assignment to `password` before `return` statement
   --> src/config/config_loader.py:369:16
    |
367 |         """Get Grafana admin password from environment"""
368 |         password = os.getenv(self.admin_password_env, "admin")
369 |         return password
    |                ^^^^^^^^
    |
help: Remove unnecessary assignment

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/config/config_loader.py:388:17
    |
386 |     endpoint: str = "/health"
387 |     check_interval: int = 60
388 |     components: List[str] = ["database", "redis", "ollama", "qwen_api"]
    |                 ^^^^
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/config/config_loader.py:426:19
    |
424 |     """Deployment configuration"""
425 |
426 |     environments: List[str] = ["dev", "staging", "prod"]
    |                   ^^^^
427 |     auto_rollback: bool = True
428 |     health_check_timeout: int = 300
    |
help: Replace with `list`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/config/config_loader.py:473:37
    |
472 |         if not config_file.exists():
473 |             raise FileNotFoundError(f"Configuration file not found: {config_path}")
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
474 |
475 |         with open(config_file, "r", encoding="utf-8") as f:
    |
help: Assign to variable; remove f-string literal

PTH123 `open()` should be replaced by `Path.open()`
   --> src/config/config_loader.py:475:14
    |
473 |             raise FileNotFoundError(f"Configuration file not found: {config_path}")
474 |
475 |         with open(config_file, "r", encoding="utf-8") as f:
    |              ^^^^
476 |             config_data = yaml.safe_load(f)
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> src/config/config_loader.py:475:32
    |
473 |             raise FileNotFoundError(f"Configuration file not found: {config_path}")
474 |
475 |         with open(config_file, "r", encoding="utf-8") as f:
    |                                ^^^
476 |             config_data = yaml.safe_load(f)
    |
help: Remove mode argument

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src/config/config_loader.py:501:13
    |
499 |             _ = self.database.connection_string
500 |         except ValueError as e:
501 |             raise ValueError(f"Database configuration error: {e}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
502 |
503 |         # Validate API keys if needed
    |

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/config/config_loader.py:501:30
    |
499 |             _ = self.database.connection_string
500 |         except ValueError as e:
501 |             raise ValueError(f"Database configuration error: {e}")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
502 |
503 |         # Validate API keys if needed
    |
help: Assign to variable; remove f-string literal

UP011 [*] Unnecessary parentheses to `functools.lru_cache`
   --> src/config/config_loader.py:517:11
    |
517 | @lru_cache()
    |           ^^
518 | def get_config(config_path: str = "config.yaml") -> Config:
519 |     """
    |
help: Remove unnecessary parentheses

F541 [*] f-string without any placeholders
   --> src/config/config_loader.py:579:15
    |
578 |         # Quick validation summary
579 |         print(f"\nâœ… Config Valid!")
    |               ^^^^^^^^^^^^^^^^^^^^^
580 |         print(f"   â€¢ App: {config.application.name} v{config.application.version}")
581 |         print(f"   â€¢ Env: {config.application.environment}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/config_loader.py:602:15
    |
600 |             print(f"   â€¢ Components: {', '.join(components)}")
601 |
602 |         print(f"\nðŸ’¡ For detailed testing run:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
603 |         print(f"   python src/config/test_loader.py")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/config_loader.py:603:15
    |
602 |         print(f"\nðŸ’¡ For detailed testing run:")
603 |         print(f"   python src/config/test_loader.py")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
604 |
605 |     except FileNotFoundError as e:
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/config_loader.py:607:15
    |
605 |     except FileNotFoundError as e:
606 |         print(f"\nâŒ File not found: {e}")
607 |         print(f"   Make sure config.yaml exists")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
608 |         sys.exit(1)
609 |     except ValueError as e:
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/config_loader.py:611:15
    |
609 |     except ValueError as e:
610 |         print(f"\nâŒ Validation Error: {e}")
611 |         print(f"   Check your .env file and config.yaml")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
612 |         sys.exit(1)
613 |     except Exception as e:
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/config/test_loader.py:24:1
   |
22 |   """
23 |
24 | / import os
25 | | import sys
26 | | from pathlib import Path
27 | | from dotenv import load_dotenv
   | |______________________________^
28 |
29 |   # Add project root to path
   |
help: Organize imports

F541 [*] f-string without any placeholders
  --> src/config/test_loader.py:75:11
   |
73 |     print("\nâœ… Configuration loaded successfully!")
74 |
75 |     print(f"\nðŸ“Š Application Info:")
   |           ^^^^^^^^^^^^^^^^^^^^^^^^^
76 |     print(f"   Name: {config.application.name}")
77 |     print(f"   Version: {config.application.version}")
   |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
  --> src/config/test_loader.py:81:11
   |
79 |     print(f"   Description: {config.application.description}")
80 |
81 |     print(f"\nðŸ—„ï¸  Database Configuration:")
   |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
82 |     print(f"   Type: {config.database.type}")
83 |     print(f"   Host: {config.database.host}")
   |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
  --> src/config/test_loader.py:94:11
   |
92 |     )
93 |
94 |     print(f"\nðŸ” Vector Search Configuration:")
   |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
95 |     print(f"   Enabled: {config.vector_search.enabled}")
96 |     print(f"   Embedding Model: {config.vector_search.embedding_model}")
   |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:102:11
    |
100 |     print(f"   Cache Enabled: {config.vector_search.cache_enabled}")
101 |
102 |     print(f"\nðŸš€ API Configuration:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^
103 |     print(f"   Host: {config.api.host}")
104 |     print(f"   Port: {config.api.port}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:108:11
    |
106 |     print(f"   Reload: {config.api.reload}")
107 |     print(f"   Log Level: {config.api.log_level}")
108 |     print(f"\n   ðŸ“ API Docs:")
    |           ^^^^^^^^^^^^^^^^^^^^
109 |     print(f"      Enabled: {config.api.docs.enabled}")
110 |     print(f"      Title: {config.api.docs.title}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:114:11
    |
112 |     print(f"      Swagger: {config.api.docs.swagger_url}")
113 |     print(f"      ReDoc: {config.api.docs.redoc_url}")
114 |     print(f"\n   ðŸŒ CORS:")
    |           ^^^^^^^^^^^^^^^^
115 |     print(f"      Enabled: {config.api.cors.enabled}")
116 |     print(f"      Origins: {', '.join(config.api.cors.origins)}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:118:11
    |
116 |     print(f"      Origins: {', '.join(config.api.cors.origins)}")
117 |     print(f"      Credentials: {config.api.cors.allow_credentials}")
118 |     print(f"\n   â±ï¸  Rate Limiting:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^
119 |     print(f"      Enabled: {config.api.rate_limit.enabled}")
120 |     print(f"      Requests/min: {config.api.rate_limit.requests_per_minute}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:123:11
    |
121 |     print(f"      Burst Size: {config.api.rate_limit.burst_size}")
122 |
123 |     print(f"\nðŸ’¾ Redis Configuration:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
124 |     print(f"   Enabled: {config.redis.enabled}")
125 |     print(f"   Host: {config.redis.host}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:129:11
    |
127 |     print(f"   Database: {config.redis.db}")
128 |     print(f"   Max Connections: {config.redis.max_connections}")
129 |     print(f"\n   â° Cache TTL:")
    |           ^^^^^^^^^^^^^^^^^^^^^
130 |     print(
131 |         f"      Artist: {config.redis.cache.artist_ttl}s ({config.redis.cache.artist_ttl // 3600}h)"
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:143:11
    |
141 |     )
142 |
143 |     print(f"\nðŸ¤– Analyzers Configuration:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
144 |
145 |     # Test QWEN config
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:148:15
    |
146 |     try:
147 |         qwen_config = config.analyzers.get_qwen()
148 |         print(f"\n   âœ… QWEN Analyzer:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^
149 |         print(f"      Model: {qwen_config.model_name}")
150 |         print(f"      Base URL: {qwen_config.base_url}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:162:15
    |
160 |     try:
161 |         ollama_config = config.analyzers.get_ollama()
162 |         print(f"\n   âœ… Ollama Analyzer:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
163 |         print(f"      Model: {ollama_config.model}")
164 |         print(f"      Base URL: {ollama_config.base_url}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:174:15
    |
172 |     try:
173 |         emotion_config = config.analyzers.get_emotion()
174 |         print(f"\n   âœ… Emotion Analyzer:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
175 |         print(f"      Model: {emotion_config.model_name}")
176 |         print(f"      Device: {emotion_config.device}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:186:15
    |
184 |     try:
185 |         hybrid_config = config.analyzers.get_hybrid()
186 |         print(f"\n   âœ… Hybrid Analyzer:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
187 |         print(f"      Algorithms: {', '.join(hybrid_config.algorithms)}")
188 |         print(f"      Consensus Threshold: {hybrid_config.consensus_threshold}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:193:11
    |
191 |         print(f"\n   âŒ Hybrid Analyzer: {e}")
192 |
193 |     print(f"\nðŸ“Š Monitoring Configuration:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
194 |     print(f"\n   ðŸ“ˆ Prometheus:")
195 |     print(f"      Enabled: {config.monitoring.prometheus.enabled}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:194:11
    |
193 |     print(f"\nðŸ“Š Monitoring Configuration:")
194 |     print(f"\n   ðŸ“ˆ Prometheus:")
    |           ^^^^^^^^^^^^^^^^^^^^^^
195 |     print(f"      Enabled: {config.monitoring.prometheus.enabled}")
196 |     print(f"      Port: {config.monitoring.prometheus.port}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:201:11
    |
199 |         f"      Default Metrics: {config.monitoring.prometheus.include_default_metrics}"
200 |     )
201 |     print(f"\n   ðŸ“Š Grafana:")
    |           ^^^^^^^^^^^^^^^^^^^
202 |     print(f"      Enabled: {config.monitoring.grafana.enabled}")
203 |     print(f"      Port: {config.monitoring.grafana.port}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:204:11
    |
202 |     print(f"      Enabled: {config.monitoring.grafana.enabled}")
203 |     print(f"      Port: {config.monitoring.grafana.port}")
204 |     print(f"\n   ðŸ¥ Health Checks:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^
205 |     print(f"      Enabled: {config.monitoring.health.enabled}")
206 |     print(f"      Endpoint: {config.monitoring.health.endpoint}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:210:11
    |
208 |     print(f"      Components: {', '.join(config.monitoring.health.components)}")
209 |
210 |     print(f"\nðŸ“ Logging Configuration:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
211 |     print(f"   Level: {config.logging.level}")
212 |     print(f"   File: {config.logging.file_path}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/config/test_loader.py:217:11
    |
215 |     print(f"   Console Output: {config.logging.console_output}")
216 |
217 |     print(f"\nðŸ”„ CI/CD Configuration:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
218 |     print(f"   GitHub Actions: {config.ci_cd.github_actions.enabled}")
219 |     print(f"   Test Coverage Required: {config.ci_cd.testing.required_coverage}%")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/core/__init__.py:11:1
   |
 9 |   """
10 |
11 | / from .config import (
12 | |     AppConfig,
13 | |     DatabaseConfig,
14 | |     ScrapingConfig,
15 | |     AnalysisConfig,
16 | |     LoggingConfig,
17 | |     APIConfig,
18 | |     ConfigManager,
19 | |     get_config,
20 | |     load_config,
21 | |     reload_config,
22 | | )
23 | |
24 | | from .app import (
25 | |     Application,
26 | |     ApplicationError,
27 | |     ConfigurationError,
28 | |     DatabaseError,
29 | |     create_app,
30 | |     get_app,
31 | |     init_app,
32 | |     AppContext,
33 | |     with_app,
34 | | )
   | |_^
35 |
36 |   __all__ = [
   |
help: Organize imports

RUF022 `__all__` is not sorted
  --> src/core/__init__.py:36:11
   |
34 |   )
35 |
36 |   __all__ = [
   |  ___________^
37 | |     # Configuration
38 | |     "AppConfig",
39 | |     "DatabaseConfig",
40 | |     "ScrapingConfig",
41 | |     "AnalysisConfig",
42 | |     "LoggingConfig",
43 | |     "APIConfig",
44 | |     "ConfigManager",
45 | |     "get_config",
46 | |     "load_config",
47 | |     "reload_config",
48 | |     # Application
49 | |     "Application",
50 | |     "ApplicationError",
51 | |     "ConfigurationError",
52 | |     "DatabaseError",
53 | |     "create_app",
54 | |     "get_app",
55 | |     "init_app",
56 | |     "AppContext",
57 | |     "with_app",
58 | | ]
   | |_^
   |
help: Apply an isort-style sorting to `__all__`

I001 [*] Import block is un-sorted or un-formatted
  --> src/core/app.py:15:1
   |
13 |   """
14 |
15 | / import logging
16 | | import sys
17 | | from pathlib import Path
18 | | from typing import Dict, Any, Optional
   | |______________________________________^
19 |
20 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð² sys.path ÐµÑÐ»Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/core/app.py:18:1
   |
16 | import sys
17 | from pathlib import Path
18 | from typing import Dict, Any, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
19 |
20 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð² sys.path ÐµÑÐ»Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾
   |

E402 Module level import not at top of file
  --> src/core/app.py:26:1
   |
25 | # Core imports
26 | from src.core.config import AppConfig, get_config, load_config
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
27 | from src.database.postgres_adapter import PostgreSQLManager, DatabaseConfig
28 | from src.interfaces.analyzer_interface import AnalyzerFactory
   |

I001 [*] Import block is un-sorted or un-formatted
  --> src/core/app.py:26:1
   |
25 |   # Core imports
26 | / from src.core.config import AppConfig, get_config, load_config
27 | | from src.database.postgres_adapter import PostgreSQLManager, DatabaseConfig
28 | | from src.interfaces.analyzer_interface import AnalyzerFactory
   | |_____________________________________________________________^
   |
help: Organize imports

E402 Module level import not at top of file
  --> src/core/app.py:27:1
   |
25 | # Core imports
26 | from src.core.config import AppConfig, get_config, load_config
27 | from src.database.postgres_adapter import PostgreSQLManager, DatabaseConfig
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
28 | from src.interfaces.analyzer_interface import AnalyzerFactory
   |

F401 [*] `src.database.postgres_adapter.DatabaseConfig` imported but unused
  --> src/core/app.py:27:62
   |
25 | # Core imports
26 | from src.core.config import AppConfig, get_config, load_config
27 | from src.database.postgres_adapter import PostgreSQLManager, DatabaseConfig
   |                                                              ^^^^^^^^^^^^^^
28 | from src.interfaces.analyzer_interface import AnalyzerFactory
   |
help: Remove unused import: `src.database.postgres_adapter.DatabaseConfig`

E402 Module level import not at top of file
  --> src/core/app.py:28:1
   |
26 | from src.core.config import AppConfig, get_config, load_config
27 | from src.database.postgres_adapter import PostgreSQLManager, DatabaseConfig
28 | from src.interfaces.analyzer_interface import AnalyzerFactory
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

PIE790 [*] Unnecessary `pass` statement
  --> src/core/app.py:34:5
   |
32 |     """Base application exception"""
33 |
34 |     pass
   |     ^^^^
   |
help: Remove unnecessary `pass`

PIE790 [*] Unnecessary `pass` statement
  --> src/core/app.py:40:5
   |
38 |     """Configuration-related errors"""
39 |
40 |     pass
   |     ^^^^
   |
help: Remove unnecessary `pass`

PIE790 [*] Unnecessary `pass` statement
  --> src/core/app.py:46:5
   |
44 |     """Database-related errors"""
45 |
46 |     pass
   |     ^^^^
   |
help: Remove unnecessary `pass`

UP045 [*] Use `X | None` for type annotations
  --> src/core/app.py:57:32
   |
55 |     """
56 |
57 |     def __init__(self, config: Optional[AppConfig] = None):
   |                                ^^^^^^^^^^^^^^^^^^^
58 |         """Initialize application with configuration"""
59 |         self.config = config or get_config()
   |
help: Convert to `X | None`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/core/app.py:151:33
    |
150 |         except Exception as e:
151 |             raise DatabaseError(f"Failed to setup database: {e}") from e
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
152 |
153 |     def _setup_analyzers(self) -> None:
    |
help: Assign to variable; remove f-string literal

UP045 [*] Use `X | None` for type annotations
   --> src/core/app.py:217:47
    |
215 |         return self.database
216 |
217 |     def get_analyzer(self, name: str, config: Optional[Dict[str, Any]] = None) -> Any:
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^
218 |         """Get analyzer instance"""
219 |         if not self._initialized:
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/core/app.py:217:56
    |
215 |         return self.database
216 |
217 |     def get_analyzer(self, name: str, config: Optional[Dict[str, Any]] = None) -> Any:
    |                                                        ^^^^
218 |         """Get analyzer instance"""
219 |         if not self._initialized:
    |
help: Replace with `dict`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/core/app.py:225:36
    |
223 |             return AnalyzerFactory.create(name, config)
224 |         except Exception as e:
225 |             raise ApplicationError(f"Failed to create analyzer '{name}': {e}") from e
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
226 |
227 |     def list_analyzers(self) -> list:
    |
help: Assign to variable; remove f-string literal

UP045 [*] Use `X | None` for type annotations
   --> src/core/app.py:251:16
    |
250 | # Global application instance
251 | _app_instance: Optional[Application] = None
    |                ^^^^^^^^^^^^^^^^^^^^^
    |
help: Convert to `X | None`

I001 [*] Import block is un-sorted or un-formatted
   --> src/core/app.py:258:9
    |
256 |       try:
257 |           # Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ñ‹ Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ (Ð¾Ð±Ñ…Ð¾Ð´ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ñ issubclass)
258 | /         from analyzers.algorithmic_analyzer import AdvancedAlgorithmicAnalyzer
259 | |         from archive.qwen_analyzer import QwenAnalyzer
260 | |         from analyzers.ollama_analyzer import OllamaAnalyzer
261 | |         from analyzers.emotion_analyzer import EmotionAnalyzer
    | |______________________________________________________________^
262 |
263 |           AnalyzerFactory._analyzers["algorithmic_basic"] = AdvancedAlgorithmicAnalyzer
    |
help: Organize imports

TRY300 Consider moving this statement to an `else` block
   --> src/core/app.py:270:9
    |
268 |         registered = list(AnalyzerFactory._analyzers.keys())
269 |         logging.info(f"Analyzers registered: {registered}")
270 |         return True
    |         ^^^^^^^^^^^
271 |     except Exception as e:
272 |         logging.error(f"Failed to initialize analyzers: {e}")
    |

UP045 [*] Use `X | None` for type annotations
   --> src/core/app.py:277:13
    |
276 | def create_app(
277 |     config: Optional[AppConfig] = None,
    |             ^^^^^^^^^^^^^^^^^^^
278 |     config_file: Optional[str] = None,
279 |     **config_kwargs,
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/core/app.py:278:18
    |
276 | def create_app(
277 |     config: Optional[AppConfig] = None,
278 |     config_file: Optional[str] = None,
    |                  ^^^^^^^^^^^^^
279 |     **config_kwargs,
280 | ) -> Application:
    |
help: Convert to `X | None`

PLW0603 Using the global statement to update `_app_instance` is discouraged
   --> src/core/app.py:292:12
    |
290 |         Configured Application instance
291 |     """
292 |     global _app_instance
    |            ^^^^^^^^^^^^^
293 |
294 |     if config is None:
    |

PLW0603 Using the global statement to update `_app_instance` is discouraged
   --> src/core/app.py:315:12
    |
313 |         ApplicationError: If no application instance exists
314 |     """
315 |     global _app_instance
    |            ^^^^^^^^^^^^^
316 |
317 |     if _app_instance is None:
    |

F841 Local variable `app` is assigned to but never used
   --> src/core/app.py:373:49
    |
371 |     def decorator(func):
372 |         def wrapper(*args, **kwargs):
373 |             with AppContext(**config_kwargs) as app:
    |                                                 ^^^
374 |                 return func(*args, **kwargs)
    |
help: Remove assignment to unused variable `app`

I001 [*] Import block is un-sorted or un-formatted
  --> src/core/config.py:19:1
   |
17 |   """
18 |
19 | / import os
20 | | import json
21 | | from pathlib import Path
   | |________________________^
22 |
23 |   # yaml - Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑŒ
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/core/config.py:30:1
   |
28 | except ImportError:
29 |     HAS_YAML = False
30 | from typing import Dict, Any, Optional, Union, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
31 | from dataclasses import dataclass, field, asdict
32 | from abc import ABC, abstractmethod
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/core/config.py:30:1
   |
28 | except ImportError:
29 |     HAS_YAML = False
30 | from typing import Dict, Any, Optional, Union, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
31 | from dataclasses import dataclass, field, asdict
32 | from abc import ABC, abstractmethod
   |

I001 [*] Import block is un-sorted or un-formatted
  --> src/core/config.py:30:1
   |
28 |   except ImportError:
29 |       HAS_YAML = False
30 | / from typing import Dict, Any, Optional, Union, List
31 | | from dataclasses import dataclass, field, asdict
32 | | from abc import ABC, abstractmethod
33 | | import logging
   | |______________^
   |
help: Organize imports

F401 [*] `abc.ABC` imported but unused
  --> src/core/config.py:32:17
   |
30 | from typing import Dict, Any, Optional, Union, List
31 | from dataclasses import dataclass, field, asdict
32 | from abc import ABC, abstractmethod
   |                 ^^^
33 | import logging
   |
help: Remove unused import

F401 [*] `abc.abstractmethod` imported but unused
  --> src/core/config.py:32:22
   |
30 | from typing import Dict, Any, Optional, Union, List
31 | from dataclasses import dataclass, field, asdict
32 | from abc import ABC, abstractmethod
   |                      ^^^^^^^^^^^^^^
33 | import logging
   |
help: Remove unused import

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/core/config.py:54:14
   |
52 |     max_retries: int = 3
53 |     timeout: int = 30
54 |     headers: Dict[str, str] = field(
   |              ^^^^
55 |         default_factory=lambda: {
56 |             "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
   |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
  --> src/core/config.py:68:26
   |
66 |     max_workers: int = 4
67 |     default_confidence_threshold: float = 0.7
68 |     supported_analyzers: List[str] = field(
   |                          ^^^^
69 |         default_factory=lambda: ["gemma", "algorithmic", "hybrid"]
70 |     )
   |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
  --> src/core/config.py:79:16
   |
77 |     level: str = "INFO"
78 |     format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
79 |     file_path: Optional[str] = None
   |                ^^^^^^^^^^^^^
80 |     max_file_size: int = 10 * 1024 * 1024  # 10MB
81 |     backup_count: int = 5
   |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
  --> src/core/config.py:89:19
   |
87 |     """API configuration for external services"""
88 |
89 |     genius_token: Optional[str] = None
   |                   ^^^^^^^^^^^^^
90 |     openai_api_key: Optional[str] = None
91 |     huggingface_token: Optional[str] = None
   |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
  --> src/core/config.py:90:21
   |
89 |     genius_token: Optional[str] = None
90 |     openai_api_key: Optional[str] = None
   |                     ^^^^^^^^^^^^^
91 |     huggingface_token: Optional[str] = None
92 |     request_delay: float = 1.0
   |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
  --> src/core/config.py:91:24
   |
89 |     genius_token: Optional[str] = None
90 |     openai_api_key: Optional[str] = None
91 |     huggingface_token: Optional[str] = None
   |                        ^^^^^^^^^^^^^
92 |     request_delay: float = 1.0
93 |     max_requests_per_minute: int = 60
   |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/core/config.py:145:26
    |
143 |             Path(directory).mkdir(parents=True, exist_ok=True)
144 |
145 |     def to_dict(self) -> Dict[str, Any]:
    |                          ^^^^
146 |         """Convert configuration to dictionary"""
147 |         return asdict(self)
    |
help: Replace with `dict`

UP007 [*] Use `X | Y` for type annotations
   --> src/core/config.py:149:39
    |
147 |         return asdict(self)
148 |
149 |     def save_to_file(self, file_path: Union[str, Path]) -> None:
    |                                       ^^^^^^^^^^^^^^^^
150 |         """Save configuration to file"""
151 |         file_path = Path(file_path)
    |
help: Convert to `X | Y`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/core/config.py:156:18
    |
155 |         if file_path.suffix.lower() == ".json":
156 |             with open(file_path, "w", encoding="utf-8") as f:
    |                  ^^^^
157 |                 json.dump(config_dict, f, indent=2, ensure_ascii=False)
158 |         elif file_path.suffix.lower() in [".yml", ".yaml"]:
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/core/config.py:163:18
    |
161 |                     "PyYAML package required for YAML support. Install with: pip install PyYAML"
162 |                 )
163 |             with open(file_path, "w", encoding="utf-8") as f:
    |                  ^^^^
164 |                 yaml.dump(config_dict, f, default_flow_style=False, allow_unicode=True)
165 |         else:
    |
help: Replace with `Path.open()`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/core/config.py:166:30
    |
164 |                 yaml.dump(config_dict, f, default_flow_style=False, allow_unicode=True)
165 |         else:
166 |             raise ValueError(f"Unsupported file format: {file_path.suffix}")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
help: Assign to variable; remove f-string literal

UP007 [*] Use `X | Y` for type annotations
   --> src/core/config.py:175:41
    |
173 |         self.logger = logging.getLogger(__name__)
174 |
175 |     def load_from_file(self, file_path: Union[str, Path]) -> Dict[str, Any]:
    |                                         ^^^^^^^^^^^^^^^^
176 |         """Load configuration from file"""
177 |         file_path = Path(file_path)
    |
help: Convert to `X | Y`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/core/config.py:175:62
    |
173 |         self.logger = logging.getLogger(__name__)
174 |
175 |     def load_from_file(self, file_path: Union[str, Path]) -> Dict[str, Any]:
    |                                                              ^^^^
176 |         """Load configuration from file"""
177 |         file_path = Path(file_path)
    |
help: Replace with `dict`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/core/config.py:180:37
    |
179 |         if not file_path.exists():
180 |             raise FileNotFoundError(f"Configuration file not found: {file_path}")
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
181 |
182 |         try:
    |
help: Assign to variable; remove f-string literal

PTH123 `open()` should be replaced by `Path.open()`
   --> src/core/config.py:184:22
    |
182 |         try:
183 |             if file_path.suffix.lower() == ".json":
184 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                      ^^^^
185 |                     return json.load(f)
186 |             elif file_path.suffix.lower() in [".yml", ".yaml"]:
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> src/core/config.py:184:38
    |
182 |         try:
183 |             if file_path.suffix.lower() == ".json":
184 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                                      ^^^
185 |                     return json.load(f)
186 |             elif file_path.suffix.lower() in [".yml", ".yaml"]:
    |
help: Remove mode argument

TRY301 Abstract `raise` to an inner function
   --> src/core/config.py:188:21
    |
186 |               elif file_path.suffix.lower() in [".yml", ".yaml"]:
187 |                   if not HAS_YAML:
188 | /                     raise ValueError(
189 | |                         "PyYAML package required for YAML support. Install with: pip install PyYAML"
190 | |                     )
    | |_____________________^
191 |                   with open(file_path, "r", encoding="utf-8") as f:
192 |                       return yaml.safe_load(f) or {}
    |

PTH123 `open()` should be replaced by `Path.open()`
   --> src/core/config.py:191:22
    |
189 |                         "PyYAML package required for YAML support. Install with: pip install PyYAML"
190 |                     )
191 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                      ^^^^
192 |                     return yaml.safe_load(f) or {}
193 |             else:
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> src/core/config.py:191:38
    |
189 |                         "PyYAML package required for YAML support. Install with: pip install PyYAML"
190 |                     )
191 |                 with open(file_path, "r", encoding="utf-8") as f:
    |                                      ^^^
192 |                     return yaml.safe_load(f) or {}
193 |             else:
    |
help: Remove mode argument

TRY301 Abstract `raise` to an inner function
   --> src/core/config.py:194:17
    |
192 |                     return yaml.safe_load(f) or {}
193 |             else:
194 |                 raise ValueError(f"Unsupported file format: {file_path.suffix}")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
195 |
196 |         except Exception as e:
    |

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/core/config.py:194:34
    |
192 |                     return yaml.safe_load(f) or {}
193 |             else:
194 |                 raise ValueError(f"Unsupported file format: {file_path.suffix}")
    |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
195 |
196 |         except Exception as e:
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/core/config.py:200:62
    |
198 |             raise
199 |
200 |     def load_from_env(self, prefix: str = "RAP_SCRAPER_") -> Dict[str, Any]:
    |                                                              ^^^^
201 |         """Load configuration from environment variables"""
202 |         config = {}
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/core/config.py:238:39
    |
236 |         return config
237 |
238 |     def merge_configs(self, *configs: Dict[str, Any]) -> Dict[str, Any]:
    |                                       ^^^^
239 |         """Merge multiple configuration dictionaries"""
240 |         result = {}
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/core/config.py:238:58
    |
236 |         return config
237 |
238 |     def merge_configs(self, *configs: Dict[str, Any]) -> Dict[str, Any]:
    |                                                          ^^^^
239 |         """Merge multiple configuration dictionaries"""
240 |         result = {}
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/core/config.py:247:33
    |
245 |         return result
246 |
247 |     def _deep_merge(self, base: Dict[str, Any], update: Dict[str, Any]) -> None:
    |                                 ^^^^
248 |         """Deep merge configuration dictionaries"""
249 |         for key, value in update.items():
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/core/config.py:247:57
    |
245 |         return result
246 |
247 |     def _deep_merge(self, base: Dict[str, Any], update: Dict[str, Any]) -> None:
    |                                                         ^^^^
248 |         """Deep merge configuration dictionaries"""
249 |         for key, value in update.items():
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/core/config.py:267:23
    |
265 |         self.logger = logging.getLogger(__name__)
266 |         self.loader = ConfigLoader()
267 |         self._config: Optional[AppConfig] = None
    |                       ^^^^^^^^^^^^^^^^^^^
268 |
269 |     def load_config(
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/core/config.py:271:22
    |
269 |     def load_config(
270 |         self,
271 |         config_file: Optional[Union[str, Path]] = None,
    |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
272 |         env_prefix: str = "RAP_SCRAPER_",
273 |         defaults: Optional[Dict[str, Any]] = None,
    |
help: Convert to `X | None`

UP007 [*] Use `X | Y` for type annotations
   --> src/core/config.py:271:31
    |
269 |     def load_config(
270 |         self,
271 |         config_file: Optional[Union[str, Path]] = None,
    |                               ^^^^^^^^^^^^^^^^
272 |         env_prefix: str = "RAP_SCRAPER_",
273 |         defaults: Optional[Dict[str, Any]] = None,
    |
help: Convert to `X | Y`

UP045 [*] Use `X | None` for type annotations
   --> src/core/config.py:273:19
    |
271 |         config_file: Optional[Union[str, Path]] = None,
272 |         env_prefix: str = "RAP_SCRAPER_",
273 |         defaults: Optional[Dict[str, Any]] = None,
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^
274 |     ) -> AppConfig:
275 |         """
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/core/config.py:273:28
    |
271 |         config_file: Optional[Union[str, Path]] = None,
272 |         env_prefix: str = "RAP_SCRAPER_",
273 |         defaults: Optional[Dict[str, Any]] = None,
    |                            ^^^^
274 |     ) -> AppConfig:
275 |         """
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/core/config.py:320:13
    |
318 |             self._config = self._dict_to_appconfig(merged_config)
319 |             self.logger.info("Configuration loaded successfully")
320 |             return self._config
    |             ^^^^^^^^^^^^^^^^^^^
321 |
322 |         except Exception as e:
    |

PLR0912 Too many branches (17 > 12)
   --> src/core/config.py:328:9
    |
326 |             return self._config
327 |
328 |     def _dict_to_appconfig(self, config_dict: Dict[str, Any]) -> AppConfig:
    |         ^^^^^^^^^^^^^^^^^^
329 |         """Convert dictionary to AppConfig object"""
330 |         # Create component configs
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/core/config.py:328:47
    |
326 |             return self._config
327 |
328 |     def _dict_to_appconfig(self, config_dict: Dict[str, Any]) -> AppConfig:
    |                                               ^^^^
329 |         """Convert dictionary to AppConfig object"""
330 |         # Create component configs
    |
help: Replace with `dict`

UP007 [*] Use `X | Y` for type annotations
   --> src/core/config.py:399:46
    |
397 |         return self.load_config(**kwargs)
398 |
399 |     def save_current_config(self, file_path: Union[str, Path]) -> None:
    |                                              ^^^^^^^^^^^^^^^^
400 |         """Save current configuration to file"""
401 |         if self._config is None:
    |
help: Convert to `X | Y`

I001 [*] Import block is un-sorted or un-formatted
  --> src/database/__init__.py:5:1
   |
 3 |   """
 4 |
 5 | / from src.database.connection import (
 6 | |     get_engine,
 7 | |     get_session_local,
 8 | |     get_db,
 9 | |     test_connection,
10 | |     get_pool_status,
11 | |     DatabaseConnection,
12 | |     Base,
13 | | )
   | |_^
14 |
15 |   __all__ = [
   |
help: Organize imports

RUF022 [*] `__all__` is not sorted
  --> src/database/__init__.py:15:11
   |
13 |   )
14 |
15 |   __all__ = [
   |  ___________^
16 | |     "get_engine",
17 | |     "get_session_local",
18 | |     "get_db",
19 | |     "test_connection",
20 | |     "get_pool_status",
21 | |     "DatabaseConnection",
22 | |     "Base",
23 | | ]
   | |_^
   |
help: Apply an isort-style sorting to `__all__`

I001 [*] Import block is un-sorted or un-formatted
  --> src/database/connection.py:15:1
   |
13 |   """
14 |
15 | / from sqlalchemy import create_engine, pool
16 | | from sqlalchemy.orm import sessionmaker, Session
17 | | from sqlalchemy.ext.declarative import declarative_base
18 | | from typing import Generator
19 | | import logging
20 | |
21 | | from src.config.config_loader import get_config
   | |_______________________________________________^
22 |
23 |   logger = logging.getLogger(__name__)
   |
help: Organize imports

UP035 [*] Import from `collections.abc` instead: `Generator`
  --> src/database/connection.py:18:1
   |
16 | from sqlalchemy.orm import sessionmaker, Session
17 | from sqlalchemy.ext.declarative import declarative_base
18 | from typing import Generator
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
19 | import logging
   |
help: Import from `collections.abc`

PLW0603 Using the global statement to update `_engine` is discouraged
  --> src/database/connection.py:40:12
   |
38 |         Engine: Configured SQLAlchemy engine with connection pooling
39 |     """
40 |     global _engine
   |            ^^^^^^^
41 |
42 |     if _engine is None:
   |

F541 [*] f-string without any placeholders
  --> src/database/connection.py:45:21
   |
43 |         config = get_config()
44 |
45 |         logger.info(f"ðŸ”§ Creating database engine...")
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
46 |         logger.info(f"   Host: {config.database.host}")
47 |         logger.info(f"   Database: {config.database.database_name}")
   |
help: Remove extraneous `f` prefix

PLW0603 Using the global statement to update `_SessionLocal` is discouraged
  --> src/database/connection.py:73:12
   |
71 |         sessionmaker: Configured session factory
72 |     """
73 |     global _SessionLocal
   |            ^^^^^^^^^^^^^
74 |
75 |     if _SessionLocal is None:
   |

N806 Variable `SessionLocal` in function should be lowercase
  --> src/database/connection.py:97:5
   |
95 |         Session: Database session
96 |     """
97 |     SessionLocal = get_session_local()
   |     ^^^^^^^^^^^^
98 |     db = SessionLocal()
99 |     try:
   |

F841 Local variable `result` is assigned to but never used
   --> src/database/connection.py:115:13
    |
113 |         engine = get_engine()
114 |         with engine.connect() as conn:
115 |             result = conn.execute("SELECT 1")
    |             ^^^^^^
116 |             logger.info("âœ… Database connection test successful!")
117 |             return True
    |
help: Remove assignment to unused variable `result`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src/database/connection.py:171:43
    |
169 |             self.session = None
170 |
171 |     def execute(self, query: str, params: dict = None):
    |                                           ^^^^
172 |         """Execute raw SQL query"""
173 |         with self.engine.connect() as conn:
    |
help: Convert to `T | None`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/database/connection.py:176:13
    |
174 |             if params:
175 |                 return conn.execute(query, params)
176 |             else:
    |             ^^^^
177 |                 return conn.execute(query)
    |
help: Remove unnecessary `else`

F541 [*] f-string without any placeholders
   --> src/database/connection.py:196:11
    |
194 |     # Load config
195 |     config = get_config()
196 |     print(f"\nðŸ“Š Database Configuration:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
197 |     print(f"   Type: {config.database.type}")
198 |     print(f"   Host: {config.database.host}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/database/connection.py:204:11
    |
203 |     # Test connection
204 |     print(f"\nðŸ”Œ Testing connection...")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
205 |     if test_connection():
206 |         print("âœ… Connection successful!")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/database/connection.py:210:15
    |
208 |         # Show pool status
209 |         pool_status = get_pool_status()
210 |         print(f"\nðŸ“Š Pool Status:")
    |               ^^^^^^^^^^^^^^^^^^^^
211 |         print(f"   Size: {pool_status['size']}")
212 |         print(f"   Checked In: {pool_status['checked_in']}")
    |
help: Remove extraneous `f` prefix

PLR1722 Use `sys.exit()` instead of `exit`
   --> src/database/connection.py:218:9
    |
216 |     else:
217 |         print("âŒ Connection failed!")
218 |         exit(1)
    |         ^^^^
    |
help: Replace `exit` with `sys.exit()`

I001 [*] Import block is un-sorted or un-formatted
  --> src/enhancers/bulk_spotify_enhancement.py:27:1
   |
25 |   """
26 |
27 | / import os
28 | | import sys
29 | | import time
30 | | import json
31 | | import sqlite3
32 | | import requests
33 | | import ssl
34 | | from datetime import datetime
35 | | from dotenv import load_dotenv
36 | | from typing import Optional, List, Dict, Any, Tuple
37 | | import logging
38 | | import re
39 | | from urllib3.util.retry import Retry
40 | | from requests.adapters import HTTPAdapter
   | |_________________________________________^
41 |
42 |   try:
   |
help: Organize imports

F401 [*] `sys` imported but unused
  --> src/enhancers/bulk_spotify_enhancement.py:28:8
   |
27 | import os
28 | import sys
   |        ^^^
29 | import time
30 | import json
   |
help: Remove unused import: `sys`

UP035 `typing.List` is deprecated, use `list` instead
  --> src/enhancers/bulk_spotify_enhancement.py:36:1
   |
34 | from datetime import datetime
35 | from dotenv import load_dotenv
36 | from typing import Optional, List, Dict, Any, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37 | import logging
38 | import re
   |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/enhancers/bulk_spotify_enhancement.py:36:1
   |
34 | from datetime import datetime
35 | from dotenv import load_dotenv
36 | from typing import Optional, List, Dict, Any, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37 | import logging
38 | import re
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> src/enhancers/bulk_spotify_enhancement.py:36:1
   |
34 | from datetime import datetime
35 | from dotenv import load_dotenv
36 | from typing import Optional, List, Dict, Any, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37 | import logging
38 | import re
   |

F401 [*] `typing.Tuple` imported but unused
  --> src/enhancers/bulk_spotify_enhancement.py:36:47
   |
34 | from datetime import datetime
35 | from dotenv import load_dotenv
36 | from typing import Optional, List, Dict, Any, Tuple
   |                                               ^^^^^
37 | import logging
38 | import re
   |
help: Remove unused import: `typing.Tuple`

RUF013 PEP 484 prohibits implicit `Optional`
  --> src/enhancers/bulk_spotify_enhancement.py:65:26
   |
64 |     def __init__(
65 |         self, client_id: str = None, client_secret: str = None, db_path: str = None
   |                          ^^^
66 |     ):
67 |         super().__init__(client_id, client_secret, db_path)
   |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
  --> src/enhancers/bulk_spotify_enhancement.py:65:53
   |
64 |     def __init__(
65 |         self, client_id: str = None, client_secret: str = None, db_path: str = None
   |                                                     ^^^
66 |     ):
67 |         super().__init__(client_id, client_secret, db_path)
   |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
  --> src/enhancers/bulk_spotify_enhancement.py:65:74
   |
64 |     def __init__(
65 |         self, client_id: str = None, client_secret: str = None, db_path: str = None
   |                                                                          ^^^
66 |     ):
67 |         super().__init__(client_id, client_secret, db_path)
   |
help: Convert to `T | None`

I001 [*] Import block is un-sorted or un-formatted
  --> src/enhancers/bulk_spotify_enhancement.py:86:9
   |
85 |           # SSL Ð¸ connection pool ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ
86 | /         import ssl
87 | |         import urllib3
   | |______________________^
88 |
89 |           # ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ warnings Ð´Ð»Ñ SSL ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹
   |
help: Organize imports

F401 [*] `ssl` imported but unused
  --> src/enhancers/bulk_spotify_enhancement.py:86:16
   |
85 |         # SSL Ð¸ connection pool ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ
86 |         import ssl
   |                ^^^
87 |         import urllib3
   |
help: Remove unused import: `ssl`

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
   --> src/enhancers/bulk_spotify_enhancement.py:116:9
    |
114 |       def _recreate_session(self):
115 |           """ÐŸÐµÑ€ÐµÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ HTTP session Ð´Ð»Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ SSL Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼"""
116 | /         try:
117 | |             self.session.close()
118 | |         except:
119 | |             pass
    | |________________^
120 |
121 |           # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²ÑƒÑŽ session
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
   --> src/enhancers/bulk_spotify_enhancement.py:118:9
    |
116 |         try:
117 |             self.session.close()
118 |         except:
    |         ^^^^^^
119 |             pass
    |

PLR0911 Too many return statements (7 > 6)
   --> src/enhancers/bulk_spotify_enhancement.py:137:9
    |
135 |         self.session.mount("https://", adapter)
136 |
137 |     def _make_request(self, endpoint: str, params: Dict = None) -> Optional[Dict]:
    |         ^^^^^^^^^^^^^
138 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ robust retry-Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð¾Ð¼"""
139 |         if not self.get_access_token():
    |

PLR0912 Too many branches (14 > 12)
   --> src/enhancers/bulk_spotify_enhancement.py:137:9
    |
135 |         self.session.mount("https://", adapter)
136 |
137 |     def _make_request(self, endpoint: str, params: Dict = None) -> Optional[Dict]:
    |         ^^^^^^^^^^^^^
138 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ robust retry-Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð¾Ð¼"""
139 |         if not self.get_access_token():
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/bulk_spotify_enhancement.py:137:52
    |
135 |         self.session.mount("https://", adapter)
136 |
137 |     def _make_request(self, endpoint: str, params: Dict = None) -> Optional[Dict]:
    |                                                    ^^^^
138 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ robust retry-Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð¾Ð¼"""
139 |         if not self.get_access_token():
    |
help: Replace with `dict`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src/enhancers/bulk_spotify_enhancement.py:137:52
    |
135 |         self.session.mount("https://", adapter)
136 |
137 |     def _make_request(self, endpoint: str, params: Dict = None) -> Optional[Dict]:
    |                                                    ^^^^
138 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ robust retry-Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð¾Ð¼"""
139 |         if not self.get_access_token():
    |
help: Convert to `T | None`

UP045 [*] Use `X | None` for type annotations
   --> src/enhancers/bulk_spotify_enhancement.py:137:68
    |
135 |         self.session.mount("https://", adapter)
136 |
137 |     def _make_request(self, endpoint: str, params: Dict = None) -> Optional[Dict]:
    |                                                                    ^^^^^^^^^^^^^^
138 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ robust retry-Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð¾Ð¼"""
139 |         if not self.get_access_token():
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/bulk_spotify_enhancement.py:137:77
    |
135 |         self.session.mount("https://", adapter)
136 |
137 |     def _make_request(self, endpoint: str, params: Dict = None) -> Optional[Dict]:
    |                                                                             ^^^^
138 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ robust retry-Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð¾Ð¼"""
139 |         if not self.get_access_token():
    |
help: Replace with `dict`

RET505 [*] Unnecessary `elif` after `return` statement
   --> src/enhancers/bulk_spotify_enhancement.py:171:17
    |
169 |                     return response.json()
170 |
171 |                 elif response.status_code == 429:
    |                 ^^^^
172 |                     # Rate limit exceeded
173 |                     retry_after = int(response.headers.get("Retry-After", 60))
    |
help: Remove unnecessary `elif`

RET507 [*] Unnecessary `else` after `continue` statement
   --> src/enhancers/bulk_spotify_enhancement.py:218:17
    |
217 |                     continue
218 |                 else:
    |                 ^^^^
219 |                     logger.error(f"Ð’ÑÐµ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ¸ Ð¸ÑÑ‡ÐµÑ€Ð¿Ð°Ð½Ñ‹ Ð´Ð»Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {url}")
220 |                     return None
    |
help: Remove unnecessary `else`

PLR0911 Too many return statements (7 > 6)
   --> src/enhancers/bulk_spotify_enhancement.py:228:9
    |
226 |         return None
227 |
228 |     def search_track_improved(self, track_name: str, artist_name: str) -> Optional[Any]:
    |         ^^^^^^^^^^^^^^^^^^^^^
229 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº Ñ‚Ñ€ÐµÐºÐ° Ñ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¼Ð¸ fallback ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÑÐ¼Ð¸"""
    |

UP045 [*] Use `X | None` for type annotations
   --> src/enhancers/bulk_spotify_enhancement.py:228:75
    |
226 |         return None
227 |
228 |     def search_track_improved(self, track_name: str, artist_name: str) -> Optional[Any]:
    |                                                                           ^^^^^^^^^^^^^
229 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº Ñ‚Ñ€ÐµÐºÐ° Ñ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¼Ð¸ fallback ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÑÐ¼Ð¸"""
    |
help: Convert to `X | None`

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:235:19
    |
233 |         # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚ÑŒ API
234 |         if not self.get_access_token():
235 |             print(f"      âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ access token")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
236 |             return None
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:245:15
    |
244 |         # Ð¡Ñ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ 1: Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº
245 |         print(f"      1ï¸âƒ£ ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÑŽ 'exact'...")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
246 |         result = self._try_search_strategy(clean_track, clean_artist, "exact")
247 |         if result:
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:250:19
    |
248 |             logger.debug(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹ 'exact': {track_name} - {artist_name}")
249 |             self.stats["strategies_used"]["exact"] += 1
250 |             print(f"      âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹ 'exact'!")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
251 |             return result
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:253:15
    |
251 |             return result
252 |
253 |         print(f"      ðŸ”„ Exact Ð½Ðµ ÑÑ€Ð°Ð±Ð¾Ñ‚Ð°Ð», Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð´Ñ€ÑƒÐ³Ð¸Ðµ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¸...")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
254 |
255 |         # Ð¡Ñ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ 2: Ð±Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ (Ð±ÐµÐ· ÑÐºÐ¾Ð±Ð¾Ðº, Ð²ÐµÑ€ÑÐ¸Ð¹)
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:265:23
    |
263 |                 )
264 |                 self.stats["strategies_used"]["basic"] += 1
265 |                 print(f"      âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹ 'basic'!")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
266 |                 return result
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:280:23
    |
278 |                 )
279 |                 self.stats["strategies_used"]["no_feat"] += 1
280 |                 print(f"      âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹ 'no_feat'!")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
281 |                 return result
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:293:23
    |
291 |                 )
292 |                 self.stats["strategies_used"]["keywords"] += 1
293 |                 print(f"      âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹ 'keywords'!")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
294 |                 return result
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:297:15
    |
296 |         # Ð¡Ñ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ 5: Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð±ÐµÐ· ÐºÐ°Ð²Ñ‹Ñ‡ÐµÐº
297 |         print(f"      5ï¸âƒ£ ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÑŽ 'simple'...")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
298 |         result = self._try_search_strategy(no_feat_track, clean_artist, "simple")
299 |         if result:
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:302:19
    |
300 |             logger.debug(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹ 'simple': {track_name} - {artist_name}")
301 |             self.stats["strategies_used"]["simple"] += 1
302 |             print(f"      âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹ 'simple'!")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
303 |             return result
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:306:15
    |
305 |         # ÐÐ¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾
306 |         print(f"      âŒ Ð¢Ñ€ÐµÐº Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð½Ð¸ Ð¾Ð´Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
307 |         self.stats["strategies_used"]["not_found"] += 1
    |
help: Remove extraneous `f` prefix

PLR0912 Too many branches (14 > 12)
   --> src/enhancers/bulk_spotify_enhancement.py:311:9
    |
309 |         return None
310 |
311 |     def _try_search_strategy(
    |         ^^^^^^^^^^^^^^^^^^^^
312 |         self, track_name: str, artist_name: str, strategy: str
313 |     ) -> Optional[Any]:
    |

UP045 [*] Use `X | None` for type annotations
   --> src/enhancers/bulk_spotify_enhancement.py:313:10
    |
311 |     def _try_search_strategy(
312 |         self, track_name: str, artist_name: str, strategy: str
313 |     ) -> Optional[Any]:
    |          ^^^^^^^^^^^^^
314 |         """ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ° Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹"""
315 |         try:
    |
help: Convert to `X | None`

SIM114 [*] Combine `if` branches using logical `or` operator
   --> src/enhancers/bulk_spotify_enhancement.py:316:13
    |
314 |           """ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ° Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹"""
315 |           try:
316 | /             if strategy == "exact":
317 | |                 query = f'track:"{track_name}" artist:"{artist_name}"'
318 | |             elif strategy == "basic":
319 | |                 query = f'track:"{track_name}" artist:"{artist_name}"'
    | |______________________________________________________________________^
320 |               elif strategy == "no_feat":
321 |                   query = f'track:"{track_name}" artist:"{artist_name}"'
    |
help: Combine `if` branches

SIM114 [*] Combine `if` branches using logical `or` operator
   --> src/enhancers/bulk_spotify_enhancement.py:318:13
    |
316 |               if strategy == "exact":
317 |                   query = f'track:"{track_name}" artist:"{artist_name}"'
318 | /             elif strategy == "basic":
319 | |                 query = f'track:"{track_name}" artist:"{artist_name}"'
320 | |             elif strategy == "no_feat":
321 | |                 query = f'track:"{track_name}" artist:"{artist_name}"'
    | |______________________________________________________________________^
322 |               elif strategy == "keywords":
323 |                   query = f'"{track_name}" artist:"{artist_name}"'
    |
help: Combine `if` branches

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:343:23
    |
341 |             data = self._make_request("search", params)
342 |             if not data:
343 |                 print(f"        âŒ ÐÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ API")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
344 |                 return None
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:347:23
    |
346 |             if "tracks" not in data:
347 |                 print(f"        âŒ ÐÐµÑ‚ Ñ‚Ñ€ÐµÐºÐ¾Ð² Ð² Ð¾Ñ‚Ð²ÐµÑ‚Ðµ API")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
348 |                 return None
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:352:23
    |
350 |             tracks = data["tracks"]["items"]
351 |             if not tracks:
352 |                 print(f"        âŒ ÐŸÑƒÑÑ‚Ð¾Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ñ‚Ñ€ÐµÐºÐ¾Ð²")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
353 |                 return None
    |
help: Remove extraneous `f` prefix

RET505 [*] Unnecessary `else` after `return` statement
   --> src/enhancers/bulk_spotify_enhancement.py:366:13
    |
364 |                 )
365 |                 return self._create_spotify_track(best_match)
366 |             else:
    |             ^^^^
367 |                 print(
368 |                     f"        âŒ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ð¹ match ÑÑ€ÐµÐ´Ð¸ {len(tracks)} Ñ‚Ñ€ÐµÐºÐ¾Ð²"
    |
help: Remove unnecessary `else`

F601 Dictionary key literal `'"'` repeated
   --> src/enhancers/bulk_spotify_enhancement.py:390:13
    |
388 |             """: "'",
389 |             '"': '"',
390 |             '"': '"',
    |             ^^^
391 |             "â€“": "-",
392 |             "â€”": "-",
    |
help: Remove repeated key literal `'"'`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/enhancers/bulk_spotify_enhancement.py:574:17
    |
572 |     def _find_best_match(
573 |         self,
574 |         tracks: List[Dict],
    |                 ^^^^
575 |         target_track: str,
576 |         target_artist: str,
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/bulk_spotify_enhancement.py:574:22
    |
572 |     def _find_best_match(
573 |         self,
574 |         tracks: List[Dict],
    |                      ^^^^
575 |         target_track: str,
576 |         target_artist: str,
    |
help: Replace with `dict`

ARG002 Unused method argument: `strategy`
   --> src/enhancers/bulk_spotify_enhancement.py:577:9
    |
575 |         target_track: str,
576 |         target_artist: str,
577 |         strategy: str = "exact",
    |         ^^^^^^^^
578 |     ) -> Optional[Dict]:
579 |         """ÐŸÐ¾Ð¸ÑÐº Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ ÑÑ€ÐµÐ´Ð¸ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð²"""
    |

UP045 [*] Use `X | None` for type annotations
   --> src/enhancers/bulk_spotify_enhancement.py:578:10
    |
576 |         target_artist: str,
577 |         strategy: str = "exact",
578 |     ) -> Optional[Dict]:
    |          ^^^^^^^^^^^^^^
579 |         """ÐŸÐ¾Ð¸ÑÐº Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ ÑÑ€ÐµÐ´Ð¸ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð²"""
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/bulk_spotify_enhancement.py:578:19
    |
576 |         target_artist: str,
577 |         strategy: str = "exact",
578 |     ) -> Optional[Dict]:
    |                   ^^^^
579 |         """ÐŸÐ¾Ð¸ÑÐº Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ ÑÑ€ÐµÐ´Ð¸ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð²"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/bulk_spotify_enhancement.py:581:42
    |
579 |         """ÐŸÐ¾Ð¸ÑÐº Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ ÑÑ€ÐµÐ´Ð¸ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð²"""
580 |
581 |         def similarity_score(track_data: Dict) -> float:
    |                                          ^^^^
582 |             """ÐžÑ†ÐµÐ½ÐºÐ° ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ Ñ‚Ñ€ÐµÐºÐ°"""
583 |             score = 0
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/bulk_spotify_enhancement.py:625:49
    |
623 |         return None
624 |
625 |     def _create_spotify_track(self, track_data: Dict) -> Any:
    |                                                 ^^^^
626 |         """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ð° SpotifyTrack Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ… API"""
627 |         try:
    |
help: Replace with `dict`

N806 Variable `SpotifyTrack` in function should be lowercase
   --> src/enhancers/bulk_spotify_enhancement.py:640:17
    |
638 |                             setattr(self, key, value)
639 |
640 |                 SpotifyTrack = SimpleSpotifyTrack
    |                 ^^^^^^^^^^^^
641 |
642 |         return SpotifyTrack(
    |

PLR0912 Too many branches (15 > 12)
   --> src/enhancers/bulk_spotify_enhancement.py:682:9
    |
680 |         self.checkpoint_file = "results/spotify_enhancement_checkpoint.json"
681 |
682 |     def enhance_all_tracks_improved(self, start_from: int = 0, batch_size: int = 1000):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
683 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ðµ Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ðµ Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ñ checkpoint'Ð°Ð¼Ð¸"""
684 |         print("ðŸŽµ Ð£Ð›Ð£Ð§Ð¨Ð•ÐÐÐžÐ• ÐœÐÐ¡Ð¡ÐžÐ’ÐžÐ• ÐžÐ‘ÐžÐ“ÐÐ©Ð•ÐÐ˜Ð• Ð¢Ð Ð•ÐšÐžÐ’")
    |

PLR0915 Too many statements (60 > 50)
   --> src/enhancers/bulk_spotify_enhancement.py:682:9
    |
680 |         self.checkpoint_file = "results/spotify_enhancement_checkpoint.json"
681 |
682 |     def enhance_all_tracks_improved(self, start_from: int = 0, batch_size: int = 1000):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
683 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ðµ Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ðµ Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ñ checkpoint'Ð°Ð¼Ð¸"""
684 |         print("ðŸŽµ Ð£Ð›Ð£Ð§Ð¨Ð•ÐÐÐžÐ• ÐœÐÐ¡Ð¡ÐžÐ’ÐžÐ• ÐžÐ‘ÐžÐ“ÐÐ©Ð•ÐÐ˜Ð• Ð¢Ð Ð•ÐšÐžÐ’")
    |

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:711:19
    |
710 |         if not tracks:
711 |             print(f"ðŸŽ‰ Ð’ÑÐµ Ñ‚Ñ€ÐµÐºÐ¸ ÑƒÐ¶Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ñ‹!")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
712 |             return
    |
help: Remove extraneous `f` prefix

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/enhancers/bulk_spotify_enhancement.py:717:36
    |
715 |         print(f"ðŸ“Š Ð’ÑÐµÐ³Ð¾ Ñ‚Ñ€ÐµÐºÐ¾Ð² Ð² Ð±Ð°Ñ‚Ñ‡Ðµ: {len(tracks)}")
716 |
717 |         self.stats["start_time"] = datetime.now()
    |                                    ^^^^^^^^^^^^^^
718 |
719 |         try:
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/enhancers/bulk_spotify_enhancement.py:760:17
    |
758 |                           time.sleep(0.15)  # ÐžÐ±Ñ‹Ñ‡Ð½Ð°Ñ Ð¿Ð°ÑƒÐ·Ð°
759 |
760 | /                 except KeyboardInterrupt:
761 | |                     print(f"\nâ¹ï¸ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ ÑÐ¸Ð³Ð½Ð°Ð» Ð¿Ñ€ÐµÑ€Ñ‹Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ñ‚Ñ€ÐµÐºÐ° {i}")
762 | |                     current_id = song_id
763 | |                     self._save_checkpoint(current_id)
764 | |                     raise  # ÐŸÑ€Ð¾Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ KeyboardInterrupt Ð²Ñ‹ÑˆÐµ
    | |_________________________^
765 |
766 |           except KeyboardInterrupt:
    |

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:767:19
    |
766 |         except KeyboardInterrupt:
767 |             print(f"\nâ¹ï¸ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
768 |             if "i" in locals() and i > 0:
769 |                 current_id = tracks[i - 1][0] if i > 0 else start_from
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:772:23
    |
770 |                 self._save_checkpoint(current_id)
771 |             else:
772 |                 print(f"âš ï¸ ÐŸÑ€ÐµÑ€Ñ‹Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð¾ Ð´Ð¾ Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
773 |         except Exception as e:
774 |             print(f"\nâŒ ÐÐµÐ¾Ð¶Ð¸Ð´Ð°Ð½Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {e}")
    |
help: Remove extraneous `f` prefix

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/bulk_spotify_enhancement.py:783:72
    |
781 |         self._clear_checkpoint()
782 |
783 |     def _process_track(self, song_id: int, title: str, artist: str) -> Dict[str, Any]:
    |                                                                        ^^^^
784 |         """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚Ñ€ÐµÐºÐ° Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ð¹ Ð»Ð¾Ð³Ð¸ÐºÐ¾Ð¹"""
    |
help: Replace with `dict`

RET505 [*] Unnecessary `else` after `return` statement
   --> src/enhancers/bulk_spotify_enhancement.py:804:13
    |
802 |                     "processing_time": time.time() - start_time,
803 |                 }
804 |             else:
    |             ^^^^
805 |                 return {
806 |                     "success": False,
    |
help: Remove unnecessary `else`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/enhancers/bulk_spotify_enhancement.py:864:13
    |
862 |               # ÐšÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ stats Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ datetime Ð² ÑÑ‚Ñ€Ð¾ÐºÑƒ
863 |               stats_copy = self.stats.copy()
864 | /             if "start_time" in stats_copy and stats_copy["start_time"]:
865 | |                 if isinstance(stats_copy["start_time"], datetime):
    | |__________________________________________________________________^
866 |                       stats_copy["start_time"] = stats_copy["start_time"].isoformat()
    |
help: Combine `if` statements using `and`

RUF019 [*] Unnecessary key check before dictionary access
   --> src/enhancers/bulk_spotify_enhancement.py:864:16
    |
862 |             # ÐšÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ stats Ð¸ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ datetime Ð² ÑÑ‚Ñ€Ð¾ÐºÑƒ
863 |             stats_copy = self.stats.copy()
864 |             if "start_time" in stats_copy and stats_copy["start_time"]:
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
865 |                 if isinstance(stats_copy["start_time"], datetime):
866 |                     stats_copy["start_time"] = stats_copy["start_time"].isoformat()
    |
help: Replace with `dict.get`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/enhancers/bulk_spotify_enhancement.py:870:30
    |
868 |             checkpoint_data = {
869 |                 "last_processed_id": current_id,
870 |                 "timestamp": datetime.now().isoformat(),
    |                              ^^^^^^^^^^^^^^
871 |                 "stats": stats_copy,
872 |             }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   --> src/enhancers/bulk_spotify_enhancement.py:875:13
    |
874 |             # Ð£Ð±ÐµÐ´Ð¸Ð¼ÑÑ, Ñ‡Ñ‚Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚
875 |             os.makedirs(os.path.dirname(self.checkpoint_file), exist_ok=True)
    |             ^^^^^^^^^^^
876 |
877 |             with open(self.checkpoint_file, "w", encoding="utf-8") as f:
    |
help: Replace with `Path(...).mkdir(parents=True)`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
   --> src/enhancers/bulk_spotify_enhancement.py:875:25
    |
874 |             # Ð£Ð±ÐµÐ´Ð¸Ð¼ÑÑ, Ñ‡Ñ‚Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚
875 |             os.makedirs(os.path.dirname(self.checkpoint_file), exist_ok=True)
    |                         ^^^^^^^^^^^^^^^
876 |
877 |             with open(self.checkpoint_file, "w", encoding="utf-8") as f:
    |
help: Replace with `Path(...).parent`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/enhancers/bulk_spotify_enhancement.py:877:18
    |
875 |             os.makedirs(os.path.dirname(self.checkpoint_file), exist_ok=True)
876 |
877 |             with open(self.checkpoint_file, "w", encoding="utf-8") as f:
    |                  ^^^^
878 |                 json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)
    |
help: Replace with `Path.open()`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> src/enhancers/bulk_spotify_enhancement.py:890:16
    |
888 |         """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° checkpoint Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹"""
889 |         try:
890 |             if os.path.exists(self.checkpoint_file):
    |                ^^^^^^^^^^^^^^
891 |                 with open(self.checkpoint_file, "r", encoding="utf-8") as f:
892 |                     data = json.load(f)
    |
help: Replace with `Path(...).exists()`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/enhancers/bulk_spotify_enhancement.py:891:22
    |
889 |         try:
890 |             if os.path.exists(self.checkpoint_file):
891 |                 with open(self.checkpoint_file, "r", encoding="utf-8") as f:
    |                      ^^^^
892 |                     data = json.load(f)
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> src/enhancers/bulk_spotify_enhancement.py:891:49
    |
889 |         try:
890 |             if os.path.exists(self.checkpoint_file):
891 |                 with open(self.checkpoint_file, "r", encoding="utf-8") as f:
    |                                                 ^^^
892 |                     data = json.load(f)
    |
help: Remove mode argument

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> src/enhancers/bulk_spotify_enhancement.py:907:16
    |
905 |         """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° checkpoint Ð¿Ð¾ÑÐ»Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ"""
906 |         try:
907 |             if os.path.exists(self.checkpoint_file):
    |                ^^^^^^^^^^^^^^
908 |                 os.remove(self.checkpoint_file)
909 |                 print("ðŸ“ Checkpoint Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½")
    |
help: Replace with `Path(...).exists()`

PTH107 `os.remove()` should be replaced by `Path.unlink()`
   --> src/enhancers/bulk_spotify_enhancement.py:908:17
    |
906 |         try:
907 |             if os.path.exists(self.checkpoint_file):
908 |                 os.remove(self.checkpoint_file)
    |                 ^^^^^^^^^
909 |                 print("ðŸ“ Checkpoint Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½")
910 |         except Exception as e:
    |
help: Replace with `Path(...).unlink()`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/enhancers/bulk_spotify_enhancement.py:933:23
    |
932 |         if self.stats["start_time"]:
933 |             elapsed = datetime.now() - self.stats["start_time"]
    |                       ^^^^^^^^^^^^^^
934 |             print(f"â±ï¸ Ð’Ñ€ÐµÐ¼Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹: {elapsed}")
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:936:15
    |
934 |             print(f"â±ï¸ Ð’Ñ€ÐµÐ¼Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹: {elapsed}")
935 |
936 |         print(f"ðŸŽµ Ð¢Ñ€ÐµÐºÐ¸:")
    |               ^^^^^^^^^^^^
937 |         print(f"   â€¢ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾: {self.stats['tracks_processed']}")
938 |         print(f"   â€¢ Ð£ÑÐ¿ÐµÑˆÐ½Ð¾: {self.stats['tracks_success']}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:951:19
    |
949 |         # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº
950 |         if self.stats["errors"]:
951 |             print(f"\nâŒ Ð¢Ð¸Ð¿Ñ‹ Ð¾ÑˆÐ¸Ð±Ð¾Ðº:")
    |                   ^^^^^^^^^^^^^^^^^^^^
952 |             for error_type, count in self.stats["errors"].items():
953 |                 print(f"   â€¢ {error_type}: {count}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/bulk_spotify_enhancement.py:957:15
    |
955 |         # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð±Ð°Ð·Ñ‹
956 |         db_stats = self.enhancer.get_stats()
957 |         print(f"\nðŸ“Š Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ Ð‘ÐÐ—Ð«:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^
958 |         for key, value in db_stats.items():
959 |             print(f"   â€¢ {key}: {value}")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/enhancers/spotify_analysis_utils.py:25:1
   |
23 |   """
24 |
25 | / import asyncio
26 | | import json
27 | | import sys
28 | | import os
29 | | from datetime import datetime
30 | | from typing import Dict, List, Any
   | |__________________________________^
31 |
32 |   # Add src to path
   |
help: Organize imports

F401 [*] `asyncio` imported but unused
  --> src/enhancers/spotify_analysis_utils.py:25:8
   |
23 | """
24 |
25 | import asyncio
   |        ^^^^^^^
26 | import json
27 | import sys
   |
help: Remove unused import: `asyncio`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/enhancers/spotify_analysis_utils.py:30:1
   |
28 | import os
29 | from datetime import datetime
30 | from typing import Dict, List, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
31 |
32 | # Add src to path
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/enhancers/spotify_analysis_utils.py:30:1
   |
28 | import os
29 | from datetime import datetime
30 | from typing import Dict, List, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
31 |
32 | # Add src to path
   |

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
  --> src/enhancers/spotify_analysis_utils.py:33:17
   |
32 | # Add src to path
33 | sys.path.append(os.path.join(os.path.dirname(__file__), ".."))
   |                 ^^^^^^^^^^^^
34 | from database.postgres_adapter import PostgreSQLAdapter
   |

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/enhancers/spotify_analysis_utils.py:33:30
   |
32 | # Add src to path
33 | sys.path.append(os.path.join(os.path.dirname(__file__), ".."))
   |                              ^^^^^^^^^^^^^^^
34 | from database.postgres_adapter import PostgreSQLAdapter
   |
help: Replace with `Path(...).parent`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/enhancers/spotify_analysis_utils.py:43:43
   |
41 |         self.db = PostgreSQLAdapter()
42 |
43 |     async def get_detailed_stats(self) -> Dict[str, Any]:
   |                                           ^^^^
44 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ð¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸"""
45 |         await self.db.connect()
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/spotify_analysis_utils.py:138:48
    |
136 |         return stats
137 |
138 |     async def find_problematic_tracks(self) -> Dict[str, List]:
    |                                                ^^^^
139 |         """ÐŸÐ¾Ð¸ÑÐº Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸"""
140 |         await self.db.connect()
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/enhancers/spotify_analysis_utils.py:138:58
    |
136 |         return stats
137 |
138 |     async def find_problematic_tracks(self) -> Dict[str, List]:
    |                                                          ^^^^
139 |         """ÐŸÐ¾Ð¸ÑÐº Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸"""
140 |         await self.db.connect()
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/spotify_analysis_utils.py:178:45
    |
176 |         return {"long_titles": long_titles, "special_characters": special_chars}
177 |
178 |     def get_artist_coverage_report(self) -> Dict[str, Any]:
    |                                             ^^^^
179 |         """ÐžÑ‚Ñ‡ÐµÑ‚ Ð¿Ð¾ Ð¿Ð¾ÐºÑ€Ñ‹Ñ‚Ð¸ÑŽ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²"""
180 |         conn = sqlite3.connect(self.db_path)
    |
help: Replace with `dict`

F821 Undefined name `sqlite3`
   --> src/enhancers/spotify_analysis_utils.py:180:16
    |
178 |     def get_artist_coverage_report(self) -> Dict[str, Any]:
179 |         """ÐžÑ‚Ñ‡ÐµÑ‚ Ð¿Ð¾ Ð¿Ð¾ÐºÑ€Ñ‹Ñ‚Ð¸ÑŽ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²"""
180 |         conn = sqlite3.connect(self.db_path)
    |                ^^^^^^^
181 |
182 |         # ÐÑ€Ñ‚Ð¸ÑÑ‚Ñ‹ Ñ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ð¾Ð¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð²
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/spotify_analysis_utils.py:232:47
    |
230 |         return coverage_groups
231 |
232 |     def suggest_optimization_targets(self) -> Dict[str, List]:
    |                                               ^^^^
233 |         """ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ°"""
234 |         conn = sqlite3.connect(self.db_path)
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/enhancers/spotify_analysis_utils.py:232:57
    |
230 |         return coverage_groups
231 |
232 |     def suggest_optimization_targets(self) -> Dict[str, List]:
    |                                                         ^^^^
233 |         """ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ°"""
234 |         conn = sqlite3.connect(self.db_path)
    |
help: Replace with `list`

F821 Undefined name `sqlite3`
   --> src/enhancers/spotify_analysis_utils.py:234:16
    |
232 |     def suggest_optimization_targets(self) -> Dict[str, List]:
233 |         """ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ°"""
234 |         conn = sqlite3.connect(self.db_path)
    |                ^^^^^^^
235 |
236 |         suggestions = {}
    |

RUF013 PEP 484 prohibits implicit `Optional`
   --> src/enhancers/spotify_analysis_utils.py:273:48
    |
271 |         return suggestions
272 |
273 |     def export_analysis_report(self, filename: str = None):
    |                                                ^^^
274 |         """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
275 |         if not filename:
    |
help: Convert to `T | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/enhancers/spotify_analysis_utils.py:276:25
    |
274 |         """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"""
275 |         if not filename:
276 |             timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    |                         ^^^^^^^^^^^^^^
277 |             filename = f"spotify_analysis_report_{timestamp}.json"
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/enhancers/spotify_analysis_utils.py:280:26
    |
279 |         report = {
280 |             "timestamp": datetime.now().isoformat(),
    |                          ^^^^^^^^^^^^^^
281 |             "detailed_stats": self.get_detailed_stats(),
282 |             "problematic_tracks": self.find_problematic_tracks(),
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

PTH123 `open()` should be replaced by `Path.open()`
   --> src/enhancers/spotify_analysis_utils.py:291:14
    |
289 |             filename = f"results/{filename}"
290 |
291 |         with open(filename, "w", encoding="utf-8") as f:
    |              ^^^^
292 |             json.dump(report, f, ensure_ascii=False, indent=2)
    |
help: Replace with `Path.open()`

F541 [*] f-string without any placeholders
   --> src/enhancers/spotify_analysis_utils.py:308:11
    |
306 |     stats = analyzer.get_detailed_stats()
307 |
308 |     print(f"ðŸ“ˆ ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^
309 |     print(f"   â€¢ Ð’ÑÐµÐ³Ð¾ Ñ‚Ñ€ÐµÐºÐ¾Ð²: {stats['total_songs']:,}")
310 |     print(f"   â€¢ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ Ñ‚Ñ€ÐµÐºÐ¾Ð²: {stats['spotify_tracks']:,}")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/spotify_analysis_utils.py:318:15
    |
317 |     if "popularity" in stats:
318 |         print(f"ðŸ“Š ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ð¾ÑÑ‚ÑŒ Ñ‚Ñ€ÐµÐºÐ¾Ð²:")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^
319 |         print(f"   â€¢ Ð¡Ñ€ÐµÐ´Ð½ÑÑ: {stats['popularity']['avg']}")
320 |         print(
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/spotify_analysis_utils.py:324:11
    |
322 |         )
323 |
324 |     print(f"\nðŸŽ¤ Ð¢Ð¾Ð¿ Ð½ÐµÐ¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
325 |     for artist, count in stats["top_unprocessed_artists"][:5]:
326 |         print(f"   â€¢ {artist}: {count} Ñ‚Ñ€ÐµÐºÐ¾Ð²")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/spotify_analysis_utils.py:328:11
    |
326 |         print(f"   â€¢ {artist}: {count} Ñ‚Ñ€ÐµÐºÐ¾Ð²")
327 |
328 |     print(f"\nâœ… Ð¢Ð¾Ð¿ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
329 |     for artist, count in stats["top_processed_artists"][:5]:
330 |         print(f"   â€¢ {artist}: {count} Ñ‚Ñ€ÐµÐºÐ¾Ð²")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/spotify_analysis_utils.py:335:11
    |
333 |     suggestions = analyzer.suggest_optimization_targets()
334 |
335 |     print(f"ðŸ”¥ ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð½Ñ‹Ðµ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ñ‹ (Ð¼Ð½Ð¾Ð³Ð¾ Ð½ÐµÐ¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð²):")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
336 |     for artist, count in suggestions["high_volume_artists"][:5]:
337 |         print(f"   â€¢ {artist}: {count} Ñ‚Ñ€ÐµÐºÐ¾Ð²")
    |
help: Remove extraneous `f` prefix

F541 [*] f-string without any placeholders
   --> src/enhancers/spotify_analysis_utils.py:346:11
    |
344 |     coverage = analyzer.get_artist_coverage_report()
345 |
346 |     print(f"ðŸ“Š ÐŸÐ¾ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ Ð¿Ð¾ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°Ð¼:")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
347 |     print(f"   â€¢ Ð‘ÐµÐ· Ð¿Ð¾ÐºÑ€Ñ‹Ñ‚Ð¸Ñ (0%): {len(coverage['no_coverage'])} Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²")
348 |     print(f"   â€¢ ÐÐ¸Ð·ÐºÐ¾Ðµ Ð¿Ð¾ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ (1-25%): {len(coverage['low_coverage'])} Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/enhancers/spotify_enhancer.py:31:1
   |
29 |   """
30 |
31 | / import asyncio
32 | | import json
33 | | import logging
34 | | import os
35 | | import time
36 | | from typing import Dict, Any, List, Optional
37 | | import sys
38 | | from pathlib import Path
39 | | from dotenv import load_dotenv
   | |______________________________^
40 |
41 |   # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/enhancers/spotify_enhancer.py:36:1
   |
34 | import os
35 | import time
36 | from typing import Dict, Any, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37 | import sys
38 | from pathlib import Path
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/enhancers/spotify_enhancer.py:36:1
   |
34 | import os
35 | import time
36 | from typing import Dict, Any, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37 | import sys
38 | from pathlib import Path
   |

E402 Module level import not at top of file
  --> src/enhancers/spotify_enhancer.py:55:1
   |
53 |     print("WARNING: python-dotenv Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ")
54 |
55 | from src.database.postgres_adapter import PostgreSQLManager
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
56 |
57 | # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ðµ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
   |

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   --> src/enhancers/spotify_enhancer.py:119:25
    |
118 |             # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÐºÐµÑˆÐµÐ¼
119 |             cache_dir = os.path.join(os.getcwd(), "data")
    |                         ^^^^^^^^^^^^
120 |             os.makedirs(cache_dir, exist_ok=True)
121 |             cache_path = os.path.join(cache_dir, ".cache")
    |

PTH109 `os.getcwd()` should be replaced by `Path.cwd()`
   --> src/enhancers/spotify_enhancer.py:119:38
    |
118 |             # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÐºÐµÑˆÐµÐ¼
119 |             cache_dir = os.path.join(os.getcwd(), "data")
    |                                      ^^^^^^^^^
120 |             os.makedirs(cache_dir, exist_ok=True)
121 |             cache_path = os.path.join(cache_dir, ".cache")
    |
help: Replace with `Path.cwd()`

PTH103 `os.makedirs()` should be replaced by `Path.mkdir(parents=True)`
   --> src/enhancers/spotify_enhancer.py:120:13
    |
118 |             # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÐºÐµÑˆÐµÐ¼
119 |             cache_dir = os.path.join(os.getcwd(), "data")
120 |             os.makedirs(cache_dir, exist_ok=True)
    |             ^^^^^^^^^^^
121 |             cache_path = os.path.join(cache_dir, ".cache")
    |
help: Replace with `Path(...).mkdir(parents=True)`

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   --> src/enhancers/spotify_enhancer.py:121:26
    |
119 |             cache_dir = os.path.join(os.getcwd(), "data")
120 |             os.makedirs(cache_dir, exist_ok=True)
121 |             cache_path = os.path.join(cache_dir, ".cache")
    |                          ^^^^^^^^^^^^
122 |
123 |             # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ spotipy
    |

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
   --> src/enhancers/spotify_enhancer.py:130:26
    |
129 | â€¦     # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð´Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
130 | â€¦     root_cache = os.path.join(os.getcwd(), ".cache")
    |                    ^^^^^^^^^^^^
131 | â€¦     logger.info(
132 | â€¦         f"ðŸ“ ÐŸÐµÑ€ÐµÐ´ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸ÐµÐ¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°: .cache Ð² ÐºÐ¾Ñ€Ð½Ðµ {'Ð•Ð¡Ð¢Ð¬' if os.path.exists(root_cache) else 'ÐÐ•Ð¢'}"
    |

PTH109 `os.getcwd()` should be replaced by `Path.cwd()`
   --> src/enhancers/spotify_enhancer.py:130:39
    |
129 | â€¦     # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð´Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
130 | â€¦     root_cache = os.path.join(os.getcwd(), ".cache")
    |                                 ^^^^^^^^^
131 | â€¦     logger.info(
132 | â€¦         f"ðŸ“ ÐŸÐµÑ€ÐµÐ´ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸ÐµÐ¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°: .cache Ð² ÐºÐ¾Ñ€Ð½Ðµ {'Ð•Ð¡Ð¢Ð¬' if os.path.exists(root_cache) else 'ÐÐ•Ð¢'}"
    |
help: Replace with `Path.cwd()`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> src/enhancers/spotify_enhancer.py:132:72
    |
130 | â€¦     root_cache = os.path.join(os.getcwd(), ".cache")
131 | â€¦     logger.info(
132 | â€¦         f"ðŸ“ ÐŸÐµÑ€ÐµÐ´ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸ÐµÐ¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°: .cache Ð² ÐºÐ¾Ñ€Ð½Ðµ {'Ð•Ð¡Ð¢Ð¬' if os.path.exists(root_cache) else 'ÐÐ•Ð¢'}"
    |                                                                   ^^^^^^^^^^^^^^
133 | â€¦     )
    |
help: Replace with `Path(...).exists()`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> src/enhancers/spotify_enhancer.py:136:16
    |
135 |             # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ ÐºÐµÑˆ Ð² ÐºÐ¾Ñ€Ð½Ðµ
136 |             if os.path.exists(root_cache):
    |                ^^^^^^^^^^^^^^
137 |                 logger.info("ðŸ—‘ï¸ Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ .cache Ð² ÐºÐ¾Ñ€Ð½Ðµ")
138 |                 os.remove(root_cache)
    |
help: Replace with `Path(...).exists()`

PTH107 `os.remove()` should be replaced by `Path.unlink()`
   --> src/enhancers/spotify_enhancer.py:138:17
    |
136 |             if os.path.exists(root_cache):
137 |                 logger.info("ðŸ—‘ï¸ Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹ .cache Ð² ÐºÐ¾Ñ€Ð½Ðµ")
138 |                 os.remove(root_cache)
    |                 ^^^^^^^^^
139 |
140 |             # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ spotify ÐºÐ»Ð¸ÐµÐ½Ñ‚
    |
help: Replace with `Path(...).unlink()`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> src/enhancers/spotify_enhancer.py:151:71
    |
149 | â€¦     # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¿Ð¾ÑÐ»Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ
150 | â€¦     logger.info(
151 | â€¦         f"ðŸ“ ÐŸÐ¾ÑÐ»Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°: .cache Ð² ÐºÐ¾Ñ€Ð½Ðµ {'Ð•Ð¡Ð¢Ð¬' if os.path.exists(root_cache) else 'ÐÐ•Ð¢'}"
    |                                                                  ^^^^^^^^^^^^^^
152 | â€¦     )
153 | â€¦     logger.info(
    |
help: Replace with `Path(...).exists()`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> src/enhancers/spotify_enhancer.py:154:71
    |
152 | â€¦     )
153 | â€¦     logger.info(
154 | â€¦         f"ðŸ“ ÐŸÐ¾ÑÐ»Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°: .cache Ð² data/ {'Ð•Ð¡Ð¢Ð¬' if os.path.exists(cache_path) else 'ÐÐ•Ð¢'}"
    |                                                                  ^^^^^^^^^^^^^^
155 | â€¦     )
    |
help: Replace with `Path(...).exists()`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> src/enhancers/spotify_enhancer.py:163:65
    |
161 |             # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¿Ð¾ÑÐ»Ðµ API Ð²Ñ‹Ð·Ð¾Ð²Ð°
162 |             logger.info(
163 |                 f"ðŸ“ ÐŸÐ¾ÑÐ»Ðµ API Ð²Ñ‹Ð·Ð¾Ð²Ð°: .cache Ð² ÐºÐ¾Ñ€Ð½Ðµ {'Ð•Ð¡Ð¢Ð¬' if os.path.exists(root_cache) else 'ÐÐ•Ð¢'}"
    |                                                                  ^^^^^^^^^^^^^^
164 |             )
165 |             logger.info(
    |
help: Replace with `Path(...).exists()`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> src/enhancers/spotify_enhancer.py:166:65
    |
164 |             )
165 |             logger.info(
166 |                 f"ðŸ“ ÐŸÐ¾ÑÐ»Ðµ API Ð²Ñ‹Ð·Ð¾Ð²Ð°: .cache Ð² data/ {'Ð•Ð¡Ð¢Ð¬' if os.path.exists(cache_path) else 'ÐÐ•Ð¢'}"
    |                                                                  ^^^^^^^^^^^^^^
167 |             )
    |
help: Replace with `Path(...).exists()`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> src/enhancers/spotify_enhancer.py:170:16
    |
169 |             # ÐŸÐµÑ€ÐµÐ¼ÐµÑ‰Ð°ÐµÐ¼ ÐºÐµÑˆ ÐµÑÐ»Ð¸ Ð¾Ð½ ÑÐ¾Ð·Ð´Ð°Ð»ÑÑ Ð² ÐºÐ¾Ñ€Ð½Ðµ
170 |             if os.path.exists(root_cache):
    |                ^^^^^^^^^^^^^^
171 |                 logger.warning(
172 |                     f"âš ï¸ .cache ÑÐ¾Ð·Ð´Ð°Ð½ Ð² ÐºÐ¾Ñ€Ð½Ðµ Ð¿Ð¾ÑÐ»Ðµ API Ð²Ñ‹Ð·Ð¾Ð²Ð°! ÐŸÐµÑ€ÐµÐ¼ÐµÑ‰Ð°ÐµÐ¼ Ð² {cache_path}"
    |
help: Replace with `Path(...).exists()`

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
   --> src/enhancers/spotify_enhancer.py:174:20
    |
172 |                     f"âš ï¸ .cache ÑÐ¾Ð·Ð´Ð°Ð½ Ð² ÐºÐ¾Ñ€Ð½Ðµ Ð¿Ð¾ÑÐ»Ðµ API Ð²Ñ‹Ð·Ð¾Ð²Ð°! ÐŸÐµÑ€ÐµÐ¼ÐµÑ‰Ð°ÐµÐ¼ Ð² {cache_path}"
173 |                 )
174 |                 if os.path.exists(cache_path):
    |                    ^^^^^^^^^^^^^^
175 |                     os.remove(cache_path)
176 |                 os.rename(root_cache, cache_path)
    |
help: Replace with `Path(...).exists()`

PTH107 `os.remove()` should be replaced by `Path.unlink()`
   --> src/enhancers/spotify_enhancer.py:175:21
    |
173 |                 )
174 |                 if os.path.exists(cache_path):
175 |                     os.remove(cache_path)
    |                     ^^^^^^^^^
176 |                 os.rename(root_cache, cache_path)
177 |                 logger.info("âœ… ÐšÐµÑˆ Ð¿ÐµÑ€ÐµÐ¼ÐµÑ‰ÐµÐ½ Ð² data/")
    |
help: Replace with `Path(...).unlink()`

PTH104 `os.rename()` should be replaced by `Path.rename()`
   --> src/enhancers/spotify_enhancer.py:176:17
    |
174 |                 if os.path.exists(cache_path):
175 |                     os.remove(cache_path)
176 |                 os.rename(root_cache, cache_path)
    |                 ^^^^^^^^^
177 |                 logger.info("âœ… ÐšÐµÑˆ Ð¿ÐµÑ€ÐµÐ¼ÐµÑ‰ÐµÐ½ Ð² data/")
    |
help: Replace with `Path(...).rename(...)`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/enhancers/spotify_enhancer.py:181:22
    |
179 | â€¦     # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ñ„Ð°Ð¹Ð»-Ð·Ð°Ð³Ð»ÑƒÑˆÐºÑƒ Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð² ÐºÐ¾Ñ€Ð½Ðµ
180 | â€¦     try:
181 | â€¦         with open(root_cache, "w") as f:
    |                ^^^^
182 | â€¦             f.write(
183 | â€¦                 "# Ð­Ñ‚Ð¾Ñ‚ Ñ„Ð°Ð¹Ð» Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÐµÑ‚ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÐºÐµÑˆÐ° Ð² ÐºÐ¾Ñ€Ð½Ðµ\n# Ð ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐµÑˆ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² data/.cache\n"
    |
help: Replace with `Path.open()`

PTH101 `os.chmod()` should be replaced by `Path.chmod()`
   --> src/enhancers/spotify_enhancer.py:185:17
    |
183 | â€¦                 "# Ð­Ñ‚Ð¾Ñ‚ Ñ„Ð°Ð¹Ð» Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÐµÑ‚ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÐºÐµÑˆÐ° Ð² ÐºÐ¾Ñ€Ð½Ðµ\n# Ð ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐµÑˆ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² data/.cache\n"
184 | â€¦             )
185 | â€¦         os.chmod(root_cache, 0o444)  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ Ñ‡Ñ‚ÐµÐ½Ð¸Ñ
    |           ^^^^^^^^
186 | â€¦         logger.info("ðŸ”’ Ð¡Ð¾Ð·Ð´Ð°Ð½ Ñ„Ð°Ð¹Ð»-Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº .cache Ð² ÐºÐ¾Ñ€Ð½Ðµ")
187 | â€¦     except Exception as e:
    |
help: Replace with `Path(...).chmod(...)`

TRY300 Consider moving this statement to an `else` block
   --> src/enhancers/spotify_enhancer.py:194:13
    |
192 |             logger.info("Spotify API connected")
193 |
194 |             return spotify
    |             ^^^^^^^^^^^^^^
195 |
196 |         except Exception as e:
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/enhancers/spotify_enhancer.py:213:9
    |
211 |           current_time = time.time()
212 |
213 | /         if self.request_count >= self.max_requests_per_minute:
214 | |             if current_time - self.last_request_time < 60:
    | |__________________________________________________________^
215 |                   sleep_time = 60 - (current_time - self.last_request_time)
216 |                   logger.info(f"â° Rate limit: Ð¶Ð´ÐµÐ¼ {sleep_time:.1f}Ñ")
    |
help: Combine `if` statements using `and`

UP045 [*] Use `X | None` for type annotations
   --> src/enhancers/spotify_enhancer.py:226:62
    |
224 |         self.request_count += 1
225 |
226 |     async def search_track(self, artist: str, title: str) -> Optional[Dict[str, Any]]:
    |                                                              ^^^^^^^^^^^^^^^^^^^^^^^^
227 |         """ÐŸÐ¾Ð¸ÑÐº Ñ‚Ñ€ÐµÐºÐ° Ð² Spotify"""
228 |         if not self.spotify:
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/spotify_enhancer.py:226:71
    |
224 |         self.request_count += 1
225 |
226 |     async def search_track(self, artist: str, title: str) -> Optional[Dict[str, Any]]:
    |                                                                       ^^^^
227 |         """ÐŸÐ¾Ð¸ÑÐº Ñ‚Ñ€ÐµÐºÐ° Ð² Spotify"""
228 |         if not self.spotify:
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/enhancers/spotify_enhancer.py:257:13
    |
255 |                 return best_match
256 |
257 |             return None
    |             ^^^^^^^^^^^
258 |
259 |         except Exception as e:
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/enhancers/spotify_enhancer.py:264:23
    |
263 |     def _find_best_match(
264 |         self, tracks: List[Dict], target_artist: str, target_title: str
    |                       ^^^^
265 |     ) -> Dict[str, Any]:
266 |         """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ð¼Ð°Ñ‚Ñ‡ Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¿Ð¾Ð¸ÑÐºÐ°"""
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/spotify_enhancer.py:264:28
    |
263 |     def _find_best_match(
264 |         self, tracks: List[Dict], target_artist: str, target_title: str
    |                            ^^^^
265 |     ) -> Dict[str, Any]:
266 |         """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ð¼Ð°Ñ‚Ñ‡ Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¿Ð¾Ð¸ÑÐºÐ°"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/spotify_enhancer.py:265:10
    |
263 |     def _find_best_match(
264 |         self, tracks: List[Dict], target_artist: str, target_title: str
265 |     ) -> Dict[str, Any]:
    |          ^^^^
266 |         """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ð¼Ð°Ñ‚Ñ‡ Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¿Ð¾Ð¸ÑÐºÐ°"""
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/spotify_enhancer.py:327:66
    |
325 |             return False
326 |
327 |     async def _save_spotify_data(self, song_id: int, track_data: Dict) -> bool:
    |                                                                  ^^^^
328 |         """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð² PostgreSQL tracks.spotify_data ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ (Ð±ÐµÐ· audio_features)"""
329 |         try:
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/enhancers/spotify_enhancer.py:351:13
    |
349 |                 await conn.execute(query, song_id, json.dumps(spotify_data))
350 |
351 |             return True
    |             ^^^^^^^^^^^
352 |
353 |         except Exception as e:
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/enhancers/spotify_enhancer.py:359:10
    |
357 |     async def get_tracks_for_enhancement(
358 |         self, limit: int = 1000
359 |     ) -> List[Dict[str, Any]]:
    |          ^^^^
360 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐµÐ½ Ð´Ð»Ñ Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ñ"""
361 |         try:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/spotify_enhancer.py:359:15
    |
357 |     async def get_tracks_for_enhancement(
358 |         self, limit: int = 1000
359 |     ) -> List[Dict[str, Any]]:
    |               ^^^^
360 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐµÐ½ Ð´Ð»Ñ Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ñ"""
361 |         try:
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/enhancers/spotify_enhancer.py:378:49
    |
377 |     async def bulk_enhance(
378 |         self, batch_size: int = 50, max_tracks: Optional[int] = None
    |                                                 ^^^^^^^^^^^^^
379 |     ) -> Dict[str, int]:
380 |         """ÐœÐ°ÑÑÐ¾Ð²Ð¾Ðµ Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐµÐ½"""
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/spotify_enhancer.py:379:10
    |
377 |     async def bulk_enhance(
378 |         self, batch_size: int = 50, max_tracks: Optional[int] = None
379 |     ) -> Dict[str, int]:
    |          ^^^^
380 |         """ÐœÐ°ÑÑÐ¾Ð²Ð¾Ðµ Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐµÐ½"""
381 |         logger.info("ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ðµ Spotify Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ")
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/enhancers/spotify_enhancer.py:424:13
    |
423 |             logger.info(f"ÐžÐ±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾: {stats}")
424 |             return stats
    |             ^^^^^^^^^^^^
425 |
426 |         except Exception as e:
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/enhancers/spotify_enhancer.py:430:46
    |
428 |             return stats
429 |
430 |     async def get_enhancement_stats(self) -> Dict[str, Any]:
    |                                              ^^^^
431 |         """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ñ"""
432 |         try:
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/enhancers/spotify_enhancer.py:453:13
    |
451 |                     return stats
452 |
453 |             return {}
    |             ^^^^^^^^^
454 |
455 |         except Exception as e:
    |

PLR0912 Too many branches (17 > 12)
   --> src/enhancers/spotify_enhancer.py:483:11
    |
483 | async def interactive_mode():
    |           ^^^^^^^^^^^^^^^^
484 |     """Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ Ñ Ð¼ÐµÐ½ÑŽ"""
485 |     enhancer = SpotifyEnhancer()
    |

PLR0915 Too many statements (61 > 50)
   --> src/enhancers/spotify_enhancer.py:483:11
    |
483 | async def interactive_mode():
    |           ^^^^^^^^^^^^^^^^
484 |     """Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ Ñ Ð¼ÐµÐ½ÑŽ"""
485 |     enhancer = SpotifyEnhancer()
    |

F541 [*] f-string without any placeholders
   --> src/enhancers/spotify_enhancer.py:537:23
    |
535 |                 print("\nðŸ§ª Ð¢ÐµÑÑ‚Ð¾Ð²Ð¾Ðµ Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ (100 Ñ‚Ñ€ÐµÐºÐ¾Ð²)")
536 |                 batch_size = int(input("Ð Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ñ‚Ñ‡Ð° (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 20): ") or "20")
537 |                 print(f"ðŸ”„ Ð—Ð°Ð¿ÑƒÑÐº Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ñ...")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
538 |                 stats = await enhancer.bulk_enhance(
539 |                     batch_size=batch_size, max_tracks=100
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
  --> src/interfaces/__init__.py:8:1
   |
 6 |   """
 7 |
 8 | / from .analyzer_interface import (
 9 | |     BaseAnalyzer,
10 | |     AnalysisResult,
11 | |     AnalyzerFactory,
12 | |     register_analyzer,
13 | | )
   | |_^
14 |
15 |   __all__ = [
   |
help: Organize imports

RUF022 `__all__` is not sorted
  --> src/interfaces/__init__.py:15:11
   |
13 |   )
14 |
15 |   __all__ = [
   |  ___________^
16 | |     # Analyzer interfaces
17 | |     "BaseAnalyzer",
18 | |     "AnalysisResult",
19 | |     "AnalyzerFactory",
20 | |     "register_analyzer",
21 | | ]
   | |_^
   |
help: Apply an isort-style sorting to `__all__`

I001 [*] Import block is un-sorted or un-formatted
  --> src/interfaces/analyzer_interface.py:41:1
   |
39 |   """
40 |
41 | / import asyncio
42 | | import time
43 | | import logging
44 | | import json
45 | | import os
46 | | import sys
47 | | from abc import ABC, abstractmethod
48 | | from typing import Dict, Any, List, Optional, Union, Tuple, AsyncGenerator
49 | | from dataclasses import dataclass, field
50 | | from datetime import datetime
51 | | from enum import Enum
52 | | import traceback
   | |________________^
53 |
54 |   # PostgreSQL Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ
   |
help: Organize imports

F401 [*] `json` imported but unused
  --> src/interfaces/analyzer_interface.py:44:8
   |
42 | import time
43 | import logging
44 | import json
   |        ^^^^
45 | import os
46 | import sys
   |
help: Remove unused import: `json`

UP035 [*] Import from `collections.abc` instead: `AsyncGenerator`
  --> src/interfaces/analyzer_interface.py:48:1
   |
46 | import sys
47 | from abc import ABC, abstractmethod
48 | from typing import Dict, Any, List, Optional, Union, Tuple, AsyncGenerator
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
49 | from dataclasses import dataclass, field
50 | from datetime import datetime
   |
help: Import from `collections.abc`

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/interfaces/analyzer_interface.py:48:1
   |
46 | import sys
47 | from abc import ABC, abstractmethod
48 | from typing import Dict, Any, List, Optional, Union, Tuple, AsyncGenerator
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
49 | from dataclasses import dataclass, field
50 | from datetime import datetime
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/interfaces/analyzer_interface.py:48:1
   |
46 | import sys
47 | from abc import ABC, abstractmethod
48 | from typing import Dict, Any, List, Optional, Union, Tuple, AsyncGenerator
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
49 | from dataclasses import dataclass, field
50 | from datetime import datetime
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> src/interfaces/analyzer_interface.py:48:1
   |
46 | import sys
47 | from abc import ABC, abstractmethod
48 | from typing import Dict, Any, List, Optional, Union, Tuple, AsyncGenerator
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
49 | from dataclasses import dataclass, field
50 | from datetime import datetime
   |

F401 [*] `typing.Union` imported but unused
  --> src/interfaces/analyzer_interface.py:48:47
   |
46 | import sys
47 | from abc import ABC, abstractmethod
48 | from typing import Dict, Any, List, Optional, Union, Tuple, AsyncGenerator
   |                                               ^^^^^
49 | from dataclasses import dataclass, field
50 | from datetime import datetime
   |
help: Remove unused import

F401 [*] `typing.Tuple` imported but unused
  --> src/interfaces/analyzer_interface.py:48:54
   |
46 | import sys
47 | from abc import ABC, abstractmethod
48 | from typing import Dict, Any, List, Optional, Union, Tuple, AsyncGenerator
   |                                                      ^^^^^
49 | from dataclasses import dataclass, field
50 | from datetime import datetime
   |
help: Remove unused import

F401 [*] `typing.AsyncGenerator` imported but unused
  --> src/interfaces/analyzer_interface.py:48:61
   |
46 | import sys
47 | from abc import ABC, abstractmethod
48 | from typing import Dict, Any, List, Optional, Union, Tuple, AsyncGenerator
   |                                                             ^^^^^^^^^^^^^^
49 | from dataclasses import dataclass, field
50 | from datetime import datetime
   |
help: Remove unused import

F401 `src.utils.config.get_db_config` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> src/interfaces/analyzer_interface.py:57:34
   |
55 | try:
56 |     from src.database.postgres_adapter import PostgreSQLManager
57 |     from src.utils.config import get_db_config
   |                                  ^^^^^^^^^^^^^
58 |
59 |     POSTGRES_AVAILABLE = True
   |
help: Remove unused import: `src.utils.config.get_db_config`

PTH100 `os.path.abspath()` should be replaced by `Path.resolve()`
  --> src/interfaces/analyzer_interface.py:67:17
   |
65 | # ÑƒÐ±ÐµÐ´Ð¸Ð¼ÑÑ, Ñ‡Ñ‚Ð¾ ÐºÐ¾Ñ€ÐµÐ½ÑŒ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ Ð² sys.path Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¼Ð¾Ð¶Ð½Ð¾ Ð±Ñ‹Ð»Ð¾ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð°ÐºÐµÑ‚ `src`.
66 | try:
67 |     repo_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
   |                 ^^^^^^^^^^^^^^^
68 |     if repo_root not in sys.path:
69 |         sys.path.insert(0, repo_root)
   |
help: Replace with `Path(...).resolve()`

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
  --> src/interfaces/analyzer_interface.py:67:33
   |
65 | # ÑƒÐ±ÐµÐ´Ð¸Ð¼ÑÑ, Ñ‡Ñ‚Ð¾ ÐºÐ¾Ñ€ÐµÐ½ÑŒ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ Ð² sys.path Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¼Ð¾Ð¶Ð½Ð¾ Ð±Ñ‹Ð»Ð¾ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð°ÐºÐµÑ‚ `src`.
66 | try:
67 |     repo_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
   |                                 ^^^^^^^^^^^^
68 |     if repo_root not in sys.path:
69 |         sys.path.insert(0, repo_root)
   |

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/interfaces/analyzer_interface.py:67:46
   |
65 | # ÑƒÐ±ÐµÐ´Ð¸Ð¼ÑÑ, Ñ‡Ñ‚Ð¾ ÐºÐ¾Ñ€ÐµÐ½ÑŒ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ Ð² sys.path Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¼Ð¾Ð¶Ð½Ð¾ Ð±Ñ‹Ð»Ð¾ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð°ÐºÐµÑ‚ `src`.
66 | try:
67 |     repo_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
   |                                              ^^^^^^^^^^^^^^^
68 |     if repo_root not in sys.path:
69 |         sys.path.insert(0, repo_root)
   |
help: Replace with `Path(...).parent`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:116:20
    |
114 |     title: str
115 |     analyzer_type: str
116 |     analysis_data: Dict[str, Any]
    |                    ^^^^
117 |
118 |     # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:123:15
    |
122 |     # PostgreSQL Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ
123 |     track_id: Optional[int] = field(default=None)
    |               ^^^^^^^^^^^^^
124 |     status: AnalysisStatus = field(default=AnalysisStatus.SUCCESS)
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:127:15
    |
126 |     # ÐœÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ
127 |     metadata: Dict[str, Any] = field(default_factory=dict)
    |               ^^^^
128 |     timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    |
help: Replace with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/interfaces/analyzer_interface.py:128:52
    |
126 |     # ÐœÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ
127 |     metadata: Dict[str, Any] = field(default_factory=dict)
128 |     timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    |                                                    ^^^^^^^^^^^^^^
129 |
130 |     # ÐžÑˆÐ¸Ð±ÐºÐ¸ Ð¸ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ°
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:131:20
    |
130 |     # ÐžÑˆÐ¸Ð±ÐºÐ¸ Ð¸ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ°
131 |     error_message: Optional[str] = field(default=None)
    |                    ^^^^^^^^^^^^^
132 |     raw_output: Optional[Dict[str, Any]] = field(default=None)
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:132:17
    |
130 |     # ÐžÑˆÐ¸Ð±ÐºÐ¸ Ð¸ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ°
131 |     error_message: Optional[str] = field(default=None)
132 |     raw_output: Optional[Dict[str, Any]] = field(default=None)
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^
133 |
134 |     def to_postgres_dict(self) -> Dict[str, Any]:
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:132:26
    |
130 |     # ÐžÑˆÐ¸Ð±ÐºÐ¸ Ð¸ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ°
131 |     error_message: Optional[str] = field(default=None)
132 |     raw_output: Optional[Dict[str, Any]] = field(default=None)
    |                          ^^^^
133 |
134 |     def to_postgres_dict(self) -> Dict[str, Any]:
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:134:35
    |
132 |     raw_output: Optional[Dict[str, Any]] = field(default=None)
133 |
134 |     def to_postgres_dict(self) -> Dict[str, Any]:
    |                                   ^^^^
135 |         """ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð´Ð»Ñ PostgreSQL"""
136 |         return {
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:163:32
    |
161 |     """
162 |
163 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^
164 |         """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
165 |         self.config = config or {}
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:163:41
    |
161 |     """
162 |
163 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
    |                                         ^^^^
164 |         """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
165 |         self.config = config or {}
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:193:63
    |
191 |     @abstractmethod
192 |     async def analyze_song(
193 |         self, artist: str, title: str, lyrics: str, track_id: Optional[int] = None
    |                                                               ^^^^^^^^^^^^^
194 |     ) -> AnalysisResult:
195 |         """
    |
help: Convert to `X | None`

PIE790 [*] Unnecessary `pass` statement
   --> src/interfaces/analyzer_interface.py:207:9
    |
205 |             AnalysisResult Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
206 |         """
207 |         pass
    |         ^^^^
208 |
209 |     @abstractmethod
    |
help: Remove unnecessary `pass`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:210:36
    |
209 |     @abstractmethod
210 |     def get_analyzer_info(self) -> Dict[str, Any]:
    |                                    ^^^^
211 |         """ÐœÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾Ð± Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ðµ"""
212 |         pass
    |
help: Replace with `dict`

PIE790 [*] Unnecessary `pass` statement
   --> src/interfaces/analyzer_interface.py:212:9
    |
210 |     def get_analyzer_info(self) -> Dict[str, Any]:
211 |         """ÐœÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾Ð± Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ðµ"""
212 |         pass
    |         ^^^^
213 |
214 |     @property
    |
help: Remove unnecessary `pass`

PIE790 [*] Unnecessary `pass` statement
   --> src/interfaces/analyzer_interface.py:218:9
    |
216 |     def analyzer_type(self) -> str:
217 |         """Ð¢Ð¸Ð¿ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð° (Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°Ñ‚ÑŒ Ñ AnalyzerType)"""
218 |         pass
    |         ^^^^
219 |
220 |     @property
    |
help: Remove unnecessary `pass`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/interfaces/analyzer_interface.py:222:37
    |
220 |     @property
221 |     @abstractmethod
222 |     def supported_features(self) -> List[str]:
    |                                     ^^^^
223 |         """Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ñ… Ñ„Ð¸Ñ‡ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
224 |         pass
    |
help: Replace with `list`

PIE790 [*] Unnecessary `pass` statement
   --> src/interfaces/analyzer_interface.py:224:9
    |
222 |     def supported_features(self) -> List[str]:
223 |         """Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ñ… Ñ„Ð¸Ñ‡ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
224 |         pass
    |         ^^^^
225 |
226 |     # PostgreSQL Ð¼ÐµÑ‚Ð¾Ð´Ñ‹
    |
help: Remove unnecessary `pass`

TRY300 Consider moving this statement to an `else` block
   --> src/interfaces/analyzer_interface.py:263:13
    |
261 |                 self.stats["failed"] += 1
262 |
263 |             return success
    |             ^^^^^^^^^^^^^^
264 |
265 |         except Exception as e:
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/interfaces/analyzer_interface.py:270:64
    |
268 |             return False
269 |
270 |     async def get_unanalyzed_tracks(self, limit: int = 100) -> List[Dict[str, Any]]:
    |                                                                ^^^^
271 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½ÐµÐ°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð² Ð´Ð»Ñ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
272 |         if not self.db_manager:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:270:69
    |
268 |             return False
269 |
270 |     async def get_unanalyzed_tracks(self, limit: int = 100) -> List[Dict[str, Any]]:
    |                                                                     ^^^^
271 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½ÐµÐ°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð² Ð´Ð»Ñ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
272 |         if not self.db_manager:
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/interfaces/analyzer_interface.py:286:13
    |
284 |                 f"ðŸ“Š {self.name}: ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(tracks)} Ð½ÐµÐ°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð²"
285 |             )
286 |             return tracks
    |             ^^^^^^^^^^^^^
287 |
288 |         except Exception as e:
    |

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:293:49
    |
292 |     async def mass_analyze(
293 |         self, batch_size: int = 50, max_tracks: Optional[int] = None
    |                                                 ^^^^^^^^^^^^^
294 |     ) -> Dict[str, int]:
295 |         """
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:294:10
    |
292 |     async def mass_analyze(
293 |         self, batch_size: int = 50, max_tracks: Optional[int] = None
294 |     ) -> Dict[str, int]:
    |          ^^^^
295 |         """
296 |         ÐœÐ°ÑÑÐ¾Ð²Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð½ÐµÐ°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð²
    |
help: Replace with `dict`

SIM103 Return the condition `not len(lyrics.strip()) < 10` directly
   --> src/interfaces/analyzer_interface.py:370:9
    |
368 |               return False
369 |
370 | /         if len(lyrics.strip()) < 10:
371 | |             return False
372 | |
373 | |         return True
    | |___________________^
374 |
375 |       def preprocess_lyrics(self, lyrics: str) -> str:
    |
help: Replace with `return not len(lyrics.strip()) < 10`

RET504 Unnecessary assignment to `lyrics` before `return` statement
   --> src/interfaces/analyzer_interface.py:384:16
    |
382 |         lyrics = re.sub(r"\s+", " ", lyrics)
383 |
384 |         return lyrics
    |                ^^^^^^
385 |
386 |     def update_stats(self, result: AnalysisResult):
    |
help: Remove unnecessary assignment

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:404:28
    |
402 |             self.stats["skipped"] += 1
403 |
404 |     def get_stats(self) -> Dict[str, Any]:
    |                            ^^^^
405 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
406 |         avg_time = self.stats["total_time"] / max(self.stats["total_analyzed"], 1)
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:426:17
    |
424 |     """
425 |
426 |     _analyzers: Dict[str, type] = {}
    |                 ^^^^
427 |     _instances: Dict[str, BaseAnalyzer] = {}
    |
help: Replace with `dict`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> src/interfaces/analyzer_interface.py:426:35
    |
424 |     """
425 |
426 |     _analyzers: Dict[str, type] = {}
    |                                   ^^
427 |     _instances: Dict[str, BaseAnalyzer] = {}
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:427:17
    |
426 |     _analyzers: Dict[str, type] = {}
427 |     _instances: Dict[str, BaseAnalyzer] = {}
    |                 ^^^^
428 |
429 |     @classmethod
    |
help: Replace with `dict`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> src/interfaces/analyzer_interface.py:427:43
    |
426 |     _analyzers: Dict[str, type] = {}
427 |     _instances: Dict[str, BaseAnalyzer] = {}
    |                                           ^^
428 |
429 |     @classmethod
    |

TRY004 Prefer `TypeError` exception for invalid type
   --> src/interfaces/analyzer_interface.py:433:13
    |
431 |         """Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÐºÐ»Ð°ÑÑÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
432 |         if not issubclass(analyzer_class, BaseAnalyzer):
433 |             raise ValueError(f"ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð½Ð°ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð¾Ñ‚ BaseAnalyzer")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
434 |
435 |         cls._analyzers[name] = analyzer_class
    |

F541 [*] f-string without any placeholders
   --> src/interfaces/analyzer_interface.py:433:30
    |
431 |         """Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÐºÐ»Ð°ÑÑÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
432 |         if not issubclass(analyzer_class, BaseAnalyzer):
433 |             raise ValueError(f"ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð½Ð°ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð¾Ñ‚ BaseAnalyzer")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
434 |
435 |         cls._analyzers[name] = analyzer_class
    |
help: Remove extraneous `f` prefix

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/interfaces/analyzer_interface.py:433:30
    |
431 |         """Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÐºÐ»Ð°ÑÑÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
432 |         if not issubclass(analyzer_class, BaseAnalyzer):
433 |             raise ValueError(f"ÐÐ½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð½Ð°ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð¾Ñ‚ BaseAnalyzer")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
434 |
435 |         cls._analyzers[name] = analyzer_class
    |
help: Assign to variable; remove f-string literal

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:440:33
    |
438 |     @classmethod
439 |     def create(
440 |         cls, name: str, config: Optional[Dict[str, Any]] = None, singleton: bool = True
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^
441 |     ) -> BaseAnalyzer:
442 |         """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:440:42
    |
438 |     @classmethod
439 |     def create(
440 |         cls, name: str, config: Optional[Dict[str, Any]] = None, singleton: bool = True
    |                                          ^^^^
441 |     ) -> BaseAnalyzer:
442 |         """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
    |
help: Replace with `dict`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/interfaces/analyzer_interface.py:445:30
    |
443 |         if name not in cls._analyzers:
444 |             available = list(cls._analyzers.keys())
445 |             raise ValueError(f"ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€: {name}. Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ: {available}")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
446 |
447 |         # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ singleton ÐµÑÐ»Ð¸ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚
    |
help: Assign to variable; remove f-string literal

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:468:19
    |
466 |         title: str,
467 |         lyrics: str,
468 |         track_id: Optional[int] = None,
    |                   ^^^^^^^^^^^^^
469 |         save_to_db: bool = True,
470 |     ) -> Dict[str, AnalysisResult]:
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:470:10
    |
468 |         track_id: Optional[int] = None,
469 |         save_to_db: bool = True,
470 |     ) -> Dict[str, AnalysisResult]:
    |          ^^^^
471 |         """
472 |         ÐÐ½Ð°Ð»Ð¸Ð· Ð¾Ð´Ð½Ð¾Ð¹ Ð¿ÐµÑÐ½Ð¸ Ð²ÑÐµÐ¼Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ð¼Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸
    |
help: Replace with `dict`

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> src/interfaces/analyzer_interface.py:489:13
    |
487 |         start_time = time.time()
488 |
489 |         for name in cls._analyzers.keys():
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
490 |             try:
491 |                 analyzer = cls.create(name)
    |
help: Remove `.keys()`

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:524:48
    |
522 |     @classmethod
523 |     async def mass_analyze_all(
524 |         cls, batch_size: int = 25, max_tracks: Optional[int] = None
    |                                                ^^^^^^^^^^^^^
525 |     ) -> Dict[str, Dict[str, int]]:
526 |         """
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:525:10
    |
523 |     async def mass_analyze_all(
524 |         cls, batch_size: int = 25, max_tracks: Optional[int] = None
525 |     ) -> Dict[str, Dict[str, int]]:
    |          ^^^^
526 |         """
527 |         ÐœÐ°ÑÑÐ¾Ð²Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÑÐµÐ¼Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:525:20
    |
523 |     async def mass_analyze_all(
524 |         cls, batch_size: int = 25, max_tracks: Optional[int] = None
525 |     ) -> Dict[str, Dict[str, int]]:
    |                    ^^^^
526 |         """
527 |         ÐœÐ°ÑÑÐ¾Ð²Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÑÐµÐ¼Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸
    |
help: Replace with `dict`

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> src/interfaces/analyzer_interface.py:540:13
    |
538 |         all_stats = {}
539 |
540 |         for name in cls._analyzers.keys():
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
541 |             try:
542 |                 analyzer = cls.create(name)
    |
help: Remove `.keys()`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/interfaces/analyzer_interface.py:568:32
    |
567 |     @classmethod
568 |     def list_available(cls) -> List[str]:
    |                                ^^^^
569 |         """Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð²"""
570 |         return list(cls._analyzers.keys())
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:573:46
    |
572 |     @classmethod
573 |     def get_analyzer_info(cls, name: str) -> Dict[str, Any]:
    |                                              ^^^^
574 |         """Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾Ð± Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ðµ"""
575 |         if name not in cls._analyzers:
    |
help: Replace with `dict`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/interfaces/analyzer_interface.py:576:30
    |
574 |         """Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾Ð± Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ðµ"""
575 |         if name not in cls._analyzers:
576 |             raise ValueError(f"ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€: {name}")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
577 |
578 |         analyzer = cls.create(name)
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:582:31
    |
581 |     @classmethod
582 |     def get_all_stats(cls) -> Dict[str, Dict[str, Any]]:
    |                               ^^^^
583 |         """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð²ÑÐµÑ… ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð²"""
584 |         stats = {}
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:582:41
    |
581 |     @classmethod
582 |     def get_all_stats(cls) -> Dict[str, Dict[str, Any]]:
    |                                         ^^^^
583 |         """Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð²ÑÐµÑ… ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð¾Ð²"""
584 |         stats = {}
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:621:32
    |
619 |     """
620 |
621 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^
622 |         super().__init__(config)
623 |         self._legacy_config = config or {}
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:621:41
    |
619 |     """
620 |
621 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
    |                                         ^^^^
622 |         super().__init__(config)
623 |         self._legacy_config = config or {}
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:630:36
    |
628 |         return AnalyzerType.QWEN.value
629 |
630 |     def get_analyzer_info(self) -> Dict[str, Any]:
    |                                    ^^^^
631 |         # Try to import legacy analyzer and reuse its info if available
632 |         try:
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/interfaces/analyzer_interface.py:638:13
    |
636 |             info = legacy.get_analyzer_info()
637 |             info["type"] = self.analyzer_type
638 |             return info
    |             ^^^^^^^^^^^
639 |         except Exception:
640 |             return {
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/interfaces/analyzer_interface.py:650:37
    |
649 |     @property
650 |     def supported_features(self) -> List[str]:
    |                                     ^^^^
651 |         try:
652 |             from archive.qwen_analyzer import QwenAnalyzer as LegacyQwen
    |
help: Replace with `list`

TRY300 Consider moving this statement to an `else` block
   --> src/interfaces/analyzer_interface.py:655:13
    |
654 |             legacy = LegacyQwen(self._legacy_config)
655 |             return legacy.supported_features
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
656 |         except Exception:
657 |             return []
    |

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:660:63
    |
659 |     async def analyze_song(
660 |         self, artist: str, title: str, lyrics: str, track_id: Optional[int] = None
    |                                                               ^^^^^^^^^^^^^
661 |     ) -> AnalysisResult:
662 |         # Validate input using base helper
    |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/interfaces/analyzer_interface.py:712:27
    |
710 |                 },
711 |                 raw_output=raw,
712 |                 timestamp=datetime.now().isoformat(),
    |                           ^^^^^^^^^^^^^^
713 |             )
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

RET504 Unnecessary assignment to `result` before `return` statement
   --> src/interfaces/analyzer_interface.py:715:20
    |
713 |             )
714 |
715 |             return result
    |                    ^^^^^^
716 |
717 |         # Execute synchronous legacy logic in background
    |
help: Remove unnecessary assignment

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:728:32
    |
726 |     """
727 |
728 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^
729 |         super().__init__(config)
730 |         self._legacy_config = config or {}
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:728:41
    |
726 |     """
727 |
728 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
    |                                         ^^^^
729 |         super().__init__(config)
730 |         self._legacy_config = config or {}
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:737:36
    |
735 |         return AnalyzerType.ALGORITHMIC.value
736 |
737 |     def get_analyzer_info(self) -> Dict[str, Any]:
    |                                    ^^^^
738 |         try:
739 |             from src.analyzers.algorithmic_analyzer import (
    |
help: Replace with `dict`

TRY300 Consider moving this statement to an `else` block
   --> src/interfaces/analyzer_interface.py:750:13
    |
748 |             )
749 |             info["type"] = self.analyzer_type
750 |             return info
    |             ^^^^^^^^^^^
751 |         except Exception:
752 |             return {
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/interfaces/analyzer_interface.py:762:37
    |
761 |     @property
762 |     def supported_features(self) -> List[str]:
    |                                     ^^^^
763 |         try:
764 |             from src.analyzers.algorithmic_analyzer import (
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:774:63
    |
773 |     async def analyze_song(
774 |         self, artist: str, title: str, lyrics: str, track_id: Optional[int] = None
    |                                                               ^^^^^^^^^^^^^
775 |     ) -> AnalysisResult:
776 |         if not self.validate_input(artist, title, lyrics):
    |
help: Convert to `X | None`

PLR0911 Too many return statements (8 > 6)
   --> src/interfaces/analyzer_interface.py:794:17
    |
793 |             # Helper to coerce various legacy result types into a dict
794 |             def to_plain_dict(obj):
    |                 ^^^^^^^^^^^^^
795 |                 if obj is None:
796 |                     return {}
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/interfaces/analyzer_interface.py:877:27
    |
875 |                 },
876 |                 raw_output=analysis_data,
877 |                 timestamp=datetime.now().isoformat(),
    |                           ^^^^^^^^^^^^^^
878 |             )
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

RET504 Unnecessary assignment to `result` before `return` statement
   --> src/interfaces/analyzer_interface.py:880:20
    |
878 |             )
879 |
880 |             return result
    |                    ^^^^^^
881 |
882 |         return await asyncio.to_thread(sync_analyze)
    |
help: Remove unnecessary assignment

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:889:32
    |
887 |     """Thin wrapper for the async EmotionAnalyzer implementation."""
888 |
889 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^
890 |         super().__init__(config)
891 |         self._legacy_config = config or {}
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:889:41
    |
887 |     """Thin wrapper for the async EmotionAnalyzer implementation."""
888 |
889 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
    |                                         ^^^^
890 |         super().__init__(config)
891 |         self._legacy_config = config or {}
    |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface.py:899:36
    |
897 |         return AnalyzerType.EMOTIONAL.value
898 |
899 |     def get_analyzer_info(self) -> Dict[str, Any]:
    |                                    ^^^^
900 |         try:
901 |             from src.analyzers.emotion_analyzer import EmotionAnalyzer as Legacy
    |
help: Replace with `dict`

PIE807 [*] Prefer `dict` over useless lambda
   --> src/interfaces/analyzer_interface.py:904:57
    |
903 |             legacy = Legacy(self._legacy_config)
904 |             return getattr(legacy, "get_analyzer_info", lambda: {})()
    |                                                         ^^^^^^^^^^
905 |         except Exception:
906 |             return {
    |
help: Replace with `lambda` with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/interfaces/analyzer_interface.py:916:37
    |
915 |     @property
916 |     def supported_features(self) -> List[str]:
    |                                     ^^^^
917 |         try:
918 |             from src.analyzers.emotion_analyzer import EmotionAnalyzer as Legacy
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface.py:926:63
    |
925 |     async def analyze_song(
926 |         self, artist: str, title: str, lyrics: str, track_id: Optional[int] = None
    |                                                               ^^^^^^^^^^^^^
927 |     ) -> AnalysisResult:
928 |         if not self.validate_input(artist, title, lyrics):
    |
help: Convert to `X | None`

PLR0911 Too many return statements (8 > 6)
   --> src/interfaces/analyzer_interface.py:947:13
    |
946 |         # Helper to coerce various legacy result types into a plain dict
947 |         def to_plain_dict(obj):
    |             ^^^^^^^^^^^^^
948 |             if obj is None:
949 |                 return {}
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/interfaces/analyzer_interface.py:1028:23
     |
1026 |             metadata=getattr(emotion_result, "metadata", {}) or {},
1027 |             raw_output=analysis_data if isinstance(analysis_data, dict) else {},
1028 |             timestamp=datetime.now().isoformat(),
     |                       ^^^^^^^^^^^^^^
1029 |         )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
    --> src/interfaces/analyzer_interface.py:1036:32
     |
1034 |     """Wrapper for legacy MultiModelAnalyzer orchestrator."""
1035 |
1036 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
     |                                ^^^^^^^^^^^^^^^^^^^^^^^^
1037 |         super().__init__(config)
1038 |         self._legacy_config = config or {}
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/interfaces/analyzer_interface.py:1036:41
     |
1034 |     """Wrapper for legacy MultiModelAnalyzer orchestrator."""
1035 |
1036 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
     |                                         ^^^^
1037 |         super().__init__(config)
1038 |         self._legacy_config = config or {}
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/interfaces/analyzer_interface.py:1045:36
     |
1043 |         return AnalyzerType.MULTIMODAL.value
1044 |
1045 |     def get_analyzer_info(self) -> Dict[str, Any]:
     |                                    ^^^^
1046 |         try:
1047 |             from src.analyzers.multi_model_analyzer import MultiModelAnalyzer as Legacy
     |
help: Replace with `dict`

PIE807 [*] Prefer `dict` over useless lambda
    --> src/interfaces/analyzer_interface.py:1050:57
     |
1049 |             legacy = Legacy()
1050 |             return getattr(legacy, "get_analyzer_info", lambda: {})()
     |                                                         ^^^^^^^^^^
1051 |         except Exception:
1052 |             return {
     |
help: Replace with `lambda` with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/interfaces/analyzer_interface.py:1062:37
     |
1061 |     @property
1062 |     def supported_features(self) -> List[str]:
     |                                     ^^^^
1063 |         try:
1064 |             from src.analyzers.multi_model_analyzer import MultiModelAnalyzer as Legacy
     |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
    --> src/interfaces/analyzer_interface.py:1072:63
     |
1071 |     async def analyze_song(
1072 |         self, artist: str, title: str, lyrics: str, track_id: Optional[int] = None
     |                                                               ^^^^^^^^^^^^^
1073 |     ) -> AnalysisResult:
1074 |         if not self.validate_input(artist, title, lyrics):
     |
help: Convert to `X | None`

PIE807 [*] Prefer `dict` over useless lambda
    --> src/interfaces/analyzer_interface.py:1088:49
     |
1086 |                 raw
1087 |                 if isinstance(raw, dict)
1088 |                 else getattr(raw, "model_dump", lambda: {})()
     |                                                 ^^^^^^^^^^
1089 |             )
     |
help: Replace with `lambda` with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/interfaces/analyzer_interface.py:1136:27
     |
1134 |                 metadata={"source": "multi_model"},
1135 |                 raw_output=analysis_data if isinstance(analysis_data, dict) else {},
1136 |                 timestamp=datetime.now().isoformat(),
     |                           ^^^^^^^^^^^^^^
1137 |             )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
    --> src/interfaces/analyzer_interface.py:1146:32
     |
1144 |     """Wrapper for legacy OllamaAnalyzer (sync)."""
1145 |
1146 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
     |                                ^^^^^^^^^^^^^^^^^^^^^^^^
1147 |         super().__init__(config)
1148 |         self._legacy_config = config or {}
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/interfaces/analyzer_interface.py:1146:41
     |
1144 |     """Wrapper for legacy OllamaAnalyzer (sync)."""
1145 |
1146 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
     |                                         ^^^^
1147 |         super().__init__(config)
1148 |         self._legacy_config = config or {}
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/interfaces/analyzer_interface.py:1155:36
     |
1153 |         return AnalyzerType.OLLAMA.value
1154 |
1155 |     def get_analyzer_info(self) -> Dict[str, Any]:
     |                                    ^^^^
1156 |         try:
1157 |             from src.analyzers.ollama_analyzer import OllamaAnalyzer as Legacy
     |
help: Replace with `dict`

PIE807 [*] Prefer `dict` over useless lambda
    --> src/interfaces/analyzer_interface.py:1160:57
     |
1159 |             legacy = Legacy(self._legacy_config)
1160 |             return getattr(legacy, "get_analyzer_info", lambda: {})()
     |                                                         ^^^^^^^^^^
1161 |         except Exception:
1162 |             return {
     |
help: Replace with `lambda` with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/interfaces/analyzer_interface.py:1172:37
     |
1171 |     @property
1172 |     def supported_features(self) -> List[str]:
     |                                     ^^^^
1173 |         try:
1174 |             from src.analyzers.ollama_analyzer import OllamaAnalyzer as Legacy
     |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
    --> src/interfaces/analyzer_interface.py:1182:63
     |
1181 |     async def analyze_song(
1182 |         self, artist: str, title: str, lyrics: str, track_id: Optional[int] = None
     |                                                               ^^^^^^^^^^^^^
1183 |     ) -> AnalysisResult:
1184 |         if not self.validate_input(artist, title, lyrics):
     |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/interfaces/analyzer_interface.py:1220:27
     |
1218 |                 },
1219 |                 raw_output=getattr(res, "raw_output", {}) or {},
1220 |                 timestamp=datetime.now().isoformat(),
     |                           ^^^^^^^^^^^^^^
1221 |             )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
    --> src/interfaces/analyzer_interface.py:1230:32
     |
1228 |     """Wrapper for simplified feature analyzer (sync or async)."""
1229 |
1230 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
     |                                ^^^^^^^^^^^^^^^^^^^^^^^^
1231 |         super().__init__(config)
1232 |         self._legacy_config = config or {}
     |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/interfaces/analyzer_interface.py:1230:41
     |
1228 |     """Wrapper for simplified feature analyzer (sync or async)."""
1229 |
1230 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
     |                                         ^^^^
1231 |         super().__init__(config)
1232 |         self._legacy_config = config or {}
     |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
    --> src/interfaces/analyzer_interface.py:1239:36
     |
1237 |         return AnalyzerType.SIMPLIFIED.value
1238 |
1239 |     def get_analyzer_info(self) -> Dict[str, Any]:
     |                                    ^^^^
1240 |         try:
1241 |             # The simplified feature analyzer exposes a LyricsAnalyzer class
     |
help: Replace with `dict`

PIE807 [*] Prefer `dict` over useless lambda
    --> src/interfaces/analyzer_interface.py:1248:57
     |
1246 |             legacy = Legacy()
1247 |             # Legacy analyzer does not implement get_analyzer_info in older versions
1248 |             info = getattr(legacy, "get_analyzer_info", lambda: {})()
     |                                                         ^^^^^^^^^^
1249 |             if not info:
1250 |                 info = {
     |
help: Replace with `lambda` with `dict`

TRY300 Consider moving this statement to an `else` block
    --> src/interfaces/analyzer_interface.py:1255:13
     |
1253 |                     "description": "Simplified features lyrics analyzer",
1254 |                 }
1255 |             return info
     |             ^^^^^^^^^^^
1256 |         except Exception:
1257 |             return {
     |

UP006 [*] Use `list` instead of `List` for type annotation
    --> src/interfaces/analyzer_interface.py:1267:37
     |
1266 |     @property
1267 |     def supported_features(self) -> List[str]:
     |                                     ^^^^
1268 |         try:
1269 |             from src.analyzers.simplified_feature_analyzer import (
     |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
    --> src/interfaces/analyzer_interface.py:1279:63
     |
1278 |     async def analyze_song(
1279 |         self, artist: str, title: str, lyrics: str, track_id: Optional[int] = None
     |                                                               ^^^^^^^^^^^^^
1280 |     ) -> AnalysisResult:
1281 |         if not self.validate_input(artist, title, lyrics):
     |
help: Convert to `X | None`

PIE807 [*] Prefer `dict` over useless lambda
    --> src/interfaces/analyzer_interface.py:1302:59
     |
1300 |                 features_dict = features.model_dump()
1301 |             else:
1302 |                 features_dict = getattr(features, "dict", lambda: {})()
     |                                                           ^^^^^^^^^^
1303 |
1304 |             confidence = features_dict.get(
     |
help: Replace with `lambda` with `dict`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
    --> src/interfaces/analyzer_interface.py:1322:27
     |
1320 |                 metadata={"analyzer_version": features_dict.get("analyzer_version")},
1321 |                 raw_output=features_dict,
1322 |                 timestamp=datetime.now().isoformat(),
     |                           ^^^^^^^^^^^^^^
1323 |             )
     |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
    --> src/interfaces/analyzer_interface.py:1335:58
     |
1335 | async def test_analyzer(analyzer_name: str, test_lyrics: Optional[str] = None) -> None:
     |                                                          ^^^^^^^^^^^^^
1336 |     """Ð¢ÐµÑÑ‚ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
1337 |     if test_lyrics is None:
     |
help: Convert to `X | None`

PT028 Test function parameter `test_lyrics` has default argument
    --> src/interfaces/analyzer_interface.py:1335:74
     |
1335 | async def test_analyzer(analyzer_name: str, test_lyrics: Optional[str] = None) -> None:
     |                                                                          ^^^^
1336 |     """Ð¢ÐµÑÑ‚ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"""
1337 |     if test_lyrics is None:
     |
help: Remove default argument

F541 [*] f-string without any placeholders
    --> src/interfaces/analyzer_interface.py:1358:19
     |
1356 |             )
1357 |
1358 |             print(f"\nâœ… Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:")
     |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
1359 |             print(f"  Confidence: {result.confidence:.2f}")
1360 |             print(f"  Processing time: {result.processing_time:.2f}s")
     |
help: Remove extraneous `f` prefix

W293 Blank line contains whitespace
    --> src/interfaces/analyzer_interface.py:1383:1
     |
1381 |     """
1382 |     Standalone Ð·Ð°Ð¿ÑƒÑÐº Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
1383 |     
     | ^^^^
1384 |     Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:
1385 |         python src/interfaces/analyzer_interface.py
     |
help: Remove whitespace from blank line

I001 [*] Import block is un-sorted or un-formatted
  --> src/interfaces/analyzer_interface_archive.py:24:1
   |
22 |   """
23 |
24 | / from abc import ABC, abstractmethod
25 | | from typing import Dict, Any, List, Optional
26 | | from dataclasses import dataclass
27 | | from enum import Enum
   | |_____________________^
28 |
29 |   # Import Ð±ÑƒÐ´ÐµÑ‚ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½ Ð¿Ð¾ÑÐ»Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð²ÑÐµÑ… ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð²
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/interfaces/analyzer_interface_archive.py:25:1
   |
24 | from abc import ABC, abstractmethod
25 | from typing import Dict, Any, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
26 | from dataclasses import dataclass
27 | from enum import Enum
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> src/interfaces/analyzer_interface_archive.py:25:1
   |
24 | from abc import ABC, abstractmethod
25 | from typing import Dict, Any, List, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
26 | from dataclasses import dataclass
27 | from enum import Enum
   |

ERA001 Found commented-out code
  --> src/interfaces/analyzer_interface_archive.py:30:1
   |
29 | # Import Ð±ÑƒÐ´ÐµÑ‚ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½ Ð¿Ð¾ÑÐ»Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð²ÑÐµÑ… ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð²
30 | # from src.models.models import EnhancedSongData
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
help: Remove commented-out code

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/interfaces/analyzer_interface_archive.py:50:15
   |
48 |     analysis_type: str
49 |     confidence: float
50 |     metadata: Dict[str, Any]
   |               ^^^^
51 |     raw_output: Dict[str, Any]
52 |     processing_time: float
   |
help: Replace with `dict`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/interfaces/analyzer_interface_archive.py:51:17
   |
49 |     confidence: float
50 |     metadata: Dict[str, Any]
51 |     raw_output: Dict[str, Any]
   |                 ^^^^
52 |     processing_time: float
53 |     timestamp: str
   |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
  --> src/interfaces/analyzer_interface_archive.py:66:32
   |
64 |     """
65 |
66 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
   |                                ^^^^^^^^^^^^^^^^^^^^^^^^
67 |         """Initialize analyzer with configuration"""
68 |         self.config = config or {}
   |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/interfaces/analyzer_interface_archive.py:66:41
   |
64 |     """
65 |
66 |     def __init__(self, config: Optional[Dict[str, Any]] = None):
   |                                         ^^^^
67 |         """Initialize analyzer with configuration"""
68 |         self.config = config or {}
   |
help: Replace with `dict`

PIE790 [*] Unnecessary `pass` statement
  --> src/interfaces/analyzer_interface_archive.py:87:9
   |
85 |             AnalysisResult with standardized output format
86 |         """
87 |         pass
   |         ^^^^
88 |
89 |     @abstractmethod
   |
help: Remove unnecessary `pass`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/interfaces/analyzer_interface_archive.py:90:36
   |
89 |     @abstractmethod
90 |     def get_analyzer_info(self) -> Dict[str, Any]:
   |                                    ^^^^
91 |         """
92 |         Return metadata about this analyzer.
   |
help: Replace with `dict`

PIE790 [*] Unnecessary `pass` statement
  --> src/interfaces/analyzer_interface_archive.py:97:9
   |
95 |             Dict containing analyzer name, version, capabilities, etc.
96 |         """
97 |         pass
   |         ^^^^
98 |
99 |     @property
   |
help: Remove unnecessary `pass`

PIE790 [*] Unnecessary `pass` statement
   --> src/interfaces/analyzer_interface_archive.py:107:9
    |
105 |         Must be one of: 'ai', 'algorithmic', 'hybrid'
106 |         """
107 |         pass
    |         ^^^^
108 |
109 |     @property
    |
help: Remove unnecessary `pass`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/interfaces/analyzer_interface_archive.py:111:37
    |
109 |     @property
110 |     @abstractmethod
111 |     def supported_features(self) -> List[str]:
    |                                     ^^^^
112 |         """Return list of features this analyzer supports"""
113 |         pass
    |
help: Replace with `list`

PIE790 [*] Unnecessary `pass` statement
   --> src/interfaces/analyzer_interface_archive.py:113:9
    |
111 |     def supported_features(self) -> List[str]:
112 |         """Return list of features this analyzer supports"""
113 |         pass
    |         ^^^^
114 |
115 |     def validate_input(self, artist: str, title: str, lyrics: str) -> bool:
    |
help: Remove unnecessary `pass`

SIM103 Return the negated condition directly
   --> src/interfaces/analyzer_interface_archive.py:124:9
    |
122 |               return False
123 |
124 | /         if len(lyrics.strip()) < 10:  # Minimum lyrics length
125 | |             return False
126 | |
127 | |         return True
    | |___________________^
128 |
129 |       def preprocess_lyrics(self, lyrics: str) -> str:
    |
help: Inline condition

RET504 Unnecessary assignment to `lyrics` before `return` statement
   --> src/interfaces/analyzer_interface_archive.py:143:16
    |
141 |         lyrics = re.sub(r"\s+", " ", lyrics)
142 |
143 |         return lyrics
    |                ^^^^^^
    |
help: Remove unnecessary assignment

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface_archive.py:153:17
    |
151 |     """
152 |
153 |     _analyzers: Dict[str, type] = {}
    |                 ^^^^
154 |     _instances: Dict[str, BaseAnalyzer] = {}
    |
help: Replace with `dict`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> src/interfaces/analyzer_interface_archive.py:153:35
    |
151 |     """
152 |
153 |     _analyzers: Dict[str, type] = {}
    |                                   ^^
154 |     _instances: Dict[str, BaseAnalyzer] = {}
    |

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface_archive.py:154:17
    |
153 |     _analyzers: Dict[str, type] = {}
154 |     _instances: Dict[str, BaseAnalyzer] = {}
    |                 ^^^^
155 |
156 |     @classmethod
    |
help: Replace with `dict`

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
   --> src/interfaces/analyzer_interface_archive.py:154:43
    |
153 |     _analyzers: Dict[str, type] = {}
154 |     _instances: Dict[str, BaseAnalyzer] = {}
    |                                           ^^
155 |
156 |     @classmethod
    |

TRY004 Prefer `TypeError` exception for invalid type
   --> src/interfaces/analyzer_interface_archive.py:166:13
    |
164 |         """
165 |         if not issubclass(analyzer_class, BaseAnalyzer):
166 |             raise ValueError(f"Analyzer class must inherit from BaseAnalyzer")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
167 |
168 |         cls._analyzers[name] = analyzer_class
    |

F541 [*] f-string without any placeholders
   --> src/interfaces/analyzer_interface_archive.py:166:30
    |
164 |         """
165 |         if not issubclass(analyzer_class, BaseAnalyzer):
166 |             raise ValueError(f"Analyzer class must inherit from BaseAnalyzer")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
167 |
168 |         cls._analyzers[name] = analyzer_class
    |
help: Remove extraneous `f` prefix

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/interfaces/analyzer_interface_archive.py:166:30
    |
164 |         """
165 |         if not issubclass(analyzer_class, BaseAnalyzer):
166 |             raise ValueError(f"Analyzer class must inherit from BaseAnalyzer")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
167 |
168 |         cls._analyzers[name] = analyzer_class
    |
help: Assign to variable; remove f-string literal

UP045 [*] Use `X | None` for type annotations
   --> src/interfaces/analyzer_interface_archive.py:172:33
    |
170 |     @classmethod
171 |     def create(
172 |         cls, name: str, config: Optional[Dict[str, Any]] = None, singleton: bool = True
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^
173 |     ) -> BaseAnalyzer:
174 |         """
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface_archive.py:172:42
    |
170 |     @classmethod
171 |     def create(
172 |         cls, name: str, config: Optional[Dict[str, Any]] = None, singleton: bool = True
    |                                          ^^^^
173 |     ) -> BaseAnalyzer:
174 |         """
    |
help: Replace with `dict`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/interfaces/analyzer_interface_archive.py:187:30
    |
185 |         if name not in cls._analyzers:
186 |             available = list(cls._analyzers.keys())
187 |             raise ValueError(f"Unknown analyzer: {name}. Available: {available}")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
188 |
189 |         # Return singleton instance if requested and exists
    |
help: Assign to variable; remove f-string literal

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/interfaces/analyzer_interface_archive.py:204:32
    |
203 |     @classmethod
204 |     def list_available(cls) -> List[str]:
    |                                ^^^^
205 |         """Return list of registered analyzer names"""
206 |         return list(cls._analyzers.keys())
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/interfaces/analyzer_interface_archive.py:209:46
    |
208 |     @classmethod
209 |     def get_analyzer_info(cls, name: str) -> Dict[str, Any]:
    |                                              ^^^^
210 |         """Get information about a registered analyzer"""
211 |         if name not in cls._analyzers:
    |
help: Replace with `dict`

EM102 Exception must not use an f-string literal, assign to variable first
   --> src/interfaces/analyzer_interface_archive.py:212:30
    |
210 |         """Get information about a registered analyzer"""
211 |         if name not in cls._analyzers:
212 |             raise ValueError(f"Unknown analyzer: {name}")
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
213 |
214 |         analyzer_class = cls._analyzers[name]
    |
help: Assign to variable; remove f-string literal

I001 [*] Import block is un-sorted or un-formatted
  --> src/models/ml_api_service.py:19:1
   |
17 |   """
18 |
19 | / from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
20 | | from fastapi.middleware.cors import CORSMiddleware
21 | | from fastapi.responses import JSONResponse
22 | | from pydantic import BaseModel, Field
23 | | from typing import List, Dict, Optional, Union
24 | | import asyncio
25 | | import logging
26 | | import sys
27 | | import os
28 | | from pathlib import Path
29 | | import pickle
30 | | import json
31 | | from datetime import datetime
32 | | import traceback
33 | | import uvicorn
   | |______________^
34 |
35 |   # Add project root to path
   |
help: Organize imports

UP035 `typing.List` is deprecated, use `list` instead
  --> src/models/ml_api_service.py:23:1
   |
21 | from fastapi.responses import JSONResponse
22 | from pydantic import BaseModel, Field
23 | from typing import List, Dict, Optional, Union
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 | import asyncio
25 | import logging
   |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/models/ml_api_service.py:23:1
   |
21 | from fastapi.responses import JSONResponse
22 | from pydantic import BaseModel, Field
23 | from typing import List, Dict, Optional, Union
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 | import asyncio
25 | import logging
   |

F401 [*] `typing.Union` imported but unused
  --> src/models/ml_api_service.py:23:42
   |
21 | from fastapi.responses import JSONResponse
22 | from pydantic import BaseModel, Field
23 | from typing import List, Dict, Optional, Union
   |                                          ^^^^^
24 | import asyncio
25 | import logging
   |
help: Remove unused import: `typing.Union`

F401 [*] `asyncio` imported but unused
  --> src/models/ml_api_service.py:24:8
   |
22 | from pydantic import BaseModel, Field
23 | from typing import List, Dict, Optional, Union
24 | import asyncio
   |        ^^^^^^^
25 | import logging
26 | import sys
   |
help: Remove unused import: `asyncio`

F401 [*] `json` imported but unused
  --> src/models/ml_api_service.py:30:8
   |
28 | from pathlib import Path
29 | import pickle
30 | import json
   |        ^^^^
31 | from datetime import datetime
32 | import traceback
   |
help: Remove unused import: `json`

ARG002 Unused method argument: `args`
  --> src/models/ml_api_service.py:51:25
   |
49 |         self.is_qwen = False
50 |
51 |     def __call__(self, *args, **kwargs):
   |                         ^^^^
52 |         return "Mock response"
   |

ARG002 Unused method argument: `kwargs`
  --> src/models/ml_api_service.py:51:33
   |
49 |         self.is_qwen = False
50 |
51 |     def __call__(self, *args, **kwargs):
   |                                 ^^^^^^
52 |         return "Mock response"
   |

ARG005 Unused lambda argument: `args`
  --> src/models/ml_api_service.py:57:24
   |
55 |         if name == "generate_lyrics":
56 |             return self._mock_generate_lyrics
57 |         return lambda *args, **kwargs: f"Mock {name} response"
   |                        ^^^^
58 |
59 |     def _mock_generate_lyrics(
   |

ARG005 Unused lambda argument: `kwargs`
  --> src/models/ml_api_service.py:57:32
   |
55 |         if name == "generate_lyrics":
56 |             return self._mock_generate_lyrics
57 |         return lambda *args, **kwargs: f"Mock {name} response"
   |                                ^^^^^^
58 |
59 |     def _mock_generate_lyrics(
   |

ARG002 Unused method argument: `max_length`
  --> src/models/ml_api_service.py:62:9
   |
60 |         self,
61 |         prompt="",
62 |         max_length=50,
   |         ^^^^^^^^^^
63 |         temperature=0.8,
64 |         style=None,
   |

ARG002 Unused method argument: `temperature`
  --> src/models/ml_api_service.py:63:9
   |
61 |         prompt="",
62 |         max_length=50,
63 |         temperature=0.8,
   |         ^^^^^^^^^^^
64 |         style=None,
65 |         mood=None,
   |

ARG002 Unused method argument: `kwargs`
  --> src/models/ml_api_service.py:67:11
   |
65 |         mood=None,
66 |         theme=None,
67 |         **kwargs,
   |           ^^^^^^
68 |     ):
69 |         """Mock QWEN lyrics generation"""
   |

I001 [*] Import block is un-sorted or un-formatted
  --> src/models/ml_api_service.py:84:5
   |
82 |   try:
83 |       # Add the project root to sys.path to access models directory
84 | /     import sys
85 | |     import os
   | |_____________^
86 |
87 |       sys.path.append(os.path.join(os.path.dirname(__file__), "..", ".."))
   |
help: Organize imports

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
  --> src/models/ml_api_service.py:87:21
   |
85 |     import os
86 |
87 |     sys.path.append(os.path.join(os.path.dirname(__file__), "..", ".."))
   |                     ^^^^^^^^^^^^
88 |
89 |     # GPT-2 removed - using QWEN as primary model
   |

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/models/ml_api_service.py:87:34
   |
85 |     import os
86 |
87 |     sys.path.append(os.path.join(os.path.dirname(__file__), "..", ".."))
   |                                  ^^^^^^^^^^^^^^^
88 |
89 |     # GPT-2 removed - using QWEN as primary model
   |
help: Replace with `Path(...).parent`

ERA001 Found commented-out code
  --> src/models/ml_api_service.py:90:5
   |
89 |     # GPT-2 removed - using QWEN as primary model
90 |     # from models.conditional_generation import ConditionalRapGenerator
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
91 |     from models.style_transfer import RapStyleTransfer
92 |     from models.quality_prediction import RapQualityPredictor
   |
help: Remove commented-out code

I001 [*] Import block is un-sorted or un-formatted
  --> src/models/ml_api_service.py:91:5
   |
89 |       # GPT-2 removed - using QWEN as primary model
90 |       # from models.conditional_generation import ConditionalRapGenerator
91 | /     from models.style_transfer import RapStyleTransfer
92 | |     from models.quality_prediction import RapQualityPredictor
93 | |     from models.trend_analysis import RapTrendAnalyzer
   | |______________________________________________________^
94 |
95 |       logger.info("âœ… All ML model imports successful")
   |
help: Organize imports

E402 Module level import not at top of file
   --> src/models/ml_api_service.py:109:1
    |
108 | # Import for lifespan
109 | from contextlib import asynccontextmanager
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
110 |
111 | # Global models instance will be initialized after class definition
    |

ARG001 Unused function argument: `app`
   --> src/models/ml_api_service.py:115:20
    |
114 | @asynccontextmanager
115 | async def lifespan(app):
    |                    ^^^
116 |     # Startup
117 |     logger.info("ðŸš€ Starting Rap ML API Service...")
    |

UP045 [*] Use `X | None` for type annotations
   --> src/models/ml_api_service.py:150:19
    |
149 |     prompt: str = Field(..., description="Initial text prompt")
150 |     artist_style: Optional[str] = Field(None, description="Target artist style")
    |                   ^^^^^^^^^^^^^
151 |     mood: Optional[str] = Field(None, description="Desired mood")
152 |     theme: Optional[str] = Field(None, description="Theme/topic")
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/ml_api_service.py:151:11
    |
149 |     prompt: str = Field(..., description="Initial text prompt")
150 |     artist_style: Optional[str] = Field(None, description="Target artist style")
151 |     mood: Optional[str] = Field(None, description="Desired mood")
    |           ^^^^^^^^^^^^^
152 |     theme: Optional[str] = Field(None, description="Theme/topic")
153 |     max_length: int = Field(150, description="Maximum generated text length")
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/ml_api_service.py:152:12
    |
150 |     artist_style: Optional[str] = Field(None, description="Target artist style")
151 |     mood: Optional[str] = Field(None, description="Desired mood")
152 |     theme: Optional[str] = Field(None, description="Theme/topic")
    |            ^^^^^^^^^^^^^
153 |     max_length: int = Field(150, description="Maximum generated text length")
154 |     temperature: float = Field(0.8, description="Generation creativity (0.1-1.0)")
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/ml_api_service.py:171:13
    |
170 |     lyrics: str = Field(..., description="Lyrics text to analyze")
171 |     artist: Optional[str] = Field(None, description="Artist name")
    |             ^^^^^^^^^^^^^
172 |     additional_features: Optional[Dict] = Field(None, description="Additional features")
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/ml_api_service.py:172:26
    |
170 |     lyrics: str = Field(..., description="Lyrics text to analyze")
171 |     artist: Optional[str] = Field(None, description="Artist name")
172 |     additional_features: Optional[Dict] = Field(None, description="Additional features")
    |                          ^^^^^^^^^^^^^^
    |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/models/ml_api_service.py:172:35
    |
170 |     lyrics: str = Field(..., description="Lyrics text to analyze")
171 |     artist: Optional[str] = Field(None, description="Artist name")
172 |     additional_features: Optional[Dict] = Field(None, description="Additional features")
    |                                   ^^^^
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/models/ml_api_service.py:181:18
    |
179 |         ..., description="Type: 'current', 'forecast', 'clusters'"
180 |     )
181 |     time_period: Optional[str] = Field("6months", description="Analysis period")
    |                  ^^^^^^^^^^^^^
182 |     focus_themes: Optional[List[str]] = Field(
183 |         None, description="Specific themes to analyze"
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/ml_api_service.py:182:19
    |
180 |     )
181 |     time_period: Optional[str] = Field("6months", description="Analysis period")
182 |     focus_themes: Optional[List[str]] = Field(
    |                   ^^^^^^^^^^^^^^^^^^^
183 |         None, description="Specific themes to analyze"
184 |     )
    |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/models/ml_api_service.py:182:28
    |
180 |     )
181 |     time_period: Optional[str] = Field("6months", description="Analysis period")
182 |     focus_themes: Optional[List[str]] = Field(
    |                            ^^^^
183 |         None, description="Specific themes to analyze"
184 |     )
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/models/ml_api_service.py:193:13
    |
191 |         ..., description="Operation: 'generate', 'transfer', 'predict', 'analyze'"
192 |     )
193 |     inputs: List[Dict] = Field(..., description="List of input requests")
    |             ^^^^
194 |     batch_id: Optional[str] = Field(None, description="Batch identifier")
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/models/ml_api_service.py:193:18
    |
191 |         ..., description="Operation: 'generate', 'transfer', 'predict', 'analyze'"
192 |     )
193 |     inputs: List[Dict] = Field(..., description="List of input requests")
    |                  ^^^^
194 |     batch_id: Optional[str] = Field(None, description="Batch identifier")
    |
help: Replace with `dict`

UP045 [*] Use `X | None` for type annotations
   --> src/models/ml_api_service.py:194:15
    |
192 |     )
193 |     inputs: List[Dict] = Field(..., description="List of input requests")
194 |     batch_id: Optional[str] = Field(None, description="Batch identifier")
    |               ^^^^^^^^^^^^^
    |
help: Convert to `X | None`

PTH123 `open()` should be replaced by `Path.open()`
   --> src/models/ml_api_service.py:239:22
    |
237 |             # Load quality predictor
238 |             try:
239 |                 with open("./models/quality_predictor.pkl", "rb") as f:
    |                      ^^^^
240 |                     self.quality_predictor = pickle.load(f)
241 |                 logger.info("âœ… Quality predictor loaded from file")
    |
help: Replace with `Path.open()`

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src/models/ml_api_service.py:259:17
    |
257 |               # In mock mode, don't raise exception
258 |               if ML_MODELS_AVAILABLE:
259 | /                 raise HTTPException(
260 | |                     status_code=500, detail=f"Model loading failed: {str(e)}"
261 | |                 )
    | |_________________^
262 |               else:
263 |                   logger.info("ðŸ”„ Continuing in mock mode...")
    |

RUF010 [*] Use explicit conversion flag
   --> src/models/ml_api_service.py:260:70
    |
258 |             if ML_MODELS_AVAILABLE:
259 |                 raise HTTPException(
260 |                     status_code=500, detail=f"Model loading failed: {str(e)}"
    |                                                                      ^^^^^^
261 |                 )
262 |             else:
    |
help: Replace with conversion flag

RET506 [*] Unnecessary `else` after `raise` statement
   --> src/models/ml_api_service.py:262:13
    |
260 |                     status_code=500, detail=f"Model loading failed: {str(e)}"
261 |                 )
262 |             else:
    |             ^^^^
263 |                 logger.info("ðŸ”„ Continuing in mock mode...")
264 |                 self.models_loaded = True
    |
help: Remove unnecessary `else`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/ml_api_service.py:288:22
    |
286 |         "status": "running",
287 |         "models_loaded": ml_models.models_loaded,
288 |         "timestamp": datetime.now().isoformat(),
    |                      ^^^^^^^^^^^^^^
289 |     }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/ml_api_service.py:303:22
    |
301 |             "trend_analyzer": ml_models.trend_analyzer is not None,
302 |         },
303 |         "timestamp": datetime.now().isoformat(),
    |                      ^^^^^^^^^^^^^^
304 |     }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> src/models/ml_api_service.py:309:52
    |
307 | @app.post("/generate")
308 | async def generate_text(
309 |     request: GenerationRequest, models: MLModels = Depends(get_models)
    |                                                    ^^^^^^^^^^^^^^^^^^^
310 | ):
311 |     """Generate rap text with conditional parameters"""
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/ml_api_service.py:365:36
    |
363 |             "metadata": {
364 |                 "model": "qwen_primary",
365 |                 "generation_time": datetime.now().isoformat(),
    |                                    ^^^^^^^^^^^^^^
366 |             },
367 |         }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src/models/ml_api_service.py:371:9
    |
369 |     except Exception as e:
370 |         logger.error(f"âŒ Generation failed: {e}")
371 |         raise HTTPException(status_code=500, detail=f"Generation failed: {str(e)}")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

RUF010 [*] Use explicit conversion flag
   --> src/models/ml_api_service.py:371:75
    |
369 |     except Exception as e:
370 |         logger.error(f"âŒ Generation failed: {e}")
371 |         raise HTTPException(status_code=500, detail=f"Generation failed: {str(e)}")
    |                                                                           ^^^^^^
    |
help: Replace with conversion flag

ARG001 Unused function argument: `models`
   --> src/models/ml_api_service.py:376:36
    |
374 | @app.post("/style-transfer")
375 | async def transfer_style(
376 |     request: StyleTransferRequest, models: MLModels = Depends(get_models)
    |                                    ^^^^^^
377 | ):
378 |     """Transfer lyrics style between artists"""
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> src/models/ml_api_service.py:376:55
    |
374 | @app.post("/style-transfer")
375 | async def transfer_style(
376 |     request: StyleTransferRequest, models: MLModels = Depends(get_models)
    |                                                       ^^^^^^^^^^^^^^^^^^^
377 | ):
378 |     """Transfer lyrics style between artists"""
    |

W293 Blank line contains whitespace
   --> src/models/ml_api_service.py:386:1
    |
384 |         # Style transfer (placeholder - would use actual trained model)
385 |         transferred_text = f"""[Style transferred from {request.source_artist} to {request.target_artist}]
386 |         
    | ^^^^^^^^
387 | Original style ({request.source_artist}):
388 | {request.lyrics[:100]}...
    |
help: Remove whitespace from blank line

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/ml_api_service.py:403:34
    |
401 |             "metadata": {
402 |                 "model": "style_transfer_t5",
403 |                 "transfer_time": datetime.now().isoformat(),
    |                                  ^^^^^^^^^^^^^^
404 |                 "original_length": len(request.lyrics),
405 |                 "transferred_length": len(transferred_text),
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src/models/ml_api_service.py:411:9
    |
409 |     except Exception as e:
410 |         logger.error(f"âŒ Style transfer failed: {e}")
411 |         raise HTTPException(status_code=500, detail=f"Style transfer failed: {str(e)}")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

RUF010 [*] Use explicit conversion flag
   --> src/models/ml_api_service.py:411:79
    |
409 |     except Exception as e:
410 |         logger.error(f"âŒ Style transfer failed: {e}")
411 |         raise HTTPException(status_code=500, detail=f"Style transfer failed: {str(e)}")
    |                                                                               ^^^^^^
    |
help: Replace with conversion flag

ARG001 Unused function argument: `models`
   --> src/models/ml_api_service.py:416:40
    |
414 | @app.post("/predict-quality")
415 | async def predict_quality(
416 |     request: QualityPredictionRequest, models: MLModels = Depends(get_models)
    |                                        ^^^^^^
417 | ):
418 |     """Predict quality metrics for lyrics"""
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> src/models/ml_api_service.py:416:59
    |
414 | @app.post("/predict-quality")
415 | async def predict_quality(
416 |     request: QualityPredictionRequest, models: MLModels = Depends(get_models)
    |                                                           ^^^^^^^^^^^^^^^^^^^
417 | ):
418 |     """Predict quality metrics for lyrics"""
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/ml_api_service.py:459:36
    |
457 |             "metadata": {
458 |                 "model": "quality_ensemble",
459 |                 "prediction_time": datetime.now().isoformat(),
    |                                    ^^^^^^^^^^^^^^
460 |                 "confidence": round(random.uniform(0.6, 0.9), 3),
461 |             },
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src/models/ml_api_service.py:466:9
    |
464 |       except Exception as e:
465 |           logger.error(f"âŒ Quality prediction failed: {e}")
466 | /         raise HTTPException(
467 | |             status_code=500, detail=f"Quality prediction failed: {str(e)}"
468 | |         )
    | |_________^
    |

RUF010 [*] Use explicit conversion flag
   --> src/models/ml_api_service.py:467:67
    |
465 |         logger.error(f"âŒ Quality prediction failed: {e}")
466 |         raise HTTPException(
467 |             status_code=500, detail=f"Quality prediction failed: {str(e)}"
    |                                                                   ^^^^^^
468 |         )
    |
help: Replace with conversion flag

ARG001 Unused function argument: `models`
   --> src/models/ml_api_service.py:473:36
    |
471 | @app.post("/analyze-trends")
472 | async def analyze_trends(
473 |     request: TrendAnalysisRequest, models: MLModels = Depends(get_models)
    |                                    ^^^^^^
474 | ):
475 |     """Analyze trends and predict emerging patterns"""
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> src/models/ml_api_service.py:473:55
    |
471 | @app.post("/analyze-trends")
472 | async def analyze_trends(
473 |     request: TrendAnalysisRequest, models: MLModels = Depends(get_models)
    |                                                       ^^^^^^^^^^^^^^^^^^^
474 | ):
475 |     """Analyze trends and predict emerging patterns"""
    |

TRY301 Abstract `raise` to an inner function
   --> src/models/ml_api_service.py:563:13
    |
562 |         else:
563 |             raise HTTPException(status_code=400, detail="Invalid analysis_type")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
564 |
565 |         return {
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/ml_api_service.py:574:34
    |
572 |             "metadata": {
573 |                 "model": "trend_analyzer",
574 |                 "analysis_time": datetime.now().isoformat(),
    |                                  ^^^^^^^^^^^^^^
575 |                 "data_source": "1000_track_sample",
576 |             },
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src/models/ml_api_service.py:581:9
    |
579 |     except Exception as e:
580 |         logger.error(f"âŒ Trend analysis failed: {e}")
581 |         raise HTTPException(status_code=500, detail=f"Trend analysis failed: {str(e)}")
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

RUF010 [*] Use explicit conversion flag
   --> src/models/ml_api_service.py:581:79
    |
579 |     except Exception as e:
580 |         logger.error(f"âŒ Trend analysis failed: {e}")
581 |         raise HTTPException(status_code=500, detail=f"Trend analysis failed: {str(e)}")
    |                                                                               ^^^^^^
    |
help: Replace with conversion flag

ARG001 Unused function argument: `background_tasks`
   --> src/models/ml_api_service.py:587:5
    |
585 | async def batch_process(
586 |     request: BatchRequest,
587 |     background_tasks: BackgroundTasks,
    |     ^^^^^^^^^^^^^^^^
588 |     models: MLModels = Depends(get_models),
589 | ):
    |

ARG001 Unused function argument: `models`
   --> src/models/ml_api_service.py:588:5
    |
586 |     request: BatchRequest,
587 |     background_tasks: BackgroundTasks,
588 |     models: MLModels = Depends(get_models),
    |     ^^^^^^
589 | ):
590 |     """Process multiple requests in batch"""
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> src/models/ml_api_service.py:588:24
    |
586 |     request: BatchRequest,
587 |     background_tasks: BackgroundTasks,
588 |     models: MLModels = Depends(get_models),
    |                        ^^^^^^^^^^^^^^^^^^^
589 | ):
590 |     """Process multiple requests in batch"""
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/ml_api_service.py:597:42
    |
596 |         batch_id = (
597 |             request.batch_id or f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    |                                          ^^^^^^^^^^^^^^
598 |         )
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/ml_api_service.py:609:33
    |
607 |             "progress_endpoint": f"/batch/{batch_id}/status",
608 |             "metadata": {
609 |                 "submitted_at": datetime.now().isoformat(),
    |                                 ^^^^^^^^^^^^^^
610 |                 "operation_type": request.operation,
611 |             },
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src/models/ml_api_service.py:616:9
    |
614 |       except Exception as e:
615 |           logger.error(f"âŒ Batch processing failed: {e}")
616 | /         raise HTTPException(
617 | |             status_code=500, detail=f"Batch processing failed: {str(e)}"
618 | |         )
    | |_________^
    |

RUF010 [*] Use explicit conversion flag
   --> src/models/ml_api_service.py:617:65
    |
615 |         logger.error(f"âŒ Batch processing failed: {e}")
616 |         raise HTTPException(
617 |             status_code=500, detail=f"Batch processing failed: {str(e)}"
    |                                                                 ^^^^^^
618 |         )
    |
help: Replace with conversion flag

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> src/models/ml_api_service.py:637:46
    |
636 | @app.get("/models/info")
637 | async def get_models_info(models: MLModels = Depends(get_models)):
    |                                              ^^^^^^^^^^^^^^^^^^^
638 |     """Get information about loaded models"""
639 |     return {
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/ml_api_service.py:663:22
    |
661 |         },
662 |         "api_version": "1.0.0",
663 |         "loaded_at": datetime.now().isoformat(),
    |                      ^^^^^^^^^^^^^^
664 |     }
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

ARG001 Unused function argument: `request`
   --> src/models/ml_api_service.py:671:36
    |
670 | @app.exception_handler(Exception)
671 | async def global_exception_handler(request, exc):
    |                                    ^^^^^^^
672 |     """Global exception handler"""
673 |     logger.error(f"âŒ Unhandled exception: {exc}")
    |

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/ml_api_service.py:681:26
    |
679 |             "error": "Internal server error",
680 |             "message": str(exc),
681 |             "timestamp": datetime.now().isoformat(),
    |                          ^^^^^^^^^^^^^^
682 |         },
683 |     )
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

I001 [*] Import block is un-sorted or un-formatted
  --> src/models/models.py:24:1
   |
22 |   """
23 |
24 | / from pydantic import BaseModel, Field
25 | | from typing import List, Optional, Dict, Any
26 | | from datetime import datetime
   | |_____________________________^
   |
help: Organize imports

UP035 `typing.List` is deprecated, use `list` instead
  --> src/models/models.py:25:1
   |
24 | from pydantic import BaseModel, Field
25 | from typing import List, Optional, Dict, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
26 | from datetime import datetime
   |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/models/models.py:25:1
   |
24 | from pydantic import BaseModel, Field
25 | from typing import List, Optional, Dict, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
26 | from datetime import datetime
   |

F401 [*] `typing.Dict` imported but unused
  --> src/models/models.py:25:36
   |
24 | from pydantic import BaseModel, Field
25 | from typing import List, Optional, Dict, Any
   |                                    ^^^^
26 | from datetime import datetime
   |
help: Remove unused import

F401 [*] `typing.Any` imported but unused
  --> src/models/models.py:25:42
   |
24 | from pydantic import BaseModel, Field
25 | from typing import List, Optional, Dict, Any
   |                                          ^^^
26 | from datetime import datetime
   |
help: Remove unused import

UP045 [*] Use `X | None` for type annotations
  --> src/models/models.py:35:15
   |
33 |         description="ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¶Ð°Ð½Ñ€ Ð¼ÑƒÐ·Ñ‹ÐºÐ¸ (hip-hop, rap, r&b, pop, etc.)"
34 |     )
35 |     subgenre: Optional[str] = Field(default=None, description="ÐŸÐ¾Ð´Ð¶Ð°Ð½Ñ€ ÐµÑÐ»Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ð¼Ð¾")
   |               ^^^^^^^^^^^^^
36 |     mood: str = Field(
37 |         description="ÐÐ°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ñ‚Ñ€ÐµÐºÐ° (energetic, melancholic, aggressive, chill, etc.)"
   |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
  --> src/models/models.py:39:20
   |
37 |         description="ÐÐ°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ñ‚Ñ€ÐµÐºÐ° (energetic, melancholic, aggressive, chill, etc.)"
38 |     )
39 |     year_estimate: Optional[int] = Field(
   |                    ^^^^^^^^^^^^^
40 |         default=None, description="ÐŸÑ€Ð¸Ð¼ÐµÑ€Ð½Ñ‹Ð¹ Ð³Ð¾Ð´ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¿Ð¾ ÑÑ‚Ð¸Ð»ÑŽ"
41 |     )
   |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
  --> src/models/models.py:58:18
   |
56 |         description="Ð¡Ð»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ñ‚ÐµÐºÑÑ‚Ð° (simple, medium, complex)"
57 |     )
58 |     main_themes: List[str] = Field(description="ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ñ‚ÐµÐ¼Ñ‹ Ð¿ÐµÑÐ½Ð¸")
   |                  ^^^^
59 |     emotional_tone: str = Field(
60 |         description="Ð­Ð¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ð¾Ð½ (positive, negative, neutral, mixed)"
   |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:101:16
    |
 99 |     artist: str
100 |     lyrics: str
101 |     genius_id: Optional[int] = None
    |                ^^^^^^^^^^^^^
102 |     scraped_date: str
103 |     word_count: int
    |
help: Convert to `X | None`

DTZ005 `datetime.datetime.now()` called without a `tz` argument
   --> src/models/models.py:111:56
    |
110 |     # ÐœÐµÑ‚Ð°Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ
111 |     analysis_date: str = Field(default_factory=lambda: datetime.now().isoformat())
    |                                                        ^^^^^^^^^^^^^^
112 |     model_version: str = Field(default="gemini-1.5-flash")
    |
help: Pass a `datetime.timezone` object to the `tz` parameter

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:119:16
    |
118 |     success: bool
119 |     song_data: Optional[EnhancedSongData] = None
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^
120 |     error_message: Optional[str] = None
121 |     processing_time: float
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:120:20
    |
118 |     success: bool
119 |     song_data: Optional[EnhancedSongData] = None
120 |     error_message: Optional[str] = None
    |                    ^^^^^^^^^^^^^
121 |     processing_time: float
    |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/models/models.py:133:13
    |
131 |     start_time: str
132 |     end_time: str
133 |     errors: List[str] = Field(default_factory=list)
    |             ^^^^
    |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/models/models.py:160:13
    |
158 |     spotify_id: str = Field(description="Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ID Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð° Ð² Spotify")
159 |     name: str = Field(description="Ð˜Ð¼Ñ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°")
160 |     genres: List[str] = Field(default_factory=list, description="Ð–Ð°Ð½Ñ€Ñ‹ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°")
    |             ^^^^
161 |     popularity: int = Field(ge=0, le=100, description="ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ð¾ÑÑ‚ÑŒ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð° (0-100)")
162 |     followers: int = Field(ge=0, description="ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð²")
    |
help: Replace with `list`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:163:16
    |
161 |     popularity: int = Field(ge=0, le=100, description="ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ð¾ÑÑ‚ÑŒ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð° (0-100)")
162 |     followers: int = Field(ge=0, description="ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð²")
163 |     image_url: Optional[str] = Field(
    |                ^^^^^^^^^^^^^
164 |         default=None, description="URL Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°"
165 |     )
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:175:17
    |
173 |     name: str = Field(description="ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ñ‚Ñ€ÐµÐºÐ°")
174 |     artist_id: str = Field(description="ID Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð° Ð² Spotify")
175 |     album_name: Optional[str] = Field(default=None, description="ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð°Ð»ÑŒÐ±Ð¾Ð¼Ð°")
    |                 ^^^^^^^^^^^^^
176 |     release_date: Optional[str] = Field(default=None, description="Ð”Ð°Ñ‚Ð° Ñ€ÐµÐ»Ð¸Ð·Ð°")
177 |     duration_ms: Optional[int] = Field(
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:176:19
    |
174 |     artist_id: str = Field(description="ID Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð° Ð² Spotify")
175 |     album_name: Optional[str] = Field(default=None, description="ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð°Ð»ÑŒÐ±Ð¾Ð¼Ð°")
176 |     release_date: Optional[str] = Field(default=None, description="Ð”Ð°Ñ‚Ð° Ñ€ÐµÐ»Ð¸Ð·Ð°")
    |                   ^^^^^^^^^^^^^
177 |     duration_ms: Optional[int] = Field(
178 |         default=None, description="Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð² Ð¼Ð¸Ð»Ð»Ð¸ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…"
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:177:18
    |
175 |     album_name: Optional[str] = Field(default=None, description="ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð°Ð»ÑŒÐ±Ð¾Ð¼Ð°")
176 |     release_date: Optional[str] = Field(default=None, description="Ð”Ð°Ñ‚Ð° Ñ€ÐµÐ»Ð¸Ð·Ð°")
177 |     duration_ms: Optional[int] = Field(
    |                  ^^^^^^^^^^^^^
178 |         default=None, description="Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð² Ð¼Ð¸Ð»Ð»Ð¸ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…"
179 |     )
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:183:18
    |
181 |     explicit: bool = Field(default=False, description="Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð»Ð¸ Ñ‚Ñ€ÐµÐº ÑÐ²Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚")
182 |     spotify_url: str = Field(description="Ð¡ÑÑ‹Ð»ÐºÐ° Ð½Ð° Ñ‚Ñ€ÐµÐº Ð² Spotify")
183 |     preview_url: Optional[str] = Field(default=None, description="URL Ð¿Ñ€ÐµÐ²ÑŒÑŽ Ñ‚Ñ€ÐµÐºÐ°")
    |                  ^^^^^^^^^^^^^
184 |     audio_features: Optional[SpotifyAudioFeatures] = Field(
185 |         default=None, description="ÐÑƒÐ´Ð¸Ð¾-Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ¸"
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:184:21
    |
182 |     spotify_url: str = Field(description="Ð¡ÑÑ‹Ð»ÐºÐ° Ð½Ð° Ñ‚Ñ€ÐµÐº Ð² Spotify")
183 |     preview_url: Optional[str] = Field(default=None, description="URL Ð¿Ñ€ÐµÐ²ÑŒÑŽ Ñ‚Ñ€ÐµÐºÐ°")
184 |     audio_features: Optional[SpotifyAudioFeatures] = Field(
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
185 |         default=None, description="ÐÑƒÐ´Ð¸Ð¾-Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ¸"
186 |     )
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:193:18
    |
192 |     success: bool
193 |     artist_data: Optional[SpotifyArtist] = None
    |                  ^^^^^^^^^^^^^^^^^^^^^^^
194 |     track_data: Optional[SpotifyTrack] = None
195 |     error_message: Optional[str] = None
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:194:17
    |
192 |     success: bool
193 |     artist_data: Optional[SpotifyArtist] = None
194 |     track_data: Optional[SpotifyTrack] = None
    |                 ^^^^^^^^^^^^^^^^^^^^^^
195 |     error_message: Optional[str] = None
196 |     processing_time: float
    |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
   --> src/models/models.py:195:20
    |
193 |     artist_data: Optional[SpotifyArtist] = None
194 |     track_data: Optional[SpotifyTrack] = None
195 |     error_message: Optional[str] = None
    |                    ^^^^^^^^^^^^^
196 |     processing_time: float
197 |     api_calls_used: int = Field(
    |
help: Convert to `X | None`

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:132:1
    |
130 |     batch_saves: int = 0
131 |     start_time: datetime = field(default_factory=datetime.now)
132 |     
    | ^^^^
133 |     def increment(self, status: ScrapingStatus, processing_time: float = 0.0):
134 |         """Ð£Ð²ÐµÐ»Ð¸Ñ‡ÐµÐ½Ð¸Ðµ ÑÑ‡ÐµÑ‚Ñ‡Ð¸ÐºÐ° Ð¿Ð¾ ÑÑ‚Ð°Ñ‚ÑƒÑÑƒ"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:141:1
    |
139 |                 / self.processed
140 |             )
141 |             
    | ^^^^^^^^^^^^
142 |         if status == ScrapingStatus.SUCCESS:
143 |             self.added += 1
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:156:1
    |
154 |         elif status == ScrapingStatus.ERROR_UNKNOWN:
155 |             self.error_unknown += 1
156 |     
    | ^^^^
157 |     @property
158 |     def total_errors(self) -> int:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:161:1
    |
159 |         return (self.error_network + self.error_api_limit + 
160 |                 self.error_parsing + self.error_unknown)
161 |     
    | ^^^^
162 |     @property
163 |     def success_rate(self) -> float:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:165:1
    |
163 |     def success_rate(self) -> float:
164 |         return (self.added / self.processed * 100) if self.processed > 0 else 0.0
165 |     
    | ^^^^
166 |     @property
167 |     def runtime(self) -> timedelta:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:172:1
    |
170 | class CircuitBreaker:
171 |     """Circuit breaker Ð´Ð»Ñ API Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð²"""
172 |     
    | ^^^^
173 |     def __init__(self, failure_threshold: int = 5, recovery_timeout: int = 60):
174 |         self.failure_threshold = failure_threshold
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:179:1
    |
177 |         self.last_failure_time = None
178 |         self.state = "closed"  # closed, open, half_open
179 |         
    | ^^^^^^^^
180 |     def call(self, func, *args, **kwargs):
181 |         """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ñ‡ÐµÑ€ÐµÐ· circuit breaker"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:188:1
    |
186 |             else:
187 |                 raise Exception("Circuit breaker is OPEN - API Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½")
188 |         
    | ^^^^^^^^
189 |         try:
190 |             result = func(*args, **kwargs)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:197:1
    |
195 |             self.record_failure()
196 |             raise e
197 |     
    | ^^^^
198 |     def record_failure(self):
199 |         """Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¸"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:202:1
    |
200 |         self.failure_count += 1
201 |         self.last_failure_time = datetime.now()
202 |         
    | ^^^^^^^^
203 |         if self.failure_count >= self.failure_threshold:
204 |             self.state = "open"
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:206:1
    |
204 |             self.state = "open"
205 |             logger.warning(f"ðŸš¨ Circuit breaker ÐžÐ¢ÐšÐ Ð«Ð¢ Ð¿Ð¾ÑÐ»Ðµ {self.failure_count} Ð¾ÑˆÐ¸Ð±Ð¾Ðº")
206 |     
    | ^^^^
207 |     def reset(self):
208 |         """Ð¡Ð±Ñ€Ð¾Ñ circuit breaker"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:216:1
    |
214 | class EnhancedResourceMonitor:
215 |     """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð² Ñ Ð¿Ñ€ÐµÐ´Ð¸ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¹ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¾Ð¹"""
216 |     
    | ^^^^
217 |     def __init__(self, memory_limit_mb: int = 2048):
218 |         self.process = psutil.Process()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:223:1
    |
221 |         self.memory_history = []
222 |         self.max_history = 10
223 |         
    | ^^^^^^^^
224 |     def get_memory_usage(self) -> float:
225 |         """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ð² ÐœÐ‘"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:227:1
    |
225 |         """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ð² ÐœÐ‘"""
226 |         return self.process.memory_info().rss / 1024 / 1024
227 |     
    | ^^^^
228 |     def get_cpu_usage(self) -> float:
229 |         """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ CPU Ð² %"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:231:1
    |
229 |         """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ CPU Ð² %"""
230 |         return self.process.cpu_percent(interval=0.1)
231 |     
    | ^^^^
232 |     def predict_memory_trend(self) -> str:
233 |         """ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ñ‚Ñ€ÐµÐ½Ð´Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð°Ð¼ÑÑ‚Ð¸"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:236:1
    |
234 |         if len(self.memory_history) < 3:
235 |             return "insufficient_data"
236 |         
    | ^^^^^^^^
237 |         recent_avg = sum(self.memory_history[-3:]) / 3
238 |         older_avg = sum(self.memory_history[-6:-3]) / 3 if len(self.memory_history) >= 6 else recent_avg
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:239:1
    |
237 |         recent_avg = sum(self.memory_history[-3:]) / 3
238 |         older_avg = sum(self.memory_history[-6:-3]) / 3 if len(self.memory_history) >= 6 else recent_avg
239 |         
    | ^^^^^^^^
240 |         if recent_avg > older_avg * 1.1:
241 |             return "increasing"
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:246:1
    |
244 |         else:
245 |             return "stable"
246 |     
    | ^^^^
247 |     def check_memory_limit(self) -> tuple[bool, str]:
248 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð»Ð¸Ð¼Ð¸Ñ‚Ð° Ð¿Ð°Ð¼ÑÑ‚Ð¸ Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:251:1
    |
249 |         current_memory = self.get_memory_usage()
250 |         self.memory_history.append(current_memory)
251 |         
    | ^^^^^^^^
252 |         if len(self.memory_history) > self.max_history:
253 |             self.memory_history.pop(0)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:254:1
    |
252 |         if len(self.memory_history) > self.max_history:
253 |             self.memory_history.pop(0)
254 |         
    | ^^^^^^^^
255 |         usage_ratio = current_memory / self.memory_limit_mb
256 |         trend = self.predict_memory_trend()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:257:1
    |
255 |         usage_ratio = current_memory / self.memory_limit_mb
256 |         trend = self.predict_memory_trend()
257 |         
    | ^^^^^^^^
258 |         if usage_ratio > 0.95:
259 |             return True, "critical"
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:266:1
    |
264 |         else:
265 |             return False, "normal"
266 |     
    | ^^^^
267 |     def log_resources(self):
268 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ðµ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:272:1
    |
270 |         cpu_percent = self.get_cpu_usage()
271 |         trend = self.predict_memory_trend()
272 |         
    | ^^^^^^^^
273 |         logger.info(f"ðŸ’¾ Memory: {memory_mb:.1f}MB | ðŸ–¥ï¸ CPU: {cpu_percent:.1f}% | ðŸ“ˆ Trend: {trend}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:274:1
    |
273 |         logger.info(f"ðŸ’¾ Memory: {memory_mb:.1f}MB | ðŸ–¥ï¸ CPU: {cpu_percent:.1f}% | ðŸ“ˆ Trend: {trend}")
274 |         
    | ^^^^^^^^
275 |         limit_exceeded, status = self.check_memory_limit()
276 |         if limit_exceeded:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:278:1
    |
276 |         if limit_exceeded:
277 |             logger.warning(f"âš ï¸ Memory status: {status} - {memory_mb:.1f}MB/{self.memory_limit_mb}MB")
278 |     
    | ^^^^
279 |     def force_garbage_collection(self) -> int:
280 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð°Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° Ð¿Ð°Ð¼ÑÑ‚Ð¸"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:285:1
    |
283 |         after_memory = self.get_memory_usage()
284 |         freed_mb = before_memory - after_memory
285 |         
    | ^^^^^^^^
286 |         logger.info(f"ðŸ—‘ï¸ GC: Ð¾ÑÐ²Ð¾Ð±Ð¾Ð¶Ð´ÐµÐ½Ð¾ {freed_mb:.1f}MB, ÑÐ¾Ð±Ñ€Ð°Ð½Ð¾ {collected} Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²")
287 |         return collected
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:291:1
    |
289 | class BatchProcessor:
290 |     """Ð‘Ð°Ñ‚Ñ‡ÐµÐ²Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€ Ð´Ð»Ñ PostgreSQL Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹"""
291 |     
    | ^^^^
292 |     def __init__(self, batch_size: int = 10, flush_interval: float = 30.0):
293 |         self.batch_size = batch_size
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:297:1
    |
295 |         self.pending_songs = []
296 |         self.last_flush = time.time()
297 |         
    | ^^^^^^^^
298 |     def add_song(self, song_data: dict):
299 |         """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐ½Ð¸ Ð² Ð±Ð°Ñ‚Ñ‡"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:301:1
    |
299 |         """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐ½Ð¸ Ð² Ð±Ð°Ñ‚Ñ‡"""
300 |         self.pending_songs.append(song_data)
301 |         
    | ^^^^^^^^
302 |         # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚ÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ
303 |         current_time = time.time()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:308:1
    |
306 |             return True  # ÐÑƒÐ¶Ð½Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ
307 |         return False
308 |     
    | ^^^^
309 |     def get_pending_batch(self) -> List[dict]:
310 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ Ð±Ð°Ñ‚Ñ‡Ð° Ð¸ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ°"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:315:1
    |
313 |         self.last_flush = time.time()
314 |         return batch
315 |     
    | ^^^^
316 |     def has_pending(self) -> bool:
317 |         """Ð•ÑÑ‚ÑŒ Ð»Ð¸ Ð¾Ð¶Ð¸Ð´Ð°ÑŽÑ‰Ð¸Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ðµ"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:322:1
    |
320 | class OptimizedPostgreSQLScraper:
321 |     """ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—Ð˜Ð ÐžÐ’ÐÐÐÐ«Ð™ ÑÐºÑ€Ð°Ð¿ÐµÑ€ Ñ PostgreSQL Ð¸ Ð¿Ñ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ð¼Ð¸ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑÐ¼Ð¸"""
322 |     
    | ^^^^
323 |     def __init__(self, token: str, memory_limit_mb: int = 2048, batch_size: int = 10):
324 |         # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾ÐºÑÐ¸ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:326:1
    |
324 |         # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾ÐºÑÐ¸ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ
325 |         self._clear_proxy_env()
326 |         
    | ^^^^^^^^
327 |         # Genius API ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸ÑÐ¼Ð¸
328 |         self.genius = lyricsgenius.Genius(
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:336:1
    |
334 |             excluded_terms=["(Remix)", "(Live)", "(Instrumental)", "(Skit)", "(Interlude)"]
335 |         )
336 |         
    | ^^^^^^^^
337 |         # ÐšÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹
338 |         self.db = PostgreSQLManager()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:343:1
    |
341 |         self.batch_processor = BatchProcessor(batch_size=batch_size)
342 |         self.metrics = SessionMetrics()
343 |         
    | ^^^^^^^^
344 |         # ÐšÑÑˆ Ð´Ð»Ñ Ð´ÐµÐ´ÑƒÐ¿Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸
345 |         self.url_cache = set()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:347:1
    |
345 |         self.url_cache = set()
346 |         self.artist_cache = {}
347 |         
    | ^^^^^^^^
348 |         # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ retry
349 |         self.base_delay = 2.0
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:353:1
    |
351 |         self.backoff_multiplier = 1.5
352 |         self.max_retries = 3
353 |         
    | ^^^^^^^^
354 |         # Ð¤Ð»Ð°Ð³Ð¸ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
355 |         self.shutdown_requested = False
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:357:1
    |
355 |         self.shutdown_requested = False
356 |         self.pause_requested = False
357 |         
    | ^^^^^^^^
358 |         # Thread pool Ð´Ð»Ñ CPU-intensive Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹
359 |         self.executor = ThreadPoolExecutor(max_workers=2)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:360:1
    |
358 |         # Thread pool Ð´Ð»Ñ CPU-intensive Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹
359 |         self.executor = ThreadPoolExecutor(max_workers=2)
360 |         
    | ^^^^^^^^
361 |         self.cleared_proxies = {}
362 |         self._setup_signal_handlers()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:363:1
    |
361 |         self.cleared_proxies = {}
362 |         self._setup_signal_handlers()
363 |         
    | ^^^^^^^^
364 |         logger.info("ðŸš€ Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½ ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—Ð˜Ð ÐžÐ’ÐÐÐÐ«Ð™ PostgreSQL ÑÐºÑ€Ð°Ð¿ÐµÑ€")
365 |         logger.info(f"âš™ï¸ Batch size: {batch_size}, Memory limit: {memory_limit_mb}MB")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:366:1
    |
364 |         logger.info("ðŸš€ Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½ ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—Ð˜Ð ÐžÐ’ÐÐÐÐ«Ð™ PostgreSQL ÑÐºÑ€Ð°Ð¿ÐµÑ€")
365 |         logger.info(f"âš™ï¸ Batch size: {batch_size}, Memory limit: {memory_limit_mb}MB")
366 |         
    | ^^^^^^^^
367 |     def _clear_proxy_env(self):
368 |         """Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÑÐµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾ÐºÑÐ¸ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:374:1
    |
372 |             'NO_PROXY', 'no_proxy'
373 |         ]
374 |         
    | ^^^^^^^^
375 |         self.cleared_proxies = {}
376 |         for var in proxy_vars:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:379:1
    |
377 |             if var in os.environ:
378 |                 self.cleared_proxies[var] = os.environ.pop(var)
379 |                 
    | ^^^^^^^^^^^^^^^^
380 |     def _restore_proxy_env(self):
381 |         """Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¾ÐºÑÐ¸ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:384:1
    |
382 |         for var, value in self.cleared_proxies.items():
383 |             os.environ[var] = value
384 |         
    | ^^^^^^^^
385 |     def _setup_signal_handlers(self):
386 |         """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¾Ð² ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²"""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:390:1
    |
388 |             logger.info(f"\nðŸ›‘ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ ÑÐ¸Ð³Ð½Ð°Ð» {signum}. Graceful shutdown...")
389 |             self.shutdown_requested = True
390 |             
    | ^^^^^^^^^^^^
391 |         signal.signal(signal.SIGINT, signal_handler)
392 |         signal.signal(signal.SIGTERM, signal_handler)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:393:1
    |
391 |         signal.signal(signal.SIGINT, signal_handler)
392 |         signal.signal(signal.SIGTERM, signal_handler)
393 |         
    | ^^^^^^^^
394 |         if sys.platform == "win32":
395 |             try:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:410:1
    |
408 |         else:
409 |             delay = random.uniform(self.base_delay, self.base_delay + 2)
410 |         
    | ^^^^^^^^
411 |         # Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÐ¼ Ð½Ð° Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ shutdown
412 |         intervals = int(delay)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:414:1
    |
412 |         intervals = int(delay)
413 |         remainder = delay - intervals
414 |         
    | ^^^^^^^^
415 |         for _ in range(intervals):
416 |             if self.shutdown_requested:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:419:1
    |
417 |                 return
418 |             await asyncio.sleep(1)
419 |                 
    | ^^^^^^^^^^^^^^^^
420 |         if remainder > 0 and not self.shutdown_requested:
421 |             await asyncio.sleep(remainder)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:427:1
    |
425 |         if not lyrics:
426 |             return ""
427 |         
    | ^^^^^^^^
428 |         # ÐŸÑ€ÐµÐ´ÐºÐ¾Ð¼Ð¿Ð¸Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ñ€ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ñ‹Ðµ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ (Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ)
429 |         patterns = [
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:439:1
    |
437 |             (re.compile(r"\n{2,}"), "\n"),
438 |         ]
439 |         
    | ^^^^^^^^
440 |         for pattern, replacement in patterns:
441 |             lyrics = pattern.sub(replacement, lyrics)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:442:1
    |
440 |         for pattern, replacement in patterns:
441 |             lyrics = pattern.sub(replacement, lyrics)
442 |         
    | ^^^^^^^^
443 |         return lyrics.strip()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:449:1
    |
447 |         if not lyrics:
448 |             return False, "empty"
449 |             
    | ^^^^^^^^^^^^
450 |         lyrics = lyrics.strip()
451 |         word_count = len(lyrics.split())
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:452:1
    |
450 |         lyrics = lyrics.strip()
451 |         word_count = len(lyrics.split())
452 |         
    | ^^^^^^^^
453 |         if len(lyrics) < 100:
454 |             return False, "too_short_chars"
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:457:1
    |
455 |         if word_count < 20:
456 |             return False, "too_short_words"
457 |             
    | ^^^^^^^^^^^^
458 |         # Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸
459 |         instrumental_markers = [
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:463:1
    |
461 |             "beat only", "outro", "intro", "skit", "interlude"
462 |         ]
463 |         
    | ^^^^^^^^
464 |         lyrics_lower = lyrics.lower()
465 |         for marker in instrumental_markers:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:468:1
    |
466 |             if marker in lyrics_lower:
467 |                 return False, f"instrumental_marker_{marker}"
468 |         
    | ^^^^^^^^
469 |         # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð° Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ð¹ÑÑ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚
470 |         unique_lines = set(line.strip() for line in lyrics.split('\n') if line.strip())
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:473:1
    |
471 |         if len(unique_lines) < word_count * 0.3:  # Ð¡Ð»Ð¸ÑˆÐºÐ¾Ð¼ Ð¼Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÐµÐ½Ð¸Ð¹
472 |             return False, "too_repetitive"
473 |         
    | ^^^^^^^^
474 |         return True, "valid"
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:484:1
    |
482 |         """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ðµ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
483 |         metadata = {}
484 |         
    | ^^^^^^^^
485 |         try:
486 |             # Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ðµ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ‚Ð¾Ð²
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:497:1
    |
495 |                 ('language', ['language']),
496 |             ]
497 |             
    | ^^^^^^^^^^^^
498 |             for key, attr_path in safe_attrs:
499 |                 value = song
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:508:1
    |
506 |                         value = None
507 |                         break
508 |                         
    | ^^^^^^^^^^^^^^^^^^^^^^^^
509 |                 if value is not None:
510 |                     metadata[key] = str(value) if not isinstance(value, (dict, list)) else value
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:511:1
    |
509 |                 if value is not None:
510 |                     metadata[key] = str(value) if not isinstance(value, (dict, list)) else value
511 |             
    | ^^^^^^^^^^^^
512 |             # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸
513 |             if hasattr(song, 'stats') and song.stats:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:518:1
    |
516 |                     metadata['pageviews'] = stats.get('pageviews', 0)
517 |                     metadata['hot'] = stats.get('hot', False)
518 |             
    | ^^^^^^^^^^^^
519 |             # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÐ·Ñ‹ÐºÐ° (ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð°Ñ ÑÐ²Ñ€Ð¸ÑÑ‚Ð¸ÐºÐ°)
520 |             if 'language' not in metadata and hasattr(song, 'lyrics'):
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:524:1
    |
522 |                 english_indicators = ['the', 'and', 'you', 'that', 'with', 'for', 'are', 'this']
523 |                 russian_indicators = ['Ñ‡Ñ‚Ð¾', 'ÐºÐ°Ðº', 'ÑÑ‚Ð¾', 'Ð¾Ð½Ð¸', 'Ð²ÑÐµ', 'Ñ‚Ð°Ðº', 'Ð¼Ð½Ðµ', 'ÐµÐ³Ð¾']
524 |                 
    | ^^^^^^^^^^^^^^^^
525 |                 lyrics_lower = song.lyrics.lower() if song.lyrics else ""
526 |                 english_count = sum(1 for word in english_indicators if word in lyrics_lower)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:528:1
    |
526 |                 english_count = sum(1 for word in english_indicators if word in lyrics_lower)
527 |                 russian_count = sum(1 for word in russian_indicators if word in lyrics_lower)
528 |                 
    | ^^^^^^^^^^^^^^^^
529 |                 if russian_count > english_count:
530 |                     metadata['language'] = 'ru'
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:533:1
    |
531 |                 else:
532 |                     metadata['language'] = 'en'
533 |                     
    | ^^^^^^^^^^^^^^^^^^^^
534 |         except Exception as e:
535 |             logger.debug(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ…: {e}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:536:1
    |
534 |         except Exception as e:
535 |             logger.debug(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ…: {e}")
536 |             
    | ^^^^^^^^^^^^
537 |         return metadata
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:543:1
    |
541 |         if not songs_batch:
542 |             return 0
543 |             
    | ^^^^^^^^^^^^
544 |         start_time = time.time()
545 |         saved_count = 0
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:546:1
    |
544 |         start_time = time.time()
545 |         saved_count = 0
546 |         
    | ^^^^^^^^
547 |         try:
548 |             # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ asyncpg Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð±Ð°Ñ‚Ñ‡ÐµÐ²Ð¾Ð³Ð¾ INSERT
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:557:1
    |
555 |                     if self.db.add_song(**song_data):
556 |                         saved_count += 1
557 |             
    | ^^^^^^^^^^^^
558 |             processing_time = time.time() - start_time
559 |             self.metrics.batch_saves += 1
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:560:1
    |
558 |             processing_time = time.time() - start_time
559 |             self.metrics.batch_saves += 1
560 |             
    | ^^^^^^^^^^^^
561 |             logger.info(f"ðŸ’¾ Ð‘Ð°Ñ‚Ñ‡ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½: {saved_count}/{len(songs_batch)} Ð¿ÐµÑÐµÐ½ Ð·Ð° {processing_time:.2f}Ñ")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:562:1
    |
561 |             logger.info(f"ðŸ’¾ Ð‘Ð°Ñ‚Ñ‡ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½: {saved_count}/{len(songs_batch)} Ð¿ÐµÑÐµÐ½ Ð·Ð° {processing_time:.2f}Ñ")
562 |             
    | ^^^^^^^^^^^^
563 |         except Exception as e:
564 |             logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð±Ð°Ñ‚Ñ‡ÐµÐ²Ð¾Ð³Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ: {e}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:565:1
    |
563 |         except Exception as e:
564 |             logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð±Ð°Ñ‚Ñ‡ÐµÐ²Ð¾Ð³Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ: {e}")
565 |             
    | ^^^^^^^^^^^^
566 |         return saved_count
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:572:1
    |
570 |         try:
571 |             logger.info(f"ðŸŽµ ÐŸÐ¾Ð¸ÑÐº Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°: {artist_name}")
572 |             
    | ^^^^^^^^^^^^
573 |             # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÑÑˆ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°
574 |             if artist_name in self.artist_cache:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:580:1
    |
578 |                     yield song, i + 1
579 |                 return
580 |             
    | ^^^^^^^^^^^^
581 |             # ÐŸÐ¾Ð¸ÑÐº Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð° Ñ‡ÐµÑ€ÐµÐ· circuit breaker
582 |             artist = await asyncio.get_event_loop().run_in_executor(
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:592:1
    |
590 |                 )
591 |             )
592 |             
    | ^^^^^^^^^^^^
593 |             self.metrics.api_calls += 1
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:594:1
    |
593 |             self.metrics.api_calls += 1
594 |             
    | ^^^^^^^^^^^^
595 |             if not artist or not hasattr(artist, 'tracks) or not artist.songs:
596 |                 logger.warning(f"âŒ ÐÑ€Ñ‚Ð¸ÑÑ‚ {artist_name} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¸Ð»Ð¸ Ð½ÐµÑ‚ Ð¿ÐµÑÐµÐ½")
    |
help: Remove whitespace from blank line

invalid-syntax: missing closing quote in string literal
   --> src/scrapers/rap_scraper_postgres.py:595:50
    |
593 |             self.metrics.api_calls += 1
594 |             
595 |             if not artist or not hasattr(artist, 'tracks) or not artist.songs:
    |                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
596 |                 logger.warning(f"âŒ ÐÑ€Ñ‚Ð¸ÑÑ‚ {artist_name} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¸Ð»Ð¸ Ð½ÐµÑ‚ Ð¿ÐµÑÐµÐ½")
597 |                 return
    |

invalid-syntax: Expected ',', found name
   --> src/scrapers/rap_scraper_postgres.py:596:17
    |
595 |             if not artist or not hasattr(artist, 'tracks) or not artist.songs:
596 |                 logger.warning(f"âŒ ÐÑ€Ñ‚Ð¸ÑÑ‚ {artist_name} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¸Ð»Ð¸ Ð½ÐµÑ‚ Ð¿ÐµÑÐµÐ½")
    |                 ^^^^^^
597 |                 return
    |

invalid-syntax: Expected ')', found newline
   --> src/scrapers/rap_scraper_postgres.py:596:82
    |
595 |             if not artist or not hasattr(artist, 'tracks) or not artist.songs:
596 |                 logger.warning(f"âŒ ÐÑ€Ñ‚Ð¸ÑÑ‚ {artist_name} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¸Ð»Ð¸ Ð½ÐµÑ‚ Ð¿ÐµÑÐµÐ½")
    |                                                                                   ^
597 |                 return
    |

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:598:1
    |
596 |                 logger.warning(f"âŒ ÐÑ€Ñ‚Ð¸ÑÑ‚ {artist_name} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¸Ð»Ð¸ Ð½ÐµÑ‚ Ð¿ÐµÑÐµÐ½")
597 |                 return
598 |             
    | ^^^^^^^^^^^^
599 |             total_songs = len(artist.songs)
600 |             logger.info(f"ðŸ“€ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {total_songs} Ð¿ÐµÑÐµÐ½ Ð´Ð»Ñ {artist_name}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:601:1
    |
599 |             total_songs = len(artist.songs)
600 |             logger.info(f"ðŸ“€ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {total_songs} Ð¿ÐµÑÐµÐ½ Ð´Ð»Ñ {artist_name}")
601 |             
    | ^^^^^^^^^^^^
602 |             # ÐšÑÑˆÐ¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
603 |             self.artist_cache[artist_name] = artist.tracks[:20]  # ÐšÑÑˆÐ¸Ñ€ÑƒÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 20 Ð¿ÐµÑÐµÐ½
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:604:1
    |
602 |             # ÐšÑÑˆÐ¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
603 |             self.artist_cache[artist_name] = artist.tracks[:20]  # ÐšÑÑˆÐ¸Ñ€ÑƒÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 20 Ð¿ÐµÑÐµÐ½
604 |             
    | ^^^^^^^^^^^^
605 |             # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ Ð¿ÐµÑÐ½Ð¸
606 |             logger.info("ðŸŽµ ÐŸÐµÑ€Ð²Ñ‹Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ðµ Ð¿ÐµÑÐ½Ð¸:")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:609:1
    |
607 |             for i, song in enumerate(artist.tracks[:5], 1):
608 |                 logger.info(f"  {i}. {song.title}")
609 |             
    | ^^^^^^^^^^^^
610 |             # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð¿ÐµÑÐ½Ð¸
611 |             for i, song in enumerate(artist.songs):
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:615:1
    |
613 |                     logger.info(f"ðŸ›‘ ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð½Ð° Ð¿ÐµÑÐ½Ðµ {i+1}/{total_songs}")
614 |                     break
615 |                     
    | ^^^^^^^^^^^^^^^^^^^^
616 |                 yield song, i + 1
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:617:1
    |
616 |                 yield song, i + 1
617 |                 
    | ^^^^^^^^^^^^^^^^
618 |                 # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿Ð°Ð¼ÑÑ‚Ð¸ ÐºÐ°Ð¶Ð´Ñ‹Ðµ 10 Ð¿ÐµÑÐµÐ½
619 |                 if i % 10 == 0:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:626:1
    |
624 |                         self.metrics.gc_runs += 1
625 |                         await asyncio.sleep(1)  # Ð”Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼Ñ Ð½Ð° GC
626 |                 
    | ^^^^^^^^^^^^^^^^
627 |         except Exception as e:
628 |             error_msg = str(e).lower()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:640:1
    |
638 |         """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ð´Ð½Ð¾Ð¹ Ð¿ÐµÑÐ½Ð¸"""
639 |         start_time = time.time()
640 |         
    | ^^^^^^^^
641 |         try:
642 |             # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° URL ÐºÑÑˆÐ°
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:647:1
    |
645 |                 self.metrics.cache_hits += 1
646 |                 return ScrapingStatus.SKIPPED_DUPLICATE
647 |             
    | ^^^^^^^^^^^^
648 |             # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿ÐµÑÐ½Ð¸
649 |             if not hasattr(song, 'lyrics') or not song.lyrics:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:657:1
    |
655 |                     )
656 |                     self.metrics.api_calls += 1
657 |                     
    | ^^^^^^^^^^^^^^^^^^^^
658 |                     if full_song and hasattr(full_song, 'lyrics'):
659 |                         song = full_song
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:662:1
    |
660 |                     else:
661 |                         return ScrapingStatus.SKIPPED_QUALITY
662 |                         
    | ^^^^^^^^^^^^^^^^^^^^^^^^
663 |                 except Exception as e:
664 |                     if "circuit breaker" in str(e).lower():
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:668:1
    |
666 |                     else:
667 |                         return ScrapingStatus.ERROR_NETWORK
668 |             
    | ^^^^^^^^^^^^
669 |             # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð° Ð² Ð‘Ð” (Ð±Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ°)
670 |             if self.db.song_exists(url=song_url):
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:673:1
    |
671 |                 self.url_cache.add(song_url)
672 |                 return ScrapingStatus.SKIPPED_DUPLICATE
673 |             
    | ^^^^^^^^^^^^
674 |             # ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð¸ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð°
675 |             lyrics = await asyncio.get_event_loop().run_in_executor(
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:678:1
    |
676 |                 self.executor, self.clean_lyrics, song.lyrics
677 |             )
678 |             
    | ^^^^^^^^^^^^
679 |             is_valid, reason = self._is_valid_lyrics(lyrics)
680 |             if not is_valid:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:683:1
    |
681 |                 logger.debug(f"â© ÐÐµÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ ({reason}): {song.title}")
682 |                 return ScrapingStatus.SKIPPED_QUALITY
683 |             
    | ^^^^^^^^^^^^
684 |             # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ…ÑÑˆÐ° Ð´Ð»Ñ Ð´ÐµÐ´ÑƒÐ¿Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸
685 |             song_hash = self.generate_song_hash(artist_name, song.title, lyrics)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:686:1
    |
684 |             # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ…ÑÑˆÐ° Ð´Ð»Ñ Ð´ÐµÐ´ÑƒÐ¿Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸
685 |             song_hash = self.generate_song_hash(artist_name, song.title, lyrics)
686 |             
    | ^^^^^^^^^^^^
687 |             # Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ…
688 |             metadata = self.extract_metadata(song)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:691:1
    |
689 |             metadata['processing_time'] = time.time() - start_time
690 |             metadata['song_hash'] = song_hash
691 |             
    | ^^^^^^^^^^^^
692 |             # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð±Ð°Ñ‚Ñ‡ÐµÐ²Ð¾Ð³Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ
693 |             song_data = {
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:701:1
    |
699 |                 'metadata': metadata
700 |             }
701 |             
    | ^^^^^^^^^^^^
702 |             # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² Ð±Ð°Ñ‚Ñ‡
703 |             should_flush = self.batch_processor.add_song(song_data)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:708:1
    |
706 |                 saved_count = await self.process_song_batch(batch)
707 |                 logger.info(f"ðŸ“¦ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ Ð±Ð°Ñ‚Ñ‡: {saved_count} Ð¿ÐµÑÐµÐ½ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾")
708 |             
    | ^^^^^^^^^^^^
709 |             # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ URL Ð² ÐºÑÑˆ
710 |             self.url_cache.add(song_url)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:711:1
    |
709 |             # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ URL Ð² ÐºÑÑˆ
710 |             self.url_cache.add(song_url)
711 |             
    | ^^^^^^^^^^^^
712 |             word_count = len(lyrics.split())
713 |             logger.info(f"âœ… ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¾: {artist_name} - {song.title} ({word_count} ÑÐ»Ð¾Ð²)")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:714:1
    |
712 |             word_count = len(lyrics.split())
713 |             logger.info(f"âœ… ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¾: {artist_name} - {song.title} ({word_count} ÑÐ»Ð¾Ð²)")
714 |             
    | ^^^^^^^^^^^^
715 |             return ScrapingStatus.SUCCESS
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:716:1
    |
715 |             return ScrapingStatus.SUCCESS
716 |             
    | ^^^^^^^^^^^^
717 |         except Exception as e:
718 |             logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ {song.title}: {e}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:724:1
    |
722 |         """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ ÑÐºÑ€Ð°Ð¿Ð¸Ð½Ð³ Ð¿ÐµÑÐµÐ½ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°"""
723 |         logger.info(f"ðŸŽ¤ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐ£Ð® Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°: {artist_name}")
724 |         
    | ^^^^^^^^
725 |         try:
726 |             processed_count = 0
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:727:1
    |
725 |         try:
726 |             processed_count = 0
727 |             
    | ^^^^^^^^^^^^
728 |             # ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²
729 |             self.monitor.log_resources()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:730:1
    |
728 |             # ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²
729 |             self.monitor.log_resources()
730 |             
    | ^^^^^^^^^^^^
731 |             async for song, song_number in self.get_songs_async_generator(artist_name, max_songs):
732 |                 if self.shutdown_requested:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:734:1
    |
732 |                 if self.shutdown_requested:
733 |                     break
734 |                 
    | ^^^^^^^^^^^^^^^^
735 |                 # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿ÐµÑÐ½Ð¸
736 |                 processing_start = time.time()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:739:1
    |
737 |                 status = await self.process_single_song(song, song_number, artist_name)
738 |                 processing_time = time.time() - processing_start
739 |                 
    | ^^^^^^^^^^^^^^^^
740 |                 # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
741 |                 self.metrics.increment(status, processing_time)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:743:1
    |
741 |                 self.metrics.increment(status, processing_time)
742 |                 processed_count += 1
743 |                 
    | ^^^^^^^^^^^^^^^^
744 |                 # Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ°
745 |                 if processed_count % 25 == 0:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:749:1
    |
747 |                     logger.info(f"ðŸ“Š Success rate: {self.metrics.success_rate:.1f}%")
748 |                     self.monitor.log_resources()
749 |                 
    | ^^^^^^^^^^^^^^^^
750 |                 # ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð¿Ð°ÑƒÐ·Ð° Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ°
751 |                 if status in [ScrapingStatus.ERROR_NETWORK, ScrapingStatus.ERROR_API_LIMIT]:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:755:1
    |
753 |                 elif status == ScrapingStatus.SUCCESS:
754 |                     await self.safe_delay(is_error=False)
755 |                 
    | ^^^^^^^^^^^^^^^^
756 |                 # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¸ Ð¿Ñ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° Ð¿Ð°Ð¼ÑÑ‚Ð¸
757 |                 if processed_count % 50 == 0:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:763:1
    |
761 |                         self.monitor.force_garbage_collection()
762 |                         self.metrics.gc_runs += 1
763 |             
    | ^^^^^^^^^^^^
764 |             # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾ÑÑ‚Ð°Ð²ÑˆÐ¸Ð¹ÑÑ Ð±Ð°Ñ‚Ñ‡
765 |             if self.batch_processor.has_pending():
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:769:1
    |
767 |                 await self.process_song_batch(final_batch)
768 |                 logger.info("ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð°Ñ‚Ñ‡")
769 |             
    | ^^^^^^^^^^^^
770 |             logger.info(f"âœ… Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° {artist_name}: Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ {processed_count} Ð¿ÐµÑÐµÐ½")
771 |             return self.metrics.added
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:772:1
    |
770 |             logger.info(f"âœ… Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° {artist_name}: Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ {processed_count} Ð¿ÐµÑÐµÐ½")
771 |             return self.metrics.added
772 |             
    | ^^^^^^^^^^^^
773 |         except Exception as e:
774 |             logger.error(f"âŒ ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ñ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð¼ {artist_name}: {e}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:780:1
    |
778 |         """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ ÑÐµÑÑÐ¸Ñ ÑÐºÑ€Ð°Ð¿Ð¸Ð½Ð³Ð° Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¼ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼"""
779 |         logger.info(f"ðŸš€ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐ£Ð® ÑÐµÑÑÐ¸ÑŽ: {len(artists)} Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²")
780 |         
    | ^^^^^^^^
781 |         initial_stats = self.db.get_stats()
782 |         logger.info(f"ðŸ“š Ð£Ð¶Ðµ Ð² PostgreSQL: {initial_stats['total_songs']} Ð¿ÐµÑÐµÐ½")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:783:1
    |
781 |         initial_stats = self.db.get_stats()
782 |         logger.info(f"ðŸ“š Ð£Ð¶Ðµ Ð² PostgreSQL: {initial_stats['total_songs']} Ð¿ÐµÑÐµÐ½")
783 |         
    | ^^^^^^^^
784 |         try:
785 |             for i, artist_name in enumerate(artists, 1):
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:789:1
    |
787 |                     logger.info("ðŸ›‘ ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð½Ð° Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÑƒ")
788 |                     break
789 |                 
    | ^^^^^^^^^^^^^^^^
790 |                 logger.info(f"\n{'='*70}")
791 |                 logger.info(f"ðŸŽ¤ ÐÑ€Ñ‚Ð¸ÑÑ‚ {i}/{len(artists)}: {artist_name}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:792:1
    |
790 |                 logger.info(f"\n{'='*70}")
791 |                 logger.info(f"ðŸŽ¤ ÐÑ€Ñ‚Ð¸ÑÑ‚ {i}/{len(artists)}: {artist_name}")
792 |                 
    | ^^^^^^^^^^^^^^^^
793 |                 # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°
794 |                 artist_start_time = time.time()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:797:1
    |
795 |                 added_count = await self.scrape_artist_songs_async(artist_name, songs_per_artist)
796 |                 artist_time = time.time() - artist_start_time
797 |                 
    | ^^^^^^^^^^^^^^^^
798 |                 # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ñƒ
799 |                 stats = self.db.get_stats()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:802:1
    |
800 | â€¦     logger.info(f"âœ… {artist_name}: +{added_count} Ð¿ÐµÑÐµÐ½ Ð·Ð° {artist_time:.1f}Ñ")
801 | â€¦     logger.info(f"ðŸ“Š Ð’ÑÐµÐ³Ð¾ Ð² Ð‘Ð”: {stats['total_songs']} Ð¿ÐµÑÐµÐ½ Ð¾Ñ‚ {stats['unique_artists']} Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²")
802 | â€¦     
^^^^^^^^^^^^
803 | â€¦     # Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÐºÐ°Ð¶Ð´Ñ‹Ðµ 5 Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²
804 | â€¦     if i % 5 == 0:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:806:1
    |
804 |                 if i % 5 == 0:
805 |                     self.show_detailed_metrics()
806 |                 
    | ^^^^^^^^^^^^^^^^
807 |                 # ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð¿Ð°ÑƒÐ·Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°Ð¼Ð¸
808 |                 if i < len(artists) and not self.shutdown_requested:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:816:1
    |
814 |                     else:
815 |                         pause_time = random.uniform(45, 60)  # ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ - Ð´Ð»Ð¸Ð½Ð½Ð°Ñ Ð¿Ð°ÑƒÐ·Ð°
816 |                     
    | ^^^^^^^^^^^^^^^^^^^^
817 |                     logger.info(f"â³ ÐŸÐ°ÑƒÐ·Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°Ð¼Ð¸: {pause_time:.1f}Ñ")
818 |                     await self.safe_delay_with_progress(pause_time)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:819:1
    |
817 |                     logger.info(f"â³ ÐŸÐ°ÑƒÐ·Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°Ð¼Ð¸: {pause_time:.1f}Ñ")
818 |                     await self.safe_delay_with_progress(pause_time)
819 |         
    | ^^^^^^^^
820 |         except Exception as e:
821 |             logger.error(f"ðŸ’¥ ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð² ÑÐµÑÑÐ¸Ð¸: {e}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:839:1
    |
837 |         stats = self.db.get_stats()
838 |         runtime = self.metrics.runtime
839 |         
    | ^^^^^^^^
840 |         logger.info(f"\n{'='*70}")
841 |         logger.info(f"ðŸ“Š Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐÐ¯ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ:")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:847:1
    |
845 |         logger.info(f"â© ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²: {self.metrics.skipped_duplicates}")
846 |         logger.info(f"ðŸš« ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾ (ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾): {self.metrics.skipped_quality}")
847 |         
    | ^^^^^^^^
848 |         logger.info(f"\nðŸš¨ ÐžÐ¨Ð˜Ð‘ÐšÐ˜:")
849 |         logger.info(f"ðŸŒ Ð¡ÐµÑ‚ÐµÐ²Ñ‹Ðµ: {self.metrics.error_network}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:853:1
    |
851 |         logger.info(f"ðŸ“ ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³: {self.metrics.error_parsing}")
852 |         logger.info(f"â“ ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ðµ: {self.metrics.error_unknown}")
853 |         
    | ^^^^^^^^
854 |         logger.info(f"\nâš¡ ÐŸÐ ÐžÐ˜Ð—Ð’ÐžÐ”Ð˜Ð¢Ð•Ð›Ð¬ÐÐžÐ¡Ð¢Ð¬:")
855 |         logger.info(f"ðŸ“ž API Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð²: {self.metrics.api_calls}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:860:1
    |
858 |         logger.info(f"â±ï¸ Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {self.metrics.avg_processing_time:.2f}Ñ")
859 |         logger.info(f"ðŸ—‘ï¸ ÐžÑ‡Ð¸ÑÑ‚Ð¾Ðº Ð¿Ð°Ð¼ÑÑ‚Ð¸: {self.metrics.gc_runs}")
860 |         
    | ^^^^^^^^
861 |         # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð‘Ð”
862 |         logger.info(f"\nðŸ˜ POSTGRESQL:")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:867:1
    |
865 |         logger.info(f"ðŸ“ Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ ÑÐ»Ð¾Ð²: {stats['avg_words']}")
866 |         logger.info(f"â­ Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾: {stats['avg_quality']}")
867 |         
    | ^^^^^^^^
868 |         # Ð­Ñ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ
869 |         if runtime.total_seconds() > 0:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:872:1
    |
870 |             songs_per_hour = (self.metrics.added / runtime.total_seconds()) * 3600
871 |             logger.info(f"ðŸŽ¯ Ð­Ñ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ: {songs_per_hour:.1f} Ð¿ÐµÑÐµÐ½/Ñ‡Ð°Ñ")
872 |         
    | ^^^^^^^^
873 |         logger.info(f"{'='*70}\n")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:879:1
    |
877 |         logger.info(f"\n{'='*70}")
878 |         logger.info(f"ðŸ Ð¤Ð˜ÐÐÐ›Ð˜Ð—ÐÐ¦Ð˜Ð¯ ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐžÐ™ Ð¡Ð•Ð¡Ð¡Ð˜Ð˜")
879 |         
    | ^^^^^^^^
880 |         # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾ÑÑ‚Ð°Ð²ÑˆÐ¸ÐµÑÑ Ð±Ð°Ñ‚Ñ‡Ð¸
881 |         if self.batch_processor.has_pending():
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:885:1
    |
883 |             await self.process_song_batch(final_batch)
884 |             logger.info("ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð¾ÑÑ‚Ð°Ð²ÑˆÐ¸ÐµÑÑ Ð±Ð°Ñ‚Ñ‡Ð¸")
885 |         
    | ^^^^^^^^
886 |         # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
887 |         self.show_detailed_metrics()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:888:1
    |
886 |         # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
887 |         self.show_detailed_metrics()
888 |         
    | ^^^^^^^^
889 |         # Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
890 |         self.show_optimization_recommendations()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:891:1
    |
889 |         # Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
890 |         self.show_optimization_recommendations()
891 |         
    | ^^^^^^^^
892 |         logger.info("ðŸ”’ Ð—Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ð¹...")
893 |         self.executor.shutdown(wait=True)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:900:1
    |
898 |         """Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº"""
899 |         logger.info(f"\nðŸ’¡ Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð˜Ð˜ ÐŸÐž ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð˜:")
900 |         
    | ^^^^^^^^
901 |         # ÐÐ½Ð°Ð»Ð¸Ð· ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸
902 |         if self.metrics.success_rate < 50:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:906:1
    |
904 | â€¦     elif self.metrics.success_rate > 90:
905 | â€¦         logger.info("âœ… ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð°Ñ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚ÑŒ - Ð¼Ð¾Ð¶Ð½Ð¾ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚ÑŒ Ð¿Ð°ÑƒÐ·Ñ‹ Ð´Ð»Ñ ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ")
906 | â€¦     
    ^^^^^^^^
907 | â€¦     # ÐÐ½Ð°Ð»Ð¸Ð· Ð¾ÑˆÐ¸Ð±Ð¾Ðº
908 | â€¦     if self.metrics.error_network > self.metrics.error_api_limit * 2:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:910:1
    |
908 |         if self.metrics.error_network > self.metrics.error_api_limit * 2:
909 |             logger.info("ðŸŒ ÐœÐ½Ð¾Ð³Ð¾ ÑÐµÑ‚ÐµÐ²Ñ‹Ñ… Ð¾ÑˆÐ¸Ð±Ð¾Ðº - Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚-ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ")
910 |         
    | ^^^^^^^^
911 |         if self.metrics.error_api_limit > 10:
912 |             logger.info("ðŸ”’ ÐœÐ½Ð¾Ð³Ð¾ API Ð»Ð¸Ð¼Ð¸Ñ‚Ð¾Ð² - ÑƒÐ²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ Ð¿Ð°ÑƒÐ·Ñ‹ Ð¼ÐµÐ¶Ð´Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:913:1
    |
911 |         if self.metrics.error_api_limit > 10:
912 |             logger.info("ðŸ”’ ÐœÐ½Ð¾Ð³Ð¾ API Ð»Ð¸Ð¼Ð¸Ñ‚Ð¾Ð² - ÑƒÐ²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ Ð¿Ð°ÑƒÐ·Ñ‹ Ð¼ÐµÐ¶Ð´Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸")
913 |         
    | ^^^^^^^^
914 |         # ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
915 |         cache_hit_rate = (self.metrics.cache_hits / max(1, self.metrics.processed)) * 100
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:918:1
    |
916 |         if cache_hit_rate > 20:
917 |             logger.info(f"ðŸ’¾ Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ ÐºÑÑˆÐ° ({cache_hit_rate:.1f}%)")
918 |         
    | ^^^^^^^^
919 |         if self.metrics.gc_runs > self.metrics.processed / 50:
920 |             logger.info("ðŸ—‘ï¸ Ð§Ð°ÑÑ‚Ñ‹Ðµ GC - Ñ€Ð°ÑÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ñ‚Ðµ ÑƒÐ²ÐµÐ»Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Ð»Ð¸Ð¼Ð¸Ñ‚Ð° Ð¿Ð°Ð¼ÑÑ‚Ð¸")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:921:1
    |
919 |         if self.metrics.gc_runs > self.metrics.processed / 50:
920 |             logger.info("ðŸ—‘ï¸ Ð§Ð°ÑÑ‚Ñ‹Ðµ GC - Ñ€Ð°ÑÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ñ‚Ðµ ÑƒÐ²ÐµÐ»Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Ð»Ð¸Ð¼Ð¸Ñ‚Ð° Ð¿Ð°Ð¼ÑÑ‚Ð¸")
921 |         
    | ^^^^^^^^
922 |         # Ð‘Ð°Ñ‚Ñ‡ÐµÐ²Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°
923 |         if self.metrics.batch_saves > 0:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:946:1
    |
944 |             with open(remaining_file, 'r', encoding='utf-8') as f:
945 |                 return json.load(f)
946 |         
    | ^^^^^^^^
947 |         full_file = os.path.join(DATA_DIR, filename)
948 |         if os.path.exists(full_file):
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:954:1
    |
952 |     except Exception as e:
953 |         logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ ÑÐ¿Ð¸ÑÐºÐ° Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²: {e}")
954 |     
    | ^^^^
955 |     # Fallback ÑÐ¿Ð¸ÑÐ¾Ðº
956 |     logger.info("ðŸ“‚ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:970:1
    |
968 |         logger.error("âŒ Genius API token Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½!")
969 |         return
970 |     
    | ^^^^
971 |     # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ ÑÐºÑ€Ð°Ð¿ÐµÑ€Ð°
972 |     MEMORY_LIMIT_MB = 4096  # Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð»Ð¸ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð¿Ð°Ð¼ÑÑ‚Ð¸
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:974:1
    |
972 |     MEMORY_LIMIT_MB = 4096  # Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð»Ð¸ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð¿Ð°Ð¼ÑÑ‚Ð¸
973 |     BATCH_SIZE = 15         # ÐžÐ¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ñ‚Ñ‡Ð°
974 |     
    | ^^^^
975 |     scraper = OptimizedPostgreSQLScraper(
976 |         GENIUS_TOKEN, 
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:980:1
    |
978 |         batch_size=BATCH_SIZE
979 |     )
980 |     
    | ^^^^
981 |     try:
982 |         artists = load_artist_list()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:984:1
    |
982 |         artists = load_artist_list()
983 |         SONGS_PER_ARTIST = 500
984 |         
    | ^^^^^^^^
985 |         logger.info(f"ðŸŽ¯ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {len(artists)} Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð¾Ð²")
986 |         logger.info(f"ðŸŽµ Ð¦ÐµÐ»ÑŒ: ~{len(artists) * SONGS_PER_ARTIST} Ð¿ÐµÑÐµÐ½")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:989:1
    |
987 |         logger.info(f"ðŸ’¾ Ð›Ð¸Ð¼Ð¸Ñ‚ Ð¿Ð°Ð¼ÑÑ‚Ð¸: {MEMORY_LIMIT_MB}MB, Batch: {BATCH_SIZE}")
988 |         logger.info(f"âš¡ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐ£Ð® Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ")
989 |         
    | ^^^^^^^^
990 |         await scraper.run_async_scraping_session(artists, SONGS_PER_ARTIST)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> src/scrapers/rap_scraper_postgres.py:991:1
    |
990 |         await scraper.run_async_scraping_session(artists, SONGS_PER_ARTIST)
991 |         
    | ^^^^^^^^
992 |     except Exception as e:
993 |         logger.error(f"ðŸ’¥ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² async_main: {e}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
    --> src/scrapers/rap_scraper_postgres.py:1002:1
     |
1000 |         logger.error("âŒ Genius API token Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð² .env!")
1001 |         return
1002 |     
     | ^^^^
1003 |     logger.info("ðŸš€ Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ€ÐµÐ¶Ð¸Ð¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:")
1004 |     logger.info("1. ðŸ”¥ ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐ«Ð™ Ñ€ÐµÐ¶Ð¸Ð¼ (Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ)")
     |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
    --> src/scrapers/rap_scraper_postgres.py:1006:1
     |
1004 |     logger.info("1. ðŸ”¥ ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐ«Ð™ Ñ€ÐµÐ¶Ð¸Ð¼ (Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ)")
1005 |     logger.info("2. ðŸ“Š Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ (ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚ÑŒ)")
1006 |     
     | ^^^^
1007 |     try:
1008 |         choice = input("Ð’Ñ‹Ð±Ð¾Ñ€ (1/2): ").strip()
     |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
    --> src/scrapers/rap_scraper_postgres.py:1009:1
     |
1007 |     try:
1008 |         choice = input("Ð’Ñ‹Ð±Ð¾Ñ€ (1/2): ").strip()
1009 |         
     | ^^^^^^^^
1010 |         if choice == "1" or choice == "":
1011 |             logger.info("âš¡ Ð—Ð°Ð¿ÑƒÑÐº Ð² ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐžÐœ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ...")
     |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
    --> src/scrapers/rap_scraper_postgres.py:1019:1
     |
1017 |             artists = load_artist_list()
1018 |             scraper.run_scraping_session(artists, 500)
1019 |             
     | ^^^^^^^^^^^^
1020 |     except KeyboardInterrupt:
1021 |         logger.info("âŒ¨ï¸ ÐŸÑ€ÐµÑ€Ñ‹Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼")
     |
help: Remove whitespace from blank line

W292 No newline at end of file
    --> src/scrapers/rap_scraper_postgres.py:1026:11
     |
1025 | if __name__ == "__main__":
1026 |     main()
     |           ^
     |
help: Add trailing newline

UP035 `typing.List` is deprecated, use `list` instead
  --> src/scrapers/ultra_rap_scraper_postgres.py:23:1
   |
21 | import os
22 | import sys
23 | from typing import List
   | ^^^^^^^^^^^^^^^^^^^^^^^
24 |
25 | # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð¸Ð· .env Ñ„Ð°Ð¹Ð»Ð°
   |

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
  --> src/scrapers/ultra_rap_scraper_postgres.py:30:16
   |
29 |     # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ .env Ð¸Ð· ÐºÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð¹ Ð¿Ð°Ð¿ÐºÐ¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
30 |     env_path = os.path.join(
   |                ^^^^^^^^^^^^
31 |         os.path.dirname(os.path.dirname(os.path.dirname(__file__))), ".env"
32 |     )
   |

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/scrapers/ultra_rap_scraper_postgres.py:31:9
   |
29 |     # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ .env Ð¸Ð· ÐºÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð¹ Ð¿Ð°Ð¿ÐºÐ¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
30 |     env_path = os.path.join(
31 |         os.path.dirname(os.path.dirname(os.path.dirname(__file__))), ".env"
   |         ^^^^^^^^^^^^^^^
32 |     )
33 |     load_dotenv(env_path)
   |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/scrapers/ultra_rap_scraper_postgres.py:31:25
   |
29 |     # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ .env Ð¸Ð· ÐºÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð¹ Ð¿Ð°Ð¿ÐºÐ¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
30 |     env_path = os.path.join(
31 |         os.path.dirname(os.path.dirname(os.path.dirname(__file__))), ".env"
   |                         ^^^^^^^^^^^^^^^
32 |     )
33 |     load_dotenv(env_path)
   |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/scrapers/ultra_rap_scraper_postgres.py:31:41
   |
29 |     # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ .env Ð¸Ð· ÐºÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð¹ Ð¿Ð°Ð¿ÐºÐ¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
30 |     env_path = os.path.join(
31 |         os.path.dirname(os.path.dirname(os.path.dirname(__file__))), ".env"
   |                                         ^^^^^^^^^^^^^^^
32 |     )
33 |     load_dotenv(env_path)
   |
help: Replace with `Path(...).parent`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/scrapers/ultra_rap_scraper_postgres.py:39:15
   |
38 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ ÑÐºÑ€Ð°Ð¿ÐµÑ€Ð°
39 | current_dir = os.path.dirname(os.path.abspath(__file__))
   |               ^^^^^^^^^^^^^^^
40 | parent_dir = os.path.dirname(current_dir)
41 | sys.path.insert(0, parent_dir)
   |
help: Replace with `Path(...).parent`

PTH100 `os.path.abspath()` should be replaced by `Path.resolve()`
  --> src/scrapers/ultra_rap_scraper_postgres.py:39:31
   |
38 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ ÑÐºÑ€Ð°Ð¿ÐµÑ€Ð°
39 | current_dir = os.path.dirname(os.path.abspath(__file__))
   |                               ^^^^^^^^^^^^^^^
40 | parent_dir = os.path.dirname(current_dir)
41 | sys.path.insert(0, parent_dir)
   |
help: Replace with `Path(...).resolve()`

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> src/scrapers/ultra_rap_scraper_postgres.py:40:14
   |
38 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ ÑÐºÑ€Ð°Ð¿ÐµÑ€Ð°
39 | current_dir = os.path.dirname(os.path.abspath(__file__))
40 | parent_dir = os.path.dirname(current_dir)
   |              ^^^^^^^^^^^^^^^
41 | sys.path.insert(0, parent_dir)
   |
help: Replace with `Path(...).parent`

E402 Module level import not at top of file
  --> src/scrapers/ultra_rap_scraper_postgres.py:65:1
   |
64 | # 1. REDIS ÐšÐ­Ð¨Ð˜Ð ÐžÐ’ÐÐÐ˜Ð• (Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð² requirements.txt: redis)
65 | import redis
   | ^^^^^^^^^^^^
66 | from typing import Optional
67 | import pickle
   |

I001 [*] Import block is un-sorted or un-formatted
  --> src/scrapers/ultra_rap_scraper_postgres.py:65:1
   |
64 |   # 1. REDIS ÐšÐ­Ð¨Ð˜Ð ÐžÐ’ÐÐÐ˜Ð• (Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð² requirements.txt: redis)
65 | / import redis
66 | | from typing import Optional
67 | | import pickle
68 | | import json
   | |___________^
   |
help: Organize imports

E402 Module level import not at top of file
  --> src/scrapers/ultra_rap_scraper_postgres.py:66:1
   |
64 | # 1. REDIS ÐšÐ­Ð¨Ð˜Ð ÐžÐ’ÐÐÐ˜Ð• (Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð² requirements.txt: redis)
65 | import redis
66 | from typing import Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^
67 | import pickle
68 | import json
   |

E402 Module level import not at top of file
  --> src/scrapers/ultra_rap_scraper_postgres.py:67:1
   |
65 | import redis
66 | from typing import Optional
67 | import pickle
   | ^^^^^^^^^^^^^
68 | import json
   |

E402 Module level import not at top of file
  --> src/scrapers/ultra_rap_scraper_postgres.py:68:1
   |
66 | from typing import Optional
67 | import pickle
68 | import json
   | ^^^^^^^^^^^
   |

UP045 [*] Use `X | None` for type annotations
  --> src/scrapers/ultra_rap_scraper_postgres.py:88:53
   |
86 |             self.local_cache = {}
87 |
88 |     def get_artist_songs(self, artist_name: str) -> Optional[List]:
   |                                                     ^^^^^^^^^^^^^^
89 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐµÐ½ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð° Ð¸Ð· ÐºÑÑˆÐ°"""
90 |         if not self.enabled:
   |
help: Convert to `X | None`

UP006 [*] Use `list` instead of `List` for type annotation
  --> src/scrapers/ultra_rap_scraper_postgres.py:88:62
   |
86 |             self.local_cache = {}
87 |
88 |     def get_artist_songs(self, artist_name: str) -> Optional[List]:
   |                                                              ^^^^
89 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐµÐ½ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð° Ð¸Ð· ÐºÑÑˆÐ°"""
90 |         if not self.enabled:
   |
help: Replace with `list`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/scrapers/ultra_rap_scraper_postgres.py:102:59
    |
100 |         return None
101 |
102 |     def cache_artist_songs(self, artist_name: str, songs: List, ttl_override=None):
    |                                                           ^^^^
103 |         """ÐšÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿ÐµÑÐµÐ½ Ð°Ñ€Ñ‚Ð¸ÑÑ‚Ð°"""
104 |         ttl = ttl_override or self.ttl
    |
help: Replace with `list`

E722 Do not use bare `except`
   --> src/scrapers/ultra_rap_scraper_postgres.py:124:9
    |
122 |         try:
123 |             return bool(self.redis.sismember("processed_songs", song_hash))
124 |         except:
    |         ^^^^^^
125 |             return False
    |

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:144:1
    |
143 | # 2. PROMETHEUS ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ (Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð² requirements.txt: prometheus-client)
144 | from prometheus_client import Counter, Histogram, Gauge, start_http_server
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
145 | import threading
    |

I001 [*] Import block is un-sorted or un-formatted
   --> src/scrapers/ultra_rap_scraper_postgres.py:144:1
    |
143 |   # 2. PROMETHEUS ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ (Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð² requirements.txt: prometheus-client)
144 | / from prometheus_client import Counter, Histogram, Gauge, start_http_server
145 | | import threading
    | |________________^
    |
help: Organize imports

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:145:1
    |
143 | # 2. PROMETHEUS ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ (Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð² requirements.txt: prometheus-client)
144 | from prometheus_client import Counter, Histogram, Gauge, start_http_server
145 | import threading
    | ^^^^^^^^^^^^^^^^
    |

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:223:1
    |
222 | # 3. ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐ«Ð™ POSTGRESQL CONNECTION POOL
223 | import asyncpg
    | ^^^^^^^^^^^^^^
224 | import asyncio
225 | from contextlib import asynccontextmanager
    |

I001 [*] Import block is un-sorted or un-formatted
   --> src/scrapers/ultra_rap_scraper_postgres.py:223:1
    |
222 |   # 3. ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐ«Ð™ POSTGRESQL CONNECTION POOL
223 | / import asyncpg
224 | | import asyncio
225 | | from contextlib import asynccontextmanager
    | |__________________________________________^
    |
help: Organize imports

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:224:1
    |
222 | # 3. ÐÐ¡Ð˜ÐÐ¥Ð ÐžÐÐÐ«Ð™ POSTGRESQL CONNECTION POOL
223 | import asyncpg
224 | import asyncio
    | ^^^^^^^^^^^^^^
225 | from contextlib import asynccontextmanager
    |

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:225:1
    |
223 | import asyncpg
224 | import asyncio
225 | from contextlib import asynccontextmanager
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/scrapers/ultra_rap_scraper_postgres.py:262:60
    |
260 |             yield conn
261 |
262 |     async def batch_add_songs_optimized(self, songs_batch: List[dict]) -> int:
    |                                                            ^^^^
263 |         """ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ð±Ð°Ñ‚Ñ‡ÐµÐ²Ð¾Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐµÐ½"""
264 |         if not songs_batch:
    |
help: Replace with `list`

B007 Loop control variable `track` not used within loop body
   --> src/scrapers/ultra_rap_scraper_postgres.py:270:17
    |
268 |             # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ COPY
269 |             rows = []
270 |             for track in tracks_batch:
    |                 ^^^^^
271 |                 rows.append(
272 |                     (
    |
help: Rename unused `track` to `_track`

F821 Undefined name `tracks_batch`
   --> src/scrapers/ultra_rap_scraper_postgres.py:270:26
    |
268 |             # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ COPY
269 |             rows = []
270 |             for track in tracks_batch:
    |                          ^^^^^^^^^^^^
271 |                 rows.append(
272 |                     (
    |

PERF401 Use a list comprehension to create a transformed list
   --> src/scrapers/ultra_rap_scraper_postgres.py:271:17
    |
269 |               rows = []
270 |               for track in tracks_batch:
271 | /                 rows.append(
272 | |                     (
273 | |                         song["artist"],
274 | |                         song["title"],
275 | |                         song["lyrics"],
276 | |                         song["url"],
277 | |                         song.get("genius_id"),
278 | |                         json.dumps(song.get("metadata", {})),
279 | |                     )
280 | |                 )
    | |_________________^
281 |
282 |               # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ COPY Ð´Ð»Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    |
help: Replace for loop with list comprehension

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:273:25
    |
271 |                 rows.append(
272 |                     (
273 |                         song["artist"],
    |                         ^^^^
274 |                         song["title"],
275 |                         song["lyrics"],
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:274:25
    |
272 |                     (
273 |                         song["artist"],
274 |                         song["title"],
    |                         ^^^^
275 |                         song["lyrics"],
276 |                         song["url"],
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:275:25
    |
273 |                         song["artist"],
274 |                         song["title"],
275 |                         song["lyrics"],
    |                         ^^^^
276 |                         song["url"],
277 |                         song.get("genius_id"),
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:276:25
    |
274 |                         song["title"],
275 |                         song["lyrics"],
276 |                         song["url"],
    |                         ^^^^
277 |                         song.get("genius_id"),
278 |                         json.dumps(song.get("metadata", {})),
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:277:25
    |
275 |                         song["lyrics"],
276 |                         song["url"],
277 |                         song.get("genius_id"),
    |                         ^^^^
278 |                         json.dumps(song.get("metadata", {})),
279 |                     )
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:278:36
    |
276 |                         song["url"],
277 |                         song.get("genius_id"),
278 |                         json.dumps(song.get("metadata", {})),
    |                                    ^^^^
279 |                     )
280 |                 )
    |

F841 Local variable `result` is assigned to but never used
   --> src/scrapers/ultra_rap_scraper_postgres.py:284:17
    |
282 |             # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ COPY Ð´Ð»Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
283 |             try:
284 |                 result = await conn.copy_records_to_table(
    |                 ^^^^^^
285 |                     "tracks",
286 |                     records=rows,
    |
help: Remove assignment to unused variable `result`

ARG002 Unused method argument: `songs_batch`
   --> src/scrapers/ultra_rap_scraper_postgres.py:303:50
    |
301 |                 return await self._fallback_batch_insert(conn, songs_batch)
302 |
303 |     async def _fallback_batch_insert(self, conn, songs_batch: List[dict]) -> int:
    |                                                  ^^^^^^^^^^^
304 |         """Fallback Ð¼ÐµÑ‚Ð¾Ð´ Ñ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¼Ð¸ INSERT"""
305 |         saved_count = 0
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/scrapers/ultra_rap_scraper_postgres.py:303:63
    |
301 |                 return await self._fallback_batch_insert(conn, songs_batch)
302 |
303 |     async def _fallback_batch_insert(self, conn, songs_batch: List[dict]) -> int:
    |                                                               ^^^^
304 |         """Fallback Ð¼ÐµÑ‚Ð¾Ð´ Ñ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¼Ð¸ INSERT"""
305 |         saved_count = 0
    |
help: Replace with `list`

B007 Loop control variable `track` not used within loop body
   --> src/scrapers/ultra_rap_scraper_postgres.py:307:17
    |
305 |         saved_count = 0
306 |         async with conn.transaction():
307 |             for track in tracks_batch:
    |                 ^^^^^
308 |                 try:
309 |                     await conn.execute(
    |
help: Rename unused `track` to `_track`

F821 Undefined name `tracks_batch`
   --> src/scrapers/ultra_rap_scraper_postgres.py:307:26
    |
305 |         saved_count = 0
306 |         async with conn.transaction():
307 |             for track in tracks_batch:
    |                          ^^^^^^^^^^^^
308 |                 try:
309 |                     await conn.execute(
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:315:25
    |
313 |                         ON CONFLICT (url) DO NOTHING
314 |                     """,
315 |                         song["artist"],
    |                         ^^^^
316 |                         song["title"],
317 |                         song["lyrics"],
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:316:25
    |
314 |                     """,
315 |                         song["artist"],
316 |                         song["title"],
    |                         ^^^^
317 |                         song["lyrics"],
318 |                         song["url"],
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:317:25
    |
315 |                         song["artist"],
316 |                         song["title"],
317 |                         song["lyrics"],
    |                         ^^^^
318 |                         song["url"],
319 |                         song.get("genius_id"),
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:318:25
    |
316 |                         song["title"],
317 |                         song["lyrics"],
318 |                         song["url"],
    |                         ^^^^
319 |                         song.get("genius_id"),
320 |                         json.dumps(song.get("metadata", {})),
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:319:25
    |
317 |                         song["lyrics"],
318 |                         song["url"],
319 |                         song.get("genius_id"),
    |                         ^^^^
320 |                         json.dumps(song.get("metadata", {})),
321 |                     )
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:320:36
    |
318 |                         song["url"],
319 |                         song.get("genius_id"),
320 |                         json.dumps(song.get("metadata", {})),
    |                                    ^^^^
321 |                     )
322 |                     saved_count += 1
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/scrapers/ultra_rap_scraper_postgres.py:323:17
    |
321 |                       )
322 |                       saved_count += 1
323 | /                 except Exception as e:
324 | |                     logger.debug(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²ÑÑ‚Ð°Ð²ÐºÐ¸ Ð¿ÐµÑÐ½Ð¸ {song['title']}: {e}")
    | |______________________________________________________________________________^
325 |           return saved_count
    |

F821 Undefined name `song`
   --> src/scrapers/ultra_rap_scraper_postgres.py:324:58
    |
322 |                     saved_count += 1
323 |                 except Exception as e:
324 |                     logger.debug(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²ÑÑ‚Ð°Ð²ÐºÐ¸ Ð¿ÐµÑÐ½Ð¸ {song['title']}: {e}")
    |                                                          ^^^^
325 |         return saved_count
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/scrapers/ultra_rap_scraper_postgres.py:327:45
    |
325 |         return saved_count
326 |
327 |     async def song_exists_batch(self, urls: List[str]) -> set:
    |                                             ^^^^
328 |         """Ð‘Ð°Ñ‚Ñ‡ÐµÐ²Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿ÐµÑÐµÐ½ Ð¿Ð¾ URL"""
329 |         if not urls:
    |
help: Replace with `list`

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:358:1
    |
357 | # 4. INTELLIGENT RATE LIMITER
358 | from collections import deque
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
359 | import time
    |

I001 [*] Import block is un-sorted or un-formatted
   --> src/scrapers/ultra_rap_scraper_postgres.py:358:1
    |
357 |   # 4. INTELLIGENT RATE LIMITER
358 | / from collections import deque
359 | | import time
    | |___________^
    |
help: Organize imports

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:359:1
    |
357 | # 4. INTELLIGENT RATE LIMITER
358 | from collections import deque
359 | import time
    | ^^^^^^^^^^^
    |

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:427:1
    |
426 | # 5. SMART RETRY DECORATOR
427 | from functools import wraps
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^
428 | import random
    |

I001 [*] Import block is un-sorted or un-formatted
   --> src/scrapers/ultra_rap_scraper_postgres.py:427:1
    |
426 |   # 5. SMART RETRY DECORATOR
427 | / from functools import wraps
428 | | import random
    | |_____________^
    |
help: Organize imports

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:428:1
    |
426 | # 5. SMART RETRY DECORATOR
427 | from functools import wraps
428 | import random
    | ^^^^^^^^^^^^^
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/scrapers/ultra_rap_scraper_postgres.py:442:17
    |
440 |                   try:
441 |                       return await func(*args, **kwargs)
442 | /                 except Exception as e:
443 | |                     last_exception = e
444 | |                     error_msg = str(e).lower()
445 | |
446 | |                     # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ‚Ð¸Ð¿ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
447 | |                     if any(
448 | |                         keyword in error_msg
449 | |                         for keyword in ["rate limit", "429", "too many requests"]
450 | |                     ):
451 | |                         delay = base_delay * (backoff_factor**attempt) + random.uniform(
452 | |                             10, 30
453 | |                         )
454 | |                         logger.warning(f"ðŸ”’ Rate limit, Ð¿Ð°ÑƒÐ·Ð° {delay:.1f}Ñ")
455 | |                     elif any(
456 | |                         keyword in error_msg
457 | |                         for keyword in ["timeout", "connection", "network"]
458 | |                     ):
459 | |                         delay = base_delay * (backoff_factor**attempt)
460 | |                         if jitter:
461 | |                             delay += random.uniform(0, delay * 0.1)
462 | |                         logger.warning(f"ðŸŒ Ð¡ÐµÑ‚ÐµÐ²Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°, Ð¿Ð°ÑƒÐ·Ð° {delay:.1f}Ñ")
463 | |                     elif "404" in error_msg or "not found" in error_msg:
464 | |                         # ÐÐµ Ñ€ÐµÑ‚Ñ€Ð°Ð¸Ð¼ 404 Ð¾ÑˆÐ¸Ð±ÐºÐ¸
465 | |                         logger.debug(f"ðŸ“­ 404 Ð¾ÑˆÐ¸Ð±ÐºÐ°, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼: {e}")
466 | |                         raise e
467 | |                     else:
468 | |                         delay = base_delay * (backoff_factor**attempt)
469 | |                         logger.warning(
470 | |                             f"â“ ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°, Ð¿Ð°ÑƒÐ·Ð° {delay:.1f}Ñ: {e}"
471 | |                         )
472 | |
473 | |                     if attempt < max_retries:
474 | |                         await asyncio.sleep(delay)
475 | |                     else:
476 | |                         logger.error(f"âŒ Ð˜ÑÑ‡ÐµÑ€Ð¿Ð°Ð½Ñ‹ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ¸ Ð´Ð»Ñ {func.__name__}")
    | |_________________________________________________________________________________^
477 |
478 |               raise last_exception
    |

TRY201 Use `raise` without specifying exception name
   --> src/scrapers/ultra_rap_scraper_postgres.py:466:31
    |
464 |                         # ÐÐµ Ñ€ÐµÑ‚Ñ€Ð°Ð¸Ð¼ 404 Ð¾ÑˆÐ¸Ð±ÐºÐ¸
465 |                         logger.debug(f"ðŸ“­ 404 Ð¾ÑˆÐ¸Ð±ÐºÐ°, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼: {e}")
466 |                         raise e
    |                               ^
467 |                     else:
468 |                         delay = base_delay * (backoff_factor**attempt)
    |
help: Remove exception name

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:486:1
    |
485 | # 6. ENHANCED BATCH PROCESSOR Ð¡ ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢ÐÐœÐ˜
486 | from queue import PriorityQueue
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
487 | import threading
488 | from dataclasses import dataclass, field
    |

I001 [*] Import block is un-sorted or un-formatted
   --> src/scrapers/ultra_rap_scraper_postgres.py:486:1
    |
485 |   # 6. ENHANCED BATCH PROCESSOR Ð¡ ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢ÐÐœÐ˜
486 | / from queue import PriorityQueue
487 | | import threading
488 | | from dataclasses import dataclass, field
489 | | from typing import Any
    | |______________________^
    |
help: Organize imports

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:487:1
    |
485 | # 6. ENHANCED BATCH PROCESSOR Ð¡ ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢ÐÐœÐ˜
486 | from queue import PriorityQueue
487 | import threading
    | ^^^^^^^^^^^^^^^^
488 | from dataclasses import dataclass, field
489 | from typing import Any
    |

F811 [*] Redefinition of unused `threading` from line 145
   --> src/scrapers/ultra_rap_scraper_postgres.py:487:8
    |
485 | # 6. ENHANCED BATCH PROCESSOR Ð¡ ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢ÐÐœÐ˜
486 | from queue import PriorityQueue
487 | import threading
    |        ^^^^^^^^^ `threading` redefined here
488 | from dataclasses import dataclass, field
489 | from typing import Any
    |
   ::: src/scrapers/ultra_rap_scraper_postgres.py:145:8
    |
143 | # 2. PROMETHEUS ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ (Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð² requirements.txt: prometheus-client)
144 | from prometheus_client import Counter, Histogram, Gauge, start_http_server
145 | import threading
    |        --------- previous definition of `threading` here
    |
help: Remove definition: `threading`

F401 [*] `threading` imported but unused
   --> src/scrapers/ultra_rap_scraper_postgres.py:487:8
    |
485 | # 6. ENHANCED BATCH PROCESSOR Ð¡ ÐŸÐ Ð˜ÐžÐ Ð˜Ð¢Ð•Ð¢ÐÐœÐ˜
486 | from queue import PriorityQueue
487 | import threading
    |        ^^^^^^^^^
488 | from dataclasses import dataclass, field
489 | from typing import Any
    |
help: Remove unused import: `threading`

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:488:1
    |
486 | from queue import PriorityQueue
487 | import threading
488 | from dataclasses import dataclass, field
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
489 | from typing import Any
    |

E402 Module level import not at top of file
   --> src/scrapers/ultra_rap_scraper_postgres.py:489:1
    |
487 | import threading
488 | from dataclasses import dataclass, field
489 | from typing import Any
    | ^^^^^^^^^^^^^^^^^^^^^^
    |

E722 Do not use bare `except`
   --> src/scrapers/ultra_rap_scraper_postgres.py:531:9
    |
530 |             return self._should_flush()
531 |         except:
    |         ^^^^^^
532 |             logger.warning("âš ï¸ ÐžÑ‡ÐµÑ€ÐµÐ´ÑŒ Ð¿ÐµÑ€ÐµÐ¿Ð¾Ð»Ð½ÐµÐ½Ð°, Ð¿Ñ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ flush")
533 |             return True
    |

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/scrapers/ultra_rap_scraper_postgres.py:546:37
    |
544 |         )
545 |
546 |     def get_priority_batch(self) -> List[dict]:
    |                                     ^^^^
547 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð±Ð°Ñ‚Ñ‡Ð° Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð¾Ð²"""
548 |         batch = []
    |
help: Replace with `list`

E722 Do not use bare `except`
   --> src/scrapers/ultra_rap_scraper_postgres.py:555:13
    |
553 |                 task = self.priority_queue.get_nowait()
554 |                 batch.append(task.data)
555 |             except:
    |             ^^^^^^
556 |                 break
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/scrapers/ultra_rap_scraper_postgres.py:555:13
    |
553 |                   task = self.priority_queue.get_nowait()
554 |                   batch.append(task.data)
555 | /             except:
556 | |                 break
    | |_____________________^
557 |
558 |           if batch:
    |

TRY201 Use `raise` without specifying exception name
   --> src/scrapers/ultra_rap_scraper_postgres.py:660:19
    |
658 |             if self.prometheus:
659 |                 self.prometheus.record_error("api_search")
660 |             raise e
    |                   ^
661 |
662 |         if not artist or not artist.songs:
    |
help: Remove exception name

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/scrapers/ultra_rap_scraper_postgres.py:711:48
    |
709 |         return status
710 |
711 |     async def run_ultra_session(self, artists: List[str], songs_per_artist: int = 500):
    |                                                ^^^^
712 |         """Ð—Ð°Ð¿ÑƒÑÐº ÑƒÐ»ÑŒÑ‚Ñ€Ð°-Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ ÑÐµÑÑÐ¸Ð¸"""
713 |         logger.info("ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº ULTRA-ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—Ð˜Ð ÐžÐ’ÐÐÐÐžÐ™ ÑÐµÑÑÐ¸Ð¸ ÑÐºÑ€Ð°Ð¿Ð¸Ð½Ð³Ð°")
    |
help: Replace with `list`

B007 Loop control variable `i` not used within loop body
   --> src/scrapers/ultra_rap_scraper_postgres.py:800:13
    |
799 |         # Ð¡Ð¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
800 |         for i in range(5):
    |             ^
801 |             limiter.record_request(success=True)
802 |         print(f"   âœ… Ð—Ð°Ð¿Ð¸ÑÐ°Ð½Ð¾ 5 ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð², RPM = {limiter.current_rpm}")
    |
help: Rename unused `i` to `_i`

TRY301 Abstract `raise` to an inner function
   --> src/scrapers/ultra_rap_scraper_postgres.py:862:17
    |
861 |             if random.random() < 0.7:  # 70% Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
862 |                 raise Exception("Test error for retry")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
863 |             return "Success!"
    |

TRY002 Create your own exception
   --> src/scrapers/ultra_rap_scraper_postgres.py:862:23
    |
861 |             if random.random() < 0.7:  # 70% Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
862 |                 raise Exception("Test error for retry")
    |                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
863 |             return "Success!"
    |

E722 Do not use bare `except`
   --> src/scrapers/ultra_rap_scraper_postgres.py:868:9
    |
866 |             result = await test_function()
867 |             print(f"   âœ… Smart Retry ÑƒÑÐ¿ÐµÑˆÐ½Ð¾: {result}")
868 |         except:
    |         ^^^^^^
869 |             print("   âš ï¸ Smart Retry: Ð²ÑÐµ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ¸ Ð¸ÑÑ‡ÐµÑ€Ð¿Ð°Ð½Ñ‹ (ÑÑ‚Ð¾ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð°)")
    |

I001 [*] Import block is un-sorted or un-formatted
  --> src/utils/__init__.py:13:1
   |
11 |   """
12 |
13 | / from .logging_utils import setup_logging, get_logger
14 | | from .validation_utils import (
15 | |     validate_text,
16 | |     clean_text,
17 | |     validate_artist_name,
18 | |     validate_track_title,
19 | | )
20 | | from .file_utils import ensure_directory, safe_json_load, safe_json_save, get_file_size
   | |_______________________________________________________________________________________^
21 |
22 |   __all__ = [
   |
help: Organize imports

RUF022 [*] `__all__` is not sorted
  --> src/utils/__init__.py:22:11
   |
20 |   from .file_utils import ensure_directory, safe_json_load, safe_json_save, get_file_size
21 |
22 |   __all__ = [
   |  ___________^
23 | |     "setup_logging",
24 | |     "get_logger",
25 | |     "validate_text",
26 | |     "clean_text",
27 | |     "validate_artist_name",
28 | |     "validate_track_title",
29 | |     "ensure_directory",
30 | |     "safe_json_load",
31 | |     "safe_json_save",
32 | |     "get_file_size",
33 | | ]
   | |_^
   |
help: Apply an isort-style sorting to `__all__`

I001 [*] Import block is un-sorted or un-formatted
  --> src/utils/config.py:24:1
   |
22 |   """
23 |
24 | / import os
25 | | from pathlib import Path
26 | | from dotenv import load_dotenv
   | |______________________________^
27 |
28 |   # Project root
   |
help: Organize imports

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/utils/file_utils.py:10:1
   |
 8 | import os
 9 | from pathlib import Path
10 | from typing import Any, Dict, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

F401 [*] `typing.Dict` imported but unused
  --> src/utils/file_utils.py:10:25
   |
 8 | import os
 9 | from pathlib import Path
10 | from typing import Any, Dict, Optional
   |                         ^^^^
   |
help: Remove unused import

F401 [*] `typing.Optional` imported but unused
  --> src/utils/file_utils.py:10:31
   |
 8 | import os
 9 | from pathlib import Path
10 | from typing import Any, Dict, Optional
   |                               ^^^^^^^^
   |
help: Remove unused import

PTH110 `os.path.exists()` should be replaced by `Path.exists()`
  --> src/utils/file_utils.py:40:16
   |
38 |     """
39 |     try:
40 |         if not os.path.exists(file_path):
   |                ^^^^^^^^^^^^^^
41 |             return default
   |
help: Replace with `Path(...).exists()`

PTH123 `open()` should be replaced by `Path.open()`
  --> src/utils/file_utils.py:43:14
   |
41 |             return default
42 |
43 |         with open(file_path, "r", encoding="utf-8") as f:
   |              ^^^^
44 |             return json.load(f)
45 |     except (json.JSONDecodeError, IOError):
   |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
  --> src/utils/file_utils.py:43:30
   |
41 |             return default
42 |
43 |         with open(file_path, "r", encoding="utf-8") as f:
   |                              ^^^
44 |             return json.load(f)
45 |     except (json.JSONDecodeError, IOError):
   |
help: Remove mode argument

UP024 [*] Replace aliased errors with `OSError`
  --> src/utils/file_utils.py:45:12
   |
43 |         with open(file_path, "r", encoding="utf-8") as f:
44 |             return json.load(f)
45 |     except (json.JSONDecodeError, IOError):
   |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
46 |         return default
   |
help: Replace with builtin `OSError`

PTH123 `open()` should be replaced by `Path.open()`
  --> src/utils/file_utils.py:64:14
   |
62 |         Path(file_path).parent.mkdir(parents=True, exist_ok=True)
63 |
64 |         with open(file_path, "w", encoding="utf-8") as f:
   |              ^^^^
65 |             json.dump(data, f, indent=2, ensure_ascii=False)
66 |         return True
   |
help: Replace with `Path.open()`

TRY300 Consider moving this statement to an `else` block
  --> src/utils/file_utils.py:66:9
   |
64 |         with open(file_path, "w", encoding="utf-8") as f:
65 |             json.dump(data, f, indent=2, ensure_ascii=False)
66 |         return True
   |         ^^^^^^^^^^^
67 |     except (IOError, TypeError):
68 |         return False
   |

UP024 [*] Replace aliased errors with `OSError`
  --> src/utils/file_utils.py:67:12
   |
65 |             json.dump(data, f, indent=2, ensure_ascii=False)
66 |         return True
67 |     except (IOError, TypeError):
   |            ^^^^^^^^^^^^^^^^^^^^
68 |         return False
   |
help: Replace with builtin `OSError`

PTH202 `os.path.getsize` should be replaced by `Path.stat().st_size`
  --> src/utils/file_utils.py:74:16
   |
72 |     """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ñ„Ð°Ð¹Ð»Ð° Ð² Ð±Ð°Ð¹Ñ‚Ð°Ñ…"""
73 |     try:
74 |         return os.path.getsize(file_path)
   |                ^^^^^^^^^^^^^^^
75 |     except OSError:
76 |         return 0
   |
help: Replace with `Path(...).stat().st_size`

F401 [*] `os` imported but unused
  --> src/utils/logging_utils.py:8:8
   |
 7 | import logging
 8 | import os
   |        ^^
 9 | from pathlib import Path
10 | from typing import Optional
   |
help: Remove unused import: `os`

UP045 [*] Use `X | None` for type annotations
  --> src/utils/logging_utils.py:16:15
   |
14 |     name: str,
15 |     level: int = logging.INFO,
16 |     log_file: Optional[str] = None,
   |               ^^^^^^^^^^^^^
17 |     console: bool = True,
18 | ) -> logging.Logger:
   |
help: Convert to `X | None`

I001 [*] Import block is un-sorted or un-formatted
  --> src/utils/postgres_db.py:29:1
   |
27 |   """
28 |
29 | / import sys
30 | | import psycopg2
31 | | from psycopg2.extras import RealDictCursor
32 | | import yaml
33 | | import logging
34 | | from pathlib import Path
35 | | from typing import List, Dict, Optional
36 | | import os
   | |_________^
37 |
38 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
   |
help: Organize imports

UP035 `typing.List` is deprecated, use `list` instead
  --> src/utils/postgres_db.py:35:1
   |
33 | import logging
34 | from pathlib import Path
35 | from typing import List, Dict, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
36 | import os
   |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> src/utils/postgres_db.py:35:1
   |
33 | import logging
34 | from pathlib import Path
35 | from typing import List, Dict, Optional
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
36 | import os
   |

F401 [*] `os` imported but unused
  --> src/utils/postgres_db.py:36:8
   |
34 | from pathlib import Path
35 | from typing import List, Dict, Optional
36 | import os
   |        ^^
37 |
38 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€Ð½ÐµÐ²ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ Ð² path Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
   |
help: Remove unused import: `os`

UP045 [*] Use `X | None` for type annotations
  --> src/utils/postgres_db.py:48:37
   |
46 |     """ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ PostgreSQL Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
47 |
48 |     def __init__(self, config_path: Optional[str] = None):
   |                                     ^^^^^^^^^^^^^
49 |         self.conn = None
50 |         self.cursor = None
   |
help: Convert to `X | None`

UP045 [*] Use `X | None` for type annotations
  --> src/utils/postgres_db.py:55:41
   |
53 |         self._create_tables()
54 |
55 |     def _load_config(self, config_path: Optional[str] = None) -> Dict:
   |                                         ^^^^^^^^^^^^^
56 |         """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¸Ð· config.yaml"""
   |
help: Convert to `X | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
  --> src/utils/postgres_db.py:55:66
   |
53 |         self._create_tables()
54 |
55 |     def _load_config(self, config_path: Optional[str] = None) -> Dict:
   |                                                                  ^^^^
56 |         """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¸Ð· config.yaml"""
   |
help: Replace with `dict`

PTH123 `open()` should be replaced by `Path.open()`
  --> src/utils/postgres_db.py:62:18
   |
61 |         try:
62 |             with open(config_path, "r", encoding="utf-8") as f:
   |                  ^^^^
63 |                 config = yaml.safe_load(f)
64 |             return config["database"]
   |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
  --> src/utils/postgres_db.py:62:36
   |
61 |         try:
62 |             with open(config_path, "r", encoding="utf-8") as f:
   |                                    ^^^
63 |                 config = yaml.safe_load(f)
64 |             return config["database"]
   |
help: Remove mode argument

TRY201 Use `raise` without specifying exception name
   --> src/utils/postgres_db.py:98:23
    |
 96 |                 self._create_database()
 97 |             else:
 98 |                 raise e
    |                       ^
 99 |
100 |     def _create_database(self):
    |
help: Remove exception name

TRY201 Use `raise` without specifying exception name
   --> src/utils/postgres_db.py:126:19
    |
124 |         except psycopg2.Error as e:
125 |             logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…: {e}")
126 |             raise e
    |                   ^
127 |
128 |     def _create_tables(self):
    |
help: Remove exception name

TRY201 Use `raise` without specifying exception name
   --> src/utils/postgres_db.py:177:19
    |
175 |             logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†: {e}")
176 |             self.conn.rollback()
177 |             raise e
    |                   ^
178 |
179 |     def add_song(
    |
help: Remove exception name

RUF013 PEP 484 prohibits implicit `Optional`
   --> src/utils/postgres_db.py:185:20
    |
183 |         lyrics: str,
184 |         url: str,
185 |         genius_id: int = None,
    |                    ^^^
186 |         metadata: Dict = None,
187 |     ) -> bool:
    |
help: Convert to `T | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/utils/postgres_db.py:186:19
    |
184 |         url: str,
185 |         genius_id: int = None,
186 |         metadata: Dict = None,
    |                   ^^^^
187 |     ) -> bool:
188 |         """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐ½Ð¸ Ñ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸"""
    |
help: Replace with `dict`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src/utils/postgres_db.py:186:19
    |
184 |         url: str,
185 |         genius_id: int = None,
186 |         metadata: Dict = None,
    |                   ^^^^
187 |     ) -> bool:
188 |         """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿ÐµÑÐ½Ð¸ Ñ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸"""
    |
help: Convert to `T | None`

TRY300 Consider moving this statement to an `else` block
   --> src/utils/postgres_db.py:224:13
    |
223 |             self.conn.commit()
224 |             return True
    |             ^^^^^^^^^^^
225 |
226 |         except psycopg2.IntegrityError as e:
    |

RET505 [*] Unnecessary `else` after `return` statement
   --> src/utils/postgres_db.py:231:13
    |
229 |                 logger.debug(f"Duplicate: {artist} - {title}")
230 |                 return False
231 |             else:
    |             ^^^^
232 |                 logger.error(f"Integrity error: {e}")
233 |                 raise e
    |
help: Remove unnecessary `else`

TRY201 Use `raise` without specifying exception name
   --> src/utils/postgres_db.py:233:23
    |
231 |             else:
232 |                 logger.error(f"Integrity error: {e}")
233 |                 raise e
    |                       ^
234 |         except psycopg2.Error as e:
235 |             self.conn.rollback()
    |
help: Remove exception name

C401 Unnecessary generator (rewrite as a set comprehension)
   --> src/utils/postgres_db.py:254:28
    |
253 |         # Ð Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð¸Ðµ ÑÐ»Ð¾Ð²
254 |         unique_words = len(set(word.lower() for word in words))
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
255 |         if len(words) > 0:
256 |             diversity = unique_words / len(words)
    |
help: Rewrite as a set comprehension

RUF013 PEP 484 prohibits implicit `Optional`
   --> src/utils/postgres_db.py:266:32
    |
264 |         return min(score, 1.0)
265 |
266 |     def song_exists(self, url: str = None, genius_id: int = None) -> bool:
    |                                ^^^
267 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿ÐµÑÐ½Ð¸"""
268 |         try:
    |
help: Convert to `T | None`

RUF013 PEP 484 prohibits implicit `Optional`
   --> src/utils/postgres_db.py:266:55
    |
264 |         return min(score, 1.0)
265 |
266 |     def song_exists(self, url: str = None, genius_id: int = None) -> bool:
    |                                                       ^^^
267 |         """ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿ÐµÑÐ½Ð¸"""
268 |         try:
    |
help: Convert to `T | None`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/utils/postgres_db.py:282:28
    |
280 |             return False
281 |
282 |     def get_stats(self) -> Dict:
    |                            ^^^^
283 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
284 |         try:
    |
help: Replace with `dict`

UP006 [*] Use `list` instead of `List` for type annotation
   --> src/utils/postgres_db.py:312:51
    |
310 |             }
311 |
312 |     def get_recent_songs(self, limit: int = 5) -> List[Dict]:
    |                                                   ^^^^
313 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ñ… Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¿ÐµÑÐµÐ½"""
314 |         try:
    |
help: Replace with `list`

UP006 [*] Use `dict` instead of `Dict` for type annotation
   --> src/utils/postgres_db.py:312:56
    |
310 |             }
311 |
312 |     def get_recent_songs(self, limit: int = 5) -> List[Dict]:
    |                                                        ^^^^
313 |         """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ñ… Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¿ÐµÑÐµÐ½"""
314 |         try:
    |
help: Replace with `dict`

F541 [*] f-string without any placeholders
   --> src/utils/postgres_db.py:358:15
    |
356 |         db = PostgreSQLManager()
357 |         stats = db.get_stats()
358 |         print(f"âœ… PostgreSQL Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾!")
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
359 |         print(f"ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°: {stats}")
360 |         db.close()
    |
help: Remove extraneous `f` prefix

TRY300 Consider moving this statement to an `else` block
   --> src/utils/postgres_db.py:361:9
    |
359 |         print(f"ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°: {stats}")
360 |         db.close()
361 |         return True
    |         ^^^^^^^^^^^
362 |     except Exception as e:
363 |         print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ: {e}")
    |

I001 [*] Import block is un-sorted or un-formatted
  --> src/utils/setup_spotify.py:28:1
   |
26 |   """
27 |
28 | / import os
29 | | import json
30 | | from dotenv import load_dotenv
31 | | from spotify_enhancer import SpotifyEnhancer
   | |____________________________________________^
32 |
33 |   # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
   |
help: Organize imports

F401 [*] `json` imported but unused
  --> src/utils/setup_spotify.py:29:8
   |
28 | import os
29 | import json
   |        ^^^^
30 | from dotenv import load_dotenv
31 | from spotify_enhancer import SpotifyEnhancer
   |
help: Remove unused import: `json`

RET505 [*] Unnecessary `else` after `return` statement
  --> src/utils/setup_spotify.py:45:5
   |
43 |         print("âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ñ‹ Spotify credentials Ð² .env Ñ„Ð°Ð¹Ð»Ðµ")
44 |         return client_id, client_secret
45 |     else:
   |     ^^^^
46 |         print("âš ï¸ Spotify credentials Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð¸Ð»Ð¸ Ð½Ðµ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ñ‹ Ð² .env Ñ„Ð°Ð¹Ð»Ðµ")
47 |         return None, None
   |
help: Remove unnecessary `else`

RET505 [*] Unnecessary `else` after `return` statement
  --> src/utils/setup_spotify.py:73:5
   |
71 |         print(f"   â±ï¸ Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {result.processing_time:.2f}Ñ")
72 |         return True
73 |     else:
   |     ^^^^
74 |         print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ°: {result.error_message}")
75 |         return False
   |
help: Remove unnecessary `else`

F541 [*] f-string without any placeholders
  --> src/utils/setup_spotify.py:93:19
   |
91 |         if track.audio_features:
92 |             af = track.audio_features
93 |             print(f"   ðŸŽ¶ ÐÑƒÐ´Ð¸Ð¾-Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ¸:")
   |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
94 |             print(f"      â€¢ Ð¢Ð°Ð½Ñ†ÐµÐ²Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: {af.danceability:.2f}")
95 |             print(f"      â€¢ Ð­Ð½ÐµÑ€Ð³Ð¸Ñ‡Ð½Ð¾ÑÑ‚ÑŒ: {af.energy:.2f}")
   |
help: Remove extraneous `f` prefix

RET505 [*] Unnecessary `else` after `return` statement
   --> src/utils/setup_spotify.py:100:5
    |
 99 |         return True
100 |     else:
    |     ^^^^
101 |         print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ° Ñ‚Ñ€ÐµÐºÐ°: {result.error_message}")
102 |         return False
    |
help: Remove unnecessary `else`

F841 Local variable `artists` is assigned to but never used
   --> src/utils/setup_spotify.py:157:5
    |
156 |     # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…
157 |     artists = show_database_preview(enhancer)
    |     ^^^^^^^
158 |
159 |     # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
    |
help: Remove assignment to unused variable `artists`

F541 [*] f-string without any placeholders
   --> src/utils/setup_spotify.py:165:11
    |
163 |         print(f"  â€¢ {key}: {value}")
164 |
165 |     print(f"\nâœ… Spotify API Ð³Ð¾Ñ‚Ð¾Ð² Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÑŽ!")
    |           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
166 |     print(f"ðŸ“Š API Ð²Ñ‹Ð·Ð¾Ð²Ð¾Ð² Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾: {enhancer.api_calls_count}")
    |
help: Remove extraneous `f` prefix

I001 [*] Import block is un-sorted or un-formatted
 --> src/utils/validation_utils.py:7:1
  |
5 |   """
6 |
7 | / import re
8 | | from typing import Optional, List
  | |_________________________________^
  |
help: Organize imports

UP035 `typing.List` is deprecated, use `list` instead
 --> src/utils/validation_utils.py:8:1
  |
7 | import re
8 | from typing import Optional, List
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |

F401 [*] `typing.Optional` imported but unused
 --> src/utils/validation_utils.py:8:20
  |
7 | import re
8 | from typing import Optional, List
  |                    ^^^^^^^^
  |
help: Remove unused import

F401 [*] `typing.List` imported but unused
 --> src/utils/validation_utils.py:8:30
  |
7 | import re
8 | from typing import Optional, List
  |                              ^^^^
  |
help: Remove unused import

SIM103 Return the negated condition directly
  --> src/utils/validation_utils.py:29:5
   |
27 |           return False
28 |
29 | /     if len(text) < min_length or len(text) > max_length:
30 | |         return False
31 | |
32 | |     return True
   | |_______________^
   |
help: Inline condition

RET504 Unnecessary assignment to `text` before `return` statement
  --> src/utils/validation_utils.py:54:12
   |
52 |     text = re.sub(r"[\x00-\x1f\x7f]", "", text)
53 |
54 |     return text
   |            ^^^^
   |
help: Remove unnecessary assignment

I001 [*] Import block is un-sorted or un-formatted
  --> tests/benchmarks/conftest.py:14:1
   |
12 |   """
13 |
14 | / import pytest
15 | | import asyncio
16 | | import sys
17 | | from pathlib import Path
   | |________________________^
18 |
19 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |
help: Organize imports

I001 [*] Import block is un-sorted or un-formatted
  --> tests/benchmarks/conftest.py:22:1
   |
20 | sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))
21 |
22 | from core.app import Application
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |
help: Organize imports

I001 [*] Import block is un-sorted or un-formatted
   --> tests/benchmarks/conftest.py:132:5
    |
130 |   def pytest_benchmark_update_machine_info(config, machine_info):
131 |       """Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¼Ð°ÑˆÐ¸Ð½Ðµ"""
132 | /     import psutil
133 | |     import platform
    | |___________________^
134 |
135 |       machine_info.update(
    |
help: Organize imports

I001 [*] Import block is un-sorted or un-formatted
  --> tests/benchmarks/test_quick_benchmarks.py:19:1
   |
17 |   """
18 |
19 | / import pytest
20 | | import asyncio
21 | | import sys
22 | | from pathlib import Path
   | |________________________^
23 |
24 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |
help: Organize imports

F401 [*] `asyncio` imported but unused
  --> tests/benchmarks/test_quick_benchmarks.py:20:8
   |
19 | import pytest
20 | import asyncio
   |        ^^^^^^^
21 | import sys
22 | from pathlib import Path
   |
help: Remove unused import: `asyncio`

RET505 [*] Unnecessary `else` after `return` statement
  --> tests/benchmarks/test_quick_benchmarks.py:53:13
   |
51 |             if hasattr(analyzer, "analyze_song"):
52 |                 return analyzer.analyze_song("Test", "Quick", text)
53 |             else:
   |             ^^^^
54 |                 # Fallback Ð´Ð»Ñ Ð´Ñ€ÑƒÐ³Ð¸Ñ… Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ¾Ð²
55 |                 return analyzer.analyze(text) if hasattr(analyzer, "analyze") else None
   |
help: Remove unnecessary `else`

RET505 [*] Unnecessary `else` after `return` statement
  --> tests/benchmarks/test_quick_benchmarks.py:81:13
   |
79 |             if hasattr(analyzer, "analyze_song"):
80 |                 return analyzer.analyze_song("Test", "Emotion", text)
81 |             else:
   |             ^^^^
82 |                 return analyzer.analyze(text) if hasattr(analyzer, "analyze") else None
   |
help: Remove unnecessary `else`

RET505 [*] Unnecessary `else` after `return` statement
   --> tests/benchmarks/test_quick_benchmarks.py:108:13
    |
106 |             if hasattr(analyzer, "analyze_song"):
107 |                 return analyzer.analyze_song("Test", "Compare", text)
108 |             else:
    |             ^^^^
109 |                 return analyzer.analyze(text) if hasattr(analyzer, "analyze") else None
    |
help: Remove unnecessary `else`

RET505 [*] Unnecessary `else` after `return` statement
   --> tests/benchmarks/test_quick_benchmarks.py:134:13
    |
132 |             if hasattr(analyzer, "analyze_song"):
133 |                 return analyzer.analyze_song("Test", "Compare", text)
134 |             else:
    |             ^^^^
135 |                 return analyzer.analyze(text) if hasattr(analyzer, "analyze") else None
    |
help: Remove unnecessary `else`

I001 [*] Import block is un-sorted or un-formatted
  --> tests/conftest.py:2:1
   |
 1 |   # Pytest Configuration and Fixtures
 2 | / import pytest
 3 | | import sqlite3
 4 | | import tempfile
 5 | | import os
 6 | | import sys
 7 | | from pathlib import Path
 8 | | from unittest.mock import Mock, patch
   | |_____________________________________^
 9 |
10 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² path Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹
   |
help: Organize imports

F401 [*] `unittest.mock.Mock` imported but unused
  --> tests/conftest.py:8:27
   |
 6 | import sys
 7 | from pathlib import Path
 8 | from unittest.mock import Mock, patch
   |                           ^^^^
 9 |
10 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² path Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹
   |
help: Remove unused import

F401 [*] `unittest.mock.patch` imported but unused
  --> tests/conftest.py:8:33
   |
 6 | import sys
 7 | from pathlib import Path
 8 | from unittest.mock import Mock, patch
   |                                 ^^^^^
 9 |
10 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² path Ð´Ð»Ñ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð° Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹
   |
help: Remove unused import

I001 [*] Import block is un-sorted or un-formatted
  --> tests/conftest.py:13:1
   |
11 |   sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
12 |
13 | / from enhancers.spotify_enhancer import SpotifyEnhancer
14 | | from models.models import SpotifyArtist, SpotifyTrack, SpotifyAudioFeatures
   | |___________________________________________________________________________^
   |
help: Organize imports

SIM115 Use a context manager for opening files
  --> tests/conftest.py:20:17
   |
18 | def temp_db():
19 |     """Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð±Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²"""
20 |     temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".db")
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
21 |     temp_file.close()
   |

PTH108 `os.unlink()` should be replaced by `Path.unlink()`
  --> tests/conftest.py:64:5
   |
63 |     # Cleanup
64 |     os.unlink(temp_file.name)
   |     ^^^^^^^^^
   |
help: Replace with `Path(...).unlink()`

I001 [*] Import block is un-sorted or un-formatted
  --> tests/test_emotion_analyzer.py:25:1
   |
23 |   """
24 |
25 | / import pytest
26 | | import asyncio
27 | | import time
28 | | from unittest.mock import patch, MagicMock
29 | | from typing import List, Dict, Any
30 | |
31 | | # Import the analyzer
32 | | import sys
33 | | import os
   | |_________^
34 |
35 |   sys.path.append(os.path.join(os.path.dirname(__file__), "..", "src"))
   |
help: Organize imports

F401 [*] `unittest.mock.MagicMock` imported but unused
  --> tests/test_emotion_analyzer.py:28:34
   |
26 | import asyncio
27 | import time
28 | from unittest.mock import patch, MagicMock
   |                                  ^^^^^^^^^
29 | from typing import List, Dict, Any
   |
help: Remove unused import: `unittest.mock.MagicMock`

UP035 `typing.List` is deprecated, use `list` instead
  --> tests/test_emotion_analyzer.py:29:1
   |
27 | import time
28 | from unittest.mock import patch, MagicMock
29 | from typing import List, Dict, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30 |
31 | # Import the analyzer
   |

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> tests/test_emotion_analyzer.py:29:1
   |
27 | import time
28 | from unittest.mock import patch, MagicMock
29 | from typing import List, Dict, Any
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30 |
31 | # Import the analyzer
   |

F401 [*] `typing.List` imported but unused
  --> tests/test_emotion_analyzer.py:29:20
   |
27 | import time
28 | from unittest.mock import patch, MagicMock
29 | from typing import List, Dict, Any
   |                    ^^^^
30 |
31 | # Import the analyzer
   |
help: Remove unused import

F401 [*] `typing.Dict` imported but unused
  --> tests/test_emotion_analyzer.py:29:26
   |
27 | import time
28 | from unittest.mock import patch, MagicMock
29 | from typing import List, Dict, Any
   |                          ^^^^
30 |
31 | # Import the analyzer
   |
help: Remove unused import

F401 [*] `typing.Any` imported but unused
  --> tests/test_emotion_analyzer.py:29:32
   |
27 | import time
28 | from unittest.mock import patch, MagicMock
29 | from typing import List, Dict, Any
   |                                ^^^
30 |
31 | # Import the analyzer
   |
help: Remove unused import

PTH118 `os.path.join()` should be replaced by `Path` with `/` operator
  --> tests/test_emotion_analyzer.py:35:17
   |
33 | import os
34 |
35 | sys.path.append(os.path.join(os.path.dirname(__file__), "..", "src"))
   |                 ^^^^^^^^^^^^
36 |
37 | from analyzers.emotion_analyzer import EmotionAnalyzer
   |

PTH120 `os.path.dirname()` should be replaced by `Path.parent`
  --> tests/test_emotion_analyzer.py:35:30
   |
33 | import os
34 |
35 | sys.path.append(os.path.join(os.path.dirname(__file__), "..", "src"))
   |                              ^^^^^^^^^^^^^^^
36 |
37 | from analyzers.emotion_analyzer import EmotionAnalyzer
   |
help: Replace with `Path(...).parent`

I001 [*] Import block is un-sorted or un-formatted
  --> tests/test_integration_comprehensive.py:7:1
   |
 5 |   """
 6 |
 7 | / import pytest
 8 | | import asyncio
 9 | | import tempfile
10 | | import json
11 | | import sys
12 | | from pathlib import Path
13 | | from unittest.mock import Mock, patch, AsyncMock
14 | | from typing import Dict, Any, List
   | |__________________________________^
15 |
16 |   # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |
help: Organize imports

F401 [*] `asyncio` imported but unused
  --> tests/test_integration_comprehensive.py:8:8
   |
 7 | import pytest
 8 | import asyncio
   |        ^^^^^^^
 9 | import tempfile
10 | import json
   |
help: Remove unused import: `asyncio`

F401 [*] `unittest.mock.Mock` imported but unused
  --> tests/test_integration_comprehensive.py:13:27
   |
11 | import sys
12 | from pathlib import Path
13 | from unittest.mock import Mock, patch, AsyncMock
   |                           ^^^^
14 | from typing import Dict, Any, List
   |
help: Remove unused import

F401 [*] `unittest.mock.patch` imported but unused
  --> tests/test_integration_comprehensive.py:13:33
   |
11 | import sys
12 | from pathlib import Path
13 | from unittest.mock import Mock, patch, AsyncMock
   |                                 ^^^^^
14 | from typing import Dict, Any, List
   |
help: Remove unused import

F401 [*] `unittest.mock.AsyncMock` imported but unused
  --> tests/test_integration_comprehensive.py:13:40
   |
11 | import sys
12 | from pathlib import Path
13 | from unittest.mock import Mock, patch, AsyncMock
   |                                        ^^^^^^^^^
14 | from typing import Dict, Any, List
   |
help: Remove unused import

UP035 `typing.Dict` is deprecated, use `dict` instead
  --> tests/test_integration_comprehensive.py:14:1
   |
12 | from pathlib import Path
13 | from unittest.mock import Mock, patch, AsyncMock
14 | from typing import Dict, Any, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
15 |
16 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> tests/test_integration_comprehensive.py:14:1
   |
12 | from pathlib import Path
13 | from unittest.mock import Mock, patch, AsyncMock
14 | from typing import Dict, Any, List
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
15 |
16 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |

F401 [*] `typing.Dict` imported but unused
  --> tests/test_integration_comprehensive.py:14:20
   |
12 | from pathlib import Path
13 | from unittest.mock import Mock, patch, AsyncMock
14 | from typing import Dict, Any, List
   |                    ^^^^
15 |
16 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |
help: Remove unused import

F401 [*] `typing.Any` imported but unused
  --> tests/test_integration_comprehensive.py:14:26
   |
12 | from pathlib import Path
13 | from unittest.mock import Mock, patch, AsyncMock
14 | from typing import Dict, Any, List
   |                          ^^^
15 |
16 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |
help: Remove unused import

F401 [*] `typing.List` imported but unused
  --> tests/test_integration_comprehensive.py:14:31
   |
12 | from pathlib import Path
13 | from unittest.mock import Mock, patch, AsyncMock
14 | from typing import Dict, Any, List
   |                               ^^^^
15 |
16 | # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ src Ð² Python path
   |
help: Remove unused import

I001 [*] Import block is un-sorted or un-formatted
  --> tests/test_integration_comprehensive.py:19:1
   |
17 |   sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
18 |
19 | / from core.app import Application
20 | | from interfaces.analyzer_interface import AnalyzerFactory
21 | | from cli.analyzer_cli import AnalyzerCLI
22 | | from cli.batch_processor import BatchProcessor
23 | | from cli.performance_monitor import PerformanceMonitor
   | |______________________________________________________^
   |
help: Organize imports

F841 Local variable `output_file` is assigned to but never used
   --> tests/test_integration_comprehensive.py:171:13
    |
170 |             input_file = temp_path / "test_input.json"
171 |             output_file = temp_path / "test_output.json"
    |             ^^^^^^^^^^^
172 |
173 |             # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    |
help: Remove assignment to unused variable `output_file`

PTH123 `open()` should be replaced by `Path.open()`
   --> tests/test_integration_comprehensive.py:174:18
    |
173 |             # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
174 |             with open(input_file, "w", encoding="utf-8") as f:
    |                  ^^^^
175 |                 json.dump([{"text": text} for text in test_texts], f)
    |
help: Replace with `Path.open()`

PTH123 `open()` should be replaced by `Path.open()`
   --> tests/test_integration_comprehensive.py:227:26
    |
225 |                 # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ Ñ„Ð°Ð¹Ð»Ñ‹ ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹ (ÐµÑÐ»Ð¸ Ð²ÑÐµ Ð¿Ñ€Ð¾ÑˆÐ»Ð¾ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾)
226 |                 if output_file.exists():
227 |                     with open(output_file, "r", encoding="utf-8") as f:
    |                          ^^^^
228 |                         saved_data = json.load(f)
229 |                         assert "metadata" in saved_data
    |
help: Replace with `Path.open()`

UP015 [*] Unnecessary mode argument
   --> tests/test_integration_comprehensive.py:227:44
    |
225 |                 # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ Ñ„Ð°Ð¹Ð»Ñ‹ ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹ (ÐµÑÐ»Ð¸ Ð²ÑÐµ Ð¿Ñ€Ð¾ÑˆÐ»Ð¾ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾)
226 |                 if output_file.exists():
227 |                     with open(output_file, "r", encoding="utf-8") as f:
    |                                            ^^^
228 |                         saved_data = json.load(f)
229 |                         assert "metadata" in saved_data
    |
help: Remove mode argument

PT011 `pytest.raises(ValueError)` is too broad, set the `match` parameter or use a more specific exception
   --> tests/test_integration_comprehensive.py:273:28
    |
271 |         cli = AnalyzerCLI()
272 |
273 |         with pytest.raises(ValueError) as exc_info:
    |                            ^^^^^^^^^^
274 |             await cli.analyze_text(
275 |                 text="Test text", analyzer_type="nonexistent_analyzer"
    |

PT017 Found assertion on exception `e` in `except` block, use `pytest.raises()` instead
   --> tests/test_integration_comprehensive.py:291:13
    |
289 |         except Exception as e:
290 |             # ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ ÑƒÐ¿Ð°ÑÑ‚ÑŒ Ð½Ð° Ð¿ÑƒÑÑ‚Ð¾Ð¼ Ñ‚ÐµÐºÑÑ‚Ðµ
291 |             assert "empty" in str(e).lower() or "invalid" in str(e).lower()
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
292 |
293 |     def test_app_resilience(self):
    |

PT017 Found assertion on exception `e` in `except` block, use `pytest.raises()` instead
   --> tests/test_integration_comprehensive.py:291:13
    |
289 |         except Exception as e:
290 |             # ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ ÑƒÐ¿Ð°ÑÑ‚ÑŒ Ð½Ð° Ð¿ÑƒÑÑ‚Ð¾Ð¼ Ñ‚ÐµÐºÑÑ‚Ðµ
291 |             assert "empty" in str(e).lower() or "invalid" in str(e).lower()
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
292 |
293 |     def test_app_resilience(self):
    |

I001 [*] Import block is un-sorted or un-formatted
 --> tests/test_ml_api.py:5:1
  |
3 |   """
4 |
5 | / import asyncio
6 | | import aiohttp
7 | | import json
8 | | from datetime import datetime
  | |_____________________________^
  |
help: Organize imports

F401 [*] `json` imported but unused
 --> tests/test_ml_api.py:7:8
  |
5 | import asyncio
6 | import aiohttp
7 | import json
  |        ^^^^
8 | from datetime import datetime
  |
help: Remove unused import: `json`

PERF203 `try`-`except` within a loop incurs performance overhead
  --> tests/test_ml_api.py:37:13
   |
35 |                               print(f"âŒ {test['name']}: HTTP {response.status}")
36 |
37 | /             except Exception as e:
38 | |                 print(f"âŒ {test['name']}: {e}")
   | |________________________________________________^
39 |
40 |       # Test generation endpoint
   |

F541 [*] f-string without any placeholders
  --> tests/test_ml_api.py:42:15
   |
40 |     # Test generation endpoint
41 |     try:
42 |         print(f"\nðŸŽ¤ Testing Text Generation...")
   |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43 |         generation_data = {
44 |             "prompt": "I'm on the mic with the flow",
   |
help: Remove extraneous `f` prefix

SIM117 [*] Use a single `with` statement with multiple contexts instead of nested `with` statements
  --> tests/test_ml_api.py:51:9
   |
49 |           }
50 |
51 | /         async with aiohttp.ClientSession() as session:
52 | |             async with session.post(
53 | |                 f"{base_url}/generate", json=generation_data
54 | |             ) as response:
   | |__________________________^
55 |                   if response.status == 200:
56 |                       data = await response.json()
   |
help: Combine `with` statements

F541 [*] f-string without any placeholders
  --> tests/test_ml_api.py:57:27
   |
55 |                 if response.status == 200:
56 |                     data = await response.json()
57 |                     print(f"âœ… Generation: SUCCESS")
   |                           ^^^^^^^^^^^^^^^^^^^^^^^^^
58 |                     print(f"   Generated: {data.get('generated_text', '')[:100]}...")
59 |                 else:
   |
help: Remove extraneous `f` prefix

DTZ005 `datetime.datetime.now()` called without a `tz` argument
  --> tests/test_ml_api.py:71:32
   |
69 |     print("ðŸš€ ML API TEST SUITE")
70 |     print("=" * 50)
71 |     print(f"Starting tests at {datetime.now()}")
   |                                ^^^^^^^^^^^^^^
72 |     print("=" * 50)
   |
help: Pass a `datetime.timezone` object to the `tz` parameter

I001 [*] Import block is un-sorted or un-formatted
 --> tests/test_models.py:2:1
  |
1 |   # Tests for Pydantic Models
2 | / import unittest
3 | | from pydantic import ValidationError
4 | | from models import (
5 | |     SpotifyArtist,
6 | |     SpotifyTrack,
7 | |     SpotifyAudioFeatures,
8 | |     SpotifyEnrichmentResult,
9 | | )
  | |_^
  |
help: Organize imports

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_models.py:28:9
   |
26 |         artist = SpotifyArtist(**artist_data)
27 |
28 |         self.assertEqual(artist.name, "Drake")
   |         ^^^^^^^^^^^^^^^^
29 |         self.assertEqual(artist.popularity, 95)
30 |         self.assertEqual(len(artist.genres), 2)
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_models.py:29:9
   |
28 |         self.assertEqual(artist.name, "Drake")
29 |         self.assertEqual(artist.popularity, 95)
   |         ^^^^^^^^^^^^^^^^
30 |         self.assertEqual(len(artist.genres), 2)
31 |         self.assertIn("hip hop", artist.genres)
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_models.py:30:9
   |
28 |         self.assertEqual(artist.name, "Drake")
29 |         self.assertEqual(artist.popularity, 95)
30 |         self.assertEqual(len(artist.genres), 2)
   |         ^^^^^^^^^^^^^^^^
31 |         self.assertIn("hip hop", artist.genres)
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIn`
  --> tests/test_models.py:31:9
   |
29 |         self.assertEqual(artist.popularity, 95)
30 |         self.assertEqual(len(artist.genres), 2)
31 |         self.assertIn("hip hop", artist.genres)
   |         ^^^^^^^^^^^^^
32 |
33 |     def test_spotify_artist_required_fields(self):
   |
help: Replace `assertIn(...)` with `assert ...`

PT027 Use `pytest.raises` instead of unittest-style `assertRaises`
  --> tests/test_models.py:36:14
   |
34 |         """Ð¢ÐµÑÑ‚ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¿Ð¾Ð»ÐµÐ¹ SpotifyArtist"""
35 |         # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¿Ð¾Ð»Ðµ name
36 |         with self.assertRaises(ValidationError):
   |              ^^^^^^^^^^^^^^^^^
37 |             SpotifyArtist(
38 |                 spotify_id="test_id",
   |
help: Replace `assertRaises` with `pytest.raises`

PT027 Use `pytest.raises` instead of unittest-style `assertRaises`
  --> tests/test_models.py:48:14
   |
46 |         """Ð¢ÐµÑÑ‚ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ popularity (Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ 0-100)"""
47 |         # Popularity Ð±Ð¾Ð»ÑŒÑˆÐµ 100
48 |         with self.assertRaises(ValidationError):
   |              ^^^^^^^^^^^^^^^^^
49 |             SpotifyArtist(
50 |                 spotify_id="test_id",
   |
help: Replace `assertRaises` with `pytest.raises`

PT027 Use `pytest.raises` instead of unittest-style `assertRaises`
  --> tests/test_models.py:58:14
   |
57 |         # Negative popularity
58 |         with self.assertRaises(ValidationError):
   |              ^^^^^^^^^^^^^^^^^
59 |             SpotifyArtist(
60 |                 spotify_id="test_id",
   |
help: Replace `assertRaises` with `pytest.raises`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_models.py:83:9
   |
81 |         track = SpotifyTrack(**track_data)
82 |
83 |         self.assertEqual(track.name, "Hotline Bling")
   |         ^^^^^^^^^^^^^^^^
84 |         self.assertEqual(track.duration_ms, 267066)
85 |         self.assertFalse(track.explicit)
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_models.py:84:9
   |
83 |         self.assertEqual(track.name, "Hotline Bling")
84 |         self.assertEqual(track.duration_ms, 267066)
   |         ^^^^^^^^^^^^^^^^
85 |         self.assertFalse(track.explicit)
86 |         self.assertEqual(track.release_date, "2016-04-29")
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertFalse`
  --> tests/test_models.py:85:9
   |
83 |         self.assertEqual(track.name, "Hotline Bling")
84 |         self.assertEqual(track.duration_ms, 267066)
85 |         self.assertFalse(track.explicit)
   |         ^^^^^^^^^^^^^^^^
86 |         self.assertEqual(track.release_date, "2016-04-29")
   |
help: Replace `assertFalse(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_models.py:86:9
   |
84 |         self.assertEqual(track.duration_ms, 267066)
85 |         self.assertFalse(track.explicit)
86 |         self.assertEqual(track.release_date, "2016-04-29")
   |         ^^^^^^^^^^^^^^^^
87 |
88 |     def test_spotify_audio_features_valid(self):
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertAlmostEqual`
   --> tests/test_models.py:104:9
    |
102 |         features = SpotifyAudioFeatures(**features_data)
103 |
104 |         self.assertAlmostEqual(features.danceability, 0.715, places=3)
    |         ^^^^^^^^^^^^^^^^^^^^^^
105 |         self.assertAlmostEqual(features.tempo, 135.051, places=3)
106 |         self.assertAlmostEqual(features.loudness, -7.305, places=3)
    |
help: Replace `assertAlmostEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertAlmostEqual`
   --> tests/test_models.py:105:9
    |
104 |         self.assertAlmostEqual(features.danceability, 0.715, places=3)
105 |         self.assertAlmostEqual(features.tempo, 135.051, places=3)
    |         ^^^^^^^^^^^^^^^^^^^^^^
106 |         self.assertAlmostEqual(features.loudness, -7.305, places=3)
    |
help: Replace `assertAlmostEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertAlmostEqual`
   --> tests/test_models.py:106:9
    |
104 |         self.assertAlmostEqual(features.danceability, 0.715, places=3)
105 |         self.assertAlmostEqual(features.tempo, 135.051, places=3)
106 |         self.assertAlmostEqual(features.loudness, -7.305, places=3)
    |         ^^^^^^^^^^^^^^^^^^^^^^
107 |
108 |     def test_spotify_audio_features_range_validation(self):
    |
help: Replace `assertAlmostEqual(...)` with `assert ...`

PT027 Use `pytest.raises` instead of unittest-style `assertRaises`
   --> tests/test_models.py:111:14
    |
109 |         """Ð¢ÐµÑÑ‚ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð¾Ð² Ð°ÑƒÐ´Ð¸Ð¾-Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº"""
110 |         # Danceability Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ 0.0-1.0
111 |         with self.assertRaises(ValidationError):
    |              ^^^^^^^^^^^^^^^^^
112 |             SpotifyAudioFeatures(
113 |                 danceability=1.5,  # Ð‘Ð¾Ð»ÑŒÑˆÐµ 1.0
    |
help: Replace `assertRaises` with `pytest.raises`

PT027 Use `pytest.raises` instead of unittest-style `assertRaises`
   --> tests/test_models.py:120:14
    |
119 |         # Energy Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ 0.0-1.0
120 |         with self.assertRaises(ValidationError):
    |              ^^^^^^^^^^^^^^^^^
121 |             SpotifyAudioFeatures(
122 |                 danceability=0.7,
    |
help: Replace `assertRaises` with `pytest.raises`

PT009 Use a regular `assert` instead of unittest-style `assertTrue`
   --> tests/test_models.py:143:9
    |
141 |         )
142 |
143 |         self.assertTrue(result.success)
    |         ^^^^^^^^^^^^^^^
144 |         self.assertEqual(result.artist_data.name, "Test Artist")
145 |         self.assertIsNone(result.error_message)
    |
help: Replace `assertTrue(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_models.py:144:9
    |
143 |         self.assertTrue(result.success)
144 |         self.assertEqual(result.artist_data.name, "Test Artist")
    |         ^^^^^^^^^^^^^^^^
145 |         self.assertIsNone(result.error_message)
146 |         self.assertEqual(result.api_calls_used, 2)
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNone`
   --> tests/test_models.py:145:9
    |
143 |         self.assertTrue(result.success)
144 |         self.assertEqual(result.artist_data.name, "Test Artist")
145 |         self.assertIsNone(result.error_message)
    |         ^^^^^^^^^^^^^^^^^
146 |         self.assertEqual(result.api_calls_used, 2)
    |
help: Replace `assertIsNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_models.py:146:9
    |
144 |         self.assertEqual(result.artist_data.name, "Test Artist")
145 |         self.assertIsNone(result.error_message)
146 |         self.assertEqual(result.api_calls_used, 2)
    |         ^^^^^^^^^^^^^^^^
147 |
148 |     def test_spotify_enrichment_result_failure(self):
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertFalse`
   --> tests/test_models.py:157:9
    |
155 |         )
156 |
157 |         self.assertFalse(result.success)
    |         ^^^^^^^^^^^^^^^^
158 |         self.assertEqual(result.error_message, "Artist not found")
159 |         self.assertIsNone(result.artist_data)
    |
help: Replace `assertFalse(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_models.py:158:9
    |
157 |         self.assertFalse(result.success)
158 |         self.assertEqual(result.error_message, "Artist not found")
    |         ^^^^^^^^^^^^^^^^
159 |         self.assertIsNone(result.artist_data)
160 |         self.assertIsNone(result.track_data)
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNone`
   --> tests/test_models.py:159:9
    |
157 |         self.assertFalse(result.success)
158 |         self.assertEqual(result.error_message, "Artist not found")
159 |         self.assertIsNone(result.artist_data)
    |         ^^^^^^^^^^^^^^^^^
160 |         self.assertIsNone(result.track_data)
    |
help: Replace `assertIsNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNone`
   --> tests/test_models.py:160:9
    |
158 |         self.assertEqual(result.error_message, "Artist not found")
159 |         self.assertIsNone(result.artist_data)
160 |         self.assertIsNone(result.track_data)
    |         ^^^^^^^^^^^^^^^^^
161 |
162 |     def test_spotify_track_with_audio_features(self):
    |
help: Replace `assertIsNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_models.py:185:9
    |
183 |         )
184 |
185 |         self.assertEqual(track.name, "Test Track")
    |         ^^^^^^^^^^^^^^^^
186 |         self.assertIsNotNone(track.audio_features)
187 |         self.assertEqual(track.audio_features.danceability, 0.8)
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNotNone`
   --> tests/test_models.py:186:9
    |
185 |         self.assertEqual(track.name, "Test Track")
186 |         self.assertIsNotNone(track.audio_features)
    |         ^^^^^^^^^^^^^^^^^^^^
187 |         self.assertEqual(track.audio_features.danceability, 0.8)
188 |         self.assertEqual(track.audio_features.tempo, 128.0)
    |
help: Replace `assertIsNotNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_models.py:187:9
    |
185 |         self.assertEqual(track.name, "Test Track")
186 |         self.assertIsNotNone(track.audio_features)
187 |         self.assertEqual(track.audio_features.danceability, 0.8)
    |         ^^^^^^^^^^^^^^^^
188 |         self.assertEqual(track.audio_features.tempo, 128.0)
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_models.py:188:9
    |
186 |         self.assertIsNotNone(track.audio_features)
187 |         self.assertEqual(track.audio_features.danceability, 0.8)
188 |         self.assertEqual(track.audio_features.tempo, 128.0)
    |         ^^^^^^^^^^^^^^^^
    |
help: Replace `assertEqual(...)` with `assert ...`

I001 [*] Import block is un-sorted or un-formatted
 --> tests/test_spotify_enhancer.py:2:1
  |
1 |   # Tests for Spotify Enhancer API Integration
2 | / import unittest
3 | | from unittest.mock import patch, Mock
4 | | import sqlite3
5 | | import json
6 | | from spotify_enhancer import SpotifyEnhancer
7 | | from models import SpotifyArtist, SpotifyTrack, SpotifyEnrichmentResult
  | |_______________________________________________________________________^
  |
help: Organize imports

F401 [*] `json` imported but unused
 --> tests/test_spotify_enhancer.py:5:8
  |
3 | from unittest.mock import patch, Mock
4 | import sqlite3
5 | import json
  |        ^^^^
6 | from spotify_enhancer import SpotifyEnhancer
7 | from models import SpotifyArtist, SpotifyTrack, SpotifyEnrichmentResult
  |
help: Remove unused import: `json`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_spotify_enhancer.py:24:9
   |
22 |     def test_initialization(self):
23 |         """Ð¢ÐµÑÑ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ SpotifyEnhancer"""
24 |         self.assertEqual(self.enhancer.client_id, "test_client_id")
   |         ^^^^^^^^^^^^^^^^
25 |         self.assertEqual(self.enhancer.client_secret, "test_client_secret")
26 |         self.assertIsNone(self.enhancer.access_token)
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_spotify_enhancer.py:25:9
   |
23 |         """Ð¢ÐµÑÑ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ SpotifyEnhancer"""
24 |         self.assertEqual(self.enhancer.client_id, "test_client_id")
25 |         self.assertEqual(self.enhancer.client_secret, "test_client_secret")
   |         ^^^^^^^^^^^^^^^^
26 |         self.assertIsNone(self.enhancer.access_token)
27 |         self.assertEqual(self.enhancer.api_calls_count, 0)
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNone`
  --> tests/test_spotify_enhancer.py:26:9
   |
24 |         self.assertEqual(self.enhancer.client_id, "test_client_id")
25 |         self.assertEqual(self.enhancer.client_secret, "test_client_secret")
26 |         self.assertIsNone(self.enhancer.access_token)
   |         ^^^^^^^^^^^^^^^^^
27 |         self.assertEqual(self.enhancer.api_calls_count, 0)
   |
help: Replace `assertIsNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_spotify_enhancer.py:27:9
   |
25 |         self.assertEqual(self.enhancer.client_secret, "test_client_secret")
26 |         self.assertIsNone(self.enhancer.access_token)
27 |         self.assertEqual(self.enhancer.api_calls_count, 0)
   |         ^^^^^^^^^^^^^^^^
28 |
29 |     @patch("spotify_enhancer.requests.post")
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertTrue`
  --> tests/test_spotify_enhancer.py:44:9
   |
42 |         result = self.enhancer.get_access_token()
43 |
44 |         self.assertTrue(result)
   |         ^^^^^^^^^^^^^^^
45 |         self.assertEqual(self.enhancer.access_token, "test_token_123")
46 |         self.assertIsNotNone(self.enhancer.token_expires_at)
   |
help: Replace `assertTrue(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_spotify_enhancer.py:45:9
   |
44 |         self.assertTrue(result)
45 |         self.assertEqual(self.enhancer.access_token, "test_token_123")
   |         ^^^^^^^^^^^^^^^^
46 |         self.assertIsNotNone(self.enhancer.token_expires_at)
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNotNone`
  --> tests/test_spotify_enhancer.py:46:9
   |
44 |         self.assertTrue(result)
45 |         self.assertEqual(self.enhancer.access_token, "test_token_123")
46 |         self.assertIsNotNone(self.enhancer.token_expires_at)
   |         ^^^^^^^^^^^^^^^^^^^^
47 |
48 |     @patch("spotify_enhancer.requests.post")
   |
help: Replace `assertIsNotNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertFalse`
  --> tests/test_spotify_enhancer.py:58:9
   |
56 |         result = self.enhancer.get_access_token()
57 |
58 |         self.assertFalse(result)
   |         ^^^^^^^^^^^^^^^^
59 |         self.assertIsNone(self.enhancer.access_token)
   |
help: Replace `assertFalse(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNone`
  --> tests/test_spotify_enhancer.py:59:9
   |
58 |         self.assertFalse(result)
59 |         self.assertIsNone(self.enhancer.access_token)
   |         ^^^^^^^^^^^^^^^^^
60 |
61 |     @patch.object(SpotifyEnhancer, "_make_request")
   |
help: Replace `assertIsNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsInstance`
  --> tests/test_spotify_enhancer.py:85:9
   |
83 |         artist = self.enhancer.search_artist("Drake")
84 |
85 |         self.assertIsInstance(artist, SpotifyArtist)
   |         ^^^^^^^^^^^^^^^^^^^^^
86 |         self.assertEqual(artist.name, "Drake")
87 |         self.assertEqual(artist.spotify_id, "test_artist_id")
   |
help: Replace `assertIsInstance(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_spotify_enhancer.py:86:9
   |
85 |         self.assertIsInstance(artist, SpotifyArtist)
86 |         self.assertEqual(artist.name, "Drake")
   |         ^^^^^^^^^^^^^^^^
87 |         self.assertEqual(artist.spotify_id, "test_artist_id")
88 |         self.assertEqual(artist.popularity, 95)
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_spotify_enhancer.py:87:9
   |
85 |         self.assertIsInstance(artist, SpotifyArtist)
86 |         self.assertEqual(artist.name, "Drake")
87 |         self.assertEqual(artist.spotify_id, "test_artist_id")
   |         ^^^^^^^^^^^^^^^^
88 |         self.assertEqual(artist.popularity, 95)
89 |         self.assertEqual(artist.followers, 50000000)
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_spotify_enhancer.py:88:9
   |
86 |         self.assertEqual(artist.name, "Drake")
87 |         self.assertEqual(artist.spotify_id, "test_artist_id")
88 |         self.assertEqual(artist.popularity, 95)
   |         ^^^^^^^^^^^^^^^^
89 |         self.assertEqual(artist.followers, 50000000)
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
  --> tests/test_spotify_enhancer.py:89:9
   |
87 |         self.assertEqual(artist.spotify_id, "test_artist_id")
88 |         self.assertEqual(artist.popularity, 95)
89 |         self.assertEqual(artist.followers, 50000000)
   |         ^^^^^^^^^^^^^^^^
90 |
91 |     @patch.object(SpotifyEnhancer, "_make_request")
   |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNone`
   --> tests/test_spotify_enhancer.py:98:9
    |
 96 |         artist = self.enhancer.search_artist("Unknown Artist")
 97 |
 98 |         self.assertIsNone(artist)
    |         ^^^^^^^^^^^^^^^^^
 99 |
100 |     @patch.object(SpotifyEnhancer, "_make_request")
    |
help: Replace `assertIsNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsInstance`
   --> tests/test_spotify_enhancer.py:125:9
    |
123 |         track = self.enhancer.search_track("Hotline Bling", "Drake")
124 |
125 |         self.assertIsInstance(track, SpotifyTrack)
    |         ^^^^^^^^^^^^^^^^^^^^^
126 |         self.assertEqual(track.name, "Hotline Bling")
127 |         self.assertEqual(track.spotify_id, "test_track_id")
    |
help: Replace `assertIsInstance(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_spotify_enhancer.py:126:9
    |
125 |         self.assertIsInstance(track, SpotifyTrack)
126 |         self.assertEqual(track.name, "Hotline Bling")
    |         ^^^^^^^^^^^^^^^^
127 |         self.assertEqual(track.spotify_id, "test_track_id")
128 |         self.assertEqual(track.album_name, "Views")
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_spotify_enhancer.py:127:9
    |
125 |         self.assertIsInstance(track, SpotifyTrack)
126 |         self.assertEqual(track.name, "Hotline Bling")
127 |         self.assertEqual(track.spotify_id, "test_track_id")
    |         ^^^^^^^^^^^^^^^^
128 |         self.assertEqual(track.album_name, "Views")
129 |         self.assertEqual(track.popularity, 85)
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_spotify_enhancer.py:128:9
    |
126 |         self.assertEqual(track.name, "Hotline Bling")
127 |         self.assertEqual(track.spotify_id, "test_track_id")
128 |         self.assertEqual(track.album_name, "Views")
    |         ^^^^^^^^^^^^^^^^
129 |         self.assertEqual(track.popularity, 85)
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_spotify_enhancer.py:129:9
    |
127 |         self.assertEqual(track.spotify_id, "test_track_id")
128 |         self.assertEqual(track.album_name, "Views")
129 |         self.assertEqual(track.popularity, 85)
    |         ^^^^^^^^^^^^^^^^
130 |
131 |     @patch.object(SpotifyEnhancer, "search_artist")
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsInstance`
   --> tests/test_spotify_enhancer.py:146:9
    |
144 |         result = self.enhancer.enhance_artist("Test Artist")
145 |
146 |         self.assertIsInstance(result, SpotifyEnrichmentResult)
    |         ^^^^^^^^^^^^^^^^^^^^^
147 |         self.assertTrue(result.success)
148 |         self.assertEqual(result.artist_data.name, "Test Artist")
    |
help: Replace `assertIsInstance(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertTrue`
   --> tests/test_spotify_enhancer.py:147:9
    |
146 |         self.assertIsInstance(result, SpotifyEnrichmentResult)
147 |         self.assertTrue(result.success)
    |         ^^^^^^^^^^^^^^^
148 |         self.assertEqual(result.artist_data.name, "Test Artist")
149 |         self.assertIsNone(result.error_message)
    |
help: Replace `assertTrue(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_spotify_enhancer.py:148:9
    |
146 |         self.assertIsInstance(result, SpotifyEnrichmentResult)
147 |         self.assertTrue(result.success)
148 |         self.assertEqual(result.artist_data.name, "Test Artist")
    |         ^^^^^^^^^^^^^^^^
149 |         self.assertIsNone(result.error_message)
150 |         self.assertGreater(result.processing_time, 0)
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNone`
   --> tests/test_spotify_enhancer.py:149:9
    |
147 |         self.assertTrue(result.success)
148 |         self.assertEqual(result.artist_data.name, "Test Artist")
149 |         self.assertIsNone(result.error_message)
    |         ^^^^^^^^^^^^^^^^^
150 |         self.assertGreater(result.processing_time, 0)
    |
help: Replace `assertIsNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertGreater`
   --> tests/test_spotify_enhancer.py:150:9
    |
148 |         self.assertEqual(result.artist_data.name, "Test Artist")
149 |         self.assertIsNone(result.error_message)
150 |         self.assertGreater(result.processing_time, 0)
    |         ^^^^^^^^^^^^^^^^^^
151 |
152 |     @patch.object(SpotifyEnhancer, "search_artist")
    |
help: Replace `assertGreater(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsInstance`
   --> tests/test_spotify_enhancer.py:159:9
    |
157 |         result = self.enhancer.enhance_artist("Unknown Artist")
158 |
159 |         self.assertIsInstance(result, SpotifyEnrichmentResult)
    |         ^^^^^^^^^^^^^^^^^^^^^
160 |         self.assertFalse(result.success)
161 |         self.assertIsNone(result.artist_data)
    |
help: Replace `assertIsInstance(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertFalse`
   --> tests/test_spotify_enhancer.py:160:9
    |
159 |         self.assertIsInstance(result, SpotifyEnrichmentResult)
160 |         self.assertFalse(result.success)
    |         ^^^^^^^^^^^^^^^^
161 |         self.assertIsNone(result.artist_data)
162 |         self.assertIn("Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½", result.error_message)
    |
help: Replace `assertFalse(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNone`
   --> tests/test_spotify_enhancer.py:161:9
    |
159 |         self.assertIsInstance(result, SpotifyEnrichmentResult)
160 |         self.assertFalse(result.success)
161 |         self.assertIsNone(result.artist_data)
    |         ^^^^^^^^^^^^^^^^^
162 |         self.assertIn("Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½", result.error_message)
    |
help: Replace `assertIsNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIn`
   --> tests/test_spotify_enhancer.py:162:9
    |
160 |         self.assertFalse(result.success)
161 |         self.assertIsNone(result.artist_data)
162 |         self.assertIn("Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½", result.error_message)
    |         ^^^^^^^^^^^^^
163 |
164 |     def test_create_spotify_tables(self):
    |
help: Replace `assertIn(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNotNone`
   --> tests/test_spotify_enhancer.py:174:9
    |
172 |             "SELECT name FROM sqlite_master WHERE type='table' AND name='spotify_artists'"
173 |         )
174 |         self.assertIsNotNone(cursor.fetchone())
    |         ^^^^^^^^^^^^^^^^^^^^
175 |
176 |         # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ñ‚Ñ€ÐµÐºÐ¾Ð²
    |
help: Replace `assertIsNotNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNotNone`
   --> tests/test_spotify_enhancer.py:180:9
    |
178 |             "SELECT name FROM sqlite_master WHERE type='table' AND name='spotify_tracks'"
179 |         )
180 |         self.assertIsNotNone(cursor.fetchone())
    |         ^^^^^^^^^^^^^^^^^^^^
181 |
182 |         # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ Ð°ÑƒÐ´Ð¸Ð¾-Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº
    |
help: Replace `assertIsNotNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNotNone`
   --> tests/test_spotify_enhancer.py:186:9
    |
184 |             "SELECT name FROM sqlite_master WHERE type='table' AND name='spotify_audio_features'"
185 |         )
186 |         self.assertIsNotNone(cursor.fetchone())
    |         ^^^^^^^^^^^^^^^^^^^^
187 |
188 |         conn.close()
    |
help: Replace `assertIsNotNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertIsNotNone`
   --> tests/test_spotify_enhancer.py:213:9
    |
211 |         conn.close()
212 |
213 |         self.assertIsNotNone(result)
    |         ^^^^^^^^^^^^^^^^^^^^
214 |         self.assertEqual(result[1], "Test Artist")  # artist_name
215 |         self.assertEqual(result[2], "test_artist_123")  # spotify_id
    |
help: Replace `assertIsNotNone(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_spotify_enhancer.py:214:9
    |
213 |         self.assertIsNotNone(result)
214 |         self.assertEqual(result[1], "Test Artist")  # artist_name
    |         ^^^^^^^^^^^^^^^^
215 |         self.assertEqual(result[2], "test_artist_123")  # spotify_id
216 |         self.assertEqual(result[4], 75)  # popularity
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_spotify_enhancer.py:215:9
    |
213 |         self.assertIsNotNone(result)
214 |         self.assertEqual(result[1], "Test Artist")  # artist_name
215 |         self.assertEqual(result[2], "test_artist_123")  # spotify_id
    |         ^^^^^^^^^^^^^^^^
216 |         self.assertEqual(result[4], 75)  # popularity
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertEqual`
   --> tests/test_spotify_enhancer.py:216:9
    |
214 |         self.assertEqual(result[1], "Test Artist")  # artist_name
215 |         self.assertEqual(result[2], "test_artist_123")  # spotify_id
216 |         self.assertEqual(result[4], 75)  # popularity
    |         ^^^^^^^^^^^^^^^^
217 |
218 |     def test_rate_limiting(self):
    |
help: Replace `assertEqual(...)` with `assert ...`

PT009 Use a regular `assert` instead of unittest-style `assertGreater`
   --> tests/test_spotify_enhancer.py:232:9
    |
231 |         # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ rate limiting Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
232 |         self.assertGreater(time.time() - start_time, 0.5)  # Ð”Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð±Ð¾Ð»ÑŒÑˆÐµ 0.5 ÑÐµÐº
    |         ^^^^^^^^^^^^^^^^^^
    |
help: Replace `assertGreater(...)` with `assert ...`

Found 2780 errors.
[*] 1427 fixable with the `--fix` option (298 hidden fixes can be enabled with the `--unsafe-fixes` option).

[91mâŒ FAILED: Ruff Check[0m

[96mðŸ“Œ Tips:[0m
[90m  â€¢ Fast dev: python lint.py check[0m
[90m  â€¢ With logs: python lint.py all --log[0m
[90m  â€¢ CI/CD: Always use --log flag for history[0m
