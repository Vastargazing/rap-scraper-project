#!/usr/bin/env python3
"""
üß† AI Project Analyzer ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤

–ù–ê–ó–ù–ê–ß–ï–ù–ò–ï:
- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ AST-–ø–∞—Ä—Å–∏–Ω–≥ –≤–º–µ—Å—Ç–æ –ø—Ä–∏–º–∏—Ç–∏–≤–Ω–æ–≥–æ grep
- –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –Ω–∞—Ä—É—à–µ–Ω–∏–π —Å —É—á–µ—Ç–æ–º PostgreSQL –º–∏–≥—Ä–∞—Ü–∏–∏
- –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–∑–∞–≤–∏—Å–∏–º—ã–π –ø–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
- –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- Security –∞–Ω–∞–ª–∏–∑ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –∏ –ø—Ä–æ–±–ª–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
python scripts/tools/ai_project_analyzer.py --analyze

–ó–ê–í–ò–°–ò–ú–û–°–¢–ò:
- Python 3.8+
- ast, dataclasses, pathlib

–†–ï–ó–£–õ–¨–¢–ê–¢:
- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
- –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∫–æ–¥–∞

–ê–í–¢–û–†: Vastargazing
–î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025
"""

import ast
import hashlib
import json
import pickle
import re
import subprocess
import sys
import time
from collections import defaultdict
from dataclasses import dataclass
from pathlib import Path


@dataclass
class CodeMetrics:
    file_path: str
    lines_of_code: int
    functions: list[str]
    classes: list[str]
    imports: list[str]
    complexity_score: float
    last_modified: float
    is_test: bool
    is_legacy: bool


@dataclass
class DuplicationResult:
    files: list[str]
    similarity: float
    common_functions: list[str]


class SecurityAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–±–ª–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.security_issues = []

    def find_security_issues(self, file_metrics: dict) -> list[str]:
        """–ü–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤ –∫–æ–¥–µ"""

        issues = []

        for file_path, metrics in file_metrics.items():
            try:
                with open(file_path, encoding="utf-8") as f:
                    content = f.read()

                # Hardcoded passwords
                password_patterns = [
                    r'password\s*=\s*["\'][^"\']{3,}["\']',
                    r'pwd\s*=\s*["\'][^"\']{3,}["\']',
                    r'secret\s*=\s*["\'][^"\']{8,}["\']',
                ]
                for pattern in password_patterns:
                    if re.search(pattern, content, re.IGNORECASE):
                        issues.append(f"üîí Hardcoded password in {file_path}")
                        break

                # SQL injection patterns
                sql_patterns = [
                    r'f".*SELECT.*FROM.*{',  # f-string SQL
                    r"\.format\(.*SELECT.*FROM",  # format SQL
                    r'\+.*["\'].*SELECT.*FROM',  # concatenated SQL
                ]
                for pattern in sql_patterns:
                    if re.search(pattern, content, re.IGNORECASE):
                        issues.append(f"üíâ Potential SQL injection in {file_path}")
                        break

                # Exposed API keys
                api_patterns = [
                    r'api_key\s*=\s*["\'][A-Za-z0-9]{20,}["\']',
                    r'token\s*=\s*["\'][A-Za-z0-9]{20,}["\']',
                    r'secret_key\s*=\s*["\'][A-Za-z0-9]{32,}["\']',
                ]
                for pattern in api_patterns:
                    if re.search(pattern, content):
                        issues.append(f"üîë Exposed API key in {file_path}")
                        break

                # Insecure random
                if re.search(r"import random\b", content) and re.search(
                    r"random\.(choice|randint|random)", content
                ):
                    if "password" in content.lower() or "token" in content.lower():
                        issues.append(f"üé≤ Insecure random for security in {file_path}")

                # Pickle security
                if re.search(r"pickle\.loads?\(", content):
                    issues.append(f"‚ö†Ô∏è Pickle usage (security risk) in {file_path}")

                # Eval/exec usage
                dangerous_funcs = [r"\beval\(", r"\bexec\(", r"__import__\("]
                for func in dangerous_funcs:
                    if re.search(func, content):
                        issues.append(f"‚ö° Dangerous function usage in {file_path}")
                        break

            except Exception:
                continue

        return issues


class PerformanceAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–±–ª–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.performance_issues = []

    def find_performance_issues(self, file_metrics: dict) -> list[str]:
        """–ü–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –∫–æ–¥–µ"""

        issues = []

        for file_path, metrics in file_metrics.items():
            try:
                with open(file_path, encoding="utf-8") as f:
                    content = f.read()

                tree = ast.parse(content)

                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Ü–∏–∫–ª—ã
                nested_loops = self._find_nested_loops(tree)
                if nested_loops > 2:
                    issues.append(
                        f"üîÑ Deep nested loops (depth: {nested_loops}) in {file_path}"
                    )

                # –ü–æ–∏—Å–∫ N+1 query patterns
                if self._has_n_plus_one_pattern(tree, content):
                    issues.append(f"üóÉÔ∏è Potential N+1 query pattern in {file_path}")

                # –ü–æ–∏—Å–∫ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –≤ —Ü–∏–∫–ª–∞—Ö
                inefficient_ops = self._find_inefficient_loop_operations(tree, content)
                for op in inefficient_ops:
                    issues.append(
                        f"‚ö° Inefficient operation in loop: {op} in {file_path}"
                    )

                # –ü–æ–∏—Å–∫ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –ø–∞–º—è—Ç–∏
                if self._has_memory_intensive_operations(content):
                    issues.append(f"üíæ Memory-intensive operations in {file_path}")

                # –ü–æ–∏—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ IO –≤ —Ü–∏–∫–ª–∞—Ö
                if self._has_sync_io_in_loops(tree, content):
                    issues.append(f"‚è≥ Synchronous I/O in loops in {file_path}")

            except Exception:
                continue

        return issues

    def _find_nested_loops(self, tree: ast.AST) -> int:
        """–ù–∞—Ö–æ–¥–∏—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≥–ª—É–±–∏–Ω—É –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤"""
        max_depth = 0

        def count_depth(node, current_depth=0):
            nonlocal max_depth

            if isinstance(node, (ast.For, ast.While)):
                current_depth += 1
                max_depth = max(max_depth, current_depth)

            for child in ast.iter_child_nodes(node):
                count_depth(child, current_depth)

        count_depth(tree)
        return max_depth

    def _has_n_plus_one_pattern(self, tree: ast.AST, content: str) -> bool:
        """–ò—â–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã N+1 –∑–∞–ø—Ä–æ—Å–æ–≤"""

        # –ü–æ–∏—Å–∫ —Ü–∏–∫–ª–æ–≤ —Å SQL –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤–Ω—É—Ç—Ä–∏
        for node in ast.walk(tree):
            if isinstance(node, (ast.For, ast.While)):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ SQL –∑–∞–ø—Ä–æ—Å—ã –≤ —Ç–µ–ª–µ —Ü–∏–∫–ª–∞
                for child in ast.walk(node):
                    if isinstance(child, ast.Call):
                        if isinstance(
                            child.func, ast.Attribute
                        ) and child.func.attr in ["execute", "query", "get", "filter"]:
                            return True

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –ª–∏—Ç–µ—Ä–∞–ª—ã —Å SQL
                    if isinstance(child, (ast.Str, ast.Constant)):
                        str_value = child.s if hasattr(child, "s") else str(child.value)
                        if isinstance(str_value, str) and any(
                            sql_word in str_value.upper()
                            for sql_word in ["SELECT", "INSERT", "UPDATE", "DELETE"]
                        ):
                            return True

        return False

    def _find_inefficient_loop_operations(
        self, tree: ast.AST, content: str
    ) -> list[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ —Ü–∏–∫–ª–∞—Ö"""
        issues = []

        for node in ast.walk(tree):
            if isinstance(node, (ast.For, ast.While)):
                # –ü–æ–∏—Å–∫ –æ–ø–µ—Ä–∞—Ü–∏–π —Å–æ —Å–ø–∏—Å–∫–∞–º–∏ –≤ —Ü–∏–∫–ª–∞—Ö
                for child in ast.walk(node):
                    if isinstance(child, ast.Call):
                        if isinstance(
                            child.func, ast.Attribute
                        ) and child.func.attr in ["append", "extend", "insert"]:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ list.append –≤ —Ü–∏–∫–ª–µ
                            if "append" in ast.dump(child):
                                issues.append(
                                    "list.append() in loop (consider list comprehension)"
                                )

                        # –ü–æ–∏—Å–∫ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
                        if isinstance(child.func, ast.Name) and child.func.id in [
                            "len",
                            "max",
                            "min",
                            "sum",
                        ]:
                            issues.append(
                                f"{child.func.id}() called in loop (cache result)"
                            )

        return issues

    def _has_memory_intensive_operations(self, content: str) -> bool:
        """–ò—â–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏, –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ –ø–∞–º—è—Ç—å"""

        memory_patterns = [
            r"\.read\(\)",  # –ß—Ç–µ–Ω–∏–µ –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞
            r"\.readlines\(\)",  # –ß—Ç–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫
            r"pickle\.loads?\([^)]+\)",  # Pickle –æ–ø–µ—Ä–∞—Ü–∏–∏
            r"json\.loads?\(.+\)",  # JSON –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –±–æ–ª—å—à–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            r"\[\s*.*\s*for\s+.*\s+in\s+.*\]",  # –ë–æ–ª—å—à–∏–µ list comprehensions
        ]

        for pattern in memory_patterns:
            if re.search(pattern, content):
                return True

        return False

    def _has_sync_io_in_loops(self, tree: ast.AST, content: str) -> bool:
        """–ò—â–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ I/O –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ —Ü–∏–∫–ª–∞—Ö"""

        for node in ast.walk(tree):
            if isinstance(node, (ast.For, ast.While)):
                loop_content = ast.dump(node)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ I/O –æ–ø–µ—Ä–∞—Ü–∏–π
                io_patterns = [
                    "open(",
                    "requests.",
                    "urllib.",
                    "socket.",
                    "subprocess.",
                ]
                for pattern in io_patterns:
                    if pattern in loop_content or pattern in content:
                        return True

        return False


class GitBlameAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä git blame –¥–ª—è –ø–æ–∏—Å–∫–∞ hotspots –∏ bus factor"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.author_stats = {}
        self.file_hotspots = {}

    def analyze_git_patterns(self, file_metrics: dict) -> dict:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ git –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–æ–Ω"""

        results = {
            "hotspots": [],
            "bus_factor_risks": [],
            "author_ownership": {},
            "change_frequency": {},
        }

        for file_path in file_metrics:
            try:
                # –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π
                change_count = self._get_file_change_count(file_path)
                if change_count > 50:  # –§–∞–π–ª—ã —Å —á–∞—Å—Ç—ã–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏
                    results["hotspots"].append(
                        {
                            "file": file_path,
                            "changes": change_count,
                            "reason": "High change frequency",
                        }
                    )

                # –ê–Ω–∞–ª–∏–∑ –∞–≤—Ç–æ—Ä—Å—Ç–≤–∞ (bus factor)
                authors = self._get_file_authors(file_path)
                if len(authors) == 1 and change_count > 10:
                    results["bus_factor_risks"].append(
                        {
                            "file": file_path,
                            "sole_author": list(authors.keys())[0],
                            "changes": change_count,
                            "risk_level": "HIGH" if change_count > 30 else "MEDIUM",
                        }
                    )

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–≤—Ç–æ—Ä–∞–º
                for author, lines in authors.items():
                    if author not in results["author_ownership"]:
                        results["author_ownership"][author] = {"files": 0, "lines": 0}
                    results["author_ownership"][author]["files"] += 1
                    results["author_ownership"][author]["lines"] += lines

                results["change_frequency"][file_path] = change_count

            except Exception:
                continue

        return results

    def _get_file_change_count(self, file_path: str) -> int:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ñ–∞–π–ª–∞ –∏–∑ git log"""
        try:
            result = subprocess.run(
                ["git", "log", "--oneline", "--", file_path],
                check=False,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=5,
            )

            if result.returncode == 0:
                return (
                    len(result.stdout.strip().split("\n"))
                    if result.stdout.strip()
                    else 0
                )
        except Exception:
            pass

        return 0

    def _get_file_authors(self, file_path: str) -> dict[str, int]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–≤—Ç–æ—Ä–æ–≤ –ø–æ —Ñ–∞–π–ª—É"""
        authors = {}

        try:
            result = subprocess.run(
                ["git", "blame", "--line-porcelain", file_path],
                check=False,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=10,
            )

            if result.returncode == 0:
                lines = result.stdout.split("\n")
                current_author = None

                for line in lines:
                    if line.startswith("author "):
                        current_author = line[7:]  # Remove "author " prefix
                    elif line.startswith("\t") and current_author:
                        # This is a code line
                        if current_author not in authors:
                            authors[current_author] = 0
                        authors[current_author] += 1

        except Exception:
            pass

        return authors


class HTMLReportGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä HTML –æ—Ç—á–µ—Ç–æ–≤ —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.output_dir = project_root / "results" / "html_reports"
        self.output_dir.mkdir(exist_ok=True, parents=True)

    def generate_dashboard(self, analysis_results: dict) -> Path:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π HTML dashboard"""

        try:
            import plotly.express as px
            import plotly.graph_objects as go
            from plotly.subplots import make_subplots
        except ImportError:
            print("‚ö†Ô∏è Plotly –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: pip install plotly")
            return self._generate_simple_dashboard(analysis_results)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        summary = analysis_results["summary"]
        metrics = analysis_results.get("export_data", {}).get("complexity_scores", {})

        # –°–æ–∑–¥–∞–µ–º subplot dashboard
        fig = make_subplots(
            rows=3,
            cols=2,
            subplot_titles=(
                "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤",
                "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ñ–∞–π–ª–æ–≤",
                "–ü—Ä–æ–±–ª–µ–º—ã –ø–æ —Ç–∏–ø–∞–º",
                "–¢–æ–ø-10 —Å–∞–º—ã—Ö —Å–ª–æ–∂–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤",
                "–¢—Ä–µ–Ω–¥ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞",
                "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞",
            ),
            specs=[
                [{"type": "histogram"}, {"type": "pie"}],
                [{"type": "bar"}, {"type": "bar"}],
                [{"type": "scatter"}, {"type": "table"}],
            ],
        )

        # 1. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if metrics:
            complexities = list(metrics.values())
            fig.add_trace(
                go.Histogram(
                    x=complexities,
                    name="–°–ª–æ–∂–Ω–æ—Å—Ç—å",
                    marker_color="lightblue",
                    opacity=0.7,
                ),
                row=1,
                col=1,
            )

        # 2. Pie chart —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤
        file_types = {
            "–ê–∫—Ç–∏–≤–Ω—ã–µ": summary["active_files"],
            "Legacy": summary["legacy_files"],
            "–¢–µ—Å—Ç—ã": summary["test_files"],
        }
        fig.add_trace(
            go.Pie(
                labels=list(file_types.keys()),
                values=list(file_types.values()),
                name="–¢–∏–ø—ã —Ñ–∞–π–ª–æ–≤",
            ),
            row=1,
            col=2,
        )

        # 3. Bar chart –ø—Ä–æ–±–ª–µ–º
        issues_count = {
            "–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å": len(analysis_results.get("security_issues", [])),
            "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å": len(analysis_results.get("performance_issues", [])),
            "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞": len(analysis_results.get("architecture_violations", [])),
            "–î—É–±–ª–∏–∫–∞—Ç—ã": len(analysis_results.get("duplicates_analysis", [])),
        }
        fig.add_trace(
            go.Bar(
                x=list(issues_count.keys()),
                y=list(issues_count.values()),
                name="–ü—Ä–æ–±–ª–µ–º—ã",
                marker_color=["red", "orange", "yellow", "lightcoral"],
            ),
            row=2,
            col=1,
        )

        # 4. –¢–æ–ø —Å–ª–æ–∂–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if metrics:
            top_complex = sorted(metrics.items(), key=lambda x: x[1], reverse=True)[:10]
            files = [Path(f).name for f, _ in top_complex]
            complexities = [c for _, c in top_complex]

            fig.add_trace(
                go.Bar(
                    x=complexities,
                    y=files,
                    orientation="h",
                    name="–°–ª–æ–∂–Ω–æ—Å—Ç—å",
                    marker_color="darkred",
                ),
                row=2,
                col=2,
            )

        # 5. Scatter –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ (—Å–ª–æ–∂–Ω–æ—Å—Ç—å vs —Å–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å)
        if metrics:
            coupling_scores = analysis_results.get("export_data", {}).get(
                "coupling_scores", {}
            )
            if coupling_scores:
                x_vals = [coupling_scores.get(f, 0) for f in metrics.keys()]
                y_vals = list(metrics.values())

                fig.add_trace(
                    go.Scatter(
                        x=x_vals,
                        y=y_vals,
                        mode="markers",
                        name="–§–∞–π–ª—ã",
                        marker=dict(
                            size=10, color=y_vals, colorscale="Reds", showscale=True
                        ),
                    ),
                    row=3,
                    col=1,
                )

        # 6. –¢–∞–±–ª–∏—Ü–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        stats_data = [
            ["–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤", summary["total_files"]],
            ["–ê–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤", summary["active_files"]],
            ["Legacy —Ñ–∞–π–ª–æ–≤", summary["legacy_files"]],
            ["–°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å", f"{summary['average_complexity']:.1f}"],
            ["–ú–∏–≥—Ä–∞—Ü–∏—è PostgreSQL", "‚úÖ" if summary["migration_status"] else "‚ùå"],
            ["–ü—Ä–æ–±–ª–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", len(analysis_results.get("security_issues", []))],
            [
                "–ü—Ä–æ–±–ª–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
                len(analysis_results.get("performance_issues", [])),
            ],
        ]

        fig.add_trace(
            go.Table(
                header=dict(
                    values=["–ú–µ—Ç—Ä–∏–∫–∞", "–ó–Ω–∞—á–µ–Ω–∏–µ"], fill_color="lightblue", align="left"
                ),
                cells=dict(
                    values=[
                        [row[0] for row in stats_data],
                        [row[1] for row in stats_data],
                    ],
                    fill_color="white",
                    align="left",
                ),
            ),
            row=3,
            col=2,
        )

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ layout
        fig.update_layout(
            height=1200,
            showlegend=False,
            title_text="üß† AI Project Analysis Dashboard",
            title_x=0.5,
            title_font_size=20,
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –æ—Å–µ–π
        fig.update_xaxes(title_text="–°–ª–æ–∂–Ω–æ—Å—Ç—å", row=1, col=1)
        fig.update_yaxes(title_text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤", row=1, col=1)
        fig.update_xaxes(title_text="–°–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å (imports)", row=3, col=1)
        fig.update_yaxes(title_text="–°–ª–æ–∂–Ω–æ—Å—Ç—å", row=3, col=1)

        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π HTML
        html_content = self._create_html_template(
            fig.to_html(include_plotlyjs="cdn"), analysis_results
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        report_file = self.output_dir / "project_analysis_dashboard.html"
        report_file.write_text(html_content, encoding="utf-8")

        return report_file

    def _generate_simple_dashboard(self, analysis_results: dict) -> Path:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Å—Ç–æ–π HTML –æ—Ç—á–µ—Ç –±–µ–∑ Plotly"""

        summary = analysis_results["summary"]

        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>AI Project Analysis Report</title>
            <meta charset="utf-8">
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
                .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; }}
                .header {{ text-align: center; color: #333; margin-bottom: 30px; }}
                .metric-card {{ 
                    display: inline-block; 
                    margin: 10px; 
                    padding: 20px; 
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    color: white; 
                    border-radius: 10px; 
                    min-width: 200px;
                    text-align: center;
                }}
                .metric-value {{ font-size: 2em; font-weight: bold; }}
                .metric-label {{ font-size: 0.9em; opacity: 0.9; }}
                .issues-section {{ margin: 30px 0; }}
                .issue-type {{ 
                    margin: 15px 0; 
                    padding: 15px; 
                    border-left: 5px solid #ff6b6b; 
                    background: #fff5f5; 
                }}
                .recommendations {{ 
                    background: #f0f8ff; 
                    padding: 20px; 
                    border-radius: 10px; 
                    border-left: 5px solid #4dabf7; 
                }}
                ul {{ padding-left: 20px; }}
                li {{ margin: 5px 0; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>üß† AI Project Analysis Report</h1>
                    <p>–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI</p>
                </div>
                
                <div class="metrics">
                    <div class="metric-card">
                        <div class="metric-value">{summary["total_files"]}</div>
                        <div class="metric-label">üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">{summary["active_files"]}</div>
                        <div class="metric-label">üî• –ê–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">{summary["legacy_files"]}</div>
                        <div class="metric-label">üóÇÔ∏è Legacy —Ñ–∞–π–ª–æ–≤</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">{summary["average_complexity"]:.1f}</div>
                        <div class="metric-label">üìä –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å</div>
                    </div>
                </div>
                
                <div class="issues-section">
                    <h2>üîç –í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã</h2>
                    
                    <div class="issue-type">
                        <h3>üîí –ü—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {len(analysis_results.get("security_issues", []))}</h3>
                        <ul>
                            {"".join(f"<li>{issue}</li>" for issue in analysis_results.get("security_issues", [])[:5])}
                        </ul>
                    </div>
                    
                    <div class="issue-type">
                        <h3>‚ö° –ü—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {len(analysis_results.get("performance_issues", []))}</h3>
                        <ul>
                            {"".join(f"<li>{issue}</li>" for issue in analysis_results.get("performance_issues", [])[:5])}
                        </ul>
                    </div>
                    
                    <div class="issue-type">
                        <h3>üèóÔ∏è –ù–∞—Ä—É—à–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {len(analysis_results.get("architecture_violations", []))}</h3>
                        <ul>
                            {"".join(f"<li>{violation}</li>" for violation in analysis_results.get("architecture_violations", [])[:5])}
                        </ul>
                    </div>
                </div>
                
                <div class="recommendations">
                    <h2>üí° AI –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h2>
                    <ul>
                        {"".join(f"<li>{rec}</li>" for rec in analysis_results.get("ai_recommendations", []))}
                    </ul>
                </div>
                
                <div style="text-align: center; margin-top: 30px; color: #666;">
                    <p>–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω AI Project Analyzer</p>
                    <p>–î–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install plotly</p>
                </div>
            </div>
        </body>
        </html>
        """

        report_file = self.output_dir / "project_analysis_simple.html"
        report_file.write_text(html_content, encoding="utf-8")

        return report_file

    def _create_html_template(self, plotly_html: str, analysis_results: dict) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π HTML —à–∞–±–ª–æ–Ω —Å Plotly –≥—Ä–∞—Ñ–∏–∫–∞–º–∏"""

        return f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>AI Project Analysis Dashboard</title>
            <meta charset="utf-8">
            <style>
                body {{ 
                    font-family: Arial, sans-serif; 
                    margin: 0; 
                    padding: 20px; 
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                }}
                .container {{ 
                    max-width: 1400px; 
                    margin: 0 auto; 
                    background: white; 
                    border-radius: 15px; 
                    overflow: hidden;
                    box-shadow: 0 10px 30px rgba(0,0,0,0.3);
                }}
                .header {{ 
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    color: white; 
                    padding: 30px; 
                    text-align: center; 
                }}
                .content {{ padding: 20px; }}
                .summary-cards {{ 
                    display: flex; 
                    justify-content: space-around; 
                    margin: 20px 0; 
                    flex-wrap: wrap;
                }}
                .card {{ 
                    background: #f8f9fa; 
                    padding: 20px; 
                    border-radius: 10px; 
                    text-align: center; 
                    margin: 10px;
                    min-width: 150px;
                    border-left: 5px solid #667eea;
                }}
                .card-value {{ font-size: 2em; font-weight: bold; color: #667eea; }}
                .card-label {{ color: #666; margin-top: 5px; }}
                .issues-grid {{ 
                    display: grid; 
                    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); 
                    gap: 20px; 
                    margin: 30px 0; 
                }}
                .issue-card {{ 
                    background: #fff; 
                    border: 1px solid #eee; 
                    border-radius: 10px; 
                    padding: 20px;
                    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                }}
                .issue-title {{ 
                    font-weight: bold; 
                    margin-bottom: 15px; 
                    font-size: 1.1em;
                }}
                .issue-list {{ 
                    max-height: 200px; 
                    overflow-y: auto; 
                }}
                .issue-list li {{ 
                    margin: 8px 0; 
                    padding: 5px; 
                    background: #f8f9fa; 
                    border-radius: 5px;
                    font-size: 0.9em;
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>üß† AI Project Analysis Dashboard</h1>
                    <p>–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏</p>
                </div>
                
                <div class="content">
                    <div class="summary-cards">
                        <div class="card">
                            <div class="card-value">{analysis_results["summary"]["total_files"]}</div>
                            <div class="card-label">üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤</div>
                        </div>
                        <div class="card">
                            <div class="card-value">{analysis_results["summary"]["active_files"]}</div>
                            <div class="card-label">üî• –ê–∫—Ç–∏–≤–Ω—ã—Ö</div>
                        </div>
                        <div class="card">
                            <div class="card-value">{len(analysis_results.get("security_issues", []))}</div>
                            <div class="card-label">üîí –ü—Ä–æ–±–ª–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏</div>
                        </div>
                        <div class="card">
                            <div class="card-value">{len(analysis_results.get("performance_issues", []))}</div>
                            <div class="card-label">‚ö° –ü—Ä–æ–±–ª–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</div>
                        </div>
                    </div>
                    
                    {plotly_html}
                    
                    <div class="issues-grid">
                        <div class="issue-card">
                            <div class="issue-title">üîí –ü—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏</div>
                            <ul class="issue-list">
                                {"".join(f"<li>{issue}</li>" for issue in analysis_results.get("security_issues", [])[:10])}
                            </ul>
                        </div>
                        
                        <div class="issue-card">
                            <div class="issue-title">‚ö° –ü—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</div>
                            <ul class="issue-list">
                                {"".join(f"<li>{issue}</li>" for issue in analysis_results.get("performance_issues", [])[:10])}
                            </ul>
                        </div>
                        
                        <div class="issue-card">
                            <div class="issue-title">üèóÔ∏è –ù–∞—Ä—É—à–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã</div>
                            <ul class="issue-list">
                                {"".join(f"<li>{violation}</li>" for violation in analysis_results.get("architecture_violations", [])[:10])}
                            </ul>
                        </div>
                        
                        <div class="issue-card">
                            <div class="issue-title">üí° AI –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</div>
                            <ul class="issue-list">
                                {"".join(f"<li>{rec}</li>" for rec in analysis_results.get("ai_recommendations", []))}
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </body>
        </html>
        """


class ProjectIntelligence:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ results/ —Å–æ–≥–ª–∞—Å–Ω–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞
        self.results_dir = self.project_root / "results"
        self.results_dir.mkdir(exist_ok=True)

        self.metrics = {}
        self.duplicates = []
        self.unused_files = set()
        self.architecture_violations = []

        # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.cache_file = self.results_dir / "analysis_cache.pkl"
        self.cache_duration = 3600  # 1 —á–∞—Å

        # –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
        self.security_analyzer = SecurityAnalyzer(self.project_root)
        self.performance_analyzer = PerformanceAnalyzer(self.project_root)
        self.git_analyzer = GitBlameAnalyzer(self.project_root)
        self.html_generator = HTMLReportGenerator(self.project_root)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Å–ª–æ–∏ –ø—Ä–æ–µ–∫—Ç–∞
        self.architecture_layers = {
            "database": ["src/database/", "postgres_adapter.py"],
            "analyzers": ["src/analyzers/"],
            "cli": ["src/cli/", "main.py"],
            "models": ["src/models/"],
            "scripts": ["scripts/"],
            "legacy": ["scripts/archive/", "_sqlite.py", "data_backup_"],
            "tests": ["tests/", "test_"],
        }

    def analyze_project(self) -> dict:
        """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
        print("üîç –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–µ–∫—Ç–∞...")

        # 1. –°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –ø–æ —Ñ–∞–π–ª–∞–º
        self._collect_file_metrics()

        # 2. –ü–æ–∏—Å–∫ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        self._find_semantic_duplicates()

        # 3. –ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
        self._find_unused_files()

        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –Ω–∞—Ä—É—à–µ–Ω–∏–π
        self._check_architecture_violations()

        # 5. –ê–Ω–∞–ª–∏–∑ PostgreSQL migration status
        self._analyze_postgresql_migration()

        # 6. –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        security_issues = self.security_analyzer.find_security_issues(self.metrics)

        # 7. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        performance_issues = self.performance_analyzer.find_performance_issues(
            self.metrics
        )

        # 8. Git blame –∞–Ω–∞–ª–∏–∑
        git_patterns = self.git_analyzer.analyze_git_patterns(self.metrics)

        return self._generate_report(security_issues, performance_issues, git_patterns)

    def analyze_with_cache(self) -> dict:
        """–ê–Ω–∞–ª–∏–∑ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        if self.cache_file.exists():
            try:
                with open(self.cache_file, "rb") as f:
                    cached_data = pickle.load(f)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∫–µ—à–∞
                if time.time() - cached_data["timestamp"] < self.cache_duration:
                    print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
                    return cached_data["results"]
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–µ—à–∞: {e}")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
        print("üîÑ –í—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞...")
        results = self.analyze_project()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
        try:
            with open(self.cache_file, "wb") as f:
                pickle.dump({"timestamp": time.time(), "results": results}, f)
            print("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∫–µ—à–∏—Ä–æ–≤–∞–Ω—ã")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞: {e}")

        return results

    def export_for_context_manager(self) -> dict:
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è AI Context Manager"""

        return {
            "complexity_scores": {
                str(path): metrics.complexity_score
                for path, metrics in self.metrics.items()
            },
            "coupling_scores": {
                str(path): len(metrics.imports)
                for path, metrics in self.metrics.items()
            },
            "duplicates": [
                {
                    "similarity": dup.similarity,
                    "files": [str(f) for f in dup.files],
                    "common_functions": dup.common_functions,
                }
                for dup in self.duplicates
            ],
            "unused_files": [str(f) for f in self.unused_files],
            "architecture_violations": self.architecture_violations,
            "layers": {
                layer: [str(f) for f in files if isinstance(f, Path)]
                for layer, files in self.architecture_layers.items()
            },
        }

    def _collect_file_metrics(self):
        """–°–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –≤—Å–µ–º Python —Ñ–∞–π–ª–∞–º"""
        for py_file in self.project_root.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue

            try:
                with open(py_file, encoding="utf-8") as f:
                    content = f.read()

                tree = ast.parse(content)

                metrics = CodeMetrics(
                    file_path=str(py_file),
                    lines_of_code=len(content.splitlines()),
                    functions=self._extract_functions(tree),
                    classes=self._extract_classes(tree),
                    imports=self._extract_imports(tree),
                    complexity_score=self._calculate_complexity(tree),
                    last_modified=py_file.stat().st_mtime,
                    is_test="test" in str(py_file).lower(),
                    is_legacy=self._is_legacy_file(py_file),
                )

                self.metrics[str(py_file)] = metrics

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {py_file}: {e}")

    def _find_semantic_duplicates(self):
        """–ü–æ–∏—Å–∫ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ AST"""
        function_hashes = defaultdict(list)

        for file_path, metrics in self.metrics.items():
            for func in metrics.functions:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö–µ—à –æ—Ç –∏–º–µ–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                func_hash = hashlib.md5(func.encode()).hexdigest()[:8]
                function_hashes[func_hash].append((file_path, func))

        # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å –ø–æ—Ö–æ–∂–∏–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏
        for func_hash, file_func_pairs in function_hashes.items():
            if len(file_func_pairs) > 1:
                files = [pair[0] for pair in file_func_pairs]
                functions = [pair[1] for pair in file_func_pairs]

                if len(set(files)) > 1:  # –†–∞–∑–Ω—ã–µ —Ñ–∞–π–ª—ã
                    similarity = len(functions) / max(
                        len(self.metrics[f].functions) for f in files
                    )
                    if similarity > 0.3:  # –ü–æ—Ä–æ–≥ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏
                        self.duplicates.append(
                            DuplicationResult(
                                files=files,
                                similarity=similarity,
                                common_functions=functions,
                            )
                        )

    def _find_unused_files(self):
        """–ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã
        all_imports = set()
        for metrics in self.metrics.values():
            all_imports.update(metrics.imports)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
        for file_path in self.metrics.keys():
            file_stem = Path(file_path).stem
            if file_stem not in all_imports and not self._is_entry_point(file_path):
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ grep
                if not self._is_referenced_in_project(file_stem):
                    self.unused_files.add(file_path)

    def _check_architecture_violations(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
        for file_path, metrics in self.metrics.items():
            layer = self._determine_layer(file_path)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Ä—É—à–µ–Ω–∏—è —Å–ª–æ–µ–≤
            for imp in metrics.imports:
                if layer == "models" and "database" in imp:
                    if not any(
                        allowed in file_path for allowed in ["adapter", "interface"]
                    ):
                        self.architecture_violations.append(
                            f"üèóÔ∏è Models layer accessing database directly: {file_path} -> {imp}"
                        )

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ legacy –∫–æ–¥–∞ –≤ –Ω–æ–≤—ã—Ö –º–æ–¥—É–ª—è—Ö
                if "sqlite" in imp.lower() and not self._is_legacy_file(
                    Path(file_path)
                ):
                    self.architecture_violations.append(
                        f"üóÇÔ∏è New module using legacy SQLite: {file_path} -> {imp}"
                    )

    def _analyze_postgresql_migration(self):
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç—É—Å–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞ PostgreSQL"""
        postgres_files = []
        sqlite_files = []

        for file_path, metrics in self.metrics.items():
            if any("postgres" in imp.lower() for imp in metrics.imports):
                postgres_files.append(file_path)
            if any("sqlite" in imp.lower() for imp in metrics.imports):
                sqlite_files.append(file_path)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –º–∏–≥—Ä–∞—Ü–∏–∏
        migration_progress = (
            len(postgres_files) / (len(postgres_files) + len(sqlite_files))
            if (len(postgres_files) + len(sqlite_files)) > 0
            else 0
        )

        if migration_progress < 0.8:
            self.architecture_violations.append(
                f"üîÑ PostgreSQL migration incomplete: {migration_progress:.1%} migrated"
            )

    def _generate_report(
        self,
        security_issues: list[str] | None = None,
        performance_issues: list[str] | None = None,
        git_patterns: dict | None = None,
    ) -> dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç"""

        # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_files = len(self.metrics)
        legacy_files = sum(1 for m in self.metrics.values() if m.is_legacy)
        test_files = sum(1 for m in self.metrics.values() if m.is_test)

        return {
            "summary": {
                "total_files": total_files,
                "legacy_files": legacy_files,
                "test_files": test_files,
                "active_files": total_files - legacy_files,
                "average_complexity": sum(
                    m.complexity_score for m in self.metrics.values()
                )
                / total_files,
                "migration_status": len(
                    [v for v in self.architecture_violations if "PostgreSQL" in v]
                )
                == 0,
            },
            "duplicates_analysis": [
                {
                    "files": d.files,
                    "similarity": d.similarity,
                    "functions": d.common_functions,
                }
                for d in self.duplicates
            ],
            "unused_files": list(self.unused_files),
            "architecture_violations": self.architecture_violations,
            "security_issues": security_issues or [],
            "performance_issues": performance_issues or [],
            "git_patterns": git_patterns or {},
            "ai_recommendations": self._generate_ai_recommendations(),
            "export_data": self.export_for_context_manager(),
        }

    def _generate_ai_recommendations(self) -> list[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        recommendations = []

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        if len(self.duplicates) > 5:
            recommendations.append(
                "üîÑ –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥: –ú–Ω–æ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∫–æ–¥–∞ - —Å–æ–∑–¥–∞–π—Ç–µ –æ–±—â–∏–µ –º–æ–¥—É–ª–∏"
            )

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        high_complexity = [m for m in self.metrics.values() if m.complexity_score > 100]
        if len(high_complexity) > 10:
            recommendations.append(
                "üìâ –£–ø—Ä–æ—â–µ–Ω–∏–µ: –ú–Ω–æ–≥–æ —Å–ª–æ–∂–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ - —Ä–∞–∑–±–µ–π—Ç–µ –Ω–∞ –º–µ–Ω—å—à–∏–µ –º–æ–¥—É–ª–∏"
            )

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º legacy
        legacy_ratio = sum(1 for m in self.metrics.values() if m.is_legacy) / len(
            self.metrics
        )
        if legacy_ratio > 0.3:
            recommendations.append(
                "üóÇÔ∏è –ú–∏–≥—Ä–∞—Ü–∏—è: –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç legacy –∫–æ–¥–∞ - –ø–ª–∞–Ω–∏—Ä—É–π—Ç–µ –º–∏–≥—Ä–∞—Ü–∏—é"
            )

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ—Å—Ç—ã
        test_ratio = sum(1 for m in self.metrics.values() if m.is_test) / len(
            self.metrics
        )
        if test_ratio < 0.2:
            recommendations.append(
                "üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: –ù–∏–∑–∫–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏ - –¥–æ–±–∞–≤—å—Ç–µ unit —Ç–µ—Å—Ç—ã"
            )

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
        if len(self.architecture_violations) > 5:
            recommendations.append(
                "üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –ú–Ω–æ–≥–æ –Ω–∞—Ä—É—à–µ–Ω–∏–π - –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∏—Ç–µ —Å–ª–æ–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"
            )

        return recommendations

    def _should_skip_file(self, file_path: Path) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ñ–∞–π–ª"""
        skip_patterns = ["__pycache__", ".git", ".venv", "venv", "env", ".pytest_cache"]
        return any(pattern in str(file_path) for pattern in skip_patterns)

    def _extract_functions(self, tree: ast.AST) -> list[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ AST"""
        functions = []
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions.append(node.name)
        return functions

    def _extract_classes(self, tree: ast.AST) -> list[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤ –∏–∑ AST"""
        classes = []
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                classes.append(node.name)
        return classes

    def _extract_imports(self, tree: ast.AST) -> list[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–ø–æ—Ä—Ç—ã –∏–∑ AST"""
        imports = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)
        return imports

    def _calculate_complexity(self, tree: ast.AST) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ü–∏–∫–ª–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å"""
        complexity = 1  # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å

        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.For, ast.While, ast.With)) or isinstance(
                node, ast.ExceptHandler
            ):
                complexity += 1

        return complexity

    def _is_legacy_file(self, file_path: Path) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª legacy"""
        legacy_indicators = ["sqlite", "backup", "archive", "old", "legacy"]
        return any(
            indicator in str(file_path).lower() for indicator in legacy_indicators
        )

    def _determine_layer(self, file_path: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —Å–ª–æ–π —Ñ–∞–π–ª–∞"""
        for layer, patterns in self.architecture_layers.items():
            if any(pattern in file_path for pattern in patterns):
                return layer
        return "other"

    def _is_entry_point(self, file_path: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —Ç–æ—á–∫–æ–π –≤—Ö–æ–¥–∞"""
        entry_points = ["main.py", "app.py", "__init__.py", "cli.py"]
        return any(ep in file_path for ep in entry_points)

    def _is_referenced_in_project(self, file_stem: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å—Å—ã–ª–∞–µ—Ç—Å—è –ª–∏ –ø—Ä–æ–µ–∫—Ç –Ω–∞ —Ñ–∞–π–ª"""
        try:
            result = subprocess.run(
                ["grep", "-r", file_stem, str(self.project_root)],
                check=False,
                capture_output=True,
                text=True,
                timeout=10,
            )
            return len(result.stdout.strip()) > 0
        except:
            return True  # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —Å—á–∏—Ç–∞–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è CLI"""
    if "--analyze" in sys.argv:
        analyzer = ProjectIntelligence()
        results = analyzer.analyze_with_cache()

        print("\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê:")
        print("=" * 50)

        summary = results["summary"]
        print(f"üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {summary['total_files']}")
        print(f"üî• –ê–∫—Ç–∏–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {summary['active_files']}")
        print(f"üóÇÔ∏è Legacy —Ñ–∞–π–ª–æ–≤: {summary['legacy_files']}")
        print(f"üß™ –¢–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: {summary['test_files']}")
        print(f"üìä –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {summary['average_complexity']:.1f}")
        print(
            f"üîÑ PostgreSQL –º–∏–≥—Ä–∞—Ü–∏—è: {'‚úÖ' if summary['migration_status'] else '‚ùå'}"
        )

        if results["duplicates_analysis"]:
            print(f"\nüîÑ –î—É–±–ª–∏–∫–∞—Ç—ã –∫–æ–¥–∞: {len(results['duplicates_analysis'])}")
            for dup in results["duplicates_analysis"][:3]:
                print(
                    f"  ‚Ä¢ {dup['similarity']:.1%} —Å—Ö–æ–∂–µ—Å—Ç–∏: {', '.join(dup['files'][:2])}"
                )

        if results["security_issues"]:
            print(f"\nüîí –ü—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {len(results['security_issues'])}")
            for issue in results["security_issues"][:5]:
                print(f"  ‚Ä¢ {issue}")

        if results["performance_issues"]:
            print(
                f"\n‚ö° –ü—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {len(results['performance_issues'])}"
            )
            for issue in results["performance_issues"][:5]:
                print(f"  ‚Ä¢ {issue}")

        if results["git_patterns"] and results["git_patterns"].get("hotspots"):
            print(f"\nüî• Git Hotspots: {len(results['git_patterns']['hotspots'])}")
            for hotspot in results["git_patterns"]["hotspots"][:3]:
                print(f"  ‚Ä¢ {hotspot['changes']} –∏–∑–º–µ–Ω–µ–Ω–∏–π: {hotspot['file']}")

        if results["git_patterns"] and results["git_patterns"].get("bus_factor_risks"):
            print(
                f"\nüë§ Bus Factor —Ä–∏—Å–∫–∏: {len(results['git_patterns']['bus_factor_risks'])}"
            )
            for risk in results["git_patterns"]["bus_factor_risks"][:3]:
                print(
                    f"  ‚Ä¢ {risk['risk_level']}: {risk['file']} (–∞–≤—Ç–æ—Ä: {risk['sole_author']})"
                )

        if results["architecture_violations"]:
            print(
                f"\nüèóÔ∏è –ù–∞—Ä—É—à–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {len(results['architecture_violations'])}"
            )
            for violation in results["architecture_violations"][:3]:
                print(f"  ‚Ä¢ {violation}")

        if results["ai_recommendations"]:
            print("\nüí° AI –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
            for rec in results["ai_recommendations"]:
                print(f"  ‚Ä¢ {rec}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        output_file = Path("results") / "project_analysis_enhanced.json"
        output_file.parent.mkdir(exist_ok=True)
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML –æ—Ç—á–µ—Ç
        print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML dashboard...")
        html_report = analyzer.html_generator.generate_dashboard(results)
        print(f"üìä HTML –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {html_report}")

    elif "--html" in sys.argv:
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ HTML –æ—Ç—á–µ—Ç–∞ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        json_file = Path("results") / "project_analysis_enhanced.json"
        if json_file.exists():
            with open(json_file, encoding="utf-8") as f:
                results = json.load(f)

            analyzer = ProjectIntelligence()
            print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML dashboard –∏–∑ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            html_report = analyzer.html_generator.generate_dashboard(results)
            print(f"üìä HTML –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {html_report}")
        else:
            print(
                "‚ùå –§–∞–π–ª results/project_analysis_enhanced.json –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ --analyze"
            )

    else:
        print("üéØ AI Project Analyzer - Enterprise Grade Code Intelligence")
        print("=" * 60)
        print("üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:")
        print("  python ai_project_analyzer.py --analyze     # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞")
        print("  python ai_project_analyzer.py --html        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á–µ—Ç–∞")
        print("\nüí° –î–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å ai_context_manager.py –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print("  analyzer = ProjectIntelligence()")
        print("  results = analyzer.export_for_context_manager()")
        print("\nüöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
        print("  ‚Ä¢ ÔøΩ –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (SQL injection, –ø–∞—Ä–æ–ª–∏, API –∫–ª—é—á–∏)")
        print("  ‚Ä¢ ‚ö° –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (—Ü–∏–∫–ª—ã, N+1 –∑–∞–ø—Ä–æ—Å—ã)")
        print("  ‚Ä¢ üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∫–æ–¥–∞")
        print("  ‚Ä¢ üèóÔ∏è –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π")
        print("  ‚Ä¢ ÔøΩ HTML dashboard —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏")
        print("  ‚Ä¢ üíæ –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        print("  ‚Ä¢ ÔøΩ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å AI Context Manager")


if __name__ == "__main__":
    main()
