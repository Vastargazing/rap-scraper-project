#!/usr/bin/env python3
"""
üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –º–∞—Å—Å–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ Qwen
"""

import sys
import os
import sqlite3
from datetime import datetime, timedelta
import time

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ path
project_root = os.path.dirname(os.path.dirname(__file__))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'src'))

def monitor_qwen_progress():
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∞–Ω–∞–ª–∏–∑–∞ Qwen"""
    
    db_path = os.path.join(project_root, 'data', 'rap_lyrics.db')
    
    if not os.path.exists(db_path):
        print("‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return
    
    print("üìä Qwen Analysis Progress Monitor")
    print("=" * 50)
    
    conn = sqlite3.connect(db_path)
    
    try:
        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
        total_query = "SELECT COUNT(*) FROM songs WHERE lyrics IS NOT NULL AND lyrics != ''"
        total_records = conn.execute(total_query).fetchone()[0]
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π (–ª—é–±–æ–π –º–æ–¥–µ–ª—å—é)
        all_analyzed_query = "SELECT COUNT(*) FROM ai_analysis"
        all_analyzed = conn.execute(all_analyzed_query).fetchone()[0]
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π Qwen
        qwen_analyzed_query = "SELECT COUNT(*) FROM ai_analysis WHERE model_version LIKE '%qwen%'"
        qwen_analyzed = conn.execute(qwen_analyzed_query).fetchone()[0]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º
        models_query = """
        SELECT model_version, COUNT(*) as count
        FROM ai_analysis 
        GROUP BY model_version 
        ORDER BY count DESC
        """
        models_stats = conn.execute(models_query).fetchall()
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∞–Ω–∞–ª–∏–∑—ã Qwen
        recent_query = """
        SELECT analysis_date, COUNT(*) as count
        FROM ai_analysis 
        WHERE model_version LIKE '%qwen%' 
        AND analysis_date >= datetime('now', '-1 hour')
        GROUP BY datetime(analysis_date, 'localtime')
        ORDER BY analysis_date DESC
        LIMIT 10
        """
        recent_analyses = conn.execute(recent_query).fetchall()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è Qwen
        time_stats_query = """
        SELECT 
            MIN(analysis_date) as first_analysis,
            MAX(analysis_date) as last_analysis,
            COUNT(*) as total_analyzed
        FROM ai_analysis 
        WHERE model_version LIKE '%qwen%'
        """
        time_stats = conn.execute(time_stats_query).fetchone()
        
        # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        qwen_progress_percent = (qwen_analyzed / total_records) * 100 if total_records > 0 else 0
        all_progress_percent = (all_analyzed / total_records) * 100 if total_records > 0 else 0
        remaining_total = total_records - all_analyzed
        remaining_qwen = total_records - qwen_analyzed
        
        print(f"üìà –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"  üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑–µ: {total_records:,}")
        print(f"  ‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –≤—Å–µ–º–∏ –º–æ–¥–µ–ª—è–º–∏: {all_analyzed:,} ({all_progress_percent:.1f}%)")
        print(f"  ü§ñ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ Qwen: {qwen_analyzed:,} ({qwen_progress_percent:.2f}%)")
        print(f"  ‚è≥ –û—Å—Ç–∞–ª–æ—Å—å –¥–ª—è –ª—é–±–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {remaining_total:,}")
        print(f"  üéØ –û—Å—Ç–∞–ª–æ—Å—å –¥–ª—è Qwen –∞–Ω–∞–ª–∏–∑–∞: {remaining_qwen:,}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º
        if models_stats:
            print(f"\nü§ñ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º:")
            for model, count in models_stats:
                percent = (count / all_analyzed) * 100 if all_analyzed > 0 else 0
                print(f"  {model}: {count:,} ({percent:.1f}%)")
        
        if time_stats[0] and qwen_analyzed > 0:  # –ï—Å–ª–∏ –µ—Å—Ç—å Qwen –∞–Ω–∞–ª–∏–∑—ã
            first_analysis = datetime.fromisoformat(time_stats[0])
            last_analysis = datetime.fromisoformat(time_stats[1])
            duration = last_analysis - first_analysis
            
            if duration.total_seconds() > 0:
                rate = qwen_analyzed / (duration.total_seconds() / 3600)  # –∑–∞–ø–∏—Å–µ–π –≤ —á–∞—Å
                estimated_remaining_hours = remaining_qwen / rate if rate > 0 else float('inf')
                
                print(f"\n‚è±Ô∏è  Qwen –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                print(f"  üöÄ –ü–µ—Ä–≤—ã–π –∞–Ω–∞–ª–∏–∑: {first_analysis.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"  üèÅ –ü–æ—Å–ª–µ–¥–Ω–∏–π –∞–Ω–∞–ª–∏–∑: {last_analysis.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"  ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {rate:.1f} –∑–∞–ø–∏—Å–µ–π/—á–∞—Å")
                
                if estimated_remaining_hours < float('inf'):
                    if estimated_remaining_hours < 24:
                        print(f"  ‚è∞ –û—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è: {estimated_remaining_hours:.1f} —á–∞—Å–æ–≤")
                    else:
                        print(f"  ‚è∞ –û—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è: {estimated_remaining_hours/24:.1f} –¥–Ω–µ–π")
        
        # –ù–µ–¥–∞–≤–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        if recent_analyses:
            print(f"\nüïê –ù–µ–¥–∞–≤–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (–ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å):")
            for timestamp, count in recent_analyses:
                dt = datetime.fromisoformat(timestamp)
                print(f"  üìÖ {dt.strftime('%H:%M:%S')}: {count} –∑–∞–ø–∏—Å–µ–π")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è–º
        sentiment_query = """
        SELECT mood, COUNT(*) as count
        FROM ai_analysis 
        WHERE model_version LIKE '%qwen%'
        GROUP BY mood
        ORDER BY count DESC
        """
        sentiments = conn.execute(sentiment_query).fetchall()
        
        if sentiments:
            print(f"\nüòä Qwen —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è–º:")
            for sentiment, count in sentiments:
                percent = (count / qwen_analyzed) * 100 if qwen_analyzed > 0 else 0
                print(f"  {sentiment}: {count} ({percent:.1f}%)")
        
        print(f"\nüîÑ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    finally:
        conn.close()

def monitor_live(interval=60):
    """–ñ–∏–≤–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –∫–∞–∂–¥—ã–µ N —Å–µ–∫—É–Ω–¥"""
    print("üîÑ –ó–∞–ø—É—Å–∫ –∂–∏–≤–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏)")
    print(f"‚è±Ô∏è  –ò–Ω—Ç–µ—Ä–≤–∞–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {interval} —Å–µ–∫—É–Ω–¥")
    print("-" * 50)
    
    try:
        while True:
            os.system('cls' if os.name == 'nt' else 'clear')  # –û—á–∏—Å—Ç–∫–∞ —ç–∫—Ä–∞–Ω–∞
            monitor_qwen_progress()
            time.sleep(interval)
    except KeyboardInterrupt:
        print("\nüëã –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∞–Ω–∞–ª–∏–∑–∞ Qwen")
    parser.add_argument("--live", action="store_true", help="–ñ–∏–≤–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
    parser.add_argument("--interval", type=int, default=60, help="–ò–Ω—Ç–µ—Ä–≤–∞–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö")
    
    args = parser.parse_args()
    
    if args.live:
        monitor_live(args.interval)
    else:
        monitor_qwen_progress()
