"""
ü§ñ –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤ –ø–µ—Å–µ–Ω —Å Safety & Hallucination Detection

–ù–ê–ó–ù–ê–ß–ï–ù–ò–ï:
- –ì–ª—É–±–æ–∫–∏–π AI-–∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ –ø–µ—Å–µ–Ω —Å –ø–æ–º–æ—â—å—é –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∂–∞–Ω—Ä–∞, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è, –∫–∞—á–µ—Å—Ç–≤–∞, —Ç–µ–º–∞—Ç–∏–∫–∏
- –î–µ—Ç–µ–∫—Ü–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ AI
- –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å —Ä–µ—à–µ–Ω–∏–π —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–±–ª–∞—á–Ω—ã—Ö –∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö API

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
- Ollama (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç): –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏, –±–µ—Å–ø–ª–∞—Ç–Ω–æ
- Google Gemma (fallback): –æ–±–ª–∞—á–Ω–æ–µ API
- Mock Provider (—Ä–µ–∑–µ—Ä–≤): –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- Safety Layer: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- Interpretability: –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏–π AI

–ó–ê–í–ò–°–ò–ú–û–°–¢–ò:
- Python 3.8+
- ollama (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)
- google-generativeai (–¥–ª—è Gemma API)
- pydantic (–¥–ª—è –º–æ–¥–µ–ª–µ–π –¥–∞–Ω–Ω—ã—Ö)
- requests (–¥–ª—è HTTP –∑–∞–ø—Ä–æ—Å–æ–≤)
- sqlite3 (–¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ë–î)

–†–ï–ó–£–õ–¨–¢–ê–¢:
- –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑: –∂–∞–Ω—Ä, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ, —ç–Ω–µ—Ä–≥–∏—è, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å, –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å, –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª
- –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏: –¥–µ—Ç–µ–∫—Ü–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π, –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
- –û–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏–π: –ø–æ—á–µ–º—É AI –ø—Ä–∏–Ω—è–ª —Ç–æ –∏–ª–∏ –∏–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏

–û–°–û–ë–ï–ù–ù–û–°–¢–ò:
- Multi-provider fallback —Å–∏—Å—Ç–µ–º–∞
- Safety & Hallucination Detection
- Interpretability & Explainability
- Batch processing —Å progress tracking
- Cost optimization (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–µ)

–ê–í–¢–û–†: AI Assistant
–î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025
"""

import json
import logging
import os
import re
import sqlite3
import time
from datetime import datetime

import requests
from dotenv import load_dotenv
from pydantic import BaseModel

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("ai_analysis.log", encoding="utf-8"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π –¥–∞–Ω–Ω—ã—Ö
from ..models.models import LyricsAnalysis, QualityMetrics, SongMetadata


class SafetyValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ AI –∞–Ω–∞–ª–∏–∑–∞ –∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π"""

    def __init__(self):
        # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–µ–º–∞—Ç–∏–∫ (English-focused)
        self.theme_keywords = {
            "money": [
                "cash",
                "money",
                "dollars",
                "bands",
                "racks",
                "bread",
                "paper",
                "coins",
                "wealth",
                "riches",
                "bank",
                "rich",
                "fortune",
            ],
            "relationships": [
                "love",
                "girl",
                "boy",
                "girlfriend",
                "boyfriend",
                "wife",
                "husband",
                "family",
                "bae",
                "baby",
                "relationship",
                "romance",
            ],
            "street_life": [
                "street",
                "block",
                "neighborhood",
                "ghetto",
                "projects",
                "corners",
                "trap",
                "streets",
                "hood",
                "city",
                "urban",
            ],
            "success": [
                "success",
                "famous",
                "star",
                "career",
                "achievement",
                "winning",
                "made it",
                "top",
                "win",
                "champion",
                "glory",
            ],
            "struggle": [
                "struggle",
                "pain",
                "problems",
                "hardship",
                "suffering",
                "tough",
                "hard times",
                "grind",
                "difficult",
                "rough",
            ],
            "drugs": [
                "drugs",
                "molly",
                "xanax",
                "percs",
                "pills",
                "cocaine",
                "heroin",
                "marijuana",
                "cannabis",
                "weed",
                "lean",
                "high",
            ],
            "violence": [
                "war",
                "fight",
                "murder",
                "blood",
                "gun",
                "knife",
                "shoot",
                "kill",
                "weapon",
                "violence",
                "battle",
                "beef",
            ],
            "party": [
                "party",
                "club",
                "dance",
                "fun",
                "alcohol",
                "beer",
                "drunk",
                "drinking",
                "turn up",
                "lit",
                "celebration",
            ],
            "depression": [
                "depression",
                "sad",
                "suicide",
                "death",
                "lonely",
                "sorrow",
                "depressed",
                "dark",
                "pain",
                "hurt",
                "broken",
            ],
            "social_issues": [
                "politics",
                "society",
                "system",
                "power",
                "protest",
                "revolution",
                "government",
                "social",
                "justice",
                "change",
            ],
        }

        # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π (English-focused)
        self.mood_indicators = {
            "aggressive": [
                "hate",
                "angry",
                "mad",
                "kill",
                "war",
                "blood",
                "fight",
                "rage",
                "fury",
                "violence",
                "beef",
                "pissed",
            ],
            "melancholic": [
                "sad",
                "sadness",
                "tears",
                "depression",
                "lonely",
                "pain",
                "hurt",
                "broken",
                "crying",
                "sorrow",
            ],
            "energetic": [
                "party",
                "club",
                "dance",
                "hype",
                "lit",
                "turn up",
                "wild",
                "crazy",
                "bounce",
                "jump",
                "energy",
            ],
            "neutral": [
                "talking",
                "telling",
                "thinking",
                "know",
                "remember",
                "see",
                "saying",
                "speaking",
                "telling",
            ],
        }

        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
        self.consistency_threshold = 0.6  # –ü–æ–Ω–∏–∂–µ–Ω –¥–ª—è –±–æ–ª–µ–µ –≥–∏–±–∫–æ–π –æ—Ü–µ–Ω–∫–∏
        self.hallucination_threshold = 0.4  # –ü–æ–≤—ã—à–µ–Ω –¥–ª—è —Å—Ç—Ä–æ–≥–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π

    def validate_analysis(self, lyrics: str, ai_analysis: dict) -> dict:
        """–ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ AI –∞–Ω–∞–ª–∏–∑–∞"""

        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        consistency_score = self.check_internal_consistency(ai_analysis)

        # 2. –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π
        factual_accuracy = self.validate_factual_claims(lyrics, ai_analysis)

        # 3. –î–µ—Ç–µ–∫—Ü–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
        hallucination_risk = self.detect_hallucinations(lyrics, ai_analysis)

        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞
        text_alignment = self.check_text_analysis_alignment(lyrics, ai_analysis)

        # 5. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—é—â–∏—Ö —Ñ–ª–∞–≥–æ–≤
        warning_flags = self.get_warning_flags(ai_analysis, lyrics)

        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        is_reliable = (
            hallucination_risk < self.hallucination_threshold
            and consistency_score > self.consistency_threshold
            and factual_accuracy > 0.5  # –ü–æ–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥
            and text_alignment > 0.4  # –ü–æ–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥
            and len(warning_flags) == 0  # –ù–∏–∫–∞–∫–∏—Ö –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        )

        return {
            "is_reliable": is_reliable,
            "reliability_score": (consistency_score + factual_accuracy + text_alignment)
            / 3,
            "consistency_score": consistency_score,
            "factual_accuracy": factual_accuracy,
            "hallucination_risk": hallucination_risk,
            "text_alignment": text_alignment,
            "warning_flags": warning_flags,
            "validation_summary": self._generate_validation_summary(
                is_reliable, hallucination_risk, consistency_score, warning_flags
            ),
        }

    def detect_hallucinations(self, lyrics: str, analysis: dict) -> float:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –≤ AI –∞–Ω–∞–ª–∏–∑–µ"""
        hallucination_score = 0.0
        lyrics_lower = lyrics.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞—è–≤–ª–µ–Ω–Ω—ã–µ —Ç–µ–º—ã
        if "main_themes" in analysis:
            claimed_themes = analysis["main_themes"]
            if isinstance(claimed_themes, list):
                for theme in claimed_themes:
                    if not self.theme_present_in_lyrics(theme, lyrics_lower):
                        hallucination_score += 0.15
                        logger.warning(
                            f"üö® Possible hallucination: theme '{theme}' not found in lyrics"
                        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        if "mood" in analysis:
            claimed_mood = analysis["mood"].lower()
            if not self.mood_supported_by_lyrics(claimed_mood, lyrics_lower):
                hallucination_score += 0.2
                logger.warning(
                    f"üö® Possible hallucination: mood '{claimed_mood}' not supported by lyrics"
                )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∂–∞–Ω—Ä (–º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–æ, —Ç–∞–∫ –∫–∞–∫ –∂–∞–Ω—Ä –º–æ–∂–µ—Ç –±—ã—Ç—å –º—É–∑—ã–∫–∞–ª—å–Ω—ã–º)
        if "genre" in analysis:
            claimed_genre = analysis["genre"].lower()
            if (
                claimed_genre in ["classical", "jazz", "country"]
                and "rap" not in lyrics_lower
            ):
                hallucination_score += 0.3  # –Ø–≤–Ω–æ –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–π –∂–∞–Ω—Ä

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º explicit content
        if "explicit_content" in analysis:
            claimed_explicit = analysis["explicit_content"]
            actual_explicit = self.detect_explicit_content(lyrics_lower)
            if claimed_explicit != actual_explicit:
                hallucination_score += 0.1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å
        if "authenticity_score" in analysis:
            auth_score = analysis["authenticity_score"]
            if isinstance(auth_score, (int, float)):
                if (
                    auth_score > 0.9 and len(lyrics.split()) < 50
                ):  # –í—ã—Å–æ–∫–∞—è –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –∫–æ—Ä–æ—Ç–∫–æ–º —Ç–µ–∫—Å—Ç–µ
                    hallucination_score += 0.1

        return min(hallucination_score, 1.0)

    def theme_present_in_lyrics(self, theme: str, lyrics_lower: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Ç–µ–º–∞ –≤ —Ç–µ–∫—Å—Ç–µ –ø–µ—Å–Ω–∏"""
        theme_lower = theme.lower().replace("_", " ")

        # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if theme_lower in lyrics_lower:
            return True

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        if theme_lower in self.theme_keywords:
            keywords = self.theme_keywords[theme_lower]
            found_keywords = sum(1 for keyword in keywords if keyword in lyrics_lower)
            return found_keywords >= 1  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–¥–Ω–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞

        # –ß–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö —Ç–µ–º (English-focused)
        if "street" in theme_lower and any(
            word in lyrics_lower
            for word in ["street", "block", "hood", "neighborhood", "ghetto"]
        ):
            return True
        if "money" in theme_lower and any(
            word in lyrics_lower
            for word in ["cash", "money", "dollars", "bands", "racks", "bread"]
        ):
            return True
        if "love" in theme_lower and any(
            word in lyrics_lower
            for word in ["love", "girl", "relationship", "girlfriend", "romance"]
        ):
            return True

        return False

    def mood_supported_by_lyrics(self, mood: str, lyrics_lower: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–∞—è–≤–ª–µ–Ω–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç—É"""
        if mood in self.mood_indicators:
            indicators = self.mood_indicators[mood]
            found_indicators = sum(
                1 for indicator in indicators if indicator in lyrics_lower
            )
            return found_indicators >= 1

        # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True (–Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å)
        return True

    def detect_explicit_content(self, lyrics_lower: str) -> bool:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç explicit –∫–æ–Ω—Ç–µ–Ω—Ç –≤ —Ç–µ–∫—Å—Ç–µ (English-focused)"""
        explicit_words = [
            "fuck",
            "shit",
            "bitch",
            "asshole",
            "damn",
            "hell",
            "pussy",
            "dick",
            "cock",
            "motherfucker",
            "nigga",
            "nigger",
            "whore",
            "slut",
            "cunt",
            "bastard",
            "piss",
        ]
        return any(word in lyrics_lower for word in explicit_words)

    def check_internal_consistency(self, analysis: dict) -> float:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞"""
        consistency_score = 1.0

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∏ —ç–Ω–µ—Ä–≥–∏–∏
        mood = analysis.get("mood", "").lower()
        energy = analysis.get("energy_level", "").lower()

        # –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
        if mood == "melancholic" and energy == "high":
            consistency_score -= 0.2  # –ì—Ä—É—Å—Ç–Ω–∞—è, –Ω–æ —ç–Ω–µ—Ä–≥–∏—á–Ω–∞—è - –≤–æ–∑–º–æ–∂–Ω–æ
        if mood == "aggressive" and energy == "low":
            consistency_score -= 0.3  # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è, –Ω–æ –Ω–∏–∑–∫–∞—è —ç–Ω–µ—Ä–≥–∏—è - —Å—Ç—Ä–∞–Ω–Ω–æ

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if "authenticity_score" in analysis and "commercial_appeal" in analysis:
            auth = analysis["authenticity_score"]
            commercial = analysis["commercial_appeal"]
            if isinstance(auth, (int, float)) and isinstance(commercial, (int, float)):
                # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å –ò –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –∞–ø–ø–µ–∞–ª - —Ä–µ–¥–∫–æ
                if auth > 0.9 and commercial > 0.9:
                    consistency_score -= 0.2

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
        complexity = analysis.get("complexity_level", "").lower()
        overall_quality = analysis.get("overall_quality", "").lower()

        if complexity == "advanced" and overall_quality == "poor":
            consistency_score -= 0.2
        if complexity == "beginner" and overall_quality == "excellent":
            consistency_score -= 0.1

        return max(consistency_score, 0.0)

    def validate_factual_claims(self, lyrics: str, analysis: dict) -> float:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≤ –∞–Ω–∞–ª–∏–∑–µ"""
        factual_score = 1.0
        lyrics_lower = lyrics.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        claimed_structure = analysis.get("structure", "").lower()
        if claimed_structure:
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            lines = [line for line in lyrics.split("\n") if line.strip()]

            if "verse-chorus-verse" in claimed_structure and len(lines) < 8:
                factual_score -= 0.2  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —Ç–∞–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            if "hook" in claimed_structure and len(lines) > 20:
                factual_score -= 0.1  # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –¥–ª—è hook

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–µ–º—É —Ä–∏—Ñ–º
        rhyme_scheme = analysis.get("rhyme_scheme", "").lower()
        if rhyme_scheme and rhyme_scheme != "unknown":
            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∏—Ñ–º
            lines = [line.strip() for line in lyrics.split("\n") if line.strip()]
            if len(lines) >= 4:
                # –ï—Å–ª–∏ –∑–∞—è–≤–ª–µ–Ω–∞ —Å–ª–æ–∂–Ω–∞—è —Å—Ö–µ–º–∞, –Ω–æ —Ç–µ–∫—Å—Ç –ø—Ä–æ—Å—Ç–æ–π
                if (
                    "complex" in rhyme_scheme
                    and len(set(line.split()[-1] for line in lines[:4] if line.split()))
                    == 1
                ):
                    factual_score -= 0.1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ vs —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        word_count = len(lyrics.split())
        complexity = analysis.get("complexity_level", "").lower()

        if complexity == "advanced" and word_count < 100:
            factual_score -= 0.2
        if complexity == "beginner" and word_count > 500:
            factual_score -= 0.1

        return max(factual_score, 0.0)

    def check_text_analysis_alignment(self, lyrics: str, analysis: dict) -> float:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –∞–Ω–∞–ª–∏–∑–æ–º"""
        alignment_score = 1.0
        lyrics_lower = lyrics.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞ –∏ –¥–µ—Ç–∞–ª—å–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞
        word_count = len(lyrics.split())

        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π, –Ω–æ –∞–Ω–∞–ª–∏–∑ –æ—á–µ–Ω—å –¥–µ—Ç–∞–ª—å–Ω—ã–π - –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
        if word_count < 50:
            detailed_fields = sum(
                1
                for key in ["main_themes", "structure", "rhyme_scheme"]
                if analysis.get(key)
            )
            if detailed_fields > 2:
                alignment_score -= 0.2

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º explicit content alignment
        actual_explicit = self.detect_explicit_content(lyrics_lower)
        claimed_explicit = analysis.get("explicit_content", False)

        if actual_explicit != claimed_explicit:
            alignment_score -= 0.3

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º energy level alignment
        energy = analysis.get("energy_level", "").lower()
        exclamation_count = lyrics.count("!")
        caps_ratio = sum(1 for c in lyrics if c.isupper()) / max(len(lyrics), 1)

        if energy == "high" and exclamation_count == 0 and caps_ratio < 0.05:
            alignment_score -= 0.2
        if energy == "low" and exclamation_count > 5:
            alignment_score -= 0.2

        return max(alignment_score, 0.0)

    def get_warning_flags(self, analysis: dict, lyrics: str) -> list:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—é—â–∏—Ö —Ñ–ª–∞–≥–æ–≤"""
        flags = []

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–µ –æ—Ü–µ–Ω–∫–∏
        if analysis.get("authenticity_score", 0) > 0.95:
            flags.append("SUSPICIOUSLY_HIGH_AUTHENTICITY")

        if analysis.get("uniqueness", 0) > 0.95:
            flags.append("SUSPICIOUSLY_HIGH_UNIQUENESS")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª–∏–Ω—ã –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        word_count = len(lyrics.split())
        complexity = analysis.get("complexity_level", "").lower()

        if word_count < 50 and complexity == "advanced":
            flags.append("SHORT_TEXT_HIGH_COMPLEXITY")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–µ–º –≤ –∫–æ—Ä–æ—Ç–∫–æ–º —Ç–µ–∫—Å—Ç–µ
        themes = analysis.get("main_themes", [])
        if word_count < 100 and len(themes) > 4:
            flags.append("SHORT_TEXT_MANY_THEMES")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        mood = analysis.get("mood", "").lower()
        commercial = analysis.get("commercial_appeal", 0)

        if mood == "melancholic" and commercial > 0.8:
            flags.append("SAD_MOOD_HIGH_COMMERCIAL")

        return flags

    def _generate_validation_summary(
        self,
        is_reliable: bool,
        hallucination_risk: float,
        consistency_score: float,
        warning_flags: list,
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        if is_reliable:
            return f"‚úÖ –ê–Ω–∞–ª–∏–∑ –Ω–∞–¥–µ–∂–µ–Ω (—Ä–∏—Å–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π: {hallucination_risk:.2f})"
        issues = []
        if hallucination_risk > 0.4:  # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥
            issues.append(f"–≤—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π ({hallucination_risk:.2f})")
        if consistency_score < 0.6:  # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥
            issues.append(f"–Ω–∏–∑–∫–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å ({consistency_score:.2f})")
        if warning_flags:
            issues.append(f"–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {len(warning_flags)}")

        return f"‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ –Ω–µ–Ω–∞–¥–µ–∂–µ–Ω: {', '.join(issues)}"


# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
class EnhancedSongData(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç AI –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Å–Ω–∏"""

    artist: str
    title: str
    metadata: SongMetadata
    lyrics_analysis: LyricsAnalysis
    quality_metrics: QualityMetrics
    model_used: str
    analysis_date: str


class ExplainableAnalysisResult(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏"""

    analysis: EnhancedSongData
    explanation: dict[str, list[str]]
    confidence: float
    decision_factors: dict[str, float]
    influential_phrases: dict[str, list[str]]


class InterpretableAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏–π AI"""

    def __init__(self, base_analyzer):
        self.base_analyzer = base_analyzer

        # –°–ª–æ–≤–∞—Ä–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        self.genre_keywords = {
            "trap": ["trap", "–º–æ–ª–ª–∏", "lean", "xanax", "—Å–∫—Ä—Ä", "–π–∞", "bando", "plug"],
            "drill": ["drill", "smoke", "opps", "block", "gang", "sliding", "packed"],
            "old_school": [
                "boom bap",
                "real hip hop",
                "90s",
                "golden era",
                "conscious",
            ],
            "gangsta": ["glock", "ak", "blood", "crip", "hood", "street", "thug"],
            "emo_rap": [
                "–¥–µ–ø—Ä–µ—Å—Å–∏—è",
                "—Å—É–∏—Ü–∏–¥",
                "–±–æ–ª—å",
                "–≥—Ä—É—Å—Ç—å",
                "–æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ",
                "—Å–ª–µ–∑—ã",
            ],
        }

        self.mood_keywords = {
            "aggressive": ["—É–±—å—é", "–≤–æ–π–Ω–∞", "–∫—Ä–æ–≤—å", "–¥—Ä–∞–∫–∞", "hate", "angry", "mad"],
            "melancholic": ["–≥—Ä—É—Å—Ç—å", "–ø–µ—á–∞–ª—å", "—Å–ª–µ–∑—ã", "–¥–µ–ø—Ä–µ—Å—Å–∏—è", "–æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ"],
            "energetic": ["party", "club", "dance", "energy", "–≤–ø–µ—Ä–µ–¥", "–¥–≤–∏–∂–µ–Ω–∏–µ"],
            "chill": ["—Ä–∞—Å—Å–ª–∞–±–æ–Ω", "—Å–ø–æ–∫–æ–π–Ω–æ", "–º–µ–¥–ª–µ–Ω–Ω–æ", "vibe", "–∞—Ç–º–æ—Å—Ñ–µ—Ä–∞"],
        }

        self.authenticity_keywords = {
            "real": ["–ø—Ä–∞–≤–¥–∞", "—Ä–µ–∞–ª—å–Ω–æ", "—á–µ—Å—Ç–Ω–æ", "–±–µ–∑ —Ñ–∞–ª—å—à–∏", "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É"],
            "fake": ["–ø–æ–Ω—Ç", "—Ñ—ç–π–∫", "–ø–∏–∂–æ–Ω", "–ø–æ–∫–∞–∑—É—Ö–∞", "–ø—Ä–∏—Ç–≤–æ—Ä—Å—Ç–≤–æ"],
            "street": ["—É–ª–∏—Ü–∞", "—Ä–∞–π–æ–Ω", "–¥–≤–æ—Ä", "–ø–æ–¥—ä–µ–∑–¥", "–∫–≤–∞—Ä—Ç–∞–ª", "–≥–µ—Ç—Ç–æ"],
            "commercial": ["money", "brand", "–∫–æ–º–º–µ—Ä—Ü–∏—è", "–ø—Ä–æ–¥–∞–∂–∏", "mainstream"],
        }

    def analyze_with_explanation(
        self, artist: str, title: str, lyrics: str
    ) -> ExplainableAnalysisResult | None:
        """–ê–Ω–∞–ª–∏–∑ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º —Ä–µ—à–µ–Ω–∏–π"""
        try:
            # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
            base_result = self.base_analyzer.analyze_song(artist, title, lyrics)
            if not base_result:
                return None

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
            explanation = self.explain_decision(lyrics, base_result)
            confidence = self.calculate_confidence(base_result, lyrics)
            decision_factors = self.extract_key_factors(lyrics, base_result)
            influential_phrases = self.find_influential_phrases(lyrics, base_result)

            return ExplainableAnalysisResult(
                analysis=base_result,
                explanation=explanation,
                confidence=confidence,
                decision_factors=decision_factors,
                influential_phrases=influential_phrases,
            )

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None

    def explain_decision(
        self, lyrics: str, result: EnhancedSongData
    ) -> dict[str, list[str]]:
        """–û–±—ä—è—Å–Ω—è–µ—Ç, –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–µ–≥–æ –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω—è–ª–∞ —Ä–µ—à–µ–Ω–∏–µ"""
        lyrics_lower = lyrics.lower()
        explanations = {
            "genre_indicators": [],
            "mood_triggers": [],
            "authenticity_markers": [],
            "quality_indicators": [],
        }

        # –ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        detected_genre = result.metadata.genre.lower()
        for genre, keywords in self.genre_keywords.items():
            if genre in detected_genre:
                found_keywords = [kw for kw in keywords if kw in lyrics_lower]
                if found_keywords:
                    explanations["genre_indicators"].extend(
                        [
                            f"–ñ–∞–Ω—Ä '{genre}' –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ —Å–ª–æ–≤–∞–º: {', '.join(found_keywords[:3])}"
                        ]
                    )

        # –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        detected_mood = result.metadata.mood.lower()
        for mood, keywords in self.mood_keywords.items():
            if mood in detected_mood:
                found_keywords = [kw for kw in keywords if kw in lyrics_lower]
                if found_keywords:
                    explanations["mood_triggers"].extend(
                        [
                            f"–ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ '{mood}' –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –ø–æ —Å–ª–æ–≤–∞–º: {', '.join(found_keywords[:3])}"
                        ]
                    )

        # –ê–Ω–∞–ª–∏–∑ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏
        auth_score = result.quality_metrics.authenticity_score
        if auth_score > 0.7:
            real_words = [
                kw for kw in self.authenticity_keywords["real"] if kw in lyrics_lower
            ]
            street_words = [
                kw for kw in self.authenticity_keywords["street"] if kw in lyrics_lower
            ]
            if real_words or street_words:
                explanations["authenticity_markers"].append(
                    f"–í—ã—Å–æ–∫–∞—è –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å ({auth_score:.2f}) –±–ª–∞–≥–æ–¥–∞—Ä—è: {', '.join((real_words + street_words)[:3])}"
                )
        elif auth_score < 0.4:
            fake_words = [
                kw for kw in self.authenticity_keywords["fake"] if kw in lyrics_lower
            ]
            commercial_words = [
                kw
                for kw in self.authenticity_keywords["commercial"]
                if kw in lyrics_lower
            ]
            if fake_words or commercial_words:
                explanations["authenticity_markers"].append(
                    f"–ù–∏–∑–∫–∞—è –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å ({auth_score:.2f}) –∏–∑-–∑–∞: {', '.join((fake_words + commercial_words)[:3])}"
                )

        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
        creativity = result.quality_metrics.lyrical_creativity
        wordplay = result.lyrics_analysis.wordplay_quality
        explanations["quality_indicators"].append(
            f"–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å: {creativity:.2f}, Wordplay: {wordplay}"
        )

        return explanations

    def calculate_confidence(self, result: EnhancedSongData, lyrics: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∞–Ω–∞–ª–∏–∑–µ"""
        confidence_factors = []

        # –§–∞–∫—Ç–æ—Ä 1: –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (–±–æ–ª—å—à–µ —Ç–µ–∫—Å—Ç–∞ = –±–æ–ª—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏)
        text_length_factor = min(len(lyrics) / 1000, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 1.0
        confidence_factors.append(text_length_factor * 0.2)

        # –§–∞–∫—Ç–æ—Ä 2: –ù–∞–ª–∏—á–∏–µ —è–≤–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∂–∞–Ω—Ä–∞
        genre_confidence = self._calculate_genre_confidence(
            lyrics, result.metadata.genre
        )
        confidence_factors.append(genre_confidence * 0.3)

        # –§–∞–∫—Ç–æ—Ä 3: –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_consistency = self._calculate_quality_consistency(
            result.quality_metrics
        )
        confidence_factors.append(quality_consistency * 0.3)

        # –§–∞–∫—Ç–æ—Ä 4: –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π (–∏–º–µ–Ω–∞, –º–µ—Å—Ç–∞, —Å–æ–±—ã—Ç–∏—è)
        detail_factor = self._calculate_detail_factor(lyrics)
        confidence_factors.append(detail_factor * 0.2)

        return min(sum(confidence_factors), 1.0)

    def _calculate_genre_confidence(self, lyrics: str, genre: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∂–∞–Ω—Ä–∞"""
        lyrics_lower = lyrics.lower()
        genre_lower = genre.lower()

        matching_keywords = 0
        total_keywords = 0

        for g, keywords in self.genre_keywords.items():
            if g in genre_lower:
                total_keywords = len(keywords)
                matching_keywords = sum(1 for kw in keywords if kw in lyrics_lower)
                break

        if total_keywords == 0:
            return 0.5  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∂–∞–Ω—Ä–æ–≤

        return matching_keywords / total_keywords

    def _calculate_quality_consistency(self, metrics: QualityMetrics) -> float:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
        scores = [
            metrics.authenticity_score,
            metrics.lyrical_creativity,
            metrics.commercial_appeal,
            metrics.uniqueness,
        ]

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
        mean_score = sum(scores) / len(scores)
        variance = sum((x - mean_score) ** 2 for x in scores) / len(scores)
        std_dev = variance**0.5

        # –ù–∏–∑–∫–æ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ = –≤—ã—Å–æ–∫–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
        consistency = max(0, 1 - (std_dev * 2))  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        return consistency

    def _calculate_detail_factor(self, lyrics: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π"""
        detail_indicators = [
            r"\b[A-Z][a-z]+\b",  # –ò–º–µ–Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ
            r"\b\d{4}\b",  # –ì–æ–¥—ã
            r"\b\d+[–∫–º]\b",  # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è
            r"\$\d+",  # –î–µ–Ω—å–≥–∏
            r"\b[–ê-–Ø–Å][–∞-—è—ë]+\b",  # –†—É—Å—Å–∫–∏–µ –∏–º–µ–Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ
        ]

        total_details = 0
        for pattern in detail_indicators:
            matches = re.findall(pattern, lyrics)
            total_details += len(matches)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞
        detail_density = total_details / max(len(lyrics.split()), 1)
        return min(detail_density * 10, 1.0)  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º

    def extract_key_factors(
        self, lyrics: str, result: EnhancedSongData
    ) -> dict[str, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –∞–Ω–∞–ª–∏–∑"""
        factors = {}
        lyrics_lower = lyrics.lower()

        # –ß–∞—Å—Ç–æ—Ç–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for category, keywords in {**self.genre_keywords, **self.mood_keywords}.items():
            keyword_count = sum(1 for kw in keywords if kw in lyrics_lower)
            factors[f"{category}_keywords"] = keyword_count / len(keywords)

        # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
        factors["text_length"] = min(len(lyrics) / 2000, 1.0)
        factors["line_count"] = min(len(lyrics.split("\n")) / 50, 1.0)
        factors["word_diversity"] = len(set(lyrics.lower().split())) / max(
            len(lyrics.split()), 1
        )

        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–∫ —Ñ–∞–∫—Ç–æ—Ä—ã
        factors["authenticity"] = result.quality_metrics.authenticity_score
        factors["creativity"] = result.quality_metrics.lyrical_creativity
        factors["commercial_appeal"] = result.quality_metrics.commercial_appeal
        factors["uniqueness"] = result.quality_metrics.uniqueness

        return factors

    def find_influential_phrases(
        self, lyrics: str, result: EnhancedSongData
    ) -> dict[str, list[str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–≤–ª–∏—è–ª–∏ –Ω–∞ –æ—Ü–µ–Ω–∫—É"""
        influential = {
            "genre_phrases": [],
            "mood_phrases": [],
            "authenticity_phrases": [],
            "quality_phrases": [],
        }

        lines = lyrics.split("\n")

        # –ü–æ–∏—Å–∫ –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑ –¥–ª—è –∂–∞–Ω—Ä–∞
        genre_lower = result.metadata.genre.lower()
        for genre, keywords in self.genre_keywords.items():
            if genre in genre_lower:
                for line in lines:
                    if any(kw in line.lower() for kw in keywords):
                        influential["genre_phrases"].append(line.strip())
                        if len(influential["genre_phrases"]) >= 3:
                            break

        # –ü–æ–∏—Å–∫ —Ñ—Ä–∞–∑ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        mood_lower = result.metadata.mood.lower()
        for mood, keywords in self.mood_keywords.items():
            if mood in mood_lower:
                for line in lines:
                    if any(kw in line.lower() for kw in keywords):
                        influential["mood_phrases"].append(line.strip())
                        if len(influential["mood_phrases"]) >= 3:
                            break

        # –ü–æ–∏—Å–∫ —Ñ—Ä–∞–∑ –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏
        auth_score = result.quality_metrics.authenticity_score
        auth_keywords = (
            self.authenticity_keywords["real"] + self.authenticity_keywords["street"]
        )
        if auth_score > 0.7:
            for line in lines:
                if any(kw in line.lower() for kw in auth_keywords):
                    influential["authenticity_phrases"].append(line.strip())
                    if len(influential["authenticity_phrases"]) >= 2:
                        break

        # –ü–æ–∏—Å–∫ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö wordplay —Ñ—Ä–∞–∑
        if result.lyrics_analysis.wordplay_quality == "excellent":
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ä–∏—Ñ–º–∞–º–∏ –∏–ª–∏ –∞–ª–ª–∏—Ç–µ—Ä–∞—Ü–∏–µ–π
            for line in lines:
                words = line.lower().split()
                if len(words) >= 4:
                    # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∏—Ñ–º—É (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è)
                    endings = [word[-2:] for word in words if len(word) > 3]
                    if (
                        len(set(endings)) < len(endings) * 0.8
                    ):  # –ú–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –æ–∫–æ–Ω—á–∞–Ω–∏–π
                        influential["quality_phrases"].append(line.strip())
                        if len(influential["quality_phrases"]) >= 2:
                            break

        return influential


class ModelProvider:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""

    def __init__(self, name: str):
        self.name = name
        self.available = False
        self.cost_per_1k_tokens = 0.0

    def check_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        raise NotImplementedError

    def analyze_song(
        self, artist: str, title: str, lyrics: str
    ) -> EnhancedSongData | None:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏"""
        raise NotImplementedError


class OllamaProvider(ModelProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Ollama"""

    def __init__(
        self, model_name: str = "llama3.2:3b", base_url: str = "http://localhost:11434"
    ):
        super().__init__("Ollama")
        self.model_name = model_name
        self.base_url = base_url
        self.cost_per_1k_tokens = 0.0  # –ë–µ—Å–ø–ª–∞—Ç–Ω–æ!
        self.available = self.check_availability()

    def check_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø—É—â–µ–Ω –ª–∏ Ollama"""
        try:
            response = requests.get(
                f"{self.base_url}/api/tags",
                timeout=5,
                proxies={"http": "", "https": ""},
            )
            if response.status_code == 200:
                models = response.json().get("models", [])
                available_models = [model["name"] for model in models]
                logger.info(f"ü¶ô Ollama –¥–æ—Å—Ç—É–ø–µ–Ω. –ú–æ–¥–µ–ª–∏: {available_models}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω–æ–π –º–æ–¥–µ–ª–∏
                if any(self.model_name in model for model in available_models):
                    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {self.model_name} –Ω–∞–π–¥–µ–Ω–∞")
                    return True
                logger.warning(
                    f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {self.model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏..."
                )
                return self._pull_model()
            return False
        except requests.exceptions.RequestException as e:
            logger.warning(f"‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            return False

    def _pull_model(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
        try:
            logger.info(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å {self.model_name}...")
            response = requests.post(
                f"{self.base_url}/api/pull",
                json={"name": self.model_name},
                timeout=300,  # 5 –º–∏–Ω—É—Ç –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É
                proxies={"http": "", "https": ""},
            )
            if response.status_code == 200:
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {self.model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                return True
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {response.text}")
            return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def analyze_song(
        self, artist: str, title: str, lyrics: str
    ) -> EnhancedSongData | None:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —á–µ—Ä–µ–∑ Ollama"""
        if not self.available:
            return None

        try:
            prompt = self._create_analysis_prompt(artist, title, lyrics)

            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
                        "top_p": 0.9,
                        "max_tokens": 1500,
                    },
                },
                timeout=60,
                proxies={"http": "", "https": ""},
            )

            if response.status_code == 200:
                result = response.json()
                analysis_text = result.get("response", "")
                return self._parse_analysis(analysis_text, artist, title)
            logger.error(f"‚ùå Ollama –æ—à–∏–±–∫–∞: {response.status_code} - {response.text}")
            return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Ollama: {e}")
            return None

    def _create_analysis_prompt(self, artist: str, title: str, lyrics: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        return f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä—ç–ø-–ø–µ—Å–Ω—é –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –°–¢–†–û–ì–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.

–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å: {artist}
–ù–∞–∑–≤–∞–Ω–∏–µ: {title}
–¢–µ–∫—Å—Ç: {lyrics[:2000]}...

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:

{{
    "metadata": {{
        "genre": "rap",
        "mood": "aggressive",
        "energy_level": "high",
        "explicit_content": true
    }},
    "lyrics_analysis": {{
        "structure": "verse-chorus-verse",
        "rhyme_scheme": "ABAB",
        "complexity_level": "advanced",
        "main_themes": ["street_life", "success", "relationships"],
        "emotional_tone": "mixed",
        "storytelling_type": "narrative",
        "wordplay_quality": "excellent"
    }},
    "quality_metrics": {{
        "authenticity_score": 0.8,
        "lyrical_creativity": 0.9,
        "commercial_appeal": 0.7,
        "uniqueness": 0.6,
        "overall_quality": "excellent",
        "ai_likelihood": 0.1
    }}
}}

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –ü–û–õ–Ø:
- emotional_tone: positive/negative/neutral/mixed
- storytelling_type: narrative/abstract/conversational
- wordplay_quality: basic/good/excellent

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤!
"""

    def _parse_analysis(
        self, analysis_text: str, artist: str, title: str
    ) -> EnhancedSongData | None:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_start = analysis_text.find("{")
            json_end = analysis_text.rfind("}") + 1

            if json_start == -1 or json_end <= json_start:
                logger.error("‚ùå JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
                return None

            json_str = analysis_text[json_start:json_end]
            data = json.loads(json_str)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è
            metadata_data = data.get("metadata", {})
            lyrics_data = data.get("lyrics_analysis", {})
            quality_data = data.get("quality_metrics", {})

            # –î–æ–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –≤ lyrics_analysis
            if "emotional_tone" not in lyrics_data:
                lyrics_data["emotional_tone"] = "neutral"
                logger.warning("‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è emotional_tone")

            if "storytelling_type" not in lyrics_data:
                lyrics_data["storytelling_type"] = "conversational"
                logger.warning(
                    "‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è storytelling_type"
                )

            if "wordplay_quality" not in lyrics_data:
                lyrics_data["wordplay_quality"] = "basic"
                logger.warning("‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è wordplay_quality")

            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            metadata = SongMetadata(**metadata_data)
            lyrics_analysis = LyricsAnalysis(**lyrics_data)
            quality_metrics = QualityMetrics(**quality_data)

            return EnhancedSongData(
                artist=artist,
                title=title,
                metadata=metadata,
                lyrics_analysis=lyrics_analysis,
                quality_metrics=quality_metrics,
                model_used=f"ollama:{self.model_name}",
                analysis_date=datetime.now().isoformat(),
            )

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            logger.debug(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {analysis_text[:500]}")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None


class MockProvider(ModelProvider):
    """Mock –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""

    def __init__(self):
        super().__init__("Mock")
        self.cost_per_1k_tokens = 0.0  # –ë–µ—Å–ø–ª–∞—Ç–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        self.available = True  # –í—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω

    def check_availability(self) -> bool:
        """Mock –ø—Ä–æ–≤–∞–π–¥–µ—Ä –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω"""
        logger.info("‚úÖ Mock –ø—Ä–æ–≤–∞–π–¥–µ—Ä –≥–æ—Ç–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏")
        return True

    def analyze_song(
        self, artist: str, title: str, lyrics: str
    ) -> EnhancedSongData | None:
        """Mock –∞–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —Å —É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è–º–∏"""
        try:
            lyrics_lower = lyrics.lower()

            # –£–º–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∂–∞–Ω—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            genre = "rap"
            if any(word in lyrics_lower for word in ["trap", "–º–æ–ª–ª–∏", "lean", "—Å–∫—Ä—Ä"]):
                genre = "trap"
            elif any(
                word in lyrics_lower for word in ["drill", "smoke", "opps", "gang"]
            ):
                genre = "drill"
            elif any(
                word in lyrics_lower for word in ["—É–ª–∏—Ü–∞", "—Ä–∞–π–æ–Ω", "–¥–≤–æ—Ä", "–ø–æ–¥—ä–µ–∑–¥"]
            ):
                genre = "gangsta_rap"
            elif any(word in lyrics_lower for word in ["–¥–µ–ø—Ä–µ—Å—Å–∏—è", "–≥—Ä—É—Å—Ç—å", "—Å–ª–µ–∑—ã"]):
                genre = "emo_rap"

            # –£–º–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
            mood = "neutral"
            aggressive_words = ["—É–±—å—é", "–≤–æ–π–Ω–∞", "–¥—Ä–∞–∫–∞", "hate", "angry"]
            sad_words = ["–≥—Ä—É—Å—Ç—å", "–ø–µ—á–∞–ª—å", "—Å–ª–µ–∑—ã", "–¥–µ–ø—Ä–µ—Å—Å–∏—è", "–æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ"]
            positive_words = ["party", "—Å—á–∞—Å—Ç—å–µ", "—Ä–∞–¥–æ—Å—Ç—å", "love", "—É—Å–ø–µ—Ö"]

            if any(word in lyrics_lower for word in aggressive_words):
                mood = "aggressive"
            elif any(word in lyrics_lower for word in sad_words):
                mood = "melancholic"
            elif any(word in lyrics_lower for word in positive_words):
                mood = "energetic"

            # –ê–Ω–∞–ª–∏–∑ —ç–Ω–µ—Ä–≥–∏–∏
            energy = "medium"
            if (
                len(lyrics.split("!")) > 3
                or "–π–∞" in lyrics_lower
                or "—Å–∫—Ä—Ä" in lyrics_lower
            ):
                energy = "high"
            elif any(word in lyrics_lower for word in ["–º–µ–¥–ª–µ–Ω–Ω–æ", "—Å–ø–æ–∫–æ–π–Ω–æ", "—Ç–∏—Ö–æ"]):
                energy = "low"

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ explicit content
            explicit_words = [
                "—Å—É–∫–∞",
                "–±–ª—è—Ç—å",
                "—Ö—É–π",
                "–ø–∏–∑–¥–∞",
                "–µ–±–∞—Ç—å",
                "fuck",
                "shit",
                "bitch",
            ]
            explicit_content = any(word in lyrics_lower for word in explicit_words)

            # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            lines = lyrics.strip().split("\n")
            non_empty_lines = [line for line in lines if line.strip()]

            structure = "verse"
            if len(non_empty_lines) > 16:
                structure = "verse-chorus-verse"
            elif len(non_empty_lines) < 8:
                structure = "hook"

            # –ê–Ω–∞–ª–∏–∑ —Ä–∏—Ñ–º—ã (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            rhyme_scheme = "ABAB"
            if len(non_empty_lines) >= 4:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª–æ–≤–∞ —Å—Ç—Ä–æ–∫
                last_words = [
                    line.strip().split()[-1].lower()
                    for line in non_empty_lines[:4]
                    if line.strip().split()
                ]
                if len(set(last_words)) == 1:
                    rhyme_scheme = "AAAA"
                elif len(set(last_words)) == 2:
                    rhyme_scheme = "AABB"

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            complexity = "intermediate"
            word_count = len(lyrics.split())
            unique_words = len(set(lyrics.lower().split()))
            diversity = unique_words / max(word_count, 1)

            if diversity > 0.7 and word_count > 200:
                complexity = "advanced"
            elif diversity < 0.5 or word_count < 100:
                complexity = "beginner"

            # –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã
            themes = []
            theme_keywords = {
                "street_life": ["—É–ª–∏—Ü–∞", "—Ä–∞–π–æ–Ω", "–¥–≤–æ—Ä", "–ø–æ–¥—ä–µ–∑–¥", "–≥–µ—Ç—Ç–æ"],
                "money": ["–¥–µ–Ω—å–≥–∏", "cash", "money", "–±–∞–±–∫–∏", "–ª–∞–≤—ç"],
                "relationships": ["–ª—é–±–æ–≤—å", "–¥–µ–≤–æ—á–∫–∞", "–æ—Ç–Ω–æ—à–µ–Ω–∏—è", "—Å–µ–º—å—è"],
                "success": ["—É—Å–ø–µ—Ö", "fame", "—Å–ª–∞–≤–∞", "—Ç–æ–ø"],
                "struggle": ["–±–æ—Ä—å–±–∞", "struggle", "–ø—Ä–æ–±–ª–µ–º—ã", "—Ç—Ä—É–¥–Ω–æ—Å—Ç–∏"],
            }

            for theme, keywords in theme_keywords.items():
                if any(keyword in lyrics_lower for keyword in keywords):
                    themes.append(theme)

            if not themes:
                themes = ["life"]

            # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            authenticity_score = 0.5
            street_words = ["—É–ª–∏—Ü–∞", "—Ä–∞–π–æ–Ω", "–¥–≤–æ—Ä", "–ø–æ–¥—ä–µ–∑–¥", "–ø—Ä–∞–≤–¥–∞", "—Ä–µ–∞–ª—å–Ω–æ"]
            fake_words = ["–ø–æ–Ω—Ç", "—Ñ—ç–π–∫", "–ø–æ–∫–∞–∑—É—Ö–∞"]

            street_count = sum(1 for word in street_words if word in lyrics_lower)
            fake_count = sum(1 for word in fake_words if word in lyrics_lower)

            authenticity_score = min(
                0.3 + (street_count * 0.15) - (fake_count * 0.1), 1.0
            )

            creativity = min(0.4 + (diversity * 0.6), 1.0)
            commercial_appeal = (
                0.5
                + (0.1 if explicit_content else 0.2)
                + (0.1 if energy == "high" else 0)
            )
            uniqueness = diversity * 0.8 + 0.2

            # –û–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            avg_quality = (
                authenticity_score + creativity + commercial_appeal + uniqueness
            ) / 4
            if avg_quality > 0.8:
                overall_quality = "excellent"
            elif avg_quality > 0.6:
                overall_quality = "good"
            elif avg_quality > 0.4:
                overall_quality = "fair"
            else:
                overall_quality = "poor"

            # AI likelihood (–æ–±—Ä–∞—Ç–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏)
            ai_likelihood = max(0.1, 1.0 - authenticity_score)

            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            metadata = SongMetadata(
                genre=genre,
                mood=mood,
                energy_level=energy,
                explicit_content=explicit_content,
            )

            lyrics_analysis = LyricsAnalysis(
                structure=structure,
                rhyme_scheme=rhyme_scheme,
                complexity_level=complexity,
                main_themes=themes,
                emotional_tone=mood,
                storytelling_type="narrative"
                if "–∏—Å—Ç–æ—Ä–∏—è" in lyrics_lower or len(non_empty_lines) > 12
                else "conversational",
                wordplay_quality="excellent"
                if creativity > 0.8
                else ("good" if creativity > 0.6 else "basic"),
            )

            quality_metrics = QualityMetrics(
                authenticity_score=authenticity_score,
                lyrical_creativity=creativity,
                commercial_appeal=commercial_appeal,
                uniqueness=uniqueness,
                overall_quality=overall_quality,
                ai_likelihood=ai_likelihood,
            )

            return EnhancedSongData(
                artist=artist,
                title=title,
                metadata=metadata,
                lyrics_analysis=lyrics_analysis,
                quality_metrics=quality_metrics,
                model_used="mock_analyzer_v1",
                analysis_date=datetime.now().isoformat(),
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Mock –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None


class GemmaProvider(ModelProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è Google Gemma API"""

    def __init__(self):
        super().__init__("Gemma")
        self.api_key = os.getenv("GOOGLE_API_KEY")
        self.available = self.check_availability()
        self.cost_per_1k_tokens = 0.0  # Free tier –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ª–∏–º–∏—Ç–æ–≤

    def check_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞ Google"""
        if not self.api_key:
            logger.warning("‚ùå GOOGLE_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
            return False

        try:
            import google.generativeai as genai
            from google.generativeai.client import configure
            from google.generativeai.generative_models import GenerativeModel

            configure(api_key=self.api_key)
            logger.info("‚úÖ Google Gemma API –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
            return True
        except ImportError:
            logger.warning("‚ùå google-generativeai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Gemma API: {e}")
            return False

    def analyze_song(
        self, artist: str, title: str, lyrics: str
    ) -> EnhancedSongData | None:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —á–µ—Ä–µ–∑ Google Gemma"""
        if not self.available:
            return None

        try:
            from google.generativeai.generative_models import GenerativeModel

            model = GenerativeModel("gemma-2-27b-it")
            prompt = self._create_analysis_prompt(artist, title, lyrics)

            response = model.generate_content(
                prompt,
                generation_config={
                    "temperature": 0.1,
                    "max_output_tokens": 1500,
                },
            )

            if response.text:
                return self._parse_analysis(response.text, artist, title)
            logger.error("‚ùå Gemma: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Gemma: {e}")
            return None

    def _create_analysis_prompt(self, artist: str, title: str, lyrics: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è Gemma"""
        return f"""
Analyze this rap song and return results in STRICT JSON format:

Artist: {artist}
Title: {title}
Lyrics: {lyrics[:2000]}...

Return ONLY valid JSON with these exact fields:
{{
    "metadata": {{
        "genre": "rap/trap/drill/old-school/gangsta/emo-rap",
        "mood": "aggressive/melancholic/energetic/neutral",
        "energy_level": "low/medium/high",
        "explicit_content": true/false
    }},
    "lyrics_analysis": {{
        "structure": "verse-chorus-verse/freestyle/storytelling",
        "rhyme_scheme": "AABA/ABAB/complex/simple",
        "complexity_level": "beginner/intermediate/advanced",
        "main_themes": ["money", "relationships", "street_life", "success"],
        "emotional_tone": "positive/negative/neutral/mixed",
        "storytelling_type": "narrative/abstract/conversational",
        "wordplay_quality": "basic/good/excellent"
    }},
    "quality_metrics": {{
        "authenticity_score": 0.0-1.0,
        "lyrical_creativity": 0.0-1.0,
        "commercial_appeal": 0.0-1.0,
        "uniqueness": 0.0-1.0,
        "overall_quality": "poor/fair/good/excellent",
        "ai_likelihood": 0.0-1.0
    }}
}}

Return ONLY JSON, no additional text!
"""

    def _parse_analysis(
        self, analysis_text: str, artist: str, title: str
    ) -> EnhancedSongData | None:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_start = analysis_text.find("{")
            json_end = analysis_text.rfind("}") + 1

            if json_start == -1 or json_end <= json_start:
                logger.error("‚ùå JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ Gemma")
                return None

            json_str = analysis_text[json_start:json_end]
            data = json.loads(json_str)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è
            metadata_data = data.get("metadata", {})
            lyrics_data = data.get("lyrics_analysis", {})
            quality_data = data.get("quality_metrics", {})

            # –î–æ–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –≤ lyrics_analysis
            if "emotional_tone" not in lyrics_data:
                lyrics_data["emotional_tone"] = "neutral"
                logger.warning("‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è emotional_tone")

            if "storytelling_type" not in lyrics_data:
                lyrics_data["storytelling_type"] = "conversational"
                logger.warning(
                    "‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è storytelling_type"
                )

            if "wordplay_quality" not in lyrics_data:
                lyrics_data["wordplay_quality"] = "basic"
                logger.warning("‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è wordplay_quality")

            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            metadata = SongMetadata(**metadata_data)
            lyrics_analysis = LyricsAnalysis(**lyrics_data)
            quality_metrics = QualityMetrics(**quality_data)

            return EnhancedSongData(
                artist=artist,
                title=title,
                metadata=metadata,
                lyrics_analysis=lyrics_analysis,
                quality_metrics=quality_metrics,
                model_used="gemma-2-27b-it",
                analysis_date=datetime.now().isoformat(),
            )

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON Gemma: {e}")
            logger.debug(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {analysis_text[:500]}")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ Gemma: {e}")
            return None


class MultiModelAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""

    def __init__(self):
        self.providers = []
        self.current_provider = None
        self.stats = {
            "total_analyzed": 0,
            "ollama_used": 0,
            "gemma_used": 0,
            "mock_used": 0,
            "total_cost": 0.0,
        }

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        self._init_providers()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        self.interpretable_analyzer = InterpretableAnalyzer(self)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        self.safety_validator = SafetyValidator()

    def analyze_with_explanations(
        self, artist: str, title: str, lyrics: str
    ) -> ExplainableAnalysisResult | None:
        """–ê–Ω–∞–ª–∏–∑ —Å –ø–æ–ª–Ω—ã–º–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏ —Ä–µ—à–µ–Ω–∏–π AI"""
        return self.interpretable_analyzer.analyze_with_explanation(
            artist, title, lyrics
        )

    def explain_existing_analysis(
        self, song_id: int, db_path: str = "rap_lyrics.db"
    ) -> dict | None:
        """–û–±—ä—è—Å–Ω—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞–Ω–∞–ª–∏–∑ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = sqlite3.connect(db_path)
            conn.row_factory = sqlite3.Row

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–µ—Å–Ω–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞
            cursor = conn.execute(
                """
                SELECT s.artist, s.title, s.lyrics, a.*
                FROM tracks s
                JOIN ai_analysis a ON s.id = a.song_id
                WHERE s.id = ?
            """,
                (song_id,),
            )

            row = cursor.fetchone()
            if not row:
                logging.warning(
                    f"–ü–µ—Å–Ω—è —Å ID {song_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞"
                )
                return None

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç EnhancedSongData –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ë–î
            metadata = SongMetadata(
                genre=row["genre"],
                mood=row["mood"],
                energy_level=row["energy_level"],
                explicit_content=bool(row["explicit_content"]),
            )

            lyrics_analysis = LyricsAnalysis(
                structure=row["structure"],
                rhyme_scheme=row["rhyme_scheme"],
                complexity_level=row["complexity_level"],
                main_themes=json.loads(row["main_themes"])
                if row["main_themes"]
                else [],
                emotional_tone="neutral",  # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                storytelling_type="conversational",
                wordplay_quality="basic",
            )

            quality_metrics = QualityMetrics(
                authenticity_score=row["authenticity_score"],
                lyrical_creativity=row["lyrical_creativity"],
                commercial_appeal=row["commercial_appeal"],
                uniqueness=row["uniqueness"],
                overall_quality=row["overall_quality"],
                ai_likelihood=row["ai_likelihood"],
            )

            enhanced_data = EnhancedSongData(
                artist=row["artist"],
                title=row["title"],
                metadata=metadata,
                lyrics_analysis=lyrics_analysis,
                quality_metrics=quality_metrics,
                model_used=row["model_version"],
                analysis_date=row["analysis_date"],
            )

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
            explanation = self.interpretable_analyzer.explain_decision(
                row["lyrics"], enhanced_data
            )
            confidence = self.interpretable_analyzer.calculate_confidence(
                enhanced_data, row["lyrics"]
            )
            decision_factors = self.interpretable_analyzer.extract_key_factors(
                row["lyrics"], enhanced_data
            )
            influential_phrases = self.interpretable_analyzer.find_influential_phrases(
                row["lyrics"], enhanced_data
            )

            conn.close()

            return {
                "song_info": {
                    "id": song_id,
                    "artist": row["artist"],
                    "title": row["title"],
                },
                "analysis": enhanced_data.model_dump(),
                "explanation": explanation,
                "confidence": confidence,
                "decision_factors": decision_factors,
                "influential_phrases": influential_phrases,
            }

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None

    def _init_providers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞"""
        logger.info("üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤...")

        # 1. Ollama (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç - –±–µ—Å–ø–ª–∞—Ç–Ω–æ)
        ollama = OllamaProvider()
        if ollama.available:
            self.providers.append(ollama)
            logger.info("‚úÖ Ollama –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")

        # 2. Google Gemma (cloud fallback)
        gemma = GemmaProvider()
        if gemma.available:
            self.providers.append(gemma)
            logger.info("‚úÖ Google Gemma –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")

        # 3. Mock Provider (–≤—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏)
        mock = MockProvider()
        self.providers.append(mock)
        logger.info("‚úÖ Mock –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–æ–±–∞–≤–ª–µ–Ω –∫–∞–∫ fallback")

        if not self.providers:
            logger.error("‚ùå –ù–∏ –æ–¥–∏–Ω AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
            raise Exception("No AI providers available")

        self.current_provider = self.providers[0]
        logger.info(f"üéØ –ê–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.current_provider.name}")

    def analyze_song(
        self, artist: str, title: str, lyrics: str
    ) -> EnhancedSongData | None:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —Å fallback –º–µ–∂–¥—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏"""

        for provider in self.providers:
            try:
                logger.info(f"ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ {provider.name}: {artist} - {title}")

                result = provider.analyze_song(artist, title, lyrics)

                if result:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    self.stats["total_analyzed"] += 1
                    if provider.name == "Ollama":
                        self.stats["ollama_used"] += 1
                    elif provider.name == "Gemma":
                        self.stats["gemma_used"] += 1
                    elif provider.name == "Mock":
                        self.stats["mock_used"] += 1

                    logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —á–µ—Ä–µ–∑ {provider.name}")
                    return result
                logger.warning(f"‚ö†Ô∏è {provider.name} –Ω–µ —Å–º–æ–≥ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å")

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ {provider.name}: {e}")
                continue

        logger.error(
            f"‚ùå –í—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ —Å–º–æ–≥–ª–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å: {artist} - {title}"
        )
        return None

    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return {
            **self.stats,
            "available_providers": [p.name for p in self.providers],
            "current_provider": self.current_provider.name
            if self.current_provider
            else None,
        }

    def batch_analyze_from_db(
        self, db_path: str = "rap_lyrics.db", limit: int = 100, offset: int = 0
    ):
        """–ú–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –ø–µ—Å–µ–Ω –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""

        logger.info(f"üéµ –ù–∞—á–∏–Ω–∞–µ–º batch –∞–Ω–∞–ª–∏–∑: {limit} –ø–µ—Å–µ–Ω —Å offset {offset}")

        try:
            conn = sqlite3.connect(db_path)
            conn.row_factory = sqlite3.Row

            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Å–Ω–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            cursor = conn.execute(
                """
                SELECT s.id, s.artist, s.title, s.lyrics 
                FROM tracks s
                LEFT JOIN ai_analysis a ON s.id = a.song_id
                WHERE a.id IS NULL  -- –¢–æ–ª—å–∫–æ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
                LIMIT ? OFFSET ?
            """,
                (limit, offset),
            )

            tracks = cursor.fetchall()
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(tracks)} –ø–µ—Å–µ–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

            successful = 0
            failed = 0

            for i, track in enumerate(tracks, 1):
                try:
                    logger.info(
                        f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {i}/{len(tracks)} - {song['artist']} - {song['title']}"
                    )

                    analysis = self.analyze_song(
                        song["artist"], song["title"], song["lyrics"]
                    )

                    if analysis:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
                        self._save_analysis_to_db(conn, song["id"], analysis)
                        successful += 1
                        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω –∞–Ω–∞–ª–∏–∑ #{successful}")
                    else:
                        failed += 1
                        logger.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å")

                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    if i < len(tracks):  # –ù–µ –¥–µ–ª–∞–µ–º –ø–∞—É–∑—É –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–µ—Å–Ω–∏
                        time.sleep(2)  # 2 —Å–µ–∫—É–Ω–¥—ã –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∞–º–∏

                except Exception as e:
                    failed += 1
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Å–Ω–∏ {song['id']}: {e}")
                    continue

            conn.close()

            logger.info(f"""
            üéâ Batch –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!
            ‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}
            ‚ùå –û—à–∏–±–æ–∫: {failed}
            üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {self.get_stats()}
            """)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ batch –∞–Ω–∞–ª–∏–∑–∞: {e}")

    def _save_analysis_to_db(
        self, conn: sqlite3.Connection, song_id: int, analysis: EnhancedSongData
    ):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn.execute(
                """
                INSERT INTO ai_analysis (
                    song_id, genre, mood, energy_level, explicit_content,
                    structure, rhyme_scheme, complexity_level, main_themes,
                    authenticity_score, lyrical_creativity, commercial_appeal,
                    uniqueness, overall_quality, ai_likelihood,
                    analysis_date, model_version
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    song_id,
                    analysis.metadata.genre,
                    analysis.metadata.mood,
                    analysis.metadata.energy_level,
                    analysis.metadata.explicit_content,
                    analysis.lyrics_analysis.structure,
                    analysis.lyrics_analysis.rhyme_scheme,
                    analysis.lyrics_analysis.complexity_level,
                    json.dumps(analysis.lyrics_analysis.main_themes),
                    analysis.quality_metrics.authenticity_score,
                    analysis.quality_metrics.lyrical_creativity,
                    analysis.quality_metrics.commercial_appeal,
                    analysis.quality_metrics.uniqueness,
                    analysis.quality_metrics.overall_quality,
                    analysis.quality_metrics.ai_likelihood,
                    analysis.analysis_date,
                    analysis.model_used,
                ),
            )
            conn.commit()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")
            raise

    def analyze_song_with_safety(
        self, artist: str, title: str, lyrics: str
    ) -> dict | None:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –¥–µ—Ç–µ–∫—Ü–∏–µ–π –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π"""

        logger.info(f"üõ°Ô∏è –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {artist} - {title}")

        # 1. –í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        analysis_result = self.analyze_song(artist, title, lyrics)

        if not analysis_result:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
            return None

        # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        analysis_dict = {
            "genre": analysis_result.metadata.genre,
            "mood": analysis_result.metadata.mood,
            "energy_level": analysis_result.metadata.energy_level,
            "explicit_content": analysis_result.metadata.explicit_content,
            "structure": analysis_result.lyrics_analysis.structure,
            "rhyme_scheme": analysis_result.lyrics_analysis.rhyme_scheme,
            "complexity_level": analysis_result.lyrics_analysis.complexity_level,
            "main_themes": analysis_result.lyrics_analysis.main_themes,
            "authenticity_score": analysis_result.quality_metrics.authenticity_score,
            "lyrical_creativity": analysis_result.quality_metrics.lyrical_creativity,
            "commercial_appeal": analysis_result.quality_metrics.commercial_appeal,
            "uniqueness": analysis_result.quality_metrics.uniqueness,
            "overall_quality": analysis_result.quality_metrics.overall_quality,
            "ai_likelihood": analysis_result.quality_metrics.ai_likelihood,
        }

        # 3. –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ SafetyValidator
        validation_result = self.safety_validator.validate_analysis(
            lyrics, analysis_dict
        )

        # 4. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        logger.info(
            f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {validation_result['validation_summary']}"
        )

        if not validation_result["is_reliable"]:
            logger.warning("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–Ω –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã–º!")
            logger.warning(
                f"   ‚Ä¢ –†–∏—Å–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π: {validation_result['hallucination_risk']:.3f}"
            )
            logger.warning(
                f"   ‚Ä¢ –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: {validation_result['consistency_score']:.3f}"
            )
            logger.warning(
                f"   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å —Ñ–∞–∫—Ç–æ–≤: {validation_result['factual_accuracy']:.3f}"
            )

            if validation_result["warning_flags"]:
                logger.warning(
                    f"   ‚Ä¢ –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {', '.join(validation_result['warning_flags'])}"
                )
        else:
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
            logger.info(
                f"   ‚Ä¢ –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å: {validation_result['reliability_score']:.3f}"
            )

        # 5. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return {
            "analysis": analysis_result,
            "validation": validation_result,
            "is_safe": validation_result["is_reliable"],
            "confidence": validation_result["reliability_score"],
            "warnings": validation_result["warning_flags"],
            "summary": validation_result["validation_summary"],
        }


def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å—é"""

    print("ü§ñ –ú–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏ —Ä–µ—à–µ–Ω–∏–π")
    print("=" * 70)

    try:
        analyzer = MultiModelAnalyzer()

        print(f"üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã: {[p.name for p in analyzer.providers]}")
        print(
            f"üéØ –ê–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {analyzer.current_provider.name if analyzer.current_provider else 'None'}"
        )

        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
        print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏...")

        # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –ø–µ—Å–Ω–∏
        test_lyrics = """
        –Ø —Å —É–ª–∏—Ü—ã, —Ä–∞–π–æ–Ω –º–µ–Ω—è –≤–æ—Å–ø–∏—Ç–∞–ª
        –í –ø–æ–¥—ä–µ–∑–¥–∞—Ö —Ç–µ–º–Ω—ã—Ö –ø—Ä–∞–≤–¥—É –ø–æ–∑–Ω–∞–≤–∞–ª
        –ú–æ–ª–æ–¥–æ—Å—Ç—å –ø—Ä–æ—à–ª–∞ –≤ –¥—ã–º—É –∏ –¥—Ä–∞–∫–∞—Ö
        –¢–µ–ø–µ—Ä—å —á–∏—Ç–∞—é –ø—Ä–∞–≤–¥—É –≤ —ç—Ç–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö
        
        –î–µ–Ω—å–≥–∏, —Å–ª–∞–≤–∞ - –≤—Å–µ —ç—Ç–æ –ø—É—Å—Ç–æ—Ç–∞
        –ì–ª–∞–≤–Ω–æ–µ –æ—Å—Ç–∞—Ç—å—Å—è —Å–æ–±–æ–π –¥–æ –∫–æ–Ω—Ü–∞
        –°–µ–º—å—è –∏ –≤–µ—Ä–Ω—ã–µ –¥—Ä—É–∑—å—è —Ä—è–¥–æ–º
        –≠—Ç–æ –±–æ–≥–∞—Ç—Å—Ç–≤–æ, –∞ –Ω–µ —Ñ–∞–ª—å—à–∏–≤—ã–π —è–¥
        """

        # –ê–Ω–∞–ª–∏–∑ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
        explainable_result = analyzer.analyze_with_explanations(
            "–¢–µ—Å—Ç–æ–≤—ã–π –∞—Ä—Ç–∏—Å—Ç", "–¢–µ—Å—Ç–æ–≤—ã–π —Ç—Ä–µ–∫", test_lyrics
        )

        if explainable_result:
            print("\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê –° –û–ë–™–Ø–°–ù–ï–ù–ò–Ø–ú–ò:")
            print("-" * 50)

            # –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑
            analysis = explainable_result.analysis
            print(f"üéµ –ñ–∞–Ω—Ä: {analysis.metadata.genre}")
            print(f"üòä –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {analysis.metadata.mood}")
            print(f"‚ö° –≠–Ω–µ—Ä–≥–∏—è: {analysis.metadata.energy_level}")
            print(f"üèÜ –ö–∞—á–µ—Å—Ç–≤–æ: {analysis.quality_metrics.overall_quality}")
            print(f"üîç –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {explainable_result.confidence:.2f}")

            # –û–±—ä—è—Å–Ω–µ–Ω–∏—è
            print("\nüí° –û–ë–™–Ø–°–ù–ï–ù–ò–Ø –†–ï–®–ï–ù–ò–ô:")
            for category, explanations in explainable_result.explanation.items():
                if explanations:
                    print(f"  {category.replace('_', ' ').title()}:")
                    for exp in explanations:
                        print(f"    ‚Ä¢ {exp}")

            # –í–ª–∏—è—Ç–µ–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
            print("\nüìù –í–õ–ò–Ø–¢–ï–õ–¨–ù–´–ï –§–†–ê–ó–´:")
            for category, phrases in explainable_result.influential_phrases.items():
                if phrases:
                    print(f"  {category.replace('_', ' ').title()}:")
                    for phrase in phrases[:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2
                        print(f"    ‚Ä¢ '{phrase}'")

            # –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            print("\nüìä –ö–õ–Æ–ß–ï–í–´–ï –§–ê–ö–¢–û–†–´ (—Ç–æ–ø-5):")
            top_factors = sorted(
                explainable_result.decision_factors.items(),
                key=lambda x: x[1],
                reverse=True,
            )[:5]
            for factor, value in top_factors:
                print(f"  ‚Ä¢ {factor.replace('_', ' ').title()}: {value:.3f}")

        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
        explanation = analyzer.explain_existing_analysis(song_id=1)

        if explanation:
            print(
                f"\nüéµ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–ª—è: {explanation['song_info']['artist']} - {explanation['song_info']['title']}"
            )
            print(f"üîç –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {explanation['confidence']:.2f}")
            print(
                f"üí° –û—Å–Ω–æ–≤–Ω—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {len(explanation['explanation']['genre_indicators'])} –∂–∞–Ω—Ä–æ–≤—ã—Ö, "
                f"{len(explanation['explanation']['mood_triggers'])} –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è"
            )

        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è SafetyValidator
        print("\nüõ°Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AI Safety & Hallucination Detection...")

        # –¢–µ—Å—Ç —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        problematic_lyrics = """
        –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç
        """

        safe_result = analyzer.analyze_song_with_safety(
            "Test Artist", "Problematic Track", problematic_lyrics
        )

        if safe_result:
            print("\nüõ°Ô∏è –†–ï–ó–£–õ–¨–¢–ê–¢ –ë–ï–ó–û–ü–ê–°–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê:")
            print("-" * 50)
            print(
                f"‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: {'–ù–ê–î–ï–ñ–ï–ù' if safe_result['is_safe'] else '–ù–ï–ù–ê–î–ï–ñ–ï–ù'}"
            )
            print(f"üîç –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {safe_result['confidence']:.3f}")
            print(f"üìù –†–µ–∑—é–º–µ: {safe_result['summary']}")

            if safe_result["warnings"]:
                print("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
                for warning in safe_result["warnings"]:
                    print(f"   ‚Ä¢ {warning}")

            # –î–µ—Ç–∞–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            validation = safe_result["validation"]
            print("\nüìä –î–ï–¢–ê–õ–ò –í–ê–õ–ò–î–ê–¶–ò–ò:")
            print(f"   ‚Ä¢ –†–∏—Å–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π: {validation['hallucination_risk']:.3f}")
            print(f"   ‚Ä¢ –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: {validation['consistency_score']:.3f}")
            print(f"   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å —Ñ–∞–∫—Ç–æ–≤: {validation['factual_accuracy']:.3f}")
            print(f"   ‚Ä¢ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–∫—Å—Ç—É: {validation['text_alignment']:.3f}")

        # –¢–µ—Å—Ç —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        print("\nüîÑ –¢–µ—Å—Ç —Å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º...")
        normal_safe_result = analyzer.analyze_song_with_safety(
            "–¢–µ—Å—Ç–æ–≤—ã–π –∞—Ä—Ç–∏—Å—Ç", "–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç—Ä–µ–∫", test_lyrics
        )

        if normal_safe_result:
            print(
                f"‚úÖ –ù–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç: {'–ù–ê–î–ï–ñ–ï–ù' if normal_safe_result['is_safe'] else '–ù–ï–ù–ê–î–ï–ñ–ï–ù'}"
            )
            print(f"üîç –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {normal_safe_result['confidence']:.3f}")
            print(f"üìù –†–µ–∑—é–º–µ: {normal_safe_result['summary']}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = analyzer.get_stats()
        print("\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {stats['total_analyzed']}")
        print(f"  ‚Ä¢ Ollama –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {stats['ollama_used']} —Ä–∞–∑")
        print(f"  ‚Ä¢ Gemma –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {stats['gemma_used']} —Ä–∞–∑")
        print(f"  ‚Ä¢ Mock –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {stats['mock_used']} —Ä–∞–∑")
        print(f"  ‚Ä¢ –û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${stats['total_cost']:.4f}")

        print("\n‚úÖ AI Safety & Hallucination Detection - –ì–û–¢–û–í–û!")
        print("üõ°Ô∏è –¢–µ–ø–µ—Ä—å AI –∞–Ω–∞–ª–∏–∑ –≤–∫–ª—é—á–∞–µ—Ç:")
        print("   ‚Ä¢ Interpretability & Model Understanding")
        print("   ‚Ä¢ Safety & Hallucination Detection")
        print("   ‚Ä¢ Consistency Validation")
        print("   ‚Ä¢ Factual Accuracy Checking")
        print("üéØ –ü—Ä–æ–¥—É–∫—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏!")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()
