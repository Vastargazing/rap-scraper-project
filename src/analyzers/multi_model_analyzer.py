"""
Multi-model AI song analysis with safety validation and hallucination detection.

This module provides a comprehensive rap song analysis system that combines multiple
AI providers (Ollama, Google Gemma, Mock) with safety layers for hallucination
detection and result validation. Features interpretable AI with explanations for
each analysis decision.

Features:
    - Multi-provider architecture with automatic fallback (Ollama ‚Üí Gemma ‚Üí Mock)
    - Hallucination detection and safety validation layer
    - Explainable AI with detailed reasoning for each decision
    - Batch processing with progress tracking
    - Cost optimization using free models as priority
    - Comprehensive song analysis: genre, mood, energy, structure, quality metrics
    - PostgreSQL integration for persistent storage

Provider Priority:
    1. Ollama: Local models (free, no API key required)
    2. Google Gemma: Cloud API (requires GOOGLE_API_KEY env var)
    3. Mock: Fallback provider for testing/demo purposes

Dependencies:
    - Python 3.8+
    - asyncpg, psycopg2-binary: PostgreSQL connectivity
    - ollama: Local model framework
    - google-generativeai: Gemma API client
    - pydantic: Data validation models
    - requests: HTTP requests

Analysis Output:
    - Complete genre, mood, energy, and structure analysis
    - Quality metrics: authenticity, creativity, commercial appeal
    - Reliability validation: hallucination detection, consistency checking
    - Decision explanations: AI reasoning for each analysis element
    - Metadata and timestamps for audit trails

Author: AI Assistant
Version: 3.0 (Multi-Model with Interpretability & Safety)
"""

import asyncio
import json
import logging
import os
import re
from datetime import datetime

import asyncpg
import psycopg2
import requests
from dotenv import load_dotenv
from psycopg2.extras import RealDictCursor
from pydantic import BaseModel, Field

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("ai_analysis.log", encoding="utf-8"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


# Load environment variables from .env file
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("ai_analysis.log", encoding="utf-8"),
        logging.StreamHandler(),
    ],
)


# ===== PostgreSQL Configuration =====
class DatabaseConfig:
    """PostgreSQL connection configuration"""

    host: str = os.getenv("POSTGRES_HOST", "localhost")
    port: int = int(os.getenv("POSTGRES_PORT", "5432"))
    database: str = os.getenv("POSTGRES_DATABASE", "rap_lyrics")
    username: str = os.getenv("POSTGRES_USERNAME", "rap_user")
    password: str = os.getenv("POSTGRES_PASSWORD", "securepassword123")
    max_connections: int = int(os.getenv("POSTGRES_MAX_CONNECTIONS", "20"))
    min_connections: int = int(os.getenv("POSTGRES_MIN_CONNECTIONS", "5"))


# ===== Data Models =====
class SongMetadata(BaseModel):
    """Song metadata model"""

    genre: str = Field(default="rap")
    mood: str = Field(default="neutral")
    energy_level: str = Field(default="medium")
    explicit_content: bool = Field(default=False)


class LyricsAnalysis(BaseModel):
    """Lyrics analysis model"""

    structure: str = Field(default="verse")
    rhyme_scheme: str = Field(default="unknown")
    complexity_level: str = Field(default="intermediate")
    main_themes: list[str] = Field(default_factory=list)
    emotional_tone: str = Field(default="neutral")
    storytelling_type: str = Field(default="conversational")
    wordplay_quality: str = Field(default="basic")


class QualityMetrics(BaseModel):
    """Quality metrics model"""

    authenticity_score: float = Field(default=0.5, ge=0.0, le=1.0)
    lyrical_creativity: float = Field(default=0.5, ge=0.0, le=1.0)
    commercial_appeal: float = Field(default=0.5, ge=0.0, le=1.0)
    uniqueness: float = Field(default=0.5, ge=0.0, le=1.0)
    overall_quality: str = Field(default="fair")
    ai_likelihood: float = Field(default=0.5, ge=0.0, le=1.0)


class EnhancedSongData(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç AI –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Å–Ω–∏"""

    artist: str
    title: str
    metadata: SongMetadata
    lyrics_analysis: LyricsAnalysis
    quality_metrics: QualityMetrics
    model_used: str
    analysis_date: str


class ExplainableAnalysisResult(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏"""

    analysis: EnhancedSongData
    explanation: dict[str, list[str]]
    confidence: float
    decision_factors: dict[str, float]
    influential_phrases: dict[str, list[str]]


# ===== PostgreSQL Database Manager =====
class PostgreSQLManager:
    """PostgreSQL connection manager with async support"""

    def __init__(self, config: DatabaseConfig = None):
        self.config = config or DatabaseConfig()
        self.pool = None
        self.logger = logging.getLogger(f"{__name__}.PostgreSQLManager")

    async def initialize(self) -> bool:
        """Initialize connection pool"""
        try:
            self.logger.info("Initializing PostgreSQL connection pool")

            dsn = f"postgresql://{self.config.username}:{self.config.password}@{self.config.host}:{self.config.port}/{self.config.database}"

            self.pool = await asyncpg.create_pool(
                dsn,
                min_size=self.config.min_connections,
                max_size=self.config.max_connections,
                command_timeout=60,
                server_settings={
                    "application_name": "multi_model_analyzer",
                    "timezone": "UTC",
                },
            )

            # Test connection
            async with self.pool.acquire() as conn:
                await conn.execute("SELECT 1")

            self.logger.info("‚úÖ PostgreSQL connection pool initialized successfully")
            return True

        except Exception as e:
            self.logger.error(f"‚ùå Failed to initialize PostgreSQL: {e}")
            return False

    async def get_connection(self):
        """Get database connection from pool"""
        if not self.pool:
            await self.initialize()
        return self.pool.acquire()

    async def close(self):
        """Close connection pool"""
        if self.pool:
            await self.pool.close()
            self.pool = None

    def get_sync_connection(self):
        """Get synchronous connection for non-async operations"""
        return psycopg2.connect(
            host=self.config.host,
            port=self.config.port,
            database=self.config.database,
            user=self.config.username,
            password=self.config.password,
            cursor_factory=RealDictCursor,
        )


class SafetyValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ AI –∞–Ω–∞–ª–∏–∑–∞ –∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π"""

    def __init__(self):
        # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–µ–º–∞—Ç–∏–∫ (English-focused)
        self.theme_keywords = {
            "money": [
                "cash",
                "money",
                "dollars",
                "bands",
                "racks",
                "bread",
                "paper",
                "coins",
                "wealth",
                "riches",
                "bank",
                "rich",
                "fortune",
            ],
            "relationships": [
                "love",
                "girl",
                "boy",
                "girlfriend",
                "boyfriend",
                "wife",
                "husband",
                "family",
                "bae",
                "baby",
                "relationship",
                "romance",
            ],
            "street_life": [
                "street",
                "block",
                "neighborhood",
                "ghetto",
                "projects",
                "corners",
                "trap",
                "streets",
                "hood",
                "city",
                "urban",
            ],
            "success": [
                "success",
                "famous",
                "star",
                "career",
                "achievement",
                "winning",
                "made it",
                "top",
                "win",
                "champion",
                "glory",
            ],
            "struggle": [
                "struggle",
                "pain",
                "problems",
                "hardship",
                "suffering",
                "tough",
                "hard times",
                "grind",
                "difficult",
                "rough",
            ],
            "drugs": [
                "drugs",
                "molly",
                "xanax",
                "percs",
                "pills",
                "cocaine",
                "heroin",
                "marijuana",
                "cannabis",
                "weed",
                "lean",
                "high",
            ],
            "violence": [
                "war",
                "fight",
                "murder",
                "blood",
                "gun",
                "knife",
                "shoot",
                "kill",
                "weapon",
                "violence",
                "battle",
                "beef",
            ],
            "party": [
                "party",
                "club",
                "dance",
                "fun",
                "alcohol",
                "beer",
                "drunk",
                "drinking",
                "turn up",
                "lit",
                "celebration",
            ],
            "depression": [
                "depression",
                "sad",
                "suicide",
                "death",
                "lonely",
                "sorrow",
                "depressed",
                "dark",
                "pain",
                "hurt",
                "broken",
            ],
            "social_issues": [
                "politics",
                "society",
                "system",
                "power",
                "protest",
                "revolution",
                "government",
                "social",
                "justice",
                "change",
            ],
        }

        # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π (English-focused)
        self.mood_indicators = {
            "aggressive": [
                "hate",
                "angry",
                "mad",
                "kill",
                "war",
                "blood",
                "fight",
                "rage",
                "fury",
                "violence",
                "beef",
                "pissed",
            ],
            "melancholic": [
                "sad",
                "sadness",
                "tears",
                "depression",
                "lonely",
                "pain",
                "hurt",
                "broken",
                "crying",
                "sorrow",
            ],
            "energetic": [
                "party",
                "club",
                "dance",
                "hype",
                "lit",
                "turn up",
                "wild",
                "crazy",
                "bounce",
                "jump",
                "energy",
            ],
            "neutral": [
                "talking",
                "telling",
                "thinking",
                "know",
                "remember",
                "see",
                "saying",
                "speaking",
                "telling",
            ],
        }

        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
        self.consistency_threshold = 0.6  # –ü–æ–Ω–∏–∂–µ–Ω –¥–ª—è –±–æ–ª–µ–µ –≥–∏–±–∫–æ–π –æ—Ü–µ–Ω–∫–∏
        self.hallucination_threshold = 0.4  # –ü–æ–≤—ã—à–µ–Ω –¥–ª—è —Å—Ç—Ä–æ–≥–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π

    def validate_analysis(self, lyrics: str, ai_analysis: dict) -> dict:
        """–ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ AI –∞–Ω–∞–ª–∏–∑–∞"""

        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        consistency_score = self.check_internal_consistency(ai_analysis)

        # 2. –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π
        factual_accuracy = self.validate_factual_claims(lyrics, ai_analysis)

        # 3. –î–µ—Ç–µ–∫—Ü–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
        hallucination_risk = self.detect_hallucinations(lyrics, ai_analysis)

        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞
        text_alignment = self.check_text_analysis_alignment(lyrics, ai_analysis)

        # 5. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—é—â–∏—Ö —Ñ–ª–∞–≥–æ–≤
        warning_flags = self.get_warning_flags(ai_analysis, lyrics)

        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        is_reliable = (
            hallucination_risk < self.hallucination_threshold
            and consistency_score > self.consistency_threshold
            and factual_accuracy > 0.5  # –ü–æ–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥
            and text_alignment > 0.4  # –ü–æ–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥
            and len(warning_flags) == 0  # –ù–∏–∫–∞–∫–∏—Ö –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        )

        return {
            "is_reliable": is_reliable,
            "reliability_score": (consistency_score + factual_accuracy + text_alignment)
            / 3,
            "consistency_score": consistency_score,
            "factual_accuracy": factual_accuracy,
            "hallucination_risk": hallucination_risk,
            "text_alignment": text_alignment,
            "warning_flags": warning_flags,
            "validation_summary": self._generate_validation_summary(
                is_reliable, hallucination_risk, consistency_score, warning_flags
            ),
        }

    def detect_hallucinations(self, lyrics: str, analysis: dict) -> float:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –≤ AI –∞–Ω–∞–ª–∏–∑–µ"""
        hallucination_score = 0.0
        lyrics_lower = lyrics.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞—è–≤–ª–µ–Ω–Ω—ã–µ —Ç–µ–º—ã
        if "main_themes" in analysis:
            claimed_themes = analysis["main_themes"]
            if isinstance(claimed_themes, list):
                for theme in claimed_themes:
                    if not self.theme_present_in_lyrics(theme, lyrics_lower):
                        hallucination_score += 0.15
                        logger.warning(
                            f"üö® Possible hallucination: theme '{theme}' not found in lyrics"
                        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        if "mood" in analysis:
            claimed_mood = analysis["mood"].lower()
            if not self.mood_supported_by_lyrics(claimed_mood, lyrics_lower):
                hallucination_score += 0.2
                logger.warning(
                    f"üö® Possible hallucination: mood '{claimed_mood}' not supported by lyrics"
                )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∂–∞–Ω—Ä (–º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–æ, —Ç–∞–∫ –∫–∞–∫ –∂–∞–Ω—Ä –º–æ–∂–µ—Ç –±—ã—Ç—å –º—É–∑—ã–∫–∞–ª—å–Ω—ã–º)
        if "genre" in analysis:
            claimed_genre = analysis["genre"].lower()
            if (
                claimed_genre in ["classical", "jazz", "country"]
                and "rap" not in lyrics_lower
            ):
                hallucination_score += 0.3  # –Ø–≤–Ω–æ –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–π –∂–∞–Ω—Ä

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º explicit content
        if "explicit_content" in analysis:
            claimed_explicit = analysis["explicit_content"]
            actual_explicit = self.detect_explicit_content(lyrics_lower)
            if claimed_explicit != actual_explicit:
                hallucination_score += 0.1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å
        if "authenticity_score" in analysis:
            auth_score = analysis["authenticity_score"]
            if isinstance(auth_score, (int, float)):
                if (
                    auth_score > 0.9 and len(lyrics.split()) < 50
                ):  # –í—ã—Å–æ–∫–∞—è –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –∫–æ—Ä–æ—Ç–∫–æ–º —Ç–µ–∫—Å—Ç–µ
                    hallucination_score += 0.1

        return min(hallucination_score, 1.0)

    def theme_present_in_lyrics(self, theme: str, lyrics_lower: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Ç–µ–º–∞ –≤ —Ç–µ–∫—Å—Ç–µ –ø–µ—Å–Ω–∏"""
        theme_lower = theme.lower().replace("_", " ")

        # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if theme_lower in lyrics_lower:
            return True

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        if theme_lower in self.theme_keywords:
            keywords = self.theme_keywords[theme_lower]
            found_keywords = sum(1 for keyword in keywords if keyword in lyrics_lower)
            return found_keywords >= 1  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–¥–Ω–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞

        # –ß–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö —Ç–µ–º (English-focused)
        if "street" in theme_lower and any(
            word in lyrics_lower
            for word in ["street", "block", "hood", "neighborhood", "ghetto"]
        ):
            return True
        if "money" in theme_lower and any(
            word in lyrics_lower
            for word in ["cash", "money", "dollars", "bands", "racks", "bread"]
        ):
            return True
        if "love" in theme_lower and any(
            word in lyrics_lower
            for word in ["love", "girl", "relationship", "girlfriend", "romance"]
        ):
            return True

        return False

    def mood_supported_by_lyrics(self, mood: str, lyrics_lower: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–∞—è–≤–ª–µ–Ω–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç—É"""
        if mood in self.mood_indicators:
            indicators = self.mood_indicators[mood]
            found_indicators = sum(
                1 for indicator in indicators if indicator in lyrics_lower
            )
            return found_indicators >= 1

        # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True (–Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å)
        return True

    def detect_explicit_content(self, lyrics_lower: str) -> bool:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç explicit –∫–æ–Ω—Ç–µ–Ω—Ç –≤ —Ç–µ–∫—Å—Ç–µ (English-focused)"""
        explicit_words = [
            "fuck",
            "shit",
            "bitch",
            "asshole",
            "damn",
            "hell",
            "pussy",
            "dick",
            "cock",
            "motherfucker",
            "nigga",
            "nigger",
            "whore",
            "slut",
            "cunt",
            "bastard",
            "piss",
        ]
        return any(word in lyrics_lower for word in explicit_words)

    def check_internal_consistency(self, analysis: dict) -> float:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞"""
        consistency_score = 1.0

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∏ —ç–Ω–µ—Ä–≥–∏–∏
        mood = analysis.get("mood", "").lower()
        energy = analysis.get("energy_level", "").lower()

        # –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
        if mood == "melancholic" and energy == "high":
            consistency_score -= 0.2  # –ì—Ä—É—Å—Ç–Ω–∞—è, –Ω–æ —ç–Ω–µ—Ä–≥–∏—á–Ω–∞—è - –≤–æ–∑–º–æ–∂–Ω–æ
        if mood == "aggressive" and energy == "low":
            consistency_score -= 0.3  # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è, –Ω–æ –Ω–∏–∑–∫–∞—è —ç–Ω–µ—Ä–≥–∏—è - —Å—Ç—Ä–∞–Ω–Ω–æ

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if "authenticity_score" in analysis and "commercial_appeal" in analysis:
            auth = analysis["authenticity_score"]
            commercial = analysis["commercial_appeal"]
            if isinstance(auth, (int, float)) and isinstance(commercial, (int, float)):
                # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å –ò –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –∞–ø–ø–µ–∞–ª - —Ä–µ–¥–∫–æ
                if auth > 0.9 and commercial > 0.9:
                    consistency_score -= 0.2

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
        complexity = analysis.get("complexity_level", "").lower()
        overall_quality = analysis.get("overall_quality", "").lower()

        if complexity == "advanced" and overall_quality == "poor":
            consistency_score -= 0.2
        if complexity == "beginner" and overall_quality == "excellent":
            consistency_score -= 0.1

        return max(consistency_score, 0.0)

    def validate_factual_claims(self, lyrics: str, analysis: dict) -> float:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≤ –∞–Ω–∞–ª–∏–∑–µ"""
        factual_score = 1.0
        lyrics_lower = lyrics.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        claimed_structure = analysis.get("structure", "").lower()
        if claimed_structure:
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            lines = [line for line in lyrics.split("\n") if line.strip()]

            if "verse-chorus-verse" in claimed_structure and len(lines) < 8:
                factual_score -= 0.2  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —Ç–∞–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            if "hook" in claimed_structure and len(lines) > 20:
                factual_score -= 0.1  # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –¥–ª—è hook

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–µ–º—É —Ä–∏—Ñ–º
        rhyme_scheme = analysis.get("rhyme_scheme", "").lower()
        if rhyme_scheme and rhyme_scheme != "unknown":
            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∏—Ñ–º
            lines = [line.strip() for line in lyrics.split("\n") if line.strip()]
            if len(lines) >= 4:
                # –ï—Å–ª–∏ –∑–∞—è–≤–ª–µ–Ω–∞ —Å–ª–æ–∂–Ω–∞—è —Å—Ö–µ–º–∞, –Ω–æ —Ç–µ–∫—Å—Ç –ø—Ä–æ—Å—Ç–æ–π
                if (
                    "complex" in rhyme_scheme
                    and len(set(line.split()[-1] for line in lines[:4] if line.split()))
                    == 1
                ):
                    factual_score -= 0.1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ vs —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        word_count = len(lyrics.split())
        complexity = analysis.get("complexity_level", "").lower()

        if complexity == "advanced" and word_count < 100:
            factual_score -= 0.2
        if complexity == "beginner" and word_count > 500:
            factual_score -= 0.1

        return max(factual_score, 0.0)

    def check_text_analysis_alignment(self, lyrics: str, analysis: dict) -> float:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –∞–Ω–∞–ª–∏–∑–æ–º"""
        alignment_score = 1.0
        lyrics_lower = lyrics.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞ –∏ –¥–µ—Ç–∞–ª—å–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞
        word_count = len(lyrics.split())

        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π, –Ω–æ –∞–Ω–∞–ª–∏–∑ –æ—á–µ–Ω—å –¥–µ—Ç–∞–ª—å–Ω—ã–π - –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
        if word_count < 50:
            detailed_fields = sum(
                1
                for key in ["main_themes", "structure", "rhyme_scheme"]
                if analysis.get(key)
            )
            if detailed_fields > 2:
                alignment_score -= 0.2

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º explicit content alignment
        actual_explicit = self.detect_explicit_content(lyrics_lower)
        claimed_explicit = analysis.get("explicit_content", False)

        if actual_explicit != claimed_explicit:
            alignment_score -= 0.3

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º energy level alignment
        energy = analysis.get("energy_level", "").lower()
        exclamation_count = lyrics.count("!")
        caps_ratio = sum(1 for c in lyrics if c.isupper()) / max(len(lyrics), 1)

        if energy == "high" and exclamation_count == 0 and caps_ratio < 0.05:
            alignment_score -= 0.2
        if energy == "low" and exclamation_count > 5:
            alignment_score -= 0.2

        return max(alignment_score, 0.0)

    def get_warning_flags(self, analysis: dict, lyrics: str) -> list:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—é—â–∏—Ö —Ñ–ª–∞–≥–æ–≤"""
        flags = []

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–µ –æ—Ü–µ–Ω–∫–∏
        if analysis.get("authenticity_score", 0) > 0.95:
            flags.append("SUSPICIOUSLY_HIGH_AUTHENTICITY")

        if analysis.get("uniqueness", 0) > 0.95:
            flags.append("SUSPICIOUSLY_HIGH_UNIQUENESS")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª–∏–Ω—ã –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        word_count = len(lyrics.split())
        complexity = analysis.get("complexity_level", "").lower()

        if word_count < 50 and complexity == "advanced":
            flags.append("SHORT_TEXT_HIGH_COMPLEXITY")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–µ–º –≤ –∫–æ—Ä–æ—Ç–∫–æ–º —Ç–µ–∫—Å—Ç–µ
        themes = analysis.get("main_themes", [])
        if word_count < 100 and len(themes) > 4:
            flags.append("SHORT_TEXT_MANY_THEMES")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        mood = analysis.get("mood", "").lower()
        commercial = analysis.get("commercial_appeal", 0)

        if mood == "melancholic" and commercial > 0.8:
            flags.append("SAD_MOOD_HIGH_COMMERCIAL")

        return flags

    def _generate_validation_summary(
        self,
        is_reliable: bool,
        hallucination_risk: float,
        consistency_score: float,
        warning_flags: list,
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        if is_reliable:
            return f"‚úÖ –ê–Ω–∞–ª–∏–∑ –Ω–∞–¥–µ–∂–µ–Ω (—Ä–∏—Å–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π: {hallucination_risk:.2f})"
        issues = []
        if hallucination_risk > 0.4:  # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥
            issues.append(f"–≤—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π ({hallucination_risk:.2f})")
        if consistency_score < 0.6:  # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥
            issues.append(f"–Ω–∏–∑–∫–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å ({consistency_score:.2f})")
        if warning_flags:
            issues.append(f"–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {len(warning_flags)}")

        return f"‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ –Ω–µ–Ω–∞–¥–µ–∂–µ–Ω: {', '.join(issues)}"


class InterpretableAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏–π AI"""

    def __init__(self, base_analyzer):
        self.base_analyzer = base_analyzer

        # –°–ª–æ–≤–∞—Ä–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        self.genre_keywords = {
            "trap": ["trap", "–º–æ–ª–ª–∏", "lean", "xanax", "—Å–∫—Ä—Ä", "–π–∞", "bando", "plug"],
            "drill": ["drill", "smoke", "opps", "block", "gang", "sliding", "packed"],
            "old_school": [
                "boom bap",
                "real hip hop",
                "90s",
                "golden era",
                "conscious",
            ],
            "gangsta": ["glock", "ak", "blood", "crip", "hood", "street", "thug"],
            "emo_rap": [
                "–¥–µ–ø—Ä–µ—Å—Å–∏—è",
                "—Å—É–∏—Ü–∏–¥",
                "–±–æ–ª—å",
                "–≥—Ä—É—Å—Ç—å",
                "–æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ",
                "—Å–ª–µ–∑—ã",
            ],
        }

        self.mood_keywords = {
            "aggressive": ["—É–±—å—é", "–≤–æ–π–Ω–∞", "–∫—Ä–æ–≤—å", "–¥—Ä–∞–∫–∞", "hate", "angry", "mad"],
            "melancholic": ["–≥—Ä—É—Å—Ç—å", "–ø–µ—á–∞–ª—å", "—Å–ª–µ–∑—ã", "–¥–µ–ø—Ä–µ—Å—Å–∏—è", "–æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ"],
            "energetic": ["party", "club", "dance", "energy", "–≤–ø–µ—Ä–µ–¥", "–¥–≤–∏–∂–µ–Ω–∏–µ"],
            "chill": ["—Ä–∞—Å—Å–ª–∞–±–æ–Ω", "—Å–ø–æ–∫–æ–π–Ω–æ", "–º–µ–¥–ª–µ–Ω–Ω–æ", "vibe", "–∞—Ç–º–æ—Å—Ñ–µ—Ä–∞"],
        }

        self.authenticity_keywords = {
            "real": ["–ø—Ä–∞–≤–¥–∞", "—Ä–µ–∞–ª—å–Ω–æ", "—á–µ—Å—Ç–Ω–æ", "–±–µ–∑ —Ñ–∞–ª—å—à–∏", "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É"],
            "fake": ["–ø–æ–Ω—Ç", "—Ñ–µ–π–∫", "–ø–∏–∂–æ–Ω", "–ø–æ–∫–∞–∑—É—Ö–∞", "–ø—Ä–∏—Ç–≤–æ—Ä—Å—Ç–≤–æ"],
            "street": ["—É–ª–∏—Ü–∞", "—Ä–∞–π–æ–Ω", "–¥–≤–æ—Ä", "–ø–æ–¥—ä–µ–∑–¥", "–∫–≤–∞—Ä—Ç–∞–ª", "–≥–µ—Ç—Ç–æ"],
            "commercial": ["money", "brand", "–∫–æ–º–º–µ—Ä—Ü–∏—è", "–ø—Ä–æ–¥–∞–∂–∏", "mainstream"],
        }

    def analyze_with_explanation(
        self, artist: str, title: str, lyrics: str
    ) -> ExplainableAnalysisResult | None:
        """–ê–Ω–∞–ª–∏–∑ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º —Ä–µ—à–µ–Ω–∏–π"""
        try:
            # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
            base_result = self.base_analyzer.analyze_song(artist, title, lyrics)
            if not base_result:
                return None

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
            explanation = self.explain_decision(lyrics, base_result)
            confidence = self.calculate_confidence(base_result, lyrics)
            decision_factors = self.extract_key_factors(lyrics, base_result)
            influential_phrases = self.find_influential_phrases(lyrics, base_result)

            return ExplainableAnalysisResult(
                analysis=base_result,
                explanation=explanation,
                confidence=confidence,
                decision_factors=decision_factors,
                influential_phrases=influential_phrases,
            )

        except Exception as e:
            logging.error(f"‚åõ –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞: {e}")
            return None

    def explain_decision(
        self, lyrics: str, result: EnhancedSongData
    ) -> dict[str, list[str]]:
        """–û–±—ä—è—Å–Ω—è–µ—Ç, –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–µ–≥–æ –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω—è–ª–∞ —Ä–µ—à–µ–Ω–∏–µ"""
        lyrics_lower = lyrics.lower()
        explanations = {
            "genre_indicators": [],
            "mood_triggers": [],
            "authenticity_markers": [],
            "quality_indicators": [],
        }

        # –ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        detected_genre = result.metadata.genre.lower()
        for genre, keywords in self.genre_keywords.items():
            if genre in detected_genre:
                found_keywords = [kw for kw in keywords if kw in lyrics_lower]
                if found_keywords:
                    explanations["genre_indicators"].extend(
                        [
                            f"–ñ–∞–Ω—Ä '{genre}' –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ —Å–ª–æ–≤–∞–º: {', '.join(found_keywords[:3])}"
                        ]
                    )

        # –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        detected_mood = result.metadata.mood.lower()
        for mood, keywords in self.mood_keywords.items():
            if mood in detected_mood:
                found_keywords = [kw for kw in keywords if kw in lyrics_lower]
                if found_keywords:
                    explanations["mood_triggers"].extend(
                        [
                            f"–ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ '{mood}' –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –ø–æ —Å–ª–æ–≤–∞–º: {', '.join(found_keywords[:3])}"
                        ]
                    )

        # –ê–Ω–∞–ª–∏–∑ –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏
        auth_score = result.quality_metrics.authenticity_score
        if auth_score > 0.7:
            real_words = [
                kw for kw in self.authenticity_keywords["real"] if kw in lyrics_lower
            ]
            street_words = [
                kw for kw in self.authenticity_keywords["street"] if kw in lyrics_lower
            ]
            if real_words or street_words:
                explanations["authenticity_markers"].append(
                    f"–í—ã—Å–æ–∫–∞—è –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å ({auth_score:.2f}) –±–ª–∞–≥–æ–¥–∞—Ä—è: {', '.join((real_words + street_words)[:3])}"
                )
        elif auth_score < 0.4:
            fake_words = [
                kw for kw in self.authenticity_keywords["fake"] if kw in lyrics_lower
            ]
            commercial_words = [
                kw
                for kw in self.authenticity_keywords["commercial"]
                if kw in lyrics_lower
            ]
            if fake_words or commercial_words:
                explanations["authenticity_markers"].append(
                    f"–ù–∏–∑–∫–∞—è –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å ({auth_score:.2f}) –∏–∑-–∑–∞: {', '.join((fake_words + commercial_words)[:3])}"
                )

        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
        creativity = result.quality_metrics.lyrical_creativity
        wordplay = result.lyrics_analysis.wordplay_quality
        explanations["quality_indicators"].append(
            f"–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å: {creativity:.2f}, Wordplay: {wordplay}"
        )

        return explanations

    def calculate_confidence(self, result: EnhancedSongData, lyrics: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∞–Ω–∞–ª–∏–∑–µ"""
        confidence_factors = []

        # –§–∞–∫—Ç–æ—Ä 1: –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (–±–æ–ª—å—à–µ —Ç–µ–∫—Å—Ç–∞ = –±–æ–ª—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏)
        text_length_factor = min(len(lyrics) / 1000, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 1.0
        confidence_factors.append(text_length_factor * 0.2)

        # –§–∞–∫—Ç–æ—Ä 2: –ù–∞–ª–∏—á–∏–µ —è–≤–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∂–∞–Ω—Ä–∞
        genre_confidence = self._calculate_genre_confidence(
            lyrics, result.metadata.genre
        )
        confidence_factors.append(genre_confidence * 0.3)

        # –§–∞–∫—Ç–æ—Ä 3: –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_consistency = self._calculate_quality_consistency(
            result.quality_metrics
        )
        confidence_factors.append(quality_consistency * 0.3)

        # –§–∞–∫—Ç–æ—Ä 4: –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π (–∏–º–µ–Ω–∞, –º–µ—Å—Ç–∞, —Å–æ–±—ã—Ç–∏—è)
        detail_factor = self._calculate_detail_factor(lyrics)
        confidence_factors.append(detail_factor * 0.2)

        return min(sum(confidence_factors), 1.0)

    def _calculate_genre_confidence(self, lyrics: str, genre: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∂–∞–Ω—Ä–∞"""
        lyrics_lower = lyrics.lower()
        genre_lower = genre.lower()

        matching_keywords = 0
        total_keywords = 0

        for g, keywords in self.genre_keywords.items():
            if g in genre_lower:
                total_keywords = len(keywords)
                matching_keywords = sum(1 for kw in keywords if kw in lyrics_lower)
                break

        if total_keywords == 0:
            return 0.5  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∂–∞–Ω—Ä–æ–≤

        return matching_keywords / total_keywords

    def _calculate_quality_consistency(self, metrics: QualityMetrics) -> float:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
        scores = [
            metrics.authenticity_score,
            metrics.lyrical_creativity,
            metrics.commercial_appeal,
            metrics.uniqueness,
        ]

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
        mean_score = sum(scores) / len(scores)
        variance = sum((x - mean_score) ** 2 for x in scores) / len(scores)
        std_dev = variance**0.5

        # –ù–∏–∑–∫–æ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ = –≤—ã—Å–æ–∫–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
        consistency = max(0, 1 - (std_dev * 2))  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        return consistency

    def _calculate_detail_factor(self, lyrics: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π"""
        detail_indicators = [
            r"\b[A-Z][a-z]+\b",  # –ò–º–µ–Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ
            r"\b\d{4}\b",  # –ì–æ–¥—ã
            r"\b\d+[–∫–º]\b",  # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è
            r"\$\d+",  # –î–µ–Ω—å–≥–∏
            r"\b[–ê-–Ø–Å][–∞-—è—ë]+\b",  # –†—É—Å—Å–∫–∏–µ –∏–º–µ–Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ
        ]

        total_details = 0
        for pattern in detail_indicators:
            matches = re.findall(pattern, lyrics)
            total_details += len(matches)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞
        detail_density = total_details / max(len(lyrics.split()), 1)
        return min(detail_density * 10, 1.0)  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º

    def extract_key_factors(
        self, lyrics: str, result: EnhancedSongData
    ) -> dict[str, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –∞–Ω–∞–ª–∏–∑"""
        factors = {}
        lyrics_lower = lyrics.lower()

        # –ß–∞—Å—Ç–æ—Ç–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for category, keywords in {**self.genre_keywords, **self.mood_keywords}.items():
            keyword_count = sum(1 for kw in keywords if kw in lyrics_lower)
            factors[f"{category}_keywords"] = keyword_count / len(keywords)

        # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
        factors["text_length"] = min(len(lyrics) / 2000, 1.0)
        factors["line_count"] = min(len(lyrics.split("\n")) / 50, 1.0)
        factors["word_diversity"] = len(set(lyrics.lower().split())) / max(
            len(lyrics.split()), 1
        )

        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–∫ —Ñ–∞–∫—Ç–æ—Ä—ã
        factors["authenticity"] = result.quality_metrics.authenticity_score
        factors["creativity"] = result.quality_metrics.lyrical_creativity
        factors["commercial_appeal"] = result.quality_metrics.commercial_appeal
        factors["uniqueness"] = result.quality_metrics.uniqueness

        return factors

    def find_influential_phrases(
        self, lyrics: str, result: EnhancedSongData
    ) -> dict[str, list[str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–≤–ª–∏—è–ª–∏ –Ω–∞ –æ—Ü–µ–Ω–∫—É"""
        influential = {
            "genre_phrases": [],
            "mood_phrases": [],
            "authenticity_phrases": [],
            "quality_phrases": [],
        }

        lines = lyrics.split("\n")

        # –ü–æ–∏—Å–∫ –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑ –¥–ª—è –∂–∞–Ω—Ä–∞
        genre_lower = result.metadata.genre.lower()
        for genre, keywords in self.genre_keywords.items():
            if genre in genre_lower:
                for line in lines:
                    if any(kw in line.lower() for kw in keywords):
                        influential["genre_phrases"].append(line.strip())
                        if len(influential["genre_phrases"]) >= 3:
                            break

        # –ü–æ–∏—Å–∫ —Ñ—Ä–∞–∑ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        mood_lower = result.metadata.mood.lower()
        for mood, keywords in self.mood_keywords.items():
            if mood in mood_lower:
                for line in lines:
                    if any(kw in line.lower() for kw in keywords):
                        influential["mood_phrases"].append(line.strip())
                        if len(influential["mood_phrases"]) >= 3:
                            break

        # –ü–æ–∏—Å–∫ —Ñ—Ä–∞–∑ –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏
        auth_score = result.quality_metrics.authenticity_score
        auth_keywords = (
            self.authenticity_keywords["real"] + self.authenticity_keywords["street"]
        )
        if auth_score > 0.7:
            for line in lines:
                if any(kw in line.lower() for kw in auth_keywords):
                    influential["authenticity_phrases"].append(line.strip())
                    if len(influential["authenticity_phrases"]) >= 2:
                        break

        # –ü–æ–∏—Å–∫ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö wordplay —Ñ—Ä–∞–∑
        if result.lyrics_analysis.wordplay_quality == "excellent":
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ä–∏—Ñ–º–∞–º–∏ –∏–ª–∏ –∞–ª–ª–∏—Ç–µ—Ä–∞—Ü–∏–µ–π
            for line in lines:
                words = line.lower().split()
                if len(words) >= 4:
                    # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∏—Ñ–º—É (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è)
                    endings = [word[-2:] for word in words if len(word) > 3]
                    if (
                        len(set(endings)) < len(endings) * 0.8
                    ):  # –ú–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –æ–∫–æ–Ω—á–∞–Ω–∏–π
                        influential["quality_phrases"].append(line.strip())
                        if len(influential["quality_phrases"]) >= 2:
                            break

        return influential


class ModelProvider:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""

    def __init__(self, name: str):
        self.name = name
        self.available = False
        self.cost_per_1k_tokens = 0.0

    def check_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        raise NotImplementedError

    def analyze_song(
        self, artist: str, title: str, lyrics: str
    ) -> EnhancedSongData | None:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏"""
        raise NotImplementedError


class OllamaProvider(ModelProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Ollama"""

    def __init__(
        self, model_name: str = "llama3.2:3b", base_url: str = "http://localhost:11434"
    ):
        super().__init__("Ollama")
        self.model_name = model_name
        self.base_url = base_url
        self.cost_per_1k_tokens = 0.0  # –ë–µ—Å–ø–ª–∞—Ç–Ω–æ!
        self.available = self.check_availability()

    def check_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø—É—â–µ–Ω –ª–∏ Ollama"""
        try:
            response = requests.get(
                f"{self.base_url}/api/tags",
                timeout=5,
                proxies={"http": "", "https": ""},
            )
            if response.status_code == 200:
                models = response.json().get("models", [])
                available_models = [model["name"] for model in models]
                logger.info(f"ü¶ô Ollama –¥–æ—Å—Ç—É–ø–µ–Ω. –ú–æ–¥–µ–ª–∏: {available_models}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω–æ–π –º–æ–¥–µ–ª–∏
                if any(self.model_name in model for model in available_models):
                    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {self.model_name} –Ω–∞–π–¥–µ–Ω–∞")
                    return True
                logger.warning(
                    f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {self.model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏..."
                )
                return self._pull_model()
            return False
        except requests.exceptions.RequestException as e:
            logger.warning(f"‚åõ Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            return False

    def _pull_model(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
        try:
            logger.info(f"üî• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å {self.model_name}...")
            response = requests.post(
                f"{self.base_url}/api/pull",
                json={"name": self.model_name},
                timeout=300,  # 5 –º–∏–Ω—É—Ç –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É
                proxies={"http": "", "https": ""},
            )
            if response.status_code == 200:
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {self.model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                return True
            logger.error(f"‚åõ –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {response.text}")
            return False
        except Exception as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def analyze_song(
        self, artist: str, title: str, lyrics: str
    ) -> EnhancedSongData | None:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —á–µ—Ä–µ–∑ Ollama"""
        if not self.available:
            return None

        try:
            prompt = self._create_analysis_prompt(artist, title, lyrics)

            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
                        "top_p": 0.9,
                        "max_tokens": 1500,
                    },
                },
                timeout=60,
                proxies={"http": "", "https": ""},
            )

            if response.status_code == 200:
                result = response.json()
                analysis_text = result.get("response", "")
                return self._parse_analysis(analysis_text, artist, title)
            logger.error(f"‚åõ Ollama –æ—à–∏–±–∫–∞: {response.status_code} - {response.text}")
            return None

        except Exception as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Ollama: {e}")
            return None

    def _create_analysis_prompt(self, artist: str, title: str, lyrics: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        return f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä—ç–ø-–ø–µ—Å–Ω—é –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –°–¢–†–û–ì–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.

–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å: {artist}
–ù–∞–∑–≤–∞–Ω–∏–µ: {title}
–¢–µ–∫—Å—Ç: {lyrics[:2000]}...

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:

{{
    "metadata": {{
        "genre": "rap",
        "mood": "aggressive",
        "energy_level": "high",
        "explicit_content": true
    }},
    "lyrics_analysis": {{
        "structure": "verse-chorus-verse",
        "rhyme_scheme": "ABAB",
        "complexity_level": "advanced",
        "main_themes": ["street_life", "success", "relationships"],
        "emotional_tone": "mixed",
        "storytelling_type": "narrative",
        "wordplay_quality": "excellent"
    }},
    "quality_metrics": {{
        "authenticity_score": 0.8,
        "lyrical_creativity": 0.9,
        "commercial_appeal": 0.7,
        "uniqueness": 0.6,
        "overall_quality": "excellent",
        "ai_likelihood": 0.1
    }}
}}

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –ü–û–õ–Ø:
- emotional_tone: positive/negative/neutral/mixed
- storytelling_type: narrative/abstract/conversational
- wordplay_quality: basic/good/excellent

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤!
"""

    def _parse_analysis(
        self, analysis_text: str, artist: str, title: str
    ) -> EnhancedSongData | None:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_start = analysis_text.find("{")
            json_end = analysis_text.rfind("}") + 1

            if json_start == -1 or json_end <= json_start:
                logger.error("‚åõ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
                return None

            json_str = analysis_text[json_start:json_end]
            data = json.loads(json_str)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è
            metadata_data = data.get("metadata", {})
            lyrics_data = data.get("lyrics_analysis", {})
            quality_data = data.get("quality_metrics", {})

            # –î–æ–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –≤ lyrics_analysis
            if "emotional_tone" not in lyrics_data:
                lyrics_data["emotional_tone"] = "neutral"
                logger.warning("‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è emotional_tone")

            if "storytelling_type" not in lyrics_data:
                lyrics_data["storytelling_type"] = "conversational"
                logger.warning(
                    "‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è storytelling_type"
                )

            if "wordplay_quality" not in lyrics_data:
                lyrics_data["wordplay_quality"] = "basic"
                logger.warning("‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è wordplay_quality")

            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            metadata = SongMetadata(**metadata_data)
            lyrics_analysis = LyricsAnalysis(**lyrics_data)
            quality_metrics = QualityMetrics(**quality_data)

            return EnhancedSongData(
                artist=artist,
                title=title,
                metadata=metadata,
                lyrics_analysis=lyrics_analysis,
                quality_metrics=quality_metrics,
                model_used="gemma-2-27b-it",
                analysis_date=datetime.now().isoformat(),
            )

        except json.JSONDecodeError as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON Gemma: {e}")
            logger.debug(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {analysis_text[:500]}")
            return None
        except Exception as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ Gemma: {e}")
            return None


class MockProvider(ModelProvider):
    """Mock –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""

    def __init__(self):
        super().__init__("Mock")
        self.cost_per_1k_tokens = 0.0  # –ë–µ—Å–ø–ª–∞—Ç–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        self.available = True  # –í—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω

    def check_availability(self) -> bool:
        """Mock –ø—Ä–æ–≤–∞–π–¥–µ—Ä –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω"""
        logger.info("‚úÖ Mock –ø—Ä–æ–≤–∞–π–¥–µ—Ä –≥–æ—Ç–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏")
        return True

    def analyze_song(
        self, artist: str, title: str, lyrics: str
    ) -> EnhancedSongData | None:
        """Mock –∞–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —Å —É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è–º–∏"""
        try:
            lyrics_lower = lyrics.lower()

            # –£–º–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∂–∞–Ω—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            genre = "rap"
            if any(word in lyrics_lower for word in ["trap", "–º–æ–ª–ª–∏", "lean", "—Å–∫—Ä—Ä"]):
                genre = "trap"
            elif any(
                word in lyrics_lower for word in ["drill", "smoke", "opps", "gang"]
            ):
                genre = "drill"
            elif any(
                word in lyrics_lower for word in ["—É–ª–∏—Ü–∞", "—Ä–∞–π–æ–Ω", "–¥–≤–æ—Ä", "–ø–æ–¥—ä–µ–∑–¥"]
            ):
                genre = "gangsta_rap"
            elif any(word in lyrics_lower for word in ["–¥–µ–ø—Ä–µ—Å—Å–∏—è", "–≥—Ä—É—Å—Ç—å", "—Å–ª–µ–∑—ã"]):
                genre = "emo_rap"

            # –£–º–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
            mood = "neutral"
            aggressive_words = ["—É–±—å—é", "–≤–æ–π–Ω–∞", "–¥—Ä–∞–∫–∞", "hate", "angry"]
            sad_words = ["–≥—Ä—É—Å—Ç—å", "–ø–µ—á–∞–ª—å", "—Å–ª–µ–∑—ã", "–¥–µ–ø—Ä–µ—Å—Å–∏—è", "–æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ"]
            positive_words = ["party", "—Å—á–∞—Å—Ç—å–µ", "—Ä–∞–¥–æ—Å—Ç—å", "love", "—É—Å–ø–µ—Ö"]

            if any(word in lyrics_lower for word in aggressive_words):
                mood = "aggressive"
            elif any(word in lyrics_lower for word in sad_words):
                mood = "melancholic"
            elif any(word in lyrics_lower for word in positive_words):
                mood = "energetic"

            # –ê–Ω–∞–ª–∏–∑ —ç–Ω–µ—Ä–≥–∏–∏
            energy = "medium"
            if (
                len(lyrics.split("!")) > 3
                or "–π–∞" in lyrics_lower
                or "—Å–∫—Ä—Ä" in lyrics_lower
            ):
                energy = "high"
            elif any(word in lyrics_lower for word in ["–º–µ–¥–ª–µ–Ω–Ω–æ", "—Å–ø–æ–∫–æ–π–Ω–æ", "—Ç–∏—Ö–æ"]):
                energy = "low"

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ explicit content
            explicit_words = [
                "—Å—É–∫–∞",
                "–±–ª—è—Ç—å",
                "—Ö—É–π",
                "–ø–∏–∑–¥–∞",
                "–µ–±–∞—Ç—å",
                "fuck",
                "shit",
                "bitch",
            ]
            explicit_content = any(word in lyrics_lower for word in explicit_words)

            # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            lines = lyrics.strip().split("\n")
            non_empty_lines = [line for line in lines if line.strip()]

            structure = "verse"
            if len(non_empty_lines) > 16:
                structure = "verse-chorus-verse"
            elif len(non_empty_lines) < 8:
                structure = "hook"

            # –ê–Ω–∞–ª–∏–∑ —Ä–∏—Ñ–º—ã (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            rhyme_scheme = "ABAB"
            if len(non_empty_lines) >= 4:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª–æ–≤–∞ —Å—Ç—Ä–æ–∫
                last_words = [
                    line.strip().split()[-1].lower()
                    for line in non_empty_lines[:4]
                    if line.strip().split()
                ]
                if len(set(last_words)) == 1:
                    rhyme_scheme = "AAAA"
                elif len(set(last_words)) == 2:
                    rhyme_scheme = "AABB"

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            complexity = "intermediate"
            word_count = len(lyrics.split())
            unique_words = len(set(lyrics.lower().split()))
            diversity = unique_words / max(word_count, 1)

            if diversity > 0.7 and word_count > 200:
                complexity = "advanced"
            elif diversity < 0.5 or word_count < 100:
                complexity = "beginner"

            # –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã
            themes = []
            theme_keywords = {
                "street_life": ["—É–ª–∏—Ü–∞", "—Ä–∞–π–æ–Ω", "–¥–≤–æ—Ä", "–ø–æ–¥—ä–µ–∑–¥"],
                "money": ["–¥–µ–Ω—å–≥–∏", "cash", "money", "–±–∞–±–∫–∏", "–ª–∞–≤—ç"],
                "relationships": ["–ª—é–±–æ–≤—å", "–¥–µ–≤–æ—á–∫–∞", "–æ—Ç–Ω–æ—à–µ–Ω–∏—è", "—Å–µ–º—å—è"],
                "success": ["—É—Å–ø–µ—Ö", "fame", "—Å–ª–∞–≤–∞", "—Ç–æ–ø"],
                "struggle": ["–±–æ—Ä—å–±–∞", "struggle", "–ø—Ä–æ–±–ª–µ–º—ã", "—Ç—Ä—É–¥–Ω–æ—Å—Ç–∏"],
            }

            for theme, keywords in theme_keywords.items():
                if any(keyword in lyrics_lower for keyword in keywords):
                    themes.append(theme)

            if not themes:
                themes = ["life"]

            # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            authenticity_score = 0.5
            street_words = ["—É–ª–∏—Ü–∞", "—Ä–∞–π–æ–Ω", "–¥–≤–æ—Ä", "–ø–æ–¥—ä–µ–∑–¥", "–ø—Ä–∞–≤–¥–∞", "—Ä–µ–∞–ª—å–Ω–æ"]
            fake_words = ["–ø–æ–Ω—Ç", "—Ñ—ç–π–∫", "–ø–æ–∫–∞–∑—É—Ö–∞"]

            street_count = sum(1 for word in street_words if word in lyrics_lower)
            fake_count = sum(1 for word in fake_words if word in lyrics_lower)

            authenticity_score = min(
                0.3 + (street_count * 0.15) - (fake_count * 0.1), 1.0
            )

            creativity = min(0.4 + (diversity * 0.6), 1.0)
            commercial_appeal = (
                0.5
                + (0.1 if explicit_content else 0.2)
                + (0.1 if energy == "high" else 0)
            )
            uniqueness = diversity * 0.8 + 0.2

            # –û–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            avg_quality = (
                authenticity_score + creativity + commercial_appeal + uniqueness
            ) / 4
            if avg_quality > 0.8:
                overall_quality = "excellent"
            elif avg_quality > 0.6:
                overall_quality = "good"
            elif avg_quality > 0.4:
                overall_quality = "fair"
            else:
                overall_quality = "poor"

            # AI likelihood (–æ–±—Ä–∞—Ç–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –∞—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏)
            ai_likelihood = max(0.1, 1.0 - authenticity_score)

            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            metadata = SongMetadata(
                genre=genre,
                mood=mood,
                energy_level=energy,
                explicit_content=explicit_content,
            )

            lyrics_analysis = LyricsAnalysis(
                structure=structure,
                rhyme_scheme=rhyme_scheme,
                complexity_level=complexity,
                main_themes=themes,
                emotional_tone=mood,
                storytelling_type="narrative"
                if "–∏—Å—Ç–æ—Ä–∏—è" in lyrics_lower or len(non_empty_lines) > 12
                else "conversational",
                wordplay_quality="excellent"
                if creativity > 0.8
                else ("good" if creativity > 0.6 else "basic"),
            )

            quality_metrics = QualityMetrics(
                authenticity_score=authenticity_score,
                lyrical_creativity=creativity,
                commercial_appeal=commercial_appeal,
                uniqueness=uniqueness,
                overall_quality=overall_quality,
                ai_likelihood=ai_likelihood,
            )

            return EnhancedSongData(
                artist=artist,
                title=title,
                metadata=metadata,
                lyrics_analysis=lyrics_analysis,
                quality_metrics=quality_metrics,
                model_used="mock_analyzer_v1",
                analysis_date=datetime.now().isoformat(),
            )

        except Exception as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ Mock –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None


class GemmaProvider(ModelProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è Google Gemma API"""

    def __init__(self):
        super().__init__("Gemma")
        self.api_key = os.getenv("GOOGLE_API_KEY")
        self.available = self.check_availability()
        self.cost_per_1k_tokens = 0.0  # Free tier –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ª–∏–º–∏—Ç–æ–≤

    def check_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞ Google"""
        if not self.api_key:
            logger.warning("‚åõ GOOGLE_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
            return False

        try:
            import google.generativeai as genai
            from google.generativeai.client import configure
            from google.generativeai.generative_models import GenerativeModel

            configure(api_key=self.api_key)
            logger.info("‚úÖ Google Gemma API –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
            return True
        except ImportError:
            logger.warning("‚åõ google-generativeai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False
        except Exception as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Gemma API: {e}")
            return False

    def analyze_song(
        self, artist: str, title: str, lyrics: str
    ) -> EnhancedSongData | None:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —á–µ—Ä–µ–∑ Google Gemma"""
        if not self.available:
            return None

        try:
            from google.generativeai.generative_models import GenerativeModel

            model = GenerativeModel("gemma-2-27b-it")
            prompt = self._create_analysis_prompt(artist, title, lyrics)

            response = model.generate_content(
                prompt,
                generation_config={
                    "temperature": 0.1,
                    "max_output_tokens": 1500,
                },
            )

            if response.text:
                return self._parse_analysis(response.text, artist, title)
            logger.error("‚åõ Gemma: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            return None

        except Exception as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Gemma: {e}")
            return None

    def _create_analysis_prompt(self, artist: str, title: str, lyrics: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è Gemma"""
        return f"""
Analyze this rap song and return results in STRICT JSON format:

Artist: {artist}
Title: {title}
Lyrics: {lyrics[:2000]}...

Return ONLY valid JSON with these exact fields:
{{
    "metadata": {{
        "genre": "rap/trap/drill/old-school/gangsta/emo-rap",
        "mood": "aggressive/melancholic/energetic/neutral",
        "energy_level": "low/medium/high",
        "explicit_content": true/false
    }},
    "lyrics_analysis": {{
        "structure": "verse-chorus-verse/freestyle/storytelling",
        "rhyme_scheme": "AABA/ABAB/complex/simple",
        "complexity_level": "beginner/intermediate/advanced",
        "main_themes": ["money", "relationships", "street_life", "success"],
        "emotional_tone": "positive/negative/neutral/mixed",
        "storytelling_type": "narrative/abstract/conversational",
        "wordplay_quality": "basic/good/excellent"
    }},
    "quality_metrics": {{
        "authenticity_score": 0.0-1.0,
        "lyrical_creativity": 0.0-1.0,
        "commercial_appeal": 0.0-1.0,
        "uniqueness": 0.0-1.0,
        "overall_quality": "poor/fair/good/excellent",
        "ai_likelihood": 0.0-1.0
    }}
}}

Return ONLY JSON, no additional text!
"""

    def _parse_analysis(
        self, analysis_text: str, artist: str, title: str
    ) -> EnhancedSongData | None:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_start = analysis_text.find("{")
            json_end = analysis_text.rfind("}") + 1

            if json_start == -1 or json_end <= json_start:
                logger.error("‚åõ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ Gemma")
                return None

            json_str = analysis_text[json_start:json_end]
            data = json.loads(json_str)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è
            metadata_data = data.get("metadata", {})
            lyrics_data = data.get("lyrics_analysis", {})
            quality_data = data.get("quality_metrics", {})

            # –î–æ–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –≤ lyrics_analysis
            if "emotional_tone" not in lyrics_data:
                lyrics_data["emotional_tone"] = "neutral"
                logger.warning("‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è emotional_tone")

            if "storytelling_type" not in lyrics_data:
                lyrics_data["storytelling_type"] = "conversational"
                logger.warning(
                    "‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è storytelling_type"
                )

            if "wordplay_quality" not in lyrics_data:
                lyrics_data["wordplay_quality"] = "basic"
                logger.warning("‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è wordplay_quality")

            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            metadata = SongMetadata(**metadata_data)
            lyrics_analysis = LyricsAnalysis(**lyrics_data)
            quality_metrics = QualityMetrics(**quality_data)

            return EnhancedSongData(
                artist=artist,
                title=title,
                metadata=metadata,
                lyrics_analysis=lyrics_analysis,
                quality_metrics=quality_metrics,
                model_used="gemma-2-27b-it",
                analysis_date=datetime.now().isoformat(),
            )

        except json.JSONDecodeError as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON Gemma: {e}")
            logger.debug(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {analysis_text[:500]}")
            return None
        except Exception as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ Gemma: {e}")
            return None


class MultiModelAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""

    def __init__(self):
        self.providers = []
        self.current_provider = None
        self.db_manager = PostgreSQLManager()
        self.stats = {
            "total_analyzed": 0,
            "ollama_used": 0,
            "gemma_used": 0,
            "mock_used": 0,
            "total_cost": 0.0,
        }

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        self._init_providers()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        self.interpretable_analyzer = InterpretableAnalyzer(self)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        self.safety_validator = SafetyValidator()

    async def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        return await self.db_manager.initialize()

    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        await self.db_manager.close()

    def analyze_with_explanations(
        self, artist: str, title: str, lyrics: str
    ) -> ExplainableAnalysisResult | None:
        """–ê–Ω–∞–ª–∏–∑ —Å –ø–æ–ª–Ω—ã–º–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏ —Ä–µ—à–µ–Ω–∏–π AI"""
        return self.interpretable_analyzer.analyze_with_explanation(
            artist, title, lyrics
        )

    async def explain_existing_analysis(self, track_id: int) -> dict | None:
        """–û–±—ä—è—Å–Ω—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞–Ω–∞–ª–∏–∑ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            async with self.db_manager.get_connection() as conn:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–µ—Å–Ω–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞
                query = """
                    SELECT t.artist, t.title, t.lyrics, ar.*
                    FROM tracks t
                    JOIN analysis_results ar ON t.id = ar.track_id
                    WHERE t.id = $1 AND ar.analyzer_type = 'multi_model_ai'
                """

                row = await conn.fetchrow(query, track_id)
                if not row:
                    logger.warning(
                        f"–ü–µ—Å–Ω—è —Å ID {track_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞"
                    )
                    return None

                # –ü–∞—Ä—Å–∏–º analysis_data
                analysis_data = json.loads(row["analysis_data"])

                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç EnhancedSongData –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ë–î
                metadata = SongMetadata(
                    genre=analysis_data.get("metadata", {}).get("genre", "rap"),
                    mood=analysis_data.get("metadata", {}).get("mood", "neutral"),
                    energy_level=analysis_data.get("metadata", {}).get(
                        "energy_level", "medium"
                    ),
                    explicit_content=analysis_data.get("metadata", {}).get(
                        "explicit_content", False
                    ),
                )

                lyrics_analysis = LyricsAnalysis(
                    structure=analysis_data.get("lyrics_analysis", {}).get(
                        "structure", "verse"
                    ),
                    rhyme_scheme=analysis_data.get("lyrics_analysis", {}).get(
                        "rhyme_scheme", "unknown"
                    ),
                    complexity_level=analysis_data.get("lyrics_analysis", {}).get(
                        "complexity_level", "intermediate"
                    ),
                    main_themes=analysis_data.get("lyrics_analysis", {}).get(
                        "main_themes", []
                    ),
                    emotional_tone=analysis_data.get("lyrics_analysis", {}).get(
                        "emotional_tone", "neutral"
                    ),
                    storytelling_type=analysis_data.get("lyrics_analysis", {}).get(
                        "storytelling_type", "conversational"
                    ),
                    wordplay_quality=analysis_data.get("lyrics_analysis", {}).get(
                        "wordplay_quality", "basic"
                    ),
                )

                quality_metrics = QualityMetrics(
                    authenticity_score=analysis_data.get("quality_metrics", {}).get(
                        "authenticity_score", 0.5
                    ),
                    lyrical_creativity=analysis_data.get("quality_metrics", {}).get(
                        "lyrical_creativity", 0.5
                    ),
                    commercial_appeal=analysis_data.get("quality_metrics", {}).get(
                        "commercial_appeal", 0.5
                    ),
                    uniqueness=analysis_data.get("quality_metrics", {}).get(
                        "uniqueness", 0.5
                    ),
                    overall_quality=analysis_data.get("quality_metrics", {}).get(
                        "overall_quality", "fair"
                    ),
                    ai_likelihood=analysis_data.get("quality_metrics", {}).get(
                        "ai_likelihood", 0.5
                    ),
                )

                enhanced_data = EnhancedSongData(
                    artist=row["artist"],
                    title=row["title"],
                    metadata=metadata,
                    lyrics_analysis=lyrics_analysis,
                    quality_metrics=quality_metrics,
                    model_used=row["model_version"],
                    analysis_date=row["created_at"].isoformat(),
                )

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
                explanation = self.interpretable_analyzer.explain_decision(
                    row["lyrics"], enhanced_data
                )
                confidence = self.interpretable_analyzer.calculate_confidence(
                    enhanced_data, row["lyrics"]
                )
                decision_factors = self.interpretable_analyzer.extract_key_factors(
                    row["lyrics"], enhanced_data
                )
                influential_phrases = (
                    self.interpretable_analyzer.find_influential_phrases(
                        row["lyrics"], enhanced_data
                    )
                )

                return {
                    "song_info": {
                        "id": track_id,
                        "artist": row["artist"],
                        "title": row["title"],
                    },
                    "analysis": enhanced_data.model_dump(),
                    "explanation": explanation,
                    "confidence": confidence,
                    "decision_factors": decision_factors,
                    "influential_phrases": influential_phrases,
                }

        except Exception as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None

    def _init_providers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞"""
        logger.info("üîç –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤...")

        # 1. Ollama (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç - –±–µ—Å–ø–ª–∞—Ç–Ω–æ)
        ollama = OllamaProvider()
        if ollama.available:
            self.providers.append(ollama)
            logger.info("‚úÖ Ollama –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")

        # 2. Google Gemma (cloud fallback)
        gemma = GemmaProvider()
        if gemma.available:
            self.providers.append(gemma)
            logger.info("‚úÖ Google Gemma –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")

        # 3. Mock Provider (–≤—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏)
        mock = MockProvider()
        self.providers.append(mock)
        logger.info("‚úÖ Mock –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–æ–±–∞–≤–ª–µ–Ω –∫–∞–∫ fallback")

        if not self.providers:
            logger.error("‚åõ –ù–∏ –æ–¥–∏–Ω AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
            raise Exception("No AI providers available")

        self.current_provider = self.providers[0]
        logger.info(f"üéØ –ê–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.current_provider.name}")

    def analyze_song(
        self, artist: str, title: str, lyrics: str
    ) -> EnhancedSongData | None:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —Å fallback –º–µ–∂–¥—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏"""

        for provider in self.providers:
            try:
                logger.info(f"ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ {provider.name}: {artist} - {title}")

                result = provider.analyze_song(artist, title, lyrics)

                if result:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    self.stats["total_analyzed"] += 1
                    if provider.name == "Ollama":
                        self.stats["ollama_used"] += 1
                    elif provider.name == "Gemma":
                        self.stats["gemma_used"] += 1
                    elif provider.name == "Mock":
                        self.stats["mock_used"] += 1

                    logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —á–µ—Ä–µ–∑ {provider.name}")
                    return result
                logger.warning(f"‚ö†Ô∏è {provider.name} –Ω–µ —Å–º–æ–≥ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å")

            except Exception as e:
                logger.error(f"‚åõ –û—à–∏–±–∫–∞ {provider.name}: {e}")
                continue

        logger.error(
            f"‚åõ –í—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ —Å–º–æ–≥–ª–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å: {artist} - {title}"
        )
        return None

    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return {
            **self.stats,
            "available_providers": [p.name for p in self.providers],
            "current_provider": self.current_provider.name
            if self.current_provider
            else None,
        }

    async def batch_analyze_from_db(self, limit: int = 100, offset: int = 0):
        """–ú–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –ø–µ—Å–µ–Ω –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""

        logger.info(f"üéµ –ù–∞—á–∏–Ω–∞–µ–º batch –∞–Ω–∞–ª–∏–∑: {limit} –ø–µ—Å–µ–Ω —Å offset {offset}")

        try:
            async with self.db_manager.get_connection() as conn:
                # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Å–Ω–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                query = """
                    SELECT t.id, t.artist, t.title, t.lyrics
                    FROM tracks t
                    LEFT JOIN analysis_results ar ON t.id = ar.track_id
                        AND ar.analyzer_type = 'multi_model_ai'
                    WHERE t.lyrics IS NOT NULL
                        AND LENGTH(TRIM(t.lyrics)) > 50
                        AND ar.id IS NULL  -- –¢–æ–ª—å–∫–æ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
                    ORDER BY t.id
                    LIMIT $1 OFFSET $2
                """

                rows = await conn.fetch(query, limit, offset)
                logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(rows)} –ø–µ—Å–µ–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

                successful = 0
                failed = 0

                for i, row in enumerate(rows, 1):
                    try:
                        logger.info(
                            f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {i}/{len(rows)} - {row['artist']} - {row['title']}"
                        )

                        analysis = self.analyze_song(
                            row["artist"], row["title"], row["lyrics"]
                        )

                        if analysis:
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
                            await self._save_analysis_to_db(conn, row["id"], analysis)
                            successful += 1
                            logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω –∞–Ω–∞–ª–∏–∑ #{successful}")
                        else:
                            failed += 1
                            logger.warning("‚åõ –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å")

                        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                        if i < len(rows):  # –ù–µ –¥–µ–ª–∞–µ–º –ø–∞—É–∑—É –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–µ—Å–Ω–∏
                            await asyncio.sleep(2)  # 2 —Å–µ–∫—É–Ω–¥—ã –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∞–º–∏

                    except Exception as e:
                        failed += 1
                        logger.error(f"‚åõ –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Å–Ω–∏ {row['id']}: {e}")
                        continue

                logger.info(f"""
                üéâ Batch –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!
                ‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}
                ‚åõ –û—à–∏–±–æ–∫: {failed}
                üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {self.get_stats()}
                """)

        except Exception as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ batch –∞–Ω–∞–ª–∏–∑–∞: {e}")

    async def _save_analysis_to_db(
        self, conn: asyncpg.Connection, track_id: int, analysis: EnhancedSongData
    ):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            analysis_data = {
                "metadata": analysis.metadata.model_dump(),
                "lyrics_analysis": analysis.lyrics_analysis.model_dump(),
                "quality_metrics": analysis.quality_metrics.model_dump(),
                "analysis_info": {
                    "analyzer_version": "multi_model_v2",
                    "analysis_timestamp": analysis.analysis_date,
                    "model_used": analysis.model_used,
                },
            }

            await conn.execute(
                """
                INSERT INTO analysis_results (
                    track_id, analyzer_type, sentiment, confidence,
                    complexity_score, themes, analysis_data,
                    processing_time_ms, model_version, created_at
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
            """,
                track_id,
                "multi_model_ai",
                analysis.metadata.mood,
                analysis.quality_metrics.authenticity_score,
                analysis.quality_metrics.lyrical_creativity,
                json.dumps(analysis.lyrics_analysis.main_themes),
                json.dumps(analysis_data),
                1000.0,  # placeholder processing time
                analysis.model_used,
                datetime.now(),
            )

        except Exception as e:
            logger.error(f"‚åõ –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")
            raise

    def analyze_song_with_safety(
        self, artist: str, title: str, lyrics: str
    ) -> dict | None:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –¥–µ—Ç–µ–∫—Ü–∏–µ–π –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π"""

        logger.info(f"üõ°Ô∏è –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {artist} - {title}")

        # 1. –í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        analysis_result = self.analyze_song(artist, title, lyrics)

        if not analysis_result:
            logger.error("‚åõ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
            return None

        # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        analysis_dict = {
            "genre": analysis_result.metadata.genre,
            "mood": analysis_result.metadata.mood,
            "energy_level": analysis_result.metadata.energy_level,
            "explicit_content": analysis_result.metadata.explicit_content,
            "structure": analysis_result.lyrics_analysis.structure,
            "rhyme_scheme": analysis_result.lyrics_analysis.rhyme_scheme,
            "complexity_level": analysis_result.lyrics_analysis.complexity_level,
            "main_themes": analysis_result.lyrics_analysis.main_themes,
            "authenticity_score": analysis_result.quality_metrics.authenticity_score,
            "lyrical_creativity": analysis_result.quality_metrics.lyrical_creativity,
            "commercial_appeal": analysis_result.quality_metrics.commercial_appeal,
            "uniqueness": analysis_result.quality_metrics.uniqueness,
            "overall_quality": analysis_result.quality_metrics.overall_quality,
            "ai_likelihood": analysis_result.quality_metrics.ai_likelihood,
        }

        # 3. –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ SafetyValidator
        validation_result = self.safety_validator.validate_analysis(
            lyrics, analysis_dict
        )

        # 4. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        logger.info(
            f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {validation_result['validation_summary']}"
        )

        if not validation_result["is_reliable"]:
            logger.warning("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–Ω –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã–º!")
            logger.warning(
                f"   ‚Ä¢ –†–∏—Å–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π: {validation_result['hallucination_risk']:.3f}"
            )
            logger.warning(
                f"   ‚Ä¢ –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: {validation_result['consistency_score']:.3f}"
            )
            logger.warning(
                f"   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å —Ñ–∞–∫—Ç–æ–≤: {validation_result['factual_accuracy']:.3f}"
            )

            if validation_result["warning_flags"]:
                logger.warning(
                    f"   ‚Ä¢ –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {', '.join(validation_result['warning_flags'])}"
                )
        else:
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
            logger.info(
                f"   ‚Ä¢ –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å: {validation_result['reliability_score']:.3f}"
            )

        # 5. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return {
            "analysis": analysis_result,
            "validation": validation_result,
            "is_safe": validation_result["is_reliable"],
            "confidence": validation_result["reliability_score"],
            "warnings": validation_result["warning_flags"],
            "summary": validation_result["validation_summary"],
        }


async def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å—é"""

    print("ü§ñ –ú–Ω–æ–≥–æ–º–æ–¥–µ–ª—å–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏ —Ä–µ—à–µ–Ω–∏–π")
    print("=" * 70)

    try:
        analyzer = MultiModelAnalyzer()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        if not await analyzer.initialize():
            print("‚åõ –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
            return

        print(f"üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã: {[p.name for p in analyzer.providers]}")
        print(
            f"üéØ –ê–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {analyzer.current_provider.name if analyzer.current_provider else 'None'}"
        )

        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
        print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏...")

        # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –ø–µ—Å–Ω–∏
        test_lyrics = """
        –Ø —Å —É–ª–∏—Ü—ã, —Ä–∞–π–æ–Ω –º–µ–Ω—è –≤–æ—Å–ø–∏—Ç–∞–ª
        –í –ø–æ–¥—ä–µ–∑–¥–∞—Ö —Ç–µ–º–Ω—ã—Ö –ø—Ä–∞–≤–¥—É –ø–æ–∑–Ω–∞–≤–∞–ª
        –ú–æ–ª–æ–¥–æ—Å—Ç—å –ø—Ä–æ—à–ª–∞ –≤ –¥—ã–º—É –∏ –¥—Ä–∞–∫–∞—Ö
        –¢–µ–ø–µ—Ä—å —á–∏—Ç–∞—é –ø—Ä–∞–≤–¥—É –≤ —ç—Ç–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö

        –î–µ–Ω—å–≥–∏, —Å–ª–∞–≤–∞ - –≤—Å–µ —ç—Ç–æ –ø—É—Å—Ç–æ—Ç–∞
        –ì–ª–∞–≤–Ω–æ–µ –æ—Å—Ç–∞—Ç—å—Å—è —Å–æ–±–æ–π –¥–æ –∫–æ–Ω—Ü–∞
        –°–µ–º—å—è –∏ –≤–µ—Ä–Ω—ã–µ –¥—Ä—É–∑—å—è —Ä—è–¥–æ–º
        –≠—Ç–æ –±–æ–≥–∞—Ç—Å—Ç–≤–æ, –∞ –Ω–µ —Ñ–∞–ª—å—à–∏–≤—ã–π —è–¥
        """

        # –ê–Ω–∞–ª–∏–∑ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
        explainable_result = analyzer.analyze_with_explanations(
            "–¢–µ—Å—Ç–æ–≤—ã–π –∞—Ä—Ç–∏—Å—Ç", "–¢–µ—Å—Ç–æ–≤—ã–π —Ç—Ä–µ–∫", test_lyrics
        )

        if explainable_result:
            print("\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê –° –û–ë–™–Ø–°–ù–ï–ù–ò–Ø–ú–ò:")
            print("-" * 50)

            # –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑
            analysis = explainable_result.analysis
            print(f"üéµ –ñ–∞–Ω—Ä: {analysis.metadata.genre}")
            print(f"üòä –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {analysis.metadata.mood}")
            print(f"‚ö° –≠–Ω–µ—Ä–≥–∏—è: {analysis.metadata.energy_level}")
            print(f"üèÜ –ö–∞—á–µ—Å—Ç–≤–æ: {analysis.quality_metrics.overall_quality}")
            print(f"üìù –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {explainable_result.confidence:.2f}")

            # –û–±—ä—è—Å–Ω–µ–Ω–∏—è
            print("\nüí° –û–ë–™–Ø–°–ù–ï–ù–ò–Ø –†–ï–®–ï–ù–ò–ô:")
            for category, explanations in explainable_result.explanation.items():
                if explanations:
                    print(f"  {category.replace('_', ' ').title()}:")
                    for exp in explanations:
                        print(f"    ‚Ä¢ {exp}")

            # –í–ª–∏—è—Ç–µ–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã
            print("\nüîç –í–õ–ò–Ø–¢–ï–õ–¨–ù–´–ï –§–†–ê–ó–´:")
            for category, phrases in explainable_result.influential_phrases.items():
                if phrases:
                    print(f"  {category.replace('_', ' ').title()}:")
                    for phrase in phrases[:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2
                        print(f"    ‚Ä¢ '{phrase}'")

            # –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            print("\nüìä –ö–õ–Æ–ß–ï–í–´–ï –§–ê–ö–¢–û–†–´ (—Ç–æ–ø-5):")
            top_factors = sorted(
                explainable_result.decision_factors.items(),
                key=lambda x: x[1],
                reverse=True,
            )[:5]
            for factor, value in top_factors:
                print(f"  ‚Ä¢ {factor.replace('_', ' ').title()}: {value:.3f}")

        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è SafetyValidator
        print("\nüõ°Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AI Safety & Hallucination Detection...")

        # –¢–µ—Å—Ç —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        problematic_lyrics = """
        –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç
        """

        safe_result = analyzer.analyze_song_with_safety(
            "Test Artist", "Problematic Track", problematic_lyrics
        )

        if safe_result:
            print("\nüõ°Ô∏è –†–ï–ó–£–õ–¨–¢–ê–¢ –ë–ï–ó–û–ü–ê–°–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê:")
            print("-" * 50)
            print(
                f"‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: {'–ù–ê–î–ï–ñ–ï–ù' if safe_result['is_safe'] else '–ù–ï–ù–ê–î–ï–ñ–ï–ù'}"
            )
            print(f"üìù –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {safe_result['confidence']:.3f}")
            print(f"üìÑ –†–µ–∑—é–º–µ: {safe_result['summary']}")

            if safe_result["warnings"]:
                print("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
                for warning in safe_result["warnings"]:
                    print(f"   ‚Ä¢ {warning}")

            # –î–µ—Ç–∞–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            validation = safe_result["validation"]
            print("\nüìä –î–ï–¢–ê–õ–ò –í–ê–õ–ò–î–ê–¶–ò–ò:")
            print(f"   ‚Ä¢ –†–∏—Å–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π: {validation['hallucination_risk']:.3f}")
            print(f"   ‚Ä¢ –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: {validation['consistency_score']:.3f}")
            print(f"   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å —Ñ–∞–∫—Ç–æ–≤: {validation['factual_accuracy']:.3f}")
            print(f"   ‚Ä¢ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–∫—Å—Ç—É: {validation['text_alignment']:.3f}")

        # –¢–µ—Å—Ç —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        print("\nüìÑ –¢–µ—Å—Ç —Å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º...")
        normal_safe_result = analyzer.analyze_song_with_safety(
            "–¢–µ—Å—Ç–æ–≤—ã–π –∞—Ä—Ç–∏—Å—Ç", "–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç—Ä–µ–∫", test_lyrics
        )

        if normal_safe_result:
            print(
                f"‚úÖ –ù–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç: {'–ù–ê–î–ï–ñ–ï–ù' if normal_safe_result['is_safe'] else '–ù–ï–ù–ê–î–ï–ñ–ï–ù'}"
            )
            print(f"üìù –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {normal_safe_result['confidence']:.3f}")
            print(f"üìÑ –†–µ–∑—é–º–µ: {normal_safe_result['summary']}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = analyzer.get_stats()
        print("\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {stats['total_analyzed']}")
        print(f"  ‚Ä¢ Ollama –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {stats['ollama_used']} —Ä–∞–∑")
        print(f"  ‚Ä¢ Gemma –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {stats['gemma_used']} —Ä–∞–∑")
        print(f"  ‚Ä¢ Mock –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω: {stats['mock_used']} —Ä–∞–∑")
        print(f"  ‚Ä¢ –û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${stats['total_cost']:.4f}")

        print("\n‚úÖ AI Safety & Hallucination Detection - –ì–û–¢–û–í–û!")
        print("üõ°Ô∏è –¢–µ–ø–µ—Ä—å AI –∞–Ω–∞–ª–∏–∑ –≤–∫–ª—é—á–∞–µ—Ç:")
        print("   ‚Ä¢ Interpretability & Model Understanding")
        print("   ‚Ä¢ Safety & Hallucination Detection")
        print("   ‚Ä¢ Consistency Validation")
        print("   ‚Ä¢ Factual Accuracy Checking")
        print("üéØ –ü—Ä–æ–¥—É–∫—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏!")

        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        await analyzer.close()

    except Exception as e:
        logger.error(f"‚åõ –û—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
