"""
ü¶ô Ollama AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤ –ø–µ—Å–µ–Ω (–ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏)

–ù–ê–ó–ù–ê–ß–ï–ù–ò–ï:
- –õ–æ–∫–∞–ª—å–Ω—ã–π AI-–∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ –ø–µ—Å–µ–Ω —á–µ—Ä–µ–∑ Ollama
- –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∏ –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –æ–±–ª–∞—á–Ω—ã–µ API
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –ø—Ä–∏–≤–∞—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ main.py, batch_processor, analyzer_cli

–ó–ê–í–ò–°–ò–ú–û–°–¢–ò:
- Python 3.8+
- src/interfaces/analyzer_interface.py
- Ollama (–ª–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä)

–†–ï–ó–£–õ–¨–¢–ê–¢:
- –ú–µ—Ç—Ä–∏–∫–∏: –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ, –∫–∞—á–µ—Å—Ç–≤–æ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –∂–∞–Ω—Ä
- –ë—ã—Å—Ç—Ä—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è —Ç–µ—Å—Ç–æ–≤ –∏ –æ–±—É—á–µ–Ω–∏—è

–ê–í–¢–û–†: AI Assistant
–î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025
"""

import json
import logging
import time
from datetime import datetime
from typing import Any

import requests

from interfaces.analyzer_interface import (
    AnalysisResult,
    BaseAnalyzer,
    register_analyzer,
)

logger = logging.getLogger(__name__)


@register_analyzer("ollama")
class OllamaAnalyzer(BaseAnalyzer):
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞ –±–∞–∑–µ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Ollama.

    –õ–æ–∫–∞–ª—å–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏ –æ–±—É—á–µ–Ω–∏—è:
    - –ë–µ—Å–ø–ª–∞—Ç–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    - –õ–æ–∫–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å)
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    - –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
    """

    def __init__(self, config: dict[str, Any] | None = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ollama –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        super().__init__(config)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama
        self.model_name = self.config.get("model_name", "llama3.2:3b")
        self.base_url = self.config.get("base_url", "http://localhost:11434")
        self.temperature = self.config.get("temperature", 0.1)
        self.timeout = self.config.get("timeout", 60)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
        self.available = self._check_availability()

        if self.available:
            logger.info(f"‚úÖ Ollama –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.model_name}")
        else:
            logger.warning("‚ö†Ô∏è Ollama –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

    def _check_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ —Å–µ—Ä–≤–µ—Ä–∞
            response = requests.get(
                f"{self.base_url}/api/tags",
                timeout=5,
                proxies={"http": "", "https": ""},
            )

            if response.status_code == 200:
                models = response.json().get("models", [])
                available_models = [model["name"] for model in models]
                logger.info(f"ü¶ô Ollama –¥–æ—Å—Ç—É–ø–µ–Ω. –ú–æ–¥–µ–ª–∏: {available_models}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω–æ–π –º–æ–¥–µ–ª–∏
                if any(self.model_name in model for model in available_models):
                    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {self.model_name} –Ω–∞–π–¥–µ–Ω–∞")
                    return True
                logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {self.model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
                return self._pull_model()

            return False

        except requests.exceptions.RequestException as e:
            logger.warning(f"‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            logger.info("üí° –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω: ollama serve")
            return False

    def _pull_model(self) -> bool:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
        try:
            logger.info(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å {self.model_name}...")

            response = requests.post(
                f"{self.base_url}/api/pull",
                json={"name": self.model_name},
                timeout=300,  # 5 –º–∏–Ω—É—Ç –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É
                proxies={"http": "", "https": ""},
            )

            if response.status_code == 200:
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {self.model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                return True
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {response.text}")
            return False

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def analyze_song(self, artist: str, title: str, lyrics: str) -> AnalysisResult:
        """
        –ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Ollama –º–æ–¥–µ–ª–∏.

        Args:
            artist: –ò–º—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
            title: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Å–Ω–∏
            lyrics: –¢–µ–∫—Å—Ç –ø–µ—Å–Ω–∏

        Returns:
            AnalysisResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        start_time = time.time()

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not self.validate_input(artist, title, lyrics):
            raise ValueError("Invalid input parameters")

        if not self.available:
            raise RuntimeError(
                "Ollama analyzer is not available. Make sure Ollama is running."
            )

        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        processed_lyrics = self.preprocess_lyrics(lyrics)

        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
            prompt = self._create_analysis_prompt(artist, title, processed_lyrics)

            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": self.temperature,
                        "top_p": 0.9,
                        "num_ctx": 4096,  # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ
                        "num_predict": 1500,  # –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç–≤–µ—Ç–∞
                    },
                },
                timeout=self.timeout,
                proxies={"http": "", "https": ""},
            )

            if response.status_code != 200:
                raise RuntimeError(
                    f"Ollama request failed: {response.status_code} - {response.text}"
                )

            result = response.json()
            analysis_text = result.get("response", "")

            if not analysis_text:
                raise RuntimeError("Empty response from Ollama model")

            # –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            analysis_data = self._parse_response(analysis_text)

            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidence = self._calculate_confidence(analysis_data)

            processing_time = time.time() - start_time

            return AnalysisResult(
                artist=artist,
                title=title,
                analysis_type="ollama",
                confidence=confidence,
                metadata={
                    "model_name": self.model_name,
                    "base_url": self.base_url,
                    "processing_date": datetime.now().isoformat(),
                    "lyrics_length": len(processed_lyrics),
                    "temperature": self.temperature,
                    "timeout": self.timeout,
                },
                raw_output=analysis_data,
                processing_time=processing_time,
                timestamp=datetime.now().isoformat(),
            )

        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama: {e}")
            raise RuntimeError(f"Ollama connection failed: {e}") from e

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Ollama –¥–ª—è {artist} - {title}: {e}")
            raise RuntimeError(f"Ollama analysis failed: {e}") from e

    def _create_analysis_prompt(self, artist: str, title: str, lyrics: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è Ollama –º–æ–¥–µ–ª–∏"""
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        max_lyrics_length = 1500
        if len(lyrics) > max_lyrics_length:
            lyrics = lyrics[:max_lyrics_length] + "..."

        return f"""Analyze this rap song and return ONLY a valid JSON response with the analysis.

Artist: {artist}
Title: {title}
Lyrics: {lyrics}

Return ONLY valid JSON with this structure:
{{
    "basic_analysis": {{
        "genre": "rap/trap/drill/old-school/gangsta/emo-rap",
        "mood": "aggressive/melancholic/energetic/confident/neutral",
        "energy": "low/medium/high",
        "explicit": true/false
    }},
    "content_themes": {{
        "main_topics": ["money", "relationships", "street_life", "success", "struggle"],
        "narrative_style": "storytelling/boastful/confessional/abstract",
        "emotional_tone": "positive/negative/neutral/mixed"
    }},
    "technical_aspects": {{
        "rhyme_complexity": "simple/moderate/complex",
        "flow_style": "steady/varied/aggressive/laid-back",
        "wordplay_level": "basic/good/excellent",
        "structure_type": "traditional/experimental/freestyle"
    }},
    "quality_assessment": {{
        "lyrical_skill": 0.0-1.0,
        "creativity": 0.0-1.0,
        "authenticity": 0.0-1.0,
        "overall_quality": 0.0-1.0
    }},
    "experimental_features": {{
        "cultural_era": "1990s/2000s/2010s/2020s",
        "regional_style": "east_coast/west_coast/south/midwest/international",
        "influences": ["list", "of", "influences"],
        "innovation_level": 0.0-1.0
    }}
}}

Respond with ONLY the JSON object, no additional text!"""

    def _parse_response(self, response_text: str) -> dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Ollama –º–æ–¥–µ–ª–∏"""
        try:
            # –ü–æ–∏—Å–∫ JSON –±–ª–æ–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1

            if json_start == -1 or json_end == 0:
                raise ValueError("No JSON found in response")

            json_str = response_text[json_start:json_end]

            # –û—á–∏—Å—Ç–∫–∞ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            json_str = json_str.replace("\\n", "\\\\n")
            json_str = json_str.replace("\n", " ")

            # –ü–∞—Ä—Å–∏–Ω–≥ JSON
            analysis_data = json.loads(json_str)

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            self._validate_analysis_structure(analysis_data)

            return analysis_data

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç Ollama: {e}")
            logger.error(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {response_text[:300]}...")

            # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —Ö–æ—Ç—è –±—ã –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            return self._extract_basic_info(response_text)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞ Ollama: {e}")
            raise ValueError(f"Ollama response parsing failed: {e}") from e

    def _extract_basic_info(self, response_text: str) -> dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON"""
        logger.warning("‚ö†Ô∏è –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞")

        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        text_lower = response_text.lower()

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∂–∞–Ω—Ä–∞
        genre = "rap"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if "trap" in text_lower:
            genre = "trap"
        elif "drill" in text_lower:
            genre = "drill"
        elif "old school" in text_lower or "old-school" in text_lower:
            genre = "old-school"

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        mood = "neutral"
        if any(word in text_lower for word in ["aggressive", "angry", "hard"]):
            mood = "aggressive"
        elif any(word in text_lower for word in ["sad", "melancholic", "depressed"]):
            mood = "melancholic"
        elif any(word in text_lower for word in ["energetic", "upbeat", "hype"]):
            mood = "energetic"
        elif any(word in text_lower for word in ["confident", "boastful"]):
            mood = "confident"

        return {
            "basic_analysis": {
                "genre": genre,
                "mood": mood,
                "energy": "medium",
                "explicit": "explicit" in text_lower or "profanity" in text_lower,
            },
            "content_themes": {
                "main_topics": ["general"],
                "narrative_style": "abstract",
                "emotional_tone": "neutral",
            },
            "technical_aspects": {
                "rhyme_complexity": "moderate",
                "flow_style": "steady",
                "wordplay_level": "basic",
                "structure_type": "traditional",
            },
            "quality_assessment": {
                "lyrical_skill": 0.5,
                "creativity": 0.5,
                "authenticity": 0.5,
                "overall_quality": 0.5,
            },
            "experimental_features": {
                "cultural_era": "2020s",
                "regional_style": "international",
                "influences": ["modern_rap"],
                "innovation_level": 0.5,
            },
            "_parsing_note": "Extracted from non-JSON response",
        }

    def _validate_analysis_structure(self, data: dict[str, Any]) -> None:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        required_sections = [
            "basic_analysis",
            "content_themes",
            "technical_aspects",
            "quality_assessment",
            "experimental_features",
        ]

        for section in required_sections:
            if section not in data:
                logger.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–µ–∫—Ü–∏—è: {section}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        quality_assessment = data.get("quality_assessment", {})
        for metric in [
            "lyrical_skill",
            "creativity",
            "authenticity",
            "overall_quality",
        ]:
            if metric in quality_assessment:
                value = quality_assessment[metric]
                if not isinstance(value, (int, float)) or not 0 <= value <= 1:
                    logger.warning(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ {metric}: {value}")

    def _calculate_confidence(self, analysis_data: dict[str, Any]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –∞–Ω–∞–ª–∏–∑–∞"""
        confidence_factors = []

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        expected_sections = 5
        completed_sections = 0

        for section_name in [
            "basic_analysis",
            "content_themes",
            "technical_aspects",
            "quality_assessment",
            "experimental_features",
        ]:
            if analysis_data.get(section_name):
                completed_sections += 1

        completeness_score = completed_sections / expected_sections
        confidence_factors.append(completeness_score)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        quality_assessment = analysis_data.get("quality_assessment", {})
        if quality_assessment:
            valid_metrics = []
            for metric_value in quality_assessment.values():
                if isinstance(metric_value, (int, float)) and 0 <= metric_value <= 1:
                    valid_metrics.append(metric_value)

            if valid_metrics:
                # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
                avg_quality = sum(valid_metrics) / len(valid_metrics)
                confidence_factors.append(avg_quality)

        # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
        if "_parsing_note" in analysis_data:
            confidence_factors.append(0.3)  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å

        # –û–±—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        if confidence_factors:
            base_confidence = sum(confidence_factors) / len(confidence_factors)
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —à—Ç—Ä–∞—Ñ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (–æ–Ω–∏ –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã)
            return base_confidence * 0.8
        return 0.4  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    def get_analyzer_info(self) -> dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–µ"""
        return {
            "name": "OllamaAnalyzer",
            "version": "2.0.0",
            "description": "Local AI analysis using Ollama models for experimentation and learning",
            "author": "Rap Scraper Project",
            "type": self.analyzer_type,
            "supported_features": self.supported_features,
            "model_info": {
                "model_name": self.model_name,
                "base_url": self.base_url,
                "provider": "Ollama Local",
                "temperature": self.temperature,
                "cost": "Free (local)",
            },
            "requirements": ["Ollama server running", "Model downloaded"],
            "available": self.available,
            "config_options": {
                "model_name": "Ollama model to use (default: llama3.2:3b)",
                "base_url": "Ollama server URL (default: http://localhost:11434)",
                "temperature": "Generation temperature (default: 0.1)",
                "timeout": "Request timeout in seconds (default: 60)",
            },
            "setup_instructions": [
                "1. Install Ollama from https://ollama.ai",
                "2. Run: ollama serve",
                "3. Pull model: ollama pull llama3.2:3b",
                "4. Start analysis",
            ],
        }

    @property
    def analyzer_type(self) -> str:
        """–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        return "ai"

    @property
    def supported_features(self) -> list[str]:
        """–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞"""
        return [
            "basic_classification",
            "mood_analysis",
            "content_analysis",
            "technical_analysis",
            "quality_assessment",
            "experimental_features",
            "local_processing",
            "privacy_friendly",
            "cost_free",
        ]
