#!/usr/bin/env python3
"""
üéØ Comprehensive AI Analysis Statistics Generator
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–æ–¥—Ä–æ–±–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º AI-–∞–Ω–∞–ª–∏–∑–æ–≤

–ù–ê–ó–ù–ê–ß–ï–ù–ò–ï:
- –°–±–æ—Ä –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ AI-–∞–Ω–∞–ª–∏–∑—É –∫–æ—Ä–ø—É—Å–∞ —Ç—Ä–µ–∫–æ–≤
- –ñ–∞–Ω—Ä–æ–≤—ã–π, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
- –≠–∫—Å–ø–æ—Ä—Ç JSON-–æ—Ç—á–µ—Ç–æ–≤ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
python scripts/tools/comprehensive_ai_stats.py
python scripts/tools/comprehensive_ai_stats.py --output results.json

–ó–ê–í–ò–°–ò–ú–û–°–¢–ò:
- Python 3.8+
- SQLite database (data/rap_lyrics.db)

–†–ï–ó–£–õ–¨–¢–ê–¢:
- JSON-–æ—Ç—á–µ—Ç—ã –≤ results/ –∏/–∏–ª–∏ –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
- –°–≤–æ–¥–Ω—ã–µ CSV/JSON –¥–ª—è –¥–∞—à–±–æ—Ä–¥–æ–≤

–ê–í–¢–û–†: Vastargazing | –î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025
"""
import sqlite3
import json
from datetime import datetime
from collections import Counter, defaultdict
from typing import Dict, List, Any

class AIAnalysisStatsGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ AI-–∞–Ω–∞–ª–∏–∑–æ–≤"""
    
    def __init__(self, db_path: str = "data/rap_lyrics.db"):
        self.db_path = db_path
        
    def get_comprehensive_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ–æ–±—ä–µ–º–ª—é—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        
        stats = {}
        
        # 1. –û–°–ù–û–í–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê
        stats['overview'] = self._get_overview_stats(conn)
        
        # 2. –ñ–ê–ù–†–û–í–´–ô –ê–ù–ê–õ–ò–ó  
        stats['genre_analysis'] = self._get_genre_stats(conn)
        
        # 3. –ê–ù–ê–õ–ò–ó –ù–ê–°–¢–†–û–ï–ù–ò–ô
        stats['mood_analysis'] = self._get_mood_stats(conn)
        
        # 4. –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ï –ú–ï–¢–†–ò–ö–ò
        stats['quality_metrics'] = self._get_quality_stats(conn)
        
        # 5. –ê–ù–ê–õ–ò–ó –ü–û –ê–†–¢–ò–°–¢–ê–ú
        stats['artist_insights'] = self._get_artist_stats(conn)
        
        # 6. –í–†–ï–ú–ï–ù–ù–´–ï –¢–†–ï–ù–î–´
        stats['temporal_trends'] = self._get_temporal_stats(conn)
        
        # 7. –¢–ï–ö–°–¢–û–í–ê–Ø –°–õ–û–ñ–ù–û–°–¢–¨
        stats['complexity_analysis'] = self._get_complexity_stats(conn)
        
        # 8. –ö–û–ú–ú–ï–†–ß–ï–°–ö–ò–ô –ü–û–¢–ï–ù–¶–ò–ê–õ
        stats['commercial_insights'] = self._get_commercial_stats(conn)
        
        conn.close()
        return stats
    
    def _get_overview_stats(self, conn) -> Dict[str, Any]:
        """–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
        cursor = conn.cursor()
        
        # –û–±—â–∏–µ —Ü–∏—Ñ—Ä—ã
        cursor.execute("SELECT COUNT(*) FROM songs")
        total_songs = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM ai_analysis")
        analyzed_songs = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT song_id) FROM ai_analysis")
        unique_analyzed = cursor.fetchone()[0]
        
        coverage = (analyzed_songs / total_songs * 100) if total_songs > 0 else 0
        
        return {
            'total_songs': total_songs,
            'analyzed_songs': analyzed_songs,
            'unique_analyzed': unique_analyzed,
            'coverage_percent': round(coverage, 2),
            'remaining_to_analyze': total_songs - unique_analyzed
        }
    
    def _get_genre_stats(self, conn) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∂–∞–Ω—Ä–∞–º"""
        cursor = conn.cursor()
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∂–∞–Ω—Ä–æ–≤
        cursor.execute("""
            SELECT genre, COUNT(*) as count
            FROM ai_analysis
            WHERE genre IS NOT NULL AND genre != ''
            GROUP BY genre
            ORDER BY count DESC
        """)
        genre_distribution = dict(cursor.fetchall())
        
        # –¢–æ–ø –ø–æ–¥–∂–∞–Ω—Ä—ã
        cursor.execute("""
            SELECT subgenre, COUNT(*) as count
            FROM ai_analysis
            WHERE subgenre IS NOT NULL AND subgenre != ''
            GROUP BY subgenre
            ORDER BY count DESC
            LIMIT 20
        """)
        subgenre_distribution = dict(cursor.fetchall())
        
        return {
            'genre_distribution': genre_distribution,
            'subgenre_distribution': subgenre_distribution,
            'total_unique_genres': len(genre_distribution),
            'total_unique_subgenres': len(subgenre_distribution)
        }
    
    def _get_mood_stats(self, conn) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
        cursor = conn.cursor()
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
        cursor.execute("""
            SELECT mood, COUNT(*) as count
            FROM ai_analysis
            WHERE mood IS NOT NULL AND mood != ''
            GROUP BY mood
            ORDER BY count DESC
        """)
        mood_distribution = dict(cursor.fetchall())
        
        # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω
        cursor.execute("""
            SELECT emotional_tone, COUNT(*) as count
            FROM ai_analysis
            WHERE emotional_tone IS NOT NULL AND emotional_tone != ''
            GROUP BY emotional_tone
            ORDER BY count DESC
        """)
        emotional_tone_distribution = dict(cursor.fetchall())
        
        # –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–µ —É—Ä–æ–≤–Ω–∏
        cursor.execute("""
            SELECT energy_level, COUNT(*) as count
            FROM ai_analysis
            WHERE energy_level IS NOT NULL AND energy_level != ''
            GROUP BY energy_level
            ORDER BY count DESC
        """)
        energy_distribution = dict(cursor.fetchall())
        
        return {
            'mood_distribution': mood_distribution,
            'emotional_tone_distribution': emotional_tone_distribution,
            'energy_distribution': energy_distribution
        }
    
    def _get_quality_stats(self, conn) -> Dict[str, Any]:
        """–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞"""
        cursor = conn.cursor()
        
        # –°—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        cursor.execute("""
            SELECT 
                AVG(authenticity_score) as avg_authenticity,
                AVG(lyrical_creativity) as avg_creativity,
                AVG(commercial_appeal) as avg_commercial,
                AVG(uniqueness) as avg_uniqueness,
                AVG(ai_likelihood) as avg_ai_likelihood
            FROM ai_analysis
            WHERE authenticity_score IS NOT NULL
        """)
        quality_averages = cursor.fetchone()
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        cursor.execute("""
            SELECT overall_quality, COUNT(*) as count
            FROM ai_analysis
            WHERE overall_quality IS NOT NULL AND overall_quality != ''
            GROUP BY overall_quality
            ORDER BY count DESC
        """)
        quality_distribution = dict(cursor.fetchall())
        
        # –¢—Ä–µ–∫–∏ —Å –≤—ã—Å–æ–∫–∏–º —Ä–∏—Å–∫–æ–º –ò–ò
        cursor.execute("""
            SELECT COUNT(*) 
            FROM ai_analysis
            WHERE ai_likelihood > 0.7
        """)
        high_ai_risk = cursor.fetchone()[0]
        
        return {
            'quality_averages': {
                'authenticity': round(quality_averages[0], 3) if quality_averages[0] else None,
                'creativity': round(quality_averages[1], 3) if quality_averages[1] else None,
                'commercial_appeal': round(quality_averages[2], 3) if quality_averages[2] else None,
                'uniqueness': round(quality_averages[3], 3) if quality_averages[3] else None,
                'ai_likelihood': round(quality_averages[4], 3) if quality_averages[4] else None
            },
            'quality_distribution': quality_distribution,
            'high_ai_risk_tracks': high_ai_risk
        }
    
    def _get_artist_stats(self, conn) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞—Ä—Ç–∏—Å—Ç–∞–º"""
        cursor = conn.cursor()
        
        # –¢–æ–ø –∞—Ä—Ç–∏—Å—Ç—ã –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∞–Ω–∞–ª–∏–∑–æ–≤
        cursor.execute("""
            SELECT s.artist, COUNT(*) as analyzed_count
            FROM songs s
            INNER JOIN ai_analysis a ON s.id = a.song_id
            GROUP BY s.artist
            ORDER BY analyzed_count DESC
            LIMIT 20
        """)
        top_analyzed_artists = dict(cursor.fetchall())
        
        # –°—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ —Ç–æ–ø-–∞—Ä—Ç–∏—Å—Ç–∞–º
        cursor.execute("""
            SELECT s.artist, 
                   AVG(a.authenticity_score) as avg_authenticity,
                   AVG(a.lyrical_creativity) as avg_creativity,
                   COUNT(*) as track_count
            FROM songs s
            INNER JOIN ai_analysis a ON s.id = a.song_id
            WHERE a.authenticity_score IS NOT NULL
            GROUP BY s.artist
            HAVING track_count >= 10
            ORDER BY avg_authenticity DESC
            LIMIT 15
        """)
        top_quality_artists = cursor.fetchall()
        
        return {
            'top_analyzed_artists': top_analyzed_artists,
            'top_quality_artists': [(artist, round(auth, 3), round(creat, 3), count) 
                                   for artist, auth, creat, count in top_quality_artists]
        }
    
    def _get_complexity_stats(self, conn) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤"""
        cursor = conn.cursor()
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        cursor.execute("""
            SELECT complexity_level, COUNT(*) as count
            FROM ai_analysis
            WHERE complexity_level IS NOT NULL AND complexity_level != ''
            GROUP BY complexity_level
            ORDER BY count DESC
        """)
        complexity_distribution = dict(cursor.fetchall())
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –∏–≥—Ä—ã —Å–ª–æ–≤
        cursor.execute("""
            SELECT wordplay_quality, COUNT(*) as count
            FROM ai_analysis
            WHERE wordplay_quality IS NOT NULL AND wordplay_quality != ''
            GROUP BY wordplay_quality
            ORDER BY count DESC
        """)
        wordplay_distribution = dict(cursor.fetchall())
        
        # –°—Ö–µ–º—ã —Ä–∏—Ñ–º–æ–≤–∫–∏
        cursor.execute("""
            SELECT rhyme_scheme, COUNT(*) as count
            FROM ai_analysis
            WHERE rhyme_scheme IS NOT NULL AND rhyme_scheme != ''
            GROUP BY rhyme_scheme
            ORDER BY count DESC
            LIMIT 15
        """)
        rhyme_distribution = dict(cursor.fetchall())
        
        return {
            'complexity_distribution': complexity_distribution,
            'wordplay_distribution': wordplay_distribution,
            'rhyme_distribution': rhyme_distribution
        }
    
    def _get_commercial_stats(self, conn) -> Dict[str, Any]:
        """–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"""
        cursor = conn.cursor()
        
        # –¢—Ä–µ–∫–∏ —Å –≤—ã—Å–æ–∫–∏–º –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º
        cursor.execute("""
            SELECT s.artist, s.title, a.commercial_appeal
            FROM songs s
            INNER JOIN ai_analysis a ON s.id = a.song_id
            WHERE a.commercial_appeal > 0.8
            ORDER BY a.commercial_appeal DESC
            LIMIT 20
        """)
        high_commercial_tracks = [(artist, title, round(appeal, 3)) for artist, title, appeal in cursor.fetchall()]
        
        # –°—Ä–µ–¥–Ω–∏–π –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –ø–æ –∂–∞–Ω—Ä–∞–º
        cursor.execute("""
            SELECT genre, AVG(commercial_appeal) as avg_commercial
            FROM ai_analysis
            WHERE commercial_appeal IS NOT NULL AND genre IS NOT NULL
            GROUP BY genre
            ORDER BY avg_commercial DESC
        """)
        commercial_by_genre = [(genre, round(avg, 3)) for genre, avg in cursor.fetchall()]
        
        return {
            'high_commercial_tracks': high_commercial_tracks,
            'commercial_by_genre': commercial_by_genre
        }
    
    def _get_temporal_stats(self, conn) -> Dict[str, Any]:
        """–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã"""
        cursor = conn.cursor()
        
        # –ê–Ω–∞–ª–∏–∑—ã –ø–æ –≥–æ–¥–∞–º (–ø–æ year_estimate)
        cursor.execute("""
            SELECT year_estimate, COUNT(*) as count
            FROM ai_analysis
            WHERE year_estimate IS NOT NULL AND year_estimate > 1990 AND year_estimate < 2030
            GROUP BY year_estimate
            ORDER BY year_estimate
        """)
        year_distribution = dict(cursor.fetchall())
        
        # –ê–Ω–∞–ª–∏–∑—ã –ø–æ –¥–Ω—è–º (–ø–æ analysis_date)
        cursor.execute("""
            SELECT DATE(analysis_date) as date, COUNT(*) as count
            FROM ai_analysis
            WHERE analysis_date IS NOT NULL
            GROUP BY DATE(analysis_date)
            ORDER BY date DESC
            LIMIT 30
        """)
        daily_analysis = dict(cursor.fetchall())
        
        return {
            'year_distribution': year_distribution,
            'daily_analysis': daily_analysis
        }
    
    def generate_report(self, output_file: str = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"results/ai_analysis_comprehensive_report_{timestamp}.json"
        elif not output_file.startswith('results/'):
            output_file = f"results/{output_file}"
        
        print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ–æ–±—ä–µ–º–ª—é—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ AI-–∞–Ω–∞–ª–∏–∑–æ–≤...")
        
        stats = self.get_comprehensive_stats()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        stats['metadata'] = {
            'generated_at': datetime.now().isoformat(),
            'database_path': self.db_path,
            'generator_version': '1.0'
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        # –ü–µ—á–∞—Ç–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π summary
        self._print_summary(stats)
        
        print(f"\nüìÑ –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
        return output_file
    
    def _print_summary(self, stats: Dict[str, Any]):
        """–ü–µ—á–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–≥–æ —Ä–µ–∑—é–º–µ"""
        overview = stats['overview']
        genre_stats = stats['genre_analysis']
        mood_stats = stats['mood_analysis']
        quality_stats = stats['quality_metrics']
        
        print("\nüéØ –ö–†–ê–¢–ö–û–ï –†–ï–ó–Æ–ú–ï –ê–ù–ê–õ–ò–ó–ê")
        print("=" * 50)
        
        print(f"üìä –ü–æ–∫—Ä—ã—Ç–∏–µ: {overview['analyzed_songs']:,} –∞–Ω–∞–ª–∏–∑–æ–≤ –∏–∑ {overview['total_songs']:,} —Ç—Ä–µ–∫–æ–≤ ({overview['coverage_percent']}%)")
        print(f"üéµ –û—Å—Ç–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å: {overview['remaining_to_analyze']:,} —Ç—Ä–µ–∫–æ–≤")
        
        print(f"\nüéº –ñ–∞–Ω—Ä–æ–≤–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ:")
        top_genres = list(genre_stats['genre_distribution'].items())[:5]
        for genre, count in top_genres:
            print(f"   ‚Ä¢ {genre}: {count:,} —Ç—Ä–µ–∫–æ–≤")
        
        print(f"\nüòä –¢–æ–ø –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è:")
        top_moods = list(mood_stats['mood_distribution'].items())[:5]
        for mood, count in top_moods:
            print(f"   ‚Ä¢ {mood}: {count:,} —Ç—Ä–µ–∫–æ–≤")
        
        if quality_stats['quality_averages']['authenticity']:
            print(f"\n‚≠ê –°—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞:")
            qa = quality_stats['quality_averages']
            print(f"   ‚Ä¢ –ê—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å: {qa['authenticity']}")
            print(f"   ‚Ä¢ –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å: {qa['creativity']}")
            print(f"   ‚Ä¢ –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª: {qa['commercial_appeal']}")
            print(f"   ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å: {qa['uniqueness']}")
            print(f"   ‚Ä¢ –†–∏—Å–∫ –ò–ò-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {qa['ai_likelihood']}")


def main():
    """CLI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    generator = AIAnalysisStatsGenerator()
    report_file = generator.generate_report()
    
    print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –û—Ç—á–µ—Ç: {report_file}")
    
    # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
    print("\nüí° –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
    print("   1. –°–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (—Ç—Ä–µ–±—É–µ—Ç matplotlib)")
    print("   2. –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
    print("   3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è markdown –æ—Ç—á–µ—Ç–∞")


if __name__ == "__main__":
    main()
