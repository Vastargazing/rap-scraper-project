#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ —Ñ–∞–π–ª–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –≤—ã–±–æ—Ä–∞ AI-–º–æ–¥–µ–ª–∏

–ù–ê–ó–ù–ê–ß–ï–ù–ò–ï:
- –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ —Ç—Ä–µ–∫–∞ —Å –ø–æ–º–æ—â—å—é –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ AI-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (Qwen, Gemma, Ollama, Algorithmic)
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞, –∂–∞–Ω—Ä–∞, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
- –í—ã–≤–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
python scripts/tools/analyze_with_model.py --text "—Ç–µ–∫—Å—Ç" --model qwen
python scripts/tools/analyze_with_model.py --file lyrics.txt --model gemma
python scripts/tools/analyze_with_model.py --list

–ó–ê–í–ò–°–ò–ú–û–°–¢–ò:
- Python 3.8+
- src/analyzers/
- src/interfaces/analyzer_interface.py
- API-–∫–ª—é—á–∏ –¥–ª—è –æ–±–ª–∞—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è)

–†–ï–ó–£–õ–¨–¢–ê–¢:
- –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
- JSON-—Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ analysis_results/ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- –õ–æ–≥–∏ –≤ logs/

–ê–í–¢–û–†: Vastargazing | –î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025
"""


import sys
import os
import time
import sqlite3
import argparse
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'src'))

def get_available_analyzers():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤"""
    try:
        from interfaces.analyzer_interface import AnalyzerFactory
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
        try:
            import analyzers.qwen_analyzer
            import analyzers.gemma_analyzer  
            import analyzers.ollama_analyzer
            import analyzers.algorithmic_analyzer
        except ImportError:
            pass
        
        return AnalyzerFactory.list_available()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤: {e}")
        return []

def test_analyzer(analyzer_name: str):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä"""
    try:
        from interfaces.analyzer_interface import AnalyzerFactory
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
        try:
            import analyzers.qwen_analyzer
            import analyzers.gemma_analyzer  
            import analyzers.ollama_analyzer
            import analyzers.algorithmic_analyzer
        except ImportError:
            pass
        
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä: {analyzer_name}")
        
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        analyzer = AnalyzerFactory.create(analyzer_name)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
        if hasattr(analyzer, 'available') and not analyzer.available:
            print(f"‚ùå –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä {analyzer_name} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return False
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_artist = "Test Artist"
        test_title = "Test Song"
        test_lyrics = "This is a test rap song with simple lyrics for testing"
        
        print(f"üìù –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –ø–µ—Å–Ω—é...")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
        result = analyzer.analyze_song(test_artist, test_title, test_lyrics)
        
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–µ–Ω!")
        print(f"   –¢–∏–ø: {result.analysis_type}")
        print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence:.2f}")
        print(f"   –í—Ä–µ–º—è: {result.processing_time:.2f}s")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è {analyzer_name}: {e}")
        return False

def mass_analyze_with_model(model_name: str, max_records: int = None):
    """–ú–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é"""
    
    print(f"üéµ –ú–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Å –º–æ–¥–µ–ª—å—é: {model_name}")
    print("=" * 50)
    
    try:
        from interfaces.analyzer_interface import AnalyzerFactory
        
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        analyzer = AnalyzerFactory.create(model_name)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
        if hasattr(analyzer, 'available') and not analyzer.available:
            print(f"‚ùå –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä {model_name} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
            return
        
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä {model_name} –≥–æ—Ç–æ–≤")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ {model_name}: {e}")
        return
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    db_path = project_root / 'data' / 'rap_lyrics.db'
    db_connection = sqlite3.connect(str(db_path))
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –∑–∞–ø–∏—Å–∏ –º–æ–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
    model_version_pattern = f"%{model_name}%"
    
    if model_name == 'qwen':
        model_version_pattern = "%qwen%"
    elif model_name == 'gemma':
        model_version_pattern = "%gemma%"
    elif model_name == 'ollama':
        model_version_pattern = "%ollama%"
    
    # –ò—â–µ–º –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏
    query = """
    SELECT s.id, s.artist, s.title, s.lyrics
    FROM songs s
    WHERE s.lyrics IS NOT NULL 
    AND s.lyrics != '' 
    AND s.id NOT IN (
        SELECT DISTINCT song_id 
        FROM ai_analysis 
        WHERE model_version LIKE ?
    )
    ORDER BY s.id
    """
    
    if max_records:
        query += f" LIMIT {max_records}"
    
    cursor = db_connection.execute(query, (model_version_pattern,))
    records = cursor.fetchall()
    total_records = len(records)
    
    print(f"üìà –ù–∞–π–¥–µ–Ω–æ {total_records} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–æ–¥–µ–ª—å—é {model_name}")
    
    if total_records == 0:
        print(f"‚úÖ –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –º–æ–¥–µ–ª—å—é {model_name}!")
        db_connection.close()
        return
    
    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    print(f"\n‚ö†Ô∏è  –ë—É–¥–µ—Ç –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {total_records} –∑–∞–ø–∏—Å–µ–π")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å: {model_name}")
    print(f"‚è±Ô∏è  –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: {(total_records * 15) // 60} –º–∏–Ω—É—Ç")
    
    confirm = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): ")
    if confirm.lower() != 'y':
        print("‚ùå –ê–Ω–∞–ª–∏–∑ –æ—Ç–º–µ–Ω–µ–Ω")
        db_connection.close()
        return
    
    # –ê–Ω–∞–ª–∏–∑
    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å {model_name}...")
    
    processed = 0
    errors = 0
    start_time = time.time()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏ –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    db_model_version = f"{model_name}-analysis"
    if model_name == 'qwen':
        db_model_version = 'qwen-3-4b-fp8'
    elif model_name == 'gemma':
        db_model_version = 'gemma-3-27b-it'
    
    for i, (track_id, artist, title, lyrics) in enumerate(records, 1):
        try:
            print(f"\nüìä {i}/{total_records}: {artist} - {title}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
            result = analyzer.analyze_song(artist, title, lyrics)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            raw_output = result.raw_output
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ)
            genre = str(raw_output.get('genre_analysis', {}).get('primary_genre', 'unknown'))[:50]
            subgenre = str(raw_output.get('genre_analysis', {}).get('subgenre', 'unknown'))[:50]
            mood = str(raw_output.get('mood_analysis', {}).get('primary_mood', 'neutral'))[:50]
            energy_level = str(raw_output.get('mood_analysis', {}).get('energy_level', 'medium'))[:20]
            explicit_content = bool(raw_output.get('content_analysis', {}).get('explicit_content', False))
            structure = str(raw_output.get('technical_analysis', {}).get('structure', 'unknown'))[:50]
            rhyme_scheme = str(raw_output.get('technical_analysis', {}).get('rhyme_scheme', 'simple'))[:30]
            complexity_level = str(raw_output.get('technical_analysis', {}).get('complexity_level', 'intermediate'))[:30]
            main_themes = str(raw_output.get('content_analysis', {}).get('main_themes', []))[:200]
            emotional_tone = str(raw_output.get('mood_analysis', {}).get('valence', 'neutral'))[:30]
            storytelling_type = str(raw_output.get('content_analysis', {}).get('narrative_style', 'unknown'))[:50]
            wordplay_quality = str(raw_output.get('technical_analysis', {}).get('wordplay_quality', 'basic'))[:30]
            
            # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
            authenticity_score = float(raw_output.get('quality_metrics', {}).get('authenticity', 0.5))
            lyrical_creativity = float(raw_output.get('quality_metrics', {}).get('lyrical_creativity', 0.5))
            commercial_appeal = float(raw_output.get('quality_metrics', {}).get('commercial_appeal', 0.5))
            uniqueness = float(raw_output.get('quality_metrics', {}).get('originality', 0.5))
            overall_quality = str(raw_output.get('quality_metrics', {}).get('overall_quality', 0.5))[:20]
            ai_likelihood = float(raw_output.get('quality_metrics', {}).get('ai_generated_likelihood', 0.5))
            
            # –í—Å—Ç–∞–≤–ª—è–µ–º –≤ —Ç–∞–±–ª–∏—Ü—É (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–ø–∏—Å–∏ –Ω–µ—Ç)
            try:
                db_connection.execute("""
                    INSERT INTO ai_analysis 
                    (song_id, genre, subgenre, mood, year_estimate, energy_level, explicit_content, 
                     structure, rhyme_scheme, complexity_level, main_themes, emotional_tone, 
                     storytelling_type, wordplay_quality, authenticity_score, lyrical_creativity, 
                     commercial_appeal, uniqueness, overall_quality, ai_likelihood, analysis_date, model_version)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    track_id, genre, subgenre, mood, '2020s', energy_level, 
                    explicit_content, structure, rhyme_scheme, complexity_level, 
                    main_themes, emotional_tone, storytelling_type, wordplay_quality,
                    authenticity_score, lyrical_creativity, commercial_appeal, uniqueness, 
                    overall_quality, ai_likelihood, datetime.now().isoformat(), db_model_version
                ))
                
                db_connection.commit()
                processed += 1
                
                print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ! (confidence: {result.confidence:.2f})")
                
            except sqlite3.IntegrityError as e:
                if "UNIQUE constraint failed" in str(e):
                    print(f"‚ö†Ô∏è –ó–∞–ø–∏—Å—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                    continue
                else:
                    raise
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            errors += 1
            continue
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–∂–¥—ã–µ 10 –∑–∞–ø–∏—Å–µ–π
        if i % 10 == 0:
            elapsed = time.time() - start_time
            rate = processed / elapsed if elapsed > 0 else 0
            remaining = total_records - i
            eta = remaining / rate / 60 if rate > 0 else 0
            
            print(f"\nüìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {i}/{total_records} ({i/total_records*100:.1f}%)")
            print(f"‚è±Ô∏è  –°–∫–æ—Ä–æ—Å—Ç—å: {rate*60:.1f} –∑–∞–ø–∏—Å–µ–π/–º–∏–Ω")
            print(f"üïê –û—Å—Ç–∞–ª–æ—Å—å: ~{eta:.1f} –º–∏–Ω")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_time = time.time() - start_time
    
    print(f"\nüéâ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
    print("=" * 30)
    print(f"ü§ñ –ú–æ–¥–µ–ª—å: {model_name}")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {processed}")
    print(f"‚ùå –û—à–∏–±–∫–∏: {errors}")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω")
    print(f"üìä –°–∫–æ—Ä–æ—Å—Ç—å: {processed/(total_time/60):.1f} –∑–∞–ø–∏—Å–µ–π/–º–∏–Ω")
    
    db_connection.close()

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='Universal Model Analyzer')
    parser.add_argument('--model', help='–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (qwen, gemma, ollama, etc.)')
    parser.add_argument('--max-records', type=int, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π')
    parser.add_argument('--test', action='store_true', help='–¢–æ–ª—å–∫–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--list', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏')
    
    args = parser.parse_args()
    
    if args.list:
        print("ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã:")
        analyzers = get_available_analyzers()
        for analyzer in analyzers:
            print(f"  üìä {analyzer}")
        return
    
    if args.test:
        if not args.model:
            print("‚ùå –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –º–æ–¥–µ–ª—å: --model <–Ω–∞–∑–≤–∞–Ω–∏–µ>")
            sys.exit(1)
        success = test_analyzer(args.model)
        sys.exit(0 if success else 1)
    
    if not args.model:
        print("‚ùå –ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –º–æ–¥–µ–ª—å: --model <–Ω–∞–∑–≤–∞–Ω–∏–µ>")
        sys.exit(1)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å
    available_analyzers = get_available_analyzers()
    if args.model not in available_analyzers:
        print(f"‚ùå –ú–æ–¥–µ–ª—å '{args.model}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        print(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(available_analyzers)}")
        sys.exit(1)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
    mass_analyze_with_model(args.model, args.max_records)

if __name__ == "__main__":
    main()
