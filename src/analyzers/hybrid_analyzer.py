"""
üß¨ –ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤ –ø–µ—Å–µ–Ω (AI + –∞–ª–≥–æ—Ä–∏—Ç–º—ã)

–ù–ê–ó–ù–ê–ß–ï–ù–ò–ï:
- –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤
- –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
- –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ main.py, batch_processor, analyzer_cli

–ó–ê–í–ò–°–ò–ú–û–°–¢–ò:
- Python 3.8+
- src/interfaces/analyzer_interface.py
- Gemma, Qwen, AlgorithmicAnalyzer

–†–ï–ó–£–õ–¨–¢–ê–¢:
- –°–æ–≤–º–µ—â–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è, —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
- –ü–æ–≤—ã—à–µ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞

–ê–í–¢–û–†: AI Assistant
–î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025
"""
import time
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from interfaces.analyzer_interface import BaseAnalyzer, AnalysisResult, AnalyzerFactory, register_analyzer

logger = logging.getLogger(__name__)


@register_analyzer("hybrid")
class HybridAnalyzer(BaseAnalyzer):
    """
    –ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–º–±–∏–Ω–∏—Ä—É—é—â–∏–π AI –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:
    - Gemma AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (–æ—Å–Ω–æ–≤–Ω–æ–π)
    - –ê–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (–¥–æ–ø–æ–ª–Ω—è—é—â–∏–π)
    - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    - –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –º–µ–∂–¥—É –º–µ—Ç–æ–¥–∞–º–∏
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        super().__init__(config)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.primary_analyzer = self.config.get('primary_analyzer', 'gemma')
        self.secondary_analyzer = self.config.get('secondary_analyzer', 'algorithmic_basic')
        self.fallback_analyzer = self.config.get('fallback_analyzer', 'ollama')
        
        # –í–µ—Å–∞ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.ai_weight = self.config.get('ai_weight', 0.7)
        self.algorithmic_weight = self.config.get('algorithmic_weight', 0.3)
        
        # –ü–æ—Ä–æ–≥–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        self.min_confidence_threshold = self.config.get('min_confidence_threshold', 0.5)
        self.use_fallback_threshold = self.config.get('use_fallback_threshold', 0.3)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.analyzers = {}
        self._initialize_analyzers()
    
    def _initialize_analyzers(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤"""
        analyzer_names = [self.primary_analyzer, self.secondary_analyzer, self.fallback_analyzer]
        
        for analyzer_name in analyzer_names:
            try:
                analyzer = AnalyzerFactory.create(
                    analyzer_name, 
                    config=self.config.get(f'{analyzer_name}_config', {}),
                    singleton=True
                )
                self.analyzers[analyzer_name] = analyzer
                logger.info(f"‚úÖ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç {analyzer_name} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å {analyzer_name}: {e}")
                self.analyzers[analyzer_name] = None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        available_analyzers = [name for name, analyzer in self.analyzers.items() if analyzer is not None]
        
        if not available_analyzers:
            logger.error("‚ùå –ù–∏ –æ–¥–∏–Ω –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
            self.available = False
        else:
            logger.info(f"‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≥–æ—Ç–æ–≤. –î–æ—Å—Ç—É–ø–Ω—ã: {available_analyzers}")
            self.available = True
    
    def analyze_song(self, artist: str, title: str, lyrics: str) -> AnalysisResult:
        """
        –ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤.
        
        Args:
            artist: –ò–º—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
            title: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Å–Ω–∏
            lyrics: –¢–µ–∫—Å—Ç –ø–µ—Å–Ω–∏
            
        Returns:
            AnalysisResult —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        start_time = time.time()
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not self.validate_input(artist, title, lyrics):
            raise ValueError("Invalid input parameters")
        
        if not self.available:
            raise RuntimeError("Hybrid analyzer is not available - no component analyzers initialized")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        processed_lyrics = self.preprocess_lyrics(lyrics)
        
        # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–æ–≤
        analysis_results = {}
        
        # 1. –û—Å–Ω–æ–≤–Ω–æ–π AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        ai_result = self._run_analyzer(self.primary_analyzer, artist, title, processed_lyrics)
        if ai_result:
            analysis_results['primary'] = ai_result
        
        # 2. –ê–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (–≤—Å–µ–≥–¥–∞ –∑–∞–ø—É—Å–∫–∞–µ–º)
        algo_result = self._run_analyzer(self.secondary_analyzer, artist, title, processed_lyrics)
        if algo_result:
            analysis_results['secondary'] = algo_result
        
        # 3. Fallback –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (–µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª –∏–ª–∏ –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        use_fallback = False
        if not ai_result:
            use_fallback = True
            logger.info("üîÑ –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        elif ai_result.confidence < self.use_fallback_threshold:
            use_fallback = True
            logger.info(f"üîÑ –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ ({ai_result.confidence:.3f}), –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        
        if use_fallback and self.fallback_analyzer != self.primary_analyzer:
            fallback_result = self._run_analyzer(self.fallback_analyzer, artist, title, processed_lyrics)
            if fallback_result:
                analysis_results['fallback'] = fallback_result
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        combined_analysis = self._combine_results(analysis_results)
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        final_confidence = self._calculate_combined_confidence(analysis_results)
        
        processing_time = time.time() - start_time
        
        return AnalysisResult(
            artist=artist,
            title=title,
            analysis_type="hybrid",
            confidence=final_confidence,
            metadata={
                "analyzers_used": list(analysis_results.keys()),
                "primary_analyzer": self.primary_analyzer,
                "secondary_analyzer": self.secondary_analyzer,
                "fallback_used": 'fallback' in analysis_results,
                "ai_weight": self.ai_weight,
                "algorithmic_weight": self.algorithmic_weight,
                "processing_date": datetime.now().isoformat(),
                "component_confidences": {
                    name: result.confidence for name, result in analysis_results.items()
                }
            },
            raw_output=combined_analysis,
            processing_time=processing_time,
            timestamp=datetime.now().isoformat()
        )
    
    def _run_analyzer(self, analyzer_name: str, artist: str, title: str, lyrics: str) -> Optional[AnalysisResult]:
        """–ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        analyzer = self.analyzers.get(analyzer_name)
        
        if not analyzer:
            logger.warning(f"‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä {analyzer_name} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return None
        
        try:
            result = analyzer.analyze_song(artist, title, lyrics)
            logger.info(f"‚úÖ {analyzer_name} –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence:.3f})")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ {analyzer_name} –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None
    
    def _combine_results(self, analysis_results: Dict[str, AnalysisResult]) -> Dict[str, Any]:
        """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        combined = {
            "hybrid_summary": {
                "analysis_methods": list(analysis_results.keys()),
                "consensus_metrics": {},
                "method_comparison": {}
            }
        }
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
        primary_data = analysis_results.get('primary', {}).raw_output if 'primary' in analysis_results else {}
        secondary_data = analysis_results.get('secondary', {}).raw_output if 'secondary' in analysis_results else {}
        fallback_data = analysis_results.get('fallback', {}).raw_output if 'fallback' in analysis_results else {}
        
        # 1. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        combined["basic_info"] = self._merge_basic_info(primary_data, secondary_data, fallback_data)
        
        # 2. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        combined["sentiment_analysis"] = self._merge_sentiment(primary_data, secondary_data)
        
        # 3. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        combined["quality_metrics"] = self._merge_quality_metrics(primary_data, secondary_data, fallback_data)
        
        # 4. –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        combined["cross_validation"] = self._cross_validate_results(analysis_results)
        
        # 5. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤
        combined["technical_analysis"] = self._merge_technical_analysis(primary_data, secondary_data, fallback_data)
        
        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        combined["component_results"] = {
            name: result.raw_output for name, result in analysis_results.items()
        }
        
        return combined
    
    def _merge_basic_info(self, primary: Dict, secondary: Dict, fallback: Dict) -> Dict[str, Any]:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        merged = {}
        
        # –ñ–∞–Ω—Ä (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞–º)
        if primary.get('genre_analysis', {}).get('primary_genre'):
            merged['genre'] = primary['genre_analysis']['primary_genre']
        elif primary.get('basic_analysis', {}).get('genre'):
            merged['genre'] = primary['basic_analysis']['genre']
        elif fallback.get('basic_analysis', {}).get('genre'):
            merged['genre'] = fallback['basic_analysis']['genre']
        else:
            merged['genre'] = 'rap'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ (–∫–æ–Ω—Å–µ–Ω—Å—É—Å)
        moods = []
        if primary.get('mood_analysis', {}).get('primary_mood'):
            moods.append(primary['mood_analysis']['primary_mood'])
        if secondary.get('sentiment_analysis', {}).get('sentiment_label'):
            moods.append(secondary['sentiment_analysis']['sentiment_label'])
        if fallback.get('basic_analysis', {}).get('mood'):
            moods.append(fallback['basic_analysis']['mood'])
        
        if moods:
            # –ü—Ä–æ—Å—Ç–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ
            from collections import Counter
            mood_votes = Counter(moods)
            merged['mood'] = mood_votes.most_common(1)[0][0]
            merged['mood_consensus'] = len(set(moods)) == 1  # –í—Å–µ —Å–æ–≥–ª–∞—Å–Ω—ã?
        
        # –≠–Ω–µ—Ä–≥–∏—è
        energy_sources = []
        if primary.get('mood_analysis', {}).get('energy_level'):
            energy_sources.append(primary['mood_analysis']['energy_level'])
        if fallback.get('basic_analysis', {}).get('energy'):
            energy_sources.append(fallback['basic_analysis']['energy'])
        
        if energy_sources:
            # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —ç–Ω–µ—Ä–≥–∏–∏
            energy_map = {'low': 1, 'medium': 2, 'high': 3}
            reverse_map = {1: 'low', 2: 'medium', 3: 'high'}
            avg_energy = sum(energy_map.get(e, 2) for e in energy_sources) / len(energy_sources)
            merged['energy_level'] = reverse_map[round(avg_energy)]
        
        return merged
    
    def _merge_sentiment(self, primary: Dict, secondary: Dict) -> Dict[str, Any]:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è"""
        merged = {}
        
        # AI –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        if primary.get('mood_analysis'):
            mood_data = primary['mood_analysis']
            merged['ai_mood'] = {
                'primary_mood': mood_data.get('primary_mood'),
                'emotional_intensity': mood_data.get('emotional_intensity'),
                'valence': mood_data.get('valence')
            }
        
        # –ê–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        if secondary.get('sentiment_analysis'):
            sentiment_data = secondary['sentiment_analysis']
            merged['algorithmic_sentiment'] = {
                'sentiment_score': sentiment_data.get('sentiment_score'),
                'sentiment_label': sentiment_data.get('sentiment_label'),
                'positive_words': sentiment_data.get('positive_words_count', 0),
                'negative_words': sentiment_data.get('negative_words_count', 0)
            }
        
        # –ö–æ–Ω—Å–µ–Ω—Å—É—Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        ai_mood = merged.get('ai_mood', {}).get('valence', 'neutral')
        algo_sentiment = merged.get('algorithmic_sentiment', {}).get('sentiment_label', 'neutral')
        
        # –ú–∞–ø–ø–∏–Ω–≥ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        mood_mapping = {
            'positive': 'positive', 'negative': 'negative', 'neutral': 'neutral',
            'aggressive': 'negative', 'melancholic': 'negative', 
            'energetic': 'positive', 'confident': 'positive'
        }
        
        ai_normalized = mood_mapping.get(ai_mood, 'neutral')
        algo_normalized = mood_mapping.get(algo_sentiment, 'neutral')
        
        merged['consensus'] = {
            'sentiment_agreement': ai_normalized == algo_normalized,
            'final_sentiment': ai_normalized if ai_normalized == algo_normalized else 'mixed'
        }
        
        return merged
    
    def _merge_quality_metrics(self, primary: Dict, secondary: Dict, fallback: Dict) -> Dict[str, Any]:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        merged = {}
        
        # AI –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        ai_quality = primary.get('quality_metrics', {})
        algo_quality = secondary.get('complexity_analysis', {})
        fallback_quality = fallback.get('quality_assessment', {})
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –≤–µ—Å–∞–º–∏
        combined_metrics = {}
        
        # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
        creativity_sources = []
        if ai_quality.get('lyrical_creativity') is not None:
            creativity_sources.append(('ai', ai_quality['lyrical_creativity'], self.ai_weight))
        if fallback_quality.get('creativity') is not None:
            creativity_sources.append(('fallback', fallback_quality['creativity'], 0.3))
        
        if creativity_sources:
            weighted_creativity = sum(score * weight for _, score, weight in creativity_sources)
            total_weight = sum(weight for _, _, weight in creativity_sources)
            combined_metrics['creativity'] = weighted_creativity / total_weight
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ
        technical_sources = []
        if ai_quality.get('technical_skill') is not None:
            technical_sources.append(('ai', ai_quality['technical_skill'], self.ai_weight))
        if fallback_quality.get('lyrical_skill') is not None:
            technical_sources.append(('fallback', fallback_quality['lyrical_skill'], 0.3))
        
        if technical_sources:
            weighted_technical = sum(score * weight for _, score, weight in technical_sources)
            total_weight = sum(weight for _, _, weight in technical_sources)
            combined_metrics['technical_skill'] = weighted_technical / total_weight
        
        # –ß–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å (—Ç–æ–ª—å–∫–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–π)
        if algo_quality.get('readability_score') is not None:
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ 0-1
            readability = algo_quality['readability_score']
            combined_metrics['readability'] = min(1.0, max(0.0, readability / 100))
        
        # –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å —Å–ª–æ–≤–∞—Ä—è
        if algo_quality.get('vocabulary_richness') is not None:
            combined_metrics['vocabulary_richness'] = algo_quality['vocabulary_richness']
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        if ai_quality.get('overall_quality') is not None:
            combined_metrics['overall_quality'] = ai_quality['overall_quality']
        elif fallback_quality.get('overall_quality') is not None:
            combined_metrics['overall_quality'] = fallback_quality['overall_quality']
        
        merged['combined_metrics'] = combined_metrics
        merged['source_metrics'] = {
            'ai_metrics': ai_quality,
            'algorithmic_metrics': algo_quality,
            'fallback_metrics': fallback_quality
        }
        
        return merged
    
    def _merge_technical_analysis(self, primary: Dict, secondary: Dict, fallback: Dict) -> Dict[str, Any]:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        merged = {}
        
        # AI —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        if primary.get('technical_analysis'):
            merged['ai_technical'] = primary['technical_analysis']
        
        # –ê–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        if secondary.get('structure_analysis'):
            merged['algorithmic_structure'] = secondary['structure_analysis']
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∏—Ñ–º
        if secondary.get('structure_analysis', {}).get('rhyme_density') is not None:
            merged['rhyme_analysis'] = {
                'density': secondary['structure_analysis']['rhyme_density'],
                'pairs': secondary['structure_analysis'].get('rhyming_pairs', 0)
            }
        
        # –ö–æ–Ω—Å–µ–Ω—Å—É—Å –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        complexities = []
        if primary.get('technical_analysis', {}).get('complexity_level'):
            complexities.append(primary['technical_analysis']['complexity_level'])
        if fallback.get('technical_aspects', {}).get('rhyme_complexity'):
            complexities.append(fallback['technical_aspects']['rhyme_complexity'])
        
        if complexities:
            # –ú–∞–ø–ø–∏–Ω–≥ —É—Ä–æ–≤–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            complexity_map = {'simple': 1, 'basic': 1, 'moderate': 2, 'intermediate': 2, 'complex': 3, 'advanced': 3, 'expert': 4}
            avg_complexity = sum(complexity_map.get(c, 2) for c in complexities) / len(complexities)
            
            if avg_complexity <= 1.5:
                merged['consensus_complexity'] = 'simple'
            elif avg_complexity <= 2.5:
                merged['consensus_complexity'] = 'moderate'
            elif avg_complexity <= 3.5:
                merged['consensus_complexity'] = 'complex'
            else:
                merged['consensus_complexity'] = 'expert'
        
        return merged
    
    def _cross_validate_results(self, analysis_results: Dict[str, AnalysisResult]) -> Dict[str, Any]:
        """–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞–º–∏"""
        validation = {
            'agreement_scores': {},
            'discrepancies': [],
            'reliability_assessment': {}
        }
        
        if len(analysis_results) < 2:
            validation['note'] = 'Insufficient analyzers for cross-validation'
            return validation
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidences = {name: result.confidence for name, result in analysis_results.items()}
        avg_confidence = sum(confidences.values()) / len(confidences)
        confidence_variance = sum((c - avg_confidence) ** 2 for c in confidences.values()) / len(confidences)
        
        validation['confidence_analysis'] = {
            'average_confidence': avg_confidence,
            'confidence_variance': confidence_variance,
            'consistent_confidence': confidence_variance < 0.1  # –ù–∏–∑–∫–∞—è –≤–∞—Ä–∏–∞—Ü–∏—è
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        processing_times = {name: result.processing_time for name, result in analysis_results.items()}
        validation['performance_analysis'] = {
            'processing_times': processing_times,
            'fastest_analyzer': min(processing_times.items(), key=lambda x: x[1])[0],
            'slowest_analyzer': max(processing_times.items(), key=lambda x: x[1])[0]
        }
        
        return validation
    
    def _calculate_combined_confidence(self, analysis_results: Dict[str, AnalysisResult]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        if not analysis_results:
            return 0.0
        
        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
        weights = {
            'primary': self.ai_weight,
            'secondary': self.algorithmic_weight,
            'fallback': 0.5  # –°—Ä–µ–¥–Ω–∏–π –≤–µ—Å –¥–ª—è fallback
        }
        
        weighted_confidences = []
        
        for name, result in analysis_results.items():
            weight = weights.get(name, 0.3)  # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –≤–µ—Å
            weighted_confidences.append(result.confidence * weight)
        
        # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        base_confidence = sum(weighted_confidences) / len(analysis_results)
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–Ω—Å–µ–Ω—Å—É—Å
        if len(analysis_results) >= 2:
            # –ï—Å–ª–∏ –≤—Å–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            min_confidence = min(result.confidence for result in analysis_results.values())
            if min_confidence > 0.7:
                base_confidence = min(1.0, base_confidence * 1.1)  # 10% –±–æ–Ω—É—Å
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ fallback
        if 'fallback' in analysis_results and 'primary' not in analysis_results:
            base_confidence *= 0.9  # 10% —à—Ç—Ä–∞—Ñ
        
        return min(1.0, max(0.0, base_confidence))
    
    def get_analyzer_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≥–∏–±—Ä–∏–¥–Ω–æ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–µ"""
        component_info = {}
        for name, analyzer in self.analyzers.items():
            if analyzer:
                try:
                    component_info[name] = analyzer.get_analyzer_info()
                except:
                    component_info[name] = {"status": "available", "info": "basic"}
            else:
                component_info[name] = {"status": "unavailable"}
        
        return {
            "name": "HybridAnalyzer",
            "version": "2.0.0",
            "description": "Combines AI and algorithmic analysis methods for comprehensive lyrics analysis",
            "author": "Rap Scraper Project",
            "type": self.analyzer_type,
            "supported_features": self.supported_features,
            "components": component_info,
            "configuration": {
                "primary_analyzer": self.primary_analyzer,
                "secondary_analyzer": self.secondary_analyzer,
                "fallback_analyzer": self.fallback_analyzer,
                "ai_weight": self.ai_weight,
                "algorithmic_weight": self.algorithmic_weight
            },
            "available": self.available,
            "config_options": {
                "primary_analyzer": "Main AI analyzer (default: gemma)",
                "secondary_analyzer": "Algorithmic analyzer (default: algorithmic_basic)",
                "fallback_analyzer": "Backup analyzer (default: ollama)",
                "ai_weight": "Weight for AI results (default: 0.7)",
                "algorithmic_weight": "Weight for algorithmic results (default: 0.3)",
                "min_confidence_threshold": "Minimum confidence threshold (default: 0.5)",
                "use_fallback_threshold": "When to use fallback analyzer (default: 0.3)"
            }
        }
    
    @property
    def analyzer_type(self) -> str:
        """–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        return "hybrid"
    
    @property
    def supported_features(self) -> List[str]:
        """–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞"""
        return [
            "multi_method_analysis",
            "cross_validation",
            "consensus_building",
            "quality_assessment",
            "technical_analysis",
            "sentiment_analysis",
            "fallback_support",
            "confidence_weighting",
            "result_merging",
            "reliability_assessment"
        ]
