#!/usr/bin/env python3
"""
ü§ñ QWEN Training & Fine-tuning Script - Primary ML Model

–ù–ê–ó–ù–ê–ß–ï–ù–ò–ï:
- –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML —Å–∏—Å—Ç–µ–º—ã
- QWEN —á–µ—Ä–µ–∑ Novita AI API –∫–∞–∫ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL (57,718 —Ç—Ä–µ–∫–æ–≤ + 269,646 –∞–Ω–∞–ª–∏–∑–æ–≤)
- Fine-tuning pipeline –¥–ª—è rap-specific –∞–Ω–∞–ª–∏–∑–∞
- Integration —Å MLOps system

–ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:
- –ú–æ–¥–µ–ª—å: qwen/qwen3-4b-fp8 (–æ—Å–Ω–æ–≤–Ω–∞—è) + qwen/qwen2.5-32b-instruct (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)
- API: Novita AI (OpenAI-compatible)
- Dataset: PostgreSQL rap_lyrics database
- –¶–µ–ª—å: Custom rap analysis model

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
python models/test_qwen.py --train                    # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
python models/test_qwen.py --evaluate                 # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
python models/test_qwen.py --test-api                 # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API
python models/test_qwen.py --prepare-dataset          # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

–ê–í–¢–û–†: AI Assistant
–î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025
–í–ï–†–°–ò–Ø: 1.0 (Primary ML Model)
"""

import argparse
import asyncio
import json
import logging
import os
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any

from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# –ò–º–ø–æ—Ä—Ç—ã
try:
    import openai
    from openai import OpenAI

    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False
    print("‚ùå OpenAI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")

try:
    import numpy as np
    import pandas as pd

    HAS_PANDAS = True
except ImportError:
    HAS_PANDAS = False
    print("‚ö†Ô∏è Pandas/Numpy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")

try:
    from src.database.postgres_adapter import PostgreSQLManager

    HAS_DB = True
except ImportError:
    HAS_DB = False
    print("‚ö†Ô∏è Database adapter –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class QwenConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è QWEN –º–æ–¥–µ–ª–∏"""

    # –û—Å–Ω–æ–≤–Ω–∞—è –∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–∞–±–æ—á–∞—è –º–æ–¥–µ–ª—å
    primary_model: str = "qwen/qwen3-4b-fp8"
    # API –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω base_url)
    base_url: str = "https://api.novita.ai/openai"
    api_key: str | None = None
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è QWEN)
    temperature: float = 0.7
    max_tokens: int = 20000  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    timeout: int = 30
    # Training –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    batch_size: int = 32
    learning_rate: float = 1e-4
    num_epochs: int = 3
    max_samples: int = 10000


class QwenTrainingSystem:
    """–°–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è QWEN –º–æ–¥–µ–ª–∏ –¥–ª—è rap –∞–Ω–∞–ª–∏–∑–∞"""

    def __init__(self, config: QwenConfig | None = None):
        self.config = config or QwenConfig()
        self.config.api_key = self.config.api_key or os.getenv("NOVITA_API_KEY")

        self.client = None
        self.db_manager = None
        self.training_data = []
        self.evaluation_data = []

        # –ü–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.results_dir = Path("results/qwen_training")
        self.results_dir.mkdir(parents=True, exist_ok=True)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
        self._initialize_client()

    def _initialize_client(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è Novita AI"""
        if not HAS_OPENAI:
            logger.error("‚ùå OpenAI library –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False

        if not self.config.api_key:
            logger.error("‚ùå NOVITA_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
            return False

        try:
            self.client = OpenAI(
                api_key=self.config.api_key,
                base_url=self.config.base_url,
                timeout=self.config.timeout,
            )
            logger.info(f"‚úÖ QWEN –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.config.primary_model}")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞: {e}")
            return False

    async def test_api_connection(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API"""
        print("üîå –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Novita AI...")

        if not self.client:
            print("‚ùå –ö–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return False

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á—É—é –º–æ–¥–µ–ª—å
        models_to_test = [
            self.config.primary_model,
        ]

        test_prompt = "Analyze this rap lyric for mood and style: 'I'm climbing to the top, never gonna stop'"

        success_count = 0

        for model in models_to_test:
            print(f"\nü§ñ Testing {model}:")
            print("-" * 50)

            try:
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "You are a rap analysis expert."},
                        {"role": "user", "content": test_prompt},
                    ],
                    max_tokens=200,
                    temperature=0.1,
                )

                if response and response.choices and response.choices[0].message:
                    content = response.choices[0].message.content or "No content"
                    tokens_used = response.usage.total_tokens if response.usage else 0

                    print(f"‚úÖ SUCCESS with {model}")
                    print(f"üìä Tokens used: {tokens_used}")
                    print(f"üìù Response preview: {content[:100]}...")
                    success_count += 1
                else:
                    print(f"‚ùå FAILED with {model}: Empty response")

            except Exception as e:
                print(f"‚ùå FAILED with {model}: {e}")

        print(
            f"\nüìà API Test Results: {success_count}/{len(models_to_test)} models working"
        )
        return success_count > 0

    async def prepare_training_dataset(self) -> bool:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–∑ PostgreSQL"""
        print("üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ training dataset –∏–∑ PostgreSQL...")

        if not HAS_DB:
            print("‚ùå Database adapter –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return False

        try:
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ
            self.db_manager = PostgreSQLManager()
            await self.db_manager.initialize()

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            if not self.db_manager or not self.db_manager.connection_pool:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
                return False

            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã
            async with self.db_manager.connection_pool.acquire() as conn:
                # –ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–∫–æ–≤ —Å –∞–Ω–∞–ª–∏–∑–∞–º–∏
                query = """
                SELECT 
                    t.id,
                    t.artist,
                    t.title,
                    t.lyrics,
                    t.genre,
                    ar.analyzer_type,
                    ar.sentiment,
                    ar.confidence,
                    ar.analysis_data,
                    ar.themes
                FROM tracks t
                JOIN analysis_results ar ON t.id = ar.track_id
                WHERE t.lyrics IS NOT NULL 
                  AND LENGTH(t.lyrics) > 100
                  AND ar.confidence > 0.5
                  AND ar.analyzer_type IN ('qwen-3-4b-fp8', 'simplified_features', 'gemma-3-27b-it')
                ORDER BY ar.confidence DESC, t.id
                LIMIT $1
                """

                records = await conn.fetch(query, self.config.max_samples)

                print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(records)} –∑–∞–ø–∏—Å–µ–π –∏–∑ –±–∞–∑—ã")

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                processed_data = []
                for record in records:
                    try:
                        # –ü–∞—Ä—Å–∏–Ω–≥ JSON –¥–∞–Ω–Ω—ã—Ö
                        analysis_data = (
                            json.loads(record["analysis_data"])
                            if record["analysis_data"]
                            else {}
                        )
                        themes = (
                            json.loads(record["themes"]) if record["themes"] else []
                        )

                        # –°–æ–∑–¥–∞–Ω–∏–µ training example
                        training_example = {
                            "id": record["id"],
                            "artist": record["artist"],
                            "title": record["title"],
                            "lyrics": record["lyrics"][:2000],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                            "genre": record["genre"] or "rap",
                            "analyzer_type": record["analyzer_type"],
                            "sentiment": record["sentiment"],
                            "confidence": float(record["confidence"]),
                            "themes": themes,
                            "analysis_data": analysis_data,
                        }

                        processed_data.append(training_example)

                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–∏ {record['id']}: {e}")
                        continue

                # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/eval
                split_idx = int(len(processed_data) * 0.8)
                self.training_data = processed_data[:split_idx]
                self.evaluation_data = processed_data[split_idx:]

                print("‚úÖ Dataset –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω:")
                print(f"  üìö Training samples: {len(self.training_data)}")
                print(f"  üß™ Evaluation samples: {len(self.evaluation_data)}")

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
                dataset_file = self.results_dir / "training_dataset.json"
                with open(dataset_file, "w", encoding="utf-8") as f:
                    json.dump(
                        {
                            "training_data": self.training_data,
                            "evaluation_data": self.evaluation_data,
                            "config": self.config.__dict__,
                            "created_at": datetime.now().isoformat(),
                        },
                        f,
                        indent=2,
                        ensure_ascii=False,
                    )

                print(f"üíæ Dataset —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {dataset_file}")
                return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ dataset: {e}")
            return False
        finally:
            if self.db_manager:
                await self.db_manager.close()

    def create_training_prompt(self, example: dict[str, Any]) -> tuple[str, str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""

        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è QWEN)
        system_prompt = """You are an expert rap lyrics analyzer. 

CRITICAL INSTRUCTIONS:
- Respond with ONLY valid JSON
- Do NOT use <think> tags or explanations
- Do NOT add any text before or after JSON
- Start response with { and end with }

Analyze rap songs for genre, mood, technical skills, and quality."""

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç —Å –ø—Ä–∏–º–µ—Ä–æ–º
        user_prompt = f"""Artist: {example["artist"]}
Title: {example["title"]}
Lyrics: {example["lyrics"][:1500]}

Return ONLY this JSON structure (no explanations):
{{
    "genre_analysis": {{
        "primary_genre": "rap",
        "subgenre": "{example.get("genre", "rap")}",
        "confidence": 0.9
    }},
    "mood_analysis": {{
        "primary_mood": "{example.get("sentiment", "neutral")}",
        "emotional_intensity": "high",
        "energy_level": "high"
    }},
    "technical_analysis": {{
        "complexity_level": "advanced",
        "rhyme_scheme": "complex",
        "flow_pattern": "varied"
    }},
    "quality_metrics": {{
        "overall_quality": {example.get("confidence", 0.8)},
        "technical_skill": 0.8,
        "authenticity": 0.9
    }}
}}"""

        return system_prompt, user_prompt

    async def simulate_training_process(self) -> dict[str, Any]:
        """–°–∏–º—É–ª—è—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è (–ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ fine-tuning —á–µ—Ä–µ–∑ API)"""
        print("üéØ –°–∏–º—É–ª—è—Ü–∏—è training process...")
        print("üí° Fine-tuning —á–µ—Ä–µ–∑ API –ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –≤—ã–ø–æ–ª–Ω—è–µ–º prompt engineering")

        if not self.training_data:
            print("‚ùå Training data –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
            return {"status": "failed", "reason": "No training data"}

        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ sample –¥–∞–Ω–Ω—ã—Ö
        test_samples = self.training_data[:5]
        results = []

        for i, sample in enumerate(test_samples, 1):
            print(f"\nüß™ Testing sample {i}/{len(test_samples)}")
            print(f"üéµ {sample['artist']} - {sample['title']}")

            try:
                if not self.client:
                    print("  ‚ùå –ö–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                    continue

                system_prompt, user_prompt = self.create_training_prompt(sample)

                response = self.client.chat.completions.create(
                    model=self.config.primary_model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    max_tokens=1000,
                    temperature=self.config.temperature,
                )

                analysis = response.choices[0].message.content or "No content"
                tokens_used = response.usage.total_tokens if response.usage else 0

                results.append(
                    {
                        "sample_id": sample["id"],
                        "artist": sample["artist"],
                        "title": sample["title"],
                        "original_sentiment": sample["sentiment"],
                        "original_confidence": sample["confidence"],
                        "model_response": analysis,
                        "tokens_used": tokens_used,
                        "success": True,
                    }
                )

                print(f"  ‚úÖ –£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ ({tokens_used} tokens)")

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                await asyncio.sleep(1)

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
                results.append(
                    {
                        "sample_id": sample["id"],
                        "artist": sample["artist"],
                        "title": sample["title"],
                        "error": str(e),
                        "success": False,
                    }
                )

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        successful = sum(1 for r in results if r["success"])
        total_tokens = sum(r.get("tokens_used", 0) for r in results if r["success"])

        training_results = {
            "status": "completed",
            "model": self.config.primary_model,
            "samples_tested": len(test_samples),
            "successful_analyses": successful,
            "success_rate": successful / len(test_samples) * 100,
            "total_tokens_used": total_tokens,
            "average_tokens_per_sample": total_tokens / max(successful, 1),
            "results": results,
            "timestamp": datetime.now().isoformat(),
        }

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results_file = (
            self.results_dir
            / f"training_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(training_results, f, indent=2, ensure_ascii=False)

        print("\nüìä Training Results:")
        print(f"  ‚úÖ Success rate: {training_results['success_rate']:.1f}%")
        print(f"  üî¢ Total tokens: {training_results['total_tokens_used']}")
        print(f"  üíæ Results saved: {results_file}")

        return training_results

    async def evaluate_model(self) -> dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ evaluation –¥–∞–Ω–Ω—ã—Ö"""
        print("üìà –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ evaluation dataset...")

        if not self.evaluation_data:
            print("‚ùå Evaluation data –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
            return {"status": "failed", "reason": "No evaluation data"}

        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ evaluation –¥–∞–Ω–Ω—ã—Ö
        eval_samples = self.evaluation_data[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –¥–µ–º–æ
        results = []

        for i, sample in enumerate(eval_samples, 1):
            print(
                f"üß™ Evaluating {i}/{len(eval_samples)}: {sample['artist']} - {sample['title']}"
            )

            try:
                if not self.client:
                    print("  ‚ùå –ö–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                    continue

                # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
                system_prompt = "You are a rap analysis expert. Analyze this rap song and provide a quality score from 0.0 to 1.0."
                user_prompt = f"Analyze the quality of this rap:\n\nArtist: {sample['artist']}\nTitle: {sample['title']}\nLyrics: {sample['lyrics'][:1000]}\n\nProvide only a quality score (0.0-1.0):"

                response = self.client.chat.completions.create(
                    model=self.config.primary_model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    max_tokens=50,
                    temperature=0.1,
                )

                predicted_score_text = response.choices[0].message.content or "0.5"
                predicted_score = predicted_score_text.strip()
                actual_score = sample["confidence"]

                # –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
                try:
                    predicted_score = float(predicted_score)
                except:
                    predicted_score = 0.5

                results.append(
                    {
                        "sample_id": sample["id"],
                        "artist": sample["artist"],
                        "title": sample["title"],
                        "actual_score": actual_score,
                        "predicted_score": predicted_score,
                        "error": abs(actual_score - predicted_score),
                        "success": True,
                    }
                )

                await asyncio.sleep(0.5)

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
                results.append(
                    {
                        "sample_id": sample["id"],
                        "artist": sample["artist"],
                        "title": sample["title"],
                        "error": str(e),
                        "success": False,
                    }
                )

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        successful_results = [r for r in results if r["success"]]
        if successful_results:
            mae = np.mean([r["error"] for r in successful_results])
            rmse = np.sqrt(np.mean([r["error"] ** 2 for r in successful_results]))
        else:
            mae = rmse = float("inf")

        evaluation_results = {
            "status": "completed",
            "model": self.config.primary_model,
            "samples_evaluated": len(eval_samples),
            "successful_evaluations": len(successful_results),
            "mae": mae,
            "rmse": rmse,
            "results": results,
            "timestamp": datetime.now().isoformat(),
        }

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        eval_file = (
            self.results_dir
            / f"evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(eval_file, "w", encoding="utf-8") as f:
            json.dump(evaluation_results, f, indent=2, ensure_ascii=False)

        print("üìä Evaluation Results:")
        print(f"  üìà MAE: {mae:.3f}")
        print(f"  üìà RMSE: {rmse:.3f}")
        print(f"  üíæ Results saved: {eval_file}")

        return evaluation_results


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(
        description="QWEN Training System - Primary ML Model",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python models/test_qwen.py --test-api                # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ API –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
  python models/test_qwen.py --prepare-dataset         # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ training dataset
  python models/test_qwen.py --train                   # –°–∏–º—É–ª—è—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
  python models/test_qwen.py --evaluate                # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
  python models/test_qwen.py --all                     # –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª ML pipeline
        """,
    )

    parser.add_argument(
        "--test-api",
        action="store_true",
        help="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Novita AI API",
    )
    parser.add_argument(
        "--prepare-dataset",
        action="store_true",
        help="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ training dataset –∏–∑ PostgreSQL",
    )
    parser.add_argument(
        "--train", action="store_true", help="–ó–∞–ø—É—Å–∫ —Å–∏–º—É–ª—è—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"
    )
    parser.add_argument(
        "--evaluate", action="store_true", help="–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ evaluation –¥–∞–Ω–Ω—ã—Ö"
    )
    parser.add_argument(
        "--all", action="store_true", help="–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π ML pipeline"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="qwen/qwen3-4b-fp8",
        help="–ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: qwen/qwen3-4b-fp8)",
    )
    parser.add_argument(
        "--max-samples",
        type=int,
        default=1000,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ samples –¥–ª—è dataset",
    )

    args = parser.parse_args()

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = QwenConfig()
    config.primary_model = args.model
    config.max_samples = args.max_samples

    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è
    training_system = QwenTrainingSystem(config)

    print("ü§ñ QWEN Training System - Primary ML Model")
    print("=" * 60)
    print(f"üéØ Model: {config.primary_model}")
    print(f"üìä Max Samples: {config.max_samples}")
    print("ÔøΩ Status: WORKING ‚úÖ")
    print("=" * 60)

    try:
        if args.test_api or args.all:
            print("\nüîå –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï API...")
            success = await training_system.test_api_connection()
            if not success:
                print("‚ùå API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ")
                return

        if args.prepare_dataset or args.all:
            print("\nüìä –ü–û–î–ì–û–¢–û–í–ö–ê DATASET...")
            success = await training_system.prepare_training_dataset()
            if not success:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å dataset")
                return

        if args.train or args.all:
            print("\nüéØ –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø...")
            results = await training_system.simulate_training_process()
            print(f"‚úÖ Training –∑–∞–≤–µ—Ä—à–µ–Ω: {results['status']}")

        if args.evaluate or args.all:
            print("\nüìà –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò...")
            results = await training_system.evaluate_model()
            print(f"‚úÖ Evaluation –∑–∞–≤–µ—Ä—à–µ–Ω: {results['status']}")

        if not any(
            [args.test_api, args.prepare_dataset, args.train, args.evaluate, args.all]
        ):
            print("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --help –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–º–∞–Ω–¥")
            print("üöÄ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—á–∞—Ç—å —Å: python models/test_qwen.py --test-api")

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        logger.exception("Detailed error:")


if __name__ == "__main__":
    asyncio.run(main())
