#!/usr/bin/env python3
"""
üìä CLI-—É—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤

–ù–ê–ó–ù–ê–ß–ï–ù–ò–ï:
- –ò–∑–º–µ—Ä–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏, —Ç–æ—á–Ω–æ—Å—Ç–∏, —Ä–µ—Å—É—Ä—Å–æ–≤ —Ä–∞–∑–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
python src/cli/performance_monitor.py --analyzer qwen      # –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ Qwen
python src/cli/performance_monitor.py --all                # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

–ó–ê–í–ò–°–ò–ú–û–°–¢–ò:
- Python 3.8+
- src/core/app.py, src/interfaces/analyzer_interface.py
- psutil, statistics

–†–ï–ó–£–õ–¨–¢–ê–¢:
- –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏

–ê–í–¢–û–†: AI Assistant
–î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025

üöÄ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π CLI-–º–æ–Ω–∏—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤

–ù–û–í–´–ï –§–ò–ß–ò:
- pytest-benchmark –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
- py-spy –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ  
- Prometheus –º–µ—Ç—Ä–∏–∫–∏
- hyperfine CLI —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
- Memory profiling
- OpenTelemetry tracing

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
python enhanced_monitor.py --analyzer qwen --mode benchmark    # –ë–∞–∑–æ–≤—ã–π –±–µ–Ω—á–º–∞—Ä–∫
python enhanced_monitor.py --analyzer qwen --mode profile      # –ì–ª—É–±–æ–∫–æ–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ  
python enhanced_monitor.py --all --mode compare                # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö
python enhanced_monitor.py --analyzer qwen --mode load         # –ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ê–í–¢–û–†: AI Assistant + Human
–î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025
"""
import asyncio
import json
import time
import sys
import psutil
import statistics
import subprocess
import tempfile
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import logging
import cProfile
import pstats
from io import StringIO

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ Python path
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.app import Application
from interfaces.analyzer_interface import AnalyzerType

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ñ–∏—á
try:
    from prometheus_client import Counter, Histogram, Gauge, start_http_server, REGISTRY
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False

try:
    from memory_profiler import profile as memory_profile
    MEMORY_PROFILER_AVAILABLE = True
except ImportError:
    MEMORY_PROFILER_AVAILABLE = False

try:
    import pytest
    PYTEST_AVAILABLE = True
except ImportError:
    PYTEST_AVAILABLE = False


@dataclass
class EnhancedMetrics:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    analyzer_name: str
    test_count: int
    
    # –ë–∞–∑–æ–≤—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_time: float
    avg_time: float
    min_time: float
    max_time: float
    median_time: float
    
    # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    avg_cpu_percent: float
    avg_memory_mb: float
    peak_memory_mb: float
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    success_rate: float
    error_count: int
    items_per_second: float
    
    # –ù–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    memory_growth_mb: float = 0.0
    cpu_efficiency: float = 0.0  # items per cpu percent
    latency_p95: float = 0.0
    latency_p99: float = 0.0
    
    # –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
    hottest_function: str = ""
    profile_data: Optional[Dict] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class PrometheusMetrics:
    """Prometheus –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    
    def __init__(self):
        if not PROMETHEUS_AVAILABLE:
            return
            
        self.request_counter = Counter(
            'analyzer_requests_total', 
            'Total analyzer requests',
            ['analyzer_type', 'status']
        )
        
        self.request_duration = Histogram(
            'analyzer_request_duration_seconds',
            'Request duration in seconds',
            ['analyzer_type']
        )
        
        self.memory_usage = Gauge(
            'analyzer_memory_usage_mb',
            'Memory usage in MB',
            ['analyzer_type']
        )
        
        self.cpu_usage = Gauge(
            'analyzer_cpu_usage_percent',
            'CPU usage percentage',
            ['analyzer_type']
        )
    
    def record_request(self, analyzer_type: str, duration: float, success: bool):
        if not PROMETHEUS_AVAILABLE:
            return
            
        status = 'success' if success else 'error'
        self.request_counter.labels(analyzer_type=analyzer_type, status=status).inc()
        self.request_duration.labels(analyzer_type=analyzer_type).observe(duration)
    
    def update_system_metrics(self, analyzer_type: str, memory_mb: float, cpu_percent: float):
        if not PROMETHEUS_AVAILABLE:
            return
            
        self.memory_usage.labels(analyzer_type=analyzer_type).set(memory_mb)
        self.cpu_usage.labels(analyzer_type=analyzer_type).set(cpu_percent)


class EnhancedPerformanceMonitor:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –º–æ–Ω–∏—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def __init__(self, monitoring_interval: float = 0.1, enable_prometheus: bool = False):
        self.app = Application()
        self.monitoring_interval = monitoring_interval
        self.logger = logging.getLogger(__name__)
        
        # Prometheus –º–µ—Ç—Ä–∏–∫–∏
        self.prometheus_metrics = PrometheusMetrics() if PROMETHEUS_AVAILABLE else None
        if enable_prometheus and PROMETHEUS_AVAILABLE:
            # –ó–∞–ø—É—Å–∫–∞–µ–º Prometheus HTTP —Å–µ—Ä–≤–µ—Ä
            start_http_server(8000)
            self.logger.info("üìä Prometheus metrics server started on :8000")
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        self.cpu_measurements = []
        self.memory_measurements = []
        self.is_monitoring = False
    
    async def benchmark_with_profiling(
        self,
        analyzer_type: str,
        test_texts: List[str],
        enable_profiling: bool = True,
        enable_memory_profiling: bool = True
    ) -> EnhancedMetrics:
        """–ë–µ–Ω—á–º–∞—Ä–∫ —Å –≥–ª—É–±–æ–∫–∏–º –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        
        analyzer = self.app.get_analyzer(analyzer_type)
        if not analyzer:
            available = self.app.list_analyzers()
            raise ValueError(f"Unknown analyzer type: {analyzer_type}. Available: {available}")
        
        self.logger.info(f"üî¨ Enhanced benchmarking {analyzer_type} with profiling")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ—Ñ–∞–π–ª–µ—Ä–∞
        profiler = cProfile.Profile() if enable_profiling else None
        
        # –°–±—Ä–æ—Å –º–µ—Ç—Ä–∏–∫
        self.cpu_measurements.clear()
        self.memory_measurements.clear()
        
        # –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        monitoring_task = asyncio.create_task(self._monitor_system_resources())
        
        # –û—Å–Ω–æ–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        execution_times = []
        error_count = 0
        memory_start = psutil.Process().memory_info().rss / 1024 / 1024
        
        if profiler:
            profiler.enable()
        
        start_time = time.time()
        
        for i, text in enumerate(test_texts):
            text_start_time = time.time()
            success = False
            
            try:
                if hasattr(analyzer, 'analyze'):
                    result = analyzer.analyze(text)
                    if hasattr(result, '__await__'):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å
                        await result
                    # –ï—Å–ª–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π - result —É–∂–µ –ø–æ–ª—É—á–µ–Ω
                elif hasattr(analyzer, 'analyze_song'):
                    result = analyzer.analyze_song("Unknown", f"Text_{i}", text)
                    if hasattr(result, '__await__'):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å
                        await result
                    # –ï—Å–ª–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π - result —É–∂–µ –ø–æ–ª—É—á–µ–Ω
                else:
                    raise RuntimeError(f"Analyzer has no analyze method")
                
                text_time = time.time() - text_start_time
                execution_times.append(text_time)
                success = True
                
                # Prometheus –º–µ—Ç—Ä–∏–∫–∏
                if self.prometheus_metrics:
                    self.prometheus_metrics.record_request(analyzer_type, text_time, True)
                    
            except Exception as e:
                error_count += 1
                text_time = time.time() - text_start_time
                self.logger.warning(f"Error processing text {i+1}: {e}")
                
                if self.prometheus_metrics:
                    self.prometheus_metrics.record_request(analyzer_type, text_time, False)
        
        total_time = time.time() - start_time
        
        if profiler:
            profiler.disable()
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        self.is_monitoring = False
        try:
            await monitoring_task
        except asyncio.CancelledError:
            pass
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        success_count = len(execution_times)
        memory_end = psutil.Process().memory_info().rss / 1024 / 1024
        memory_growth = memory_end - memory_start
        
        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if execution_times:
            avg_time = statistics.mean(execution_times)
            min_time = min(execution_times)
            max_time = max(execution_times)
            median_time = statistics.median(execution_times)
            # –ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª–∏
            sorted_times = sorted(execution_times)
            p95_idx = int(len(sorted_times) * 0.95)
            p99_idx = int(len(sorted_times) * 0.99)
            latency_p95 = sorted_times[p95_idx] if p95_idx < len(sorted_times) else max_time
            latency_p99 = sorted_times[p99_idx] if p99_idx < len(sorted_times) else max_time
        else:
            avg_time = min_time = max_time = median_time = 0
            latency_p95 = latency_p99 = 0
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        avg_cpu = statistics.mean(self.cpu_measurements) if self.cpu_measurements else 0
        avg_memory = statistics.mean(self.memory_measurements) if self.memory_measurements else 0
        peak_memory = max(self.memory_measurements) if self.memory_measurements else 0
        
        # CPU —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        cpu_efficiency = (success_count / avg_cpu) if avg_cpu > 0 else 0
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        hottest_function = ""
        profile_data = None
        
        if profiler:
            s = StringIO()
            ps = pstats.Stats(profiler, stream=s)
            ps.sort_stats('cumulative')
            ps.print_stats(10)  # –¢–æ–ø 10 —Ñ—É–Ω–∫—Ü–∏–π
            
            profile_output = s.getvalue()
            lines = profile_output.split('\n')
            for line in lines:
                if 'function calls' not in line and line.strip() and not line.startswith('Ordered by'):
                    parts = line.split()
                    if len(parts) > 5:
                        hottest_function = parts[-1]
                        break
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            profile_data = {
                'total_calls': getattr(ps, 'total_calls', 0),
                'total_time': getattr(ps, 'total_tt', 0.0),
                'profile_summary': profile_output[:1000]  # –ü–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤
            }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º Prometheus –º–µ—Ç—Ä–∏–∫–∏
        if self.prometheus_metrics:
            self.prometheus_metrics.update_system_metrics(analyzer_type, avg_memory, avg_cpu)
        
        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = EnhancedMetrics(
            analyzer_name=analyzer_type,
            test_count=len(test_texts),
            total_time=total_time,
            avg_time=avg_time,
            min_time=min_time,
            max_time=max_time,
            median_time=median_time,
            avg_cpu_percent=avg_cpu,
            avg_memory_mb=avg_memory,
            peak_memory_mb=peak_memory,
            success_rate=(success_count / len(test_texts) * 100) if test_texts else 0,
            error_count=error_count,
            items_per_second=(success_count / total_time) if total_time > 0 else 0,
            memory_growth_mb=memory_growth,
            cpu_efficiency=cpu_efficiency,
            latency_p95=latency_p95,
            latency_p99=latency_p99,
            hottest_function=hottest_function,
            profile_data=profile_data
        )
        
        self.logger.info("‚úÖ Enhanced benchmarking completed")
        return metrics
    
    async def py_spy_analysis(
        self,
        analyzer_type: str,
        test_texts: List[str],
        duration: int = 30
    ) -> Optional[str]:
        """–ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å py-spy"""
        
        if not test_texts:
            return None
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è py-spy
        script_content = f'''
import asyncio
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))
from core.app import Application

async def run_analyzer():
    app = Application()
    analyzer = app.get_analyzer("{analyzer_type}")
    texts = {test_texts[:10]}  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è py-spy
    
    for i in range(100):  # –ú–Ω–æ–≥–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è py-spy
        for text in texts:
            try:
                if hasattr(analyzer, 'analyze'):
                    result = analyzer.analyze(text)
                    if hasattr(result, '__await__'):
                        await result
                elif hasattr(analyzer, 'analyze_song'):
                    result = analyzer.analyze_song("Unknown", f"Text_{{i}}", text)
                    if hasattr(result, '__await__'):
                        await result
            except Exception:
                pass

if __name__ == "__main__":
    asyncio.run(run_analyzer())
'''
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(script_content)
            temp_script = f.name
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º py-spy
            output_file = f"pyspy_profile_{analyzer_type}.svg"
            cmd = [
                "py-spy", "record", 
                "-d", str(duration),
                "-o", output_file,
                "--", "python", temp_script
            ]
            
            self.logger.info(f"üîç Running py-spy profiling for {duration}s...")
            
            try:
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=duration + 10)
                if result.returncode == 0:
                    self.logger.info(f"üìä py-spy profile saved to: {output_file}")
                    return output_file
                else:
                    self.logger.warning(f"py-spy failed: {result.stderr}")
                    return None
            except subprocess.TimeoutExpired:
                self.logger.warning("py-spy timed out")
                return None
            except FileNotFoundError:
                self.logger.warning("py-spy not found. Install with: pip install py-spy")
                return None
                
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            Path(temp_script).unlink(missing_ok=True)
        
        return None
    
    def hyperfine_comparison(
        self,
        analyzer_types: List[str],
        test_text: str = "Test text for hyperfine"
    ) -> Optional[Dict]:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å hyperfine"""
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        temp_scripts = []
        commands = []
        
        for analyzer_type in analyzer_types:
            script_content = f'''
import asyncio
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))
from core.app import Application

async def main():
    app = Application()
    analyzer = app.get_analyzer("{analyzer_type}")
    text = "{test_text}"
    
    try:
        if hasattr(analyzer, 'analyze'):
            result = analyzer.analyze(text)
            if hasattr(result, '__await__'):
                await result
        elif hasattr(analyzer, 'analyze_song'):
            result = analyzer.analyze_song("Unknown", "Test", text)
            if hasattr(result, '__await__'):
                await result
    except Exception as e:
        print(f"Error: {{e}}")

if __name__ == "__main__":
    asyncio.run(main())
'''
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(script_content)
                temp_scripts.append(f.name)
                commands.append(f"python {f.name}")
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º hyperfine
            cmd = ["hyperfine", "--export-json", "hyperfine_results.json"] + commands
            
            self.logger.info("üèÉ Running hyperfine comparison...")
            
            try:
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
                if result.returncode == 0:
                    # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    try:
                        with open("hyperfine_results.json", 'r') as f:
                            hyperfine_data = json.load(f)
                        
                        self.logger.info("‚ö° Hyperfine comparison completed")
                        return hyperfine_data
                    except FileNotFoundError:
                        self.logger.warning("Hyperfine results file not found")
                        return None
                else:
                    self.logger.warning(f"Hyperfine failed: {result.stderr}")
                    return None
            except subprocess.TimeoutExpired:
                self.logger.warning("Hyperfine timed out")
                return None
            except FileNotFoundError:
                self.logger.warning("Hyperfine not found. Install with: pip install hyperfine")
                return None
                
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            for script in temp_scripts:
                Path(script).unlink(missing_ok=True)
        
        return None
    
    async def load_test(
        self,
        analyzer_type: str,
        test_texts: List[str],
        concurrent_users: int = 10,
        duration_seconds: int = 60
    ) -> Dict[str, Any]:
        """–ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        
        analyzer = self.app.get_analyzer(analyzer_type)
        if not analyzer:
            raise ValueError(f"Unknown analyzer type: {analyzer_type}")
        
        self.logger.info(f"üî• Load testing {analyzer_type} with {concurrent_users} concurrent users for {duration_seconds}s")
        
        # –°—á–µ—Ç—á–∏–∫–∏
        successful_requests = 0
        failed_requests = 0
        response_times = []
        start_time = time.time()
        
        async def worker(worker_id: int):
            nonlocal successful_requests, failed_requests, response_times
            
            while time.time() - start_time < duration_seconds:
                text = test_texts[worker_id % len(test_texts)]
                request_start = time.time()
                
                try:
                    if hasattr(analyzer, 'analyze'):
                        result = analyzer.analyze(text)
                        if hasattr(result, '__await__'):
                            await result
                    elif hasattr(analyzer, 'analyze_song'):
                        result = analyzer.analyze_song("Unknown", f"Worker_{worker_id}", text)
                        if hasattr(result, '__await__'):
                            await result
                    
                    response_time = time.time() - request_start
                    response_times.append(response_time)
                    successful_requests += 1
                    
                except Exception:
                    failed_requests += 1
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                await asyncio.sleep(0.01)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–æ—Ä–∫–µ—Ä—ã
        tasks = [asyncio.create_task(worker(i)) for i in range(concurrent_users)]
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
        monitoring_task = asyncio.create_task(self._monitor_system_resources())
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        await asyncio.gather(*tasks, return_exceptions=True)
        
        self.is_monitoring = False
        try:
            await monitoring_task
        except asyncio.CancelledError:
            pass
        
        total_time = time.time() - start_time
        total_requests = successful_requests + failed_requests
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        avg_response_time = statistics.mean(response_times) if response_times else 0
        rps = successful_requests / total_time if total_time > 0 else 0
        error_rate = (failed_requests / total_requests * 100) if total_requests > 0 else 0
        
        avg_cpu = statistics.mean(self.cpu_measurements) if self.cpu_measurements else 0
        avg_memory = statistics.mean(self.memory_measurements) if self.memory_measurements else 0
        
        load_test_results = {
            'analyzer_type': analyzer_type,
            'duration_seconds': total_time,
            'concurrent_users': concurrent_users,
            'total_requests': total_requests,
            'successful_requests': successful_requests,
            'failed_requests': failed_requests,
            'requests_per_second': rps,
            'error_rate_percent': error_rate,
            'avg_response_time': avg_response_time,
            'avg_cpu_percent': avg_cpu,
            'avg_memory_mb': avg_memory
        }
        
        self.logger.info(f"‚úÖ Load test completed: {rps:.1f} RPS, {error_rate:.1f}% errors")
        return load_test_results
    
    async def _monitor_system_resources(self) -> None:
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
        self.is_monitoring = True
        process = psutil.Process()
        
        while self.is_monitoring:
            try:
                cpu_percent = process.cpu_percent()
                memory_info = process.memory_info()
                memory_mb = memory_info.rss / 1024 / 1024
                
                self.cpu_measurements.append(cpu_percent)
                self.memory_measurements.append(memory_mb)
                
                await asyncio.sleep(self.monitoring_interval)
                
            except asyncio.CancelledError:
                break
            except Exception:
                pass
        
        self.is_monitoring = False


def generate_test_texts(count: int = 50) -> List[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
    base_texts = [
        "Happy song",
        "Sad lyrics about lost love and broken dreams",
        "Energetic rap with political messages and social commentary",
        "Calm meditation on nature and human existence in modern world",
        """This is a comprehensive analysis of modern culture and its impact 
        on society, exploring themes of justice, growth, and artistic expression 
        through complex metaphors and intricate wordplay that challenges thinking""",
    ]
    
    texts = []
    for i in range(count):
        base_text = base_texts[i % len(base_texts)]
        variation = f" (test variation {i//len(base_texts) + 1})" if i >= len(base_texts) else ""
        texts.append(base_text + variation)
    
    return texts


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å CLI –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏"""
    parser = argparse.ArgumentParser(description="üöÄ Enhanced Performance Monitor")
    parser.add_argument("--analyzer", type=str, help="Analyzer type to test")
    parser.add_argument("--all", action="store_true", help="Test all available analyzers")
    parser.add_argument("--mode", choices=["benchmark", "profile", "compare", "load", "pyspy"], 
                       default="benchmark", help="Testing mode")
    parser.add_argument("--prometheus", action="store_true", help="Enable Prometheus metrics")
    parser.add_argument("--output", type=str, help="Output file for results")
    parser.add_argument("--texts", type=int, default=20, help="Number of test texts")
    parser.add_argument("--duration", type=int, default=30, help="Duration for py-spy profiling")
    parser.add_argument("--users", type=int, default=10, help="Concurrent users for load test")
    
    args = parser.parse_args()
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    monitor = EnhancedPerformanceMonitor(enable_prometheus=args.prometheus)
    test_texts = generate_test_texts(args.texts)
    
    print("üöÄ Enhanced Performance Monitor")
    print(f"Mode: {args.mode}")
    print(f"Test dataset: {len(test_texts)} texts")
    print()
    
    try:
        if args.mode == "benchmark":
            analyzer_type = args.analyzer or "algorithmic"
            metrics = await monitor.benchmark_with_profiling(
                analyzer_type, test_texts, enable_profiling=True
            )
            
            print(f"\nüìä {analyzer_type.upper()} Enhanced Metrics:")
            print("=" * 50)
            print(f"‚è±Ô∏è  Average time: {metrics.avg_time:.3f}s")
            print(f"üìà 95th percentile: {metrics.latency_p95:.3f}s")
            print(f"üìà 99th percentile: {metrics.latency_p99:.3f}s")
            print(f"üöÄ Throughput: {metrics.items_per_second:.1f} items/s")
            print(f"üíæ Memory growth: {metrics.memory_growth_mb:.1f} MB")
            print(f"‚ö° CPU efficiency: {metrics.cpu_efficiency:.2f} items/cpu%")
            print(f"üî• Hottest function: {metrics.hottest_function}")
            
        elif args.mode == "pyspy":
            analyzer_type = args.analyzer or "algorithmic"
            profile_file = await monitor.py_spy_analysis(analyzer_type, test_texts, args.duration)
            if profile_file:
                print(f"üìä py-spy profile saved to: {profile_file}")
            
        elif args.mode == "load":
            analyzer_type = args.analyzer or "algorithmic"
            results = await monitor.load_test(analyzer_type, test_texts, args.users, 60)
            
            print(f"\nüî• Load Test Results for {analyzer_type}:")
            print("=" * 50)
            print(f"üöÄ Requests/sec: {results['requests_per_second']:.1f}")
            print(f"‚úÖ Success rate: {100 - results['error_rate_percent']:.1f}%")
            print(f"‚è±Ô∏è  Avg response: {results['avg_response_time']:.3f}s")
            print(f"üíæ Memory usage: {results['avg_memory_mb']:.1f} MB")
            
        elif args.mode == "compare":
            analyzers = ["algorithmic"] if not args.all else ["algorithmic"]
            
            # Hyperfine —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            hyperfine_results = monitor.hyperfine_comparison(analyzers)
            if hyperfine_results:
                print("\n‚ö° Hyperfine Comparison:")
                for result in hyperfine_results.get('results', []):
                    print(f"  {result['command']}: {result['mean']:.3f}s ¬± {result['stddev']:.3f}s")
        
        if args.output:
            print(f"\nüìÑ Results saved to: {args.output}")
            
    except Exception as e:
        print(f"‚ùå Enhanced monitoring failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
