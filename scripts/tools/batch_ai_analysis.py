#!/usr/bin/env python3
"""
ü§ñ Batch AI Analysis Tool - Production-grade dataset processor

Processes large rap lyrics datasets in configurable batches with resume support.
Ideal for running AI analysis on thousands of songs without overwhelming system resources.

‚ú® Features:
- üìä Batch processing with configurable size
- üîÑ Resume support (continues from where it left off)
- ‚è∏Ô∏è Graceful interruption handling
- üß™ Dry-run mode for testing
- üìà Progress tracking and logging
- üíæ Resource-conscious processing

Usage examples:
    python scripts/tools/run_full_analysis.py --batch-size 50
    python scripts/tools/run_full_analysis.py --batch-size 10 --sleep 3 --max-batches 50
    python scripts/tools/run_full_analysis.py --dry-run

‚ö†Ô∏è  Production tool - processes entire database in AI analysis pipeline.
"""

import argparse
import sqlite3
import time
import logging
import sys
from typing import Optional

# Add project root to path for imports
import sys
from pathlib import Path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Analyzer will be imported when needed to avoid import errors in help mode

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def count_remaining(db_path: str) -> int:
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    cur.execute("""
        SELECT COUNT(*) as cnt
        FROM tracks s
        LEFT JOIN ai_analysis a ON s.id = a.song_id
        WHERE a.id IS NULL
    """)
    row = cur.fetchone()
    conn.close()
    return int(row[0]) if row else 0


def main(db_path: str, batch_size: int, sleep_sec: float, max_batches: Optional[int], dry_run: bool):
    """Main batch processing function with enhanced logging"""
    logger.info("ü§ñ Starting Batch AI Analysis Tool")
    logger.info("=" * 60)
    logger.info(f"üìä Config: db={db_path} | batch_size={batch_size} | sleep={sleep_sec}s | max_batches={max_batches}")
    
    remaining = count_remaining(db_path)
    logger.info(f"üéµ Songs remaining to analyze: {remaining:,}")

    if dry_run:
        estimated_batches = (remaining + batch_size - 1) // batch_size  # Ceiling division
        estimated_time = estimated_batches * sleep_sec / 60  # Minutes
        logger.info("üß™ DRY-RUN MODE - Analysis preview:")
        logger.info(f"   üìä Estimated batches: {estimated_batches}")
        logger.info(f"   ‚è±Ô∏è  Estimated time: {estimated_time:.1f} minutes")
        logger.info("   üîÑ No actual processing will occur")
        return

    logger.info("üöÄ Initializing MultiModel Analyzer...")
    try:
        from src.analyzers.multi_model_analyzer import MultiModelAnalyzer
        analyzer = MultiModelAnalyzer()
        logger.info("‚úÖ Analyzer ready")
    except ImportError as e:
        logger.error(f"‚ùå Failed to import MultiModelAnalyzer: {e}")
        logger.error("   Make sure you're running from project root and dependencies are installed")
        return

    batches = 0
    start_time = time.time()
    total_processed = 0
    
    try:
        logger.info("\nüîÑ Starting batch processing...")
        while True:
            remaining = count_remaining(db_path)
            if remaining <= 0:
                logger.info("üéâ All songs analyzed! No remaining songs to process.")
                #!/usr/bin/env python3
                """
                üéØ Batch AI Analysis Tool
                –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π resume

                –ù–ê–ó–ù–ê–ß–ï–ù–ò–ï:
                - –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ —Ç—Ä–µ–∫–æ–≤ –≤ –±–∞—Ç—á–∞—Ö –¥–ª—è AI-–∞–Ω–∞–ª–∏–∑–∞
                - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –ø–æ—Å–ª–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
                - –ü—Ä–æ–≥—Ä–µ—Å—Å —Ç—Ä–µ–∫–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

                –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
                python scripts/tools/batch_ai_analysis.py --batch-size 50
                python scripts/tools/batch_ai_analysis.py --dry-run
                python scripts/tools/batch_ai_analysis.py --help

                –ó–ê–í–ò–°–ò–ú–û–°–¢–ò:
                - Python 3.8+
                - src/core/app.py, src/interfaces/analyzer_interface.py
                - SQLite –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö (data/rap_lyrics.db)

                –†–ï–ó–£–õ–¨–¢–ê–¢:
                - –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ ai_analysis
                - –ü—Ä–æ–≥—Ä–µ—Å—Å-–ª–æ–≥–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ logs/

                –ê–í–¢–û–†: Vastargazing | –î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025
                """
                break

            if max_batches is not None and batches >= max_batches:
                logger.info(f"üõë Reached max_batches limit ({max_batches})")
                break

            current_batch = min(batch_size, remaining)
            progress = f"({batches+1}" + (f"/{max_batches}" if max_batches else "") + ")"
            
            logger.info(f"\nüì¶ Batch {progress}: Processing {current_batch} songs | {remaining:,} remaining")

            # Process batch using analyzer's existing method
            batch_start = time.time()
            analyzer.batch_analyze_from_db(db_path=db_path, limit=current_batch, offset=0)
            batch_time = time.time() - batch_start
            
            batches += 1
            total_processed += current_batch
            
            # Performance metrics
            avg_time_per_song = batch_time / current_batch if current_batch > 0 else 0
            logger.info(f"‚úÖ Batch completed in {batch_time:.1f}s | {avg_time_per_song:.2f}s per song")

            # Sleep between batches (except for last one)
            if remaining > current_batch and sleep_sec > 0:
                logger.info(f"‚è∏Ô∏è  Sleeping {sleep_sec}s before next batch...")
                time.sleep(sleep_sec)

    except KeyboardInterrupt:
        logger.info("\n‚ö†Ô∏è  Processing interrupted by user (Ctrl+C)")
    except Exception as e:
        logger.exception(f"üí• Unexpected error during processing: {e}")
    finally:
        total_time = time.time() - start_time
        remaining_final = count_remaining(db_path)
        
        logger.info("\n" + "=" * 60)
        logger.info("üèÅ BATCH PROCESSING SUMMARY")
        logger.info("=" * 60)
        logger.info(f"üì¶ Batches completed: {batches}")
        logger.info(f"üéµ Songs processed: {total_processed:,}")
        logger.info(f"üéµ Songs remaining: {remaining_final:,}")
        logger.info(f"‚è±Ô∏è  Total time: {total_time/60:.1f} minutes")
        
        if total_processed > 0:
            avg_time = total_time / total_processed
            logger.info(f"üìä Average time per song: {avg_time:.2f}s")
        
        if remaining_final == 0:
            logger.info("üéâ SUCCESS: All songs analyzed!")
        elif batches > 0:
            logger.info("‚úÖ Partial success - resume with same command to continue")
        
        logger.info("=" * 60)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='ü§ñ Batch AI Analysis Tool - Process large datasets in configurable batches',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s --batch-size 50                    # Process 50 tracks per batch
  %(prog)s --batch-size 10 --sleep 3          # Smaller batches with 3s pause
  %(prog)s --max-batches 20 --dry-run         # Test run for first 20 batches
  %(prog)s --db custom.db --batch-size 100    # Custom database path

Note: Tool automatically resumes from where it left off.
        """
    )
    
    parser.add_argument('--db', type=str, default='data/rap_lyrics.db', 
                       help='Path to SQLite database (default: data/rap_lyrics.db)')
    parser.add_argument('--batch-size', type=int, default=25,
                       help='Number of songs per batch (default: 25)')
    parser.add_argument('--sleep', type=float, default=1.0,
                       help='Seconds to sleep between batches (default: 1.0)')
    parser.add_argument('--max-batches', type=int, default=None,
                       help='Maximum batches to run (optional, for testing)')
    parser.add_argument('--dry-run', action='store_true',
                       help='Show processing plan without running analysis')

    args = parser.parse_args()
    main(db_path=args.db, batch_size=args.batch_size, sleep_sec=args.sleep, 
         max_batches=args.max_batches, dry_run=args.dry_run)
