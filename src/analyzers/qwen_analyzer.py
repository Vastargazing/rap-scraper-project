"""
ü§ñ Qwen AI –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤ –ø–µ—Å–µ–Ω (Novita AI)

–ù–ê–ó–ù–ê–ß–ï–ù–ò–ï:
- –ì–ª—É–±–æ–∫–∏–π AI-–∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ –ø–µ—Å–µ–Ω —Å –ø–æ–º–æ—â—å—é Qwen-3-4B
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∂–∞–Ω—Ä–∞, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è, –∫–∞—á–µ—Å—Ç–≤–∞, —Ç–µ–º–∞—Ç–∏–∫–∏
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–±–ª–∞—á–Ω–æ–≥–æ API Novita AI

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ main.py, batch_processor, analyzer_cli

–ó–ê–í–ò–°–ò–ú–û–°–¢–ò:
- Python 3.8+
- src/interfaces/analyzer_interface.py
- Novita AI/Qwen API –∫–ª—é—á–∏

–†–ï–ó–£–õ–¨–¢–ê–¢:
- –ú–µ—Ç—Ä–∏–∫–∏: –∂–∞–Ω—Ä, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ, –∫–∞—á–µ—Å—Ç–≤–æ, —Ç–µ–º–∞—Ç–∏–∫–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è production –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π

–ê–í–¢–û–†: AI Assistant
–î–ê–¢–ê: –°–µ–Ω—Ç—è–±—Ä—å 2025
"""
import json
import time
import logging
import os
from typing import Dict, Any, List, Optional
from datetime import datetime

from interfaces.analyzer_interface import BaseAnalyzer, AnalysisResult, register_analyzer

# –£—Å–ª–æ–≤–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
try:
    import openai
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False

logger = logging.getLogger(__name__)


@register_analyzer("qwen")
class QwenAnalyzer(BaseAnalyzer):
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞ –±–∞–∑–µ Qwen –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Novita AI API.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤ –ø–µ—Å–µ–Ω:
    - –ñ–∞–Ω—Ä–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
    - –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∏ —ç–º–æ—Ü–∏–π
    - –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–æ–≤
    - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–º–∞—Ç–∏–∫–∏
    - –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Qwen –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        super().__init__(config)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
        self.model_name = self.config.get('model_name', 'qwen/qwen3-4b-fp8')
        self.base_url = self.config.get('base_url', 'https://api.novita.ai/openai/v1')
        self.temperature = self.config.get('temperature', 0.1)
        self.max_tokens = self.config.get('max_tokens', 1500)
        self.timeout = self.config.get('timeout', 30)
        
        # API –∫–ª—é—á
        self.api_key = self.config.get('api_key') or os.getenv("NOVITA_API_KEY")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
        self.available = self._check_availability()
        
        if self.available:
            self.client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.base_url,
                timeout=self.timeout
            )
            logger.info(f"‚úÖ Qwen –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.model_name}")
        else:
            logger.warning("‚ö†Ô∏è Qwen –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    
    def _check_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Novita AI API"""
        if not HAS_OPENAI:
            logger.error("‚ùå openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")
            return False
        
        if not self.api_key:
            logger.error("‚ùå NOVITA_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
            return False
        
        try:
            # –¢–µ—Å—Ç–æ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
            
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç API
            response = client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Test"}
                ],
                max_tokens=10,
                temperature=0.1
            )
            
            if response.choices and response.choices[0].message:
                logger.info("‚úÖ Novita AI Qwen API —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω")
                return True
            else:
                logger.error("‚ùå –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Qwen API")
                return False
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Qwen API: {e}")
            return False
    
    def analyze_song(self, artist: str, title: str, lyrics: str) -> AnalysisResult:
        """
        –ê–Ω–∞–ª–∏–∑ –ø–µ—Å–Ω–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Qwen –º–æ–¥–µ–ª–∏.
        
        Args:
            artist: –ò–º—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
            title: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Å–Ω–∏
            lyrics: –¢–µ–∫—Å—Ç –ø–µ—Å–Ω–∏
            
        Returns:
            AnalysisResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        start_time = time.time()
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not self.validate_input(artist, title, lyrics):
            raise ValueError("Invalid input parameters")
        
        if not self.available:
            raise RuntimeError("Qwen analyzer is not available")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        processed_lyrics = self.preprocess_lyrics(lyrics)
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
            system_prompt, user_prompt = self._create_analysis_prompts(artist, title, processed_lyrics)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            if not response.choices or not response.choices[0].message.content:
                raise RuntimeError("Empty response from Qwen model")
            
            # –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            analysis_data = self._parse_response(response.choices[0].message.content)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidence = self._calculate_confidence(analysis_data)
            
            processing_time = time.time() - start_time
            
            return AnalysisResult(
                artist=artist,
                title=title,
                analysis_type="qwen",
                confidence=confidence,
                metadata={
                    "model_name": self.model_name,
                    "model_version": "qwen3-4b-fp8",
                    "processing_date": datetime.now().isoformat(),
                    "lyrics_length": len(processed_lyrics),
                    "temperature": self.temperature,
                    "max_tokens": self.max_tokens,
                    "provider": "Novita AI",
                    "usage": {
                        "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                        "completion_tokens": response.usage.completion_tokens if response.usage else 0,
                        "total_tokens": response.usage.total_tokens if response.usage else 0
                    }
                },
                raw_output=analysis_data,
                processing_time=processing_time,
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Qwen –¥–ª—è {artist} - {title}: {e}")
            raise RuntimeError(f"Qwen analysis failed: {e}") from e
    
    def _create_analysis_prompts(self, artist: str, title: str, lyrics: str) -> tuple[str, str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è Qwen –º–æ–¥–µ–ª–∏"""
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ –¥–ª—è API
        max_lyrics_length = 2000
        if len(lyrics) > max_lyrics_length:
            lyrics = lyrics[:max_lyrics_length] + "..."
        
        system_prompt = """You are a rap lyrics analyzer. You MUST respond with ONLY a JSON object, no other text.

CRITICAL: Do not include ANY explanations, thoughts, or text outside the JSON. 
NO <think> tags, NO explanations, NO additional text.
Start your response with { and end with }.

Analyze rap songs and return JSON with this structure only."""
        
        user_prompt = f"""Artist: {artist}
Title: {title}
Lyrics: {lyrics}

Return ONLY this JSON structure (fill with actual analysis):
{{
    "genre_analysis": {{
        "primary_genre": "rap",
        "subgenre": "string",
        "confidence": 0.9
    }},
    "mood_analysis": {{
        "primary_mood": "confident",
        "emotional_intensity": "high",
        "energy_level": "high", 
        "valence": "positive"
    }},
    "content_analysis": {{
        "explicit_content": false,
        "explicit_level": "none",
        "main_themes": ["success"],
        "narrative_style": "boastful"
    }},
    "technical_analysis": {{
        "rhyme_scheme": "complex",
        "flow_pattern": "varied",
        "complexity_level": "advanced",
        "wordplay_quality": "excellent",
        "metaphor_usage": "moderate",
        "structure": "traditional"
    }},
    "quality_metrics": {{
        "lyrical_creativity": 0.8,
        "technical_skill": 0.9,
        "authenticity": 0.9,
        "commercial_appeal": 0.8,
        "originality": 0.8,
        "overall_quality": 0.8,
        "ai_generated_likelihood": 0.1
    }},
    "cultural_context": {{
        "era_estimate": "2020s",
        "regional_style": "mainstream",
        "cultural_references": [],
        "social_commentary": false
    }}
}}"""
        
        return system_prompt, user_prompt
    
    def _parse_response(self, response_text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Qwen –º–æ–¥–µ–ª–∏"""
        try:
            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
            response_text = response_text.strip()
            
            # –£–¥–∞–ª—è–µ–º —Ç–µ–≥–∏ <think>...</think> 
            import re
            response_text = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL)
            response_text = response_text.strip()
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            logger.debug(f"Cleaned response (first 500 chars): {response_text[:500]}")
            
            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —É–∂–µ JSON, –ø–∞—Ä—Å–∏–º –Ω–∞–ø—Ä—è–º—É—é
            if response_text.startswith('{') and response_text.endswith('}'):
                try:
                    analysis_data = json.loads(response_text)
                    logger.debug("‚úÖ Direct JSON parsing successful")
                except json.JSONDecodeError as e:
                    logger.warning(f"Direct JSON parsing failed: {e}")
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å –∏ –ø–∞—Ä—Å–∏—Ç—å —Å–Ω–æ–≤–∞
                    fixed_json = self._fix_common_json_issues(response_text)
                    try:
                        analysis_data = json.loads(fixed_json)
                        logger.debug("‚úÖ JSON parsing successful after fixes")
                    except json.JSONDecodeError:
                        logger.error(f"JSON still invalid after fixes")
                        analysis_data = self._create_fallback_analysis()
            else:
                # –ü–æ–∏—Å–∫ JSON –±–ª–æ–∫–∞ –≤ —Ç–µ–∫—Å—Ç–µ
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                
                if json_start == -1 or json_end == 0:
                    logger.error(f"No JSON found in response. Full response: {response_text}")
                    # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–π –æ—Ç–≤–µ—Ç
                    analysis_data = self._create_fallback_analysis()
                else:
                    json_str = response_text[json_start:json_end]
                    try:
                        analysis_data = json.loads(json_str)
                    except json.JSONDecodeError:
                        logger.error(f"Invalid JSON in response: {json_str}")
                        analysis_data = self._create_fallback_analysis()
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            self._validate_analysis_structure(analysis_data)
            
            return analysis_data
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            logger.error(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {response_text[:500]}...")
            return self._create_fallback_analysis()
        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return self._create_fallback_analysis()
    
    def _fix_common_json_issues(self, json_str: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å JSON"""
        import re
        
        # –£–¥–∞–ª—è–µ–º trailing commas
        json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –Ω–∞ –¥–≤–æ–π–Ω—ã–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        json_str = re.sub(r"'([^']*)':", r'"\1":', json_str)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –≤ –∫–æ–Ω—Ü–µ
        json_str = json_str.strip()
        
        return json_str
    
    def _validate_analysis_structure(self, data: Dict[str, Any]) -> None:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        required_sections = [
            'genre_analysis', 'mood_analysis', 'content_analysis',
            'technical_analysis', 'quality_metrics', 'cultural_context'
        ]
        
        for section in required_sections:
            if section not in data:
                raise ValueError(f"Missing required section: {section}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        quality_metrics = data.get('quality_metrics', {})
        for metric in ['lyrical_creativity', 'technical_skill', 'authenticity', 
                      'commercial_appeal', 'originality', 'overall_quality']:
            if metric in quality_metrics:
                value = quality_metrics[metric]
                if not isinstance(value, (int, float)) or not 0 <= value <= 1:
                    logger.warning(f"Invalid metric value for {metric}: {value}")
    
    def _calculate_confidence(self, analysis_data: Dict[str, Any]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –∞–Ω–∞–ª–∏–∑–∞"""
        confidence_factors = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        sections_completed = 0
        total_sections = 6
        
        for section_name in ['genre_analysis', 'mood_analysis', 'content_analysis',
                           'technical_analysis', 'quality_metrics', 'cultural_context']:
            if section_name in analysis_data and analysis_data[section_name]:
                sections_completed += 1
        
        completeness_score = sections_completed / total_sections
        confidence_factors.append(completeness_score)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –∂–∞–Ω—Ä–µ
        genre_analysis = analysis_data.get('genre_analysis', {})
        if 'confidence' in genre_analysis:
            genre_confidence = genre_analysis['confidence']
            if isinstance(genre_confidence, (int, float)) and 0 <= genre_confidence <= 1:
                confidence_factors.append(genre_confidence)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        quality_metrics = analysis_data.get('quality_metrics', {})
        if quality_metrics:
            # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
            valid_metrics = []
            for metric_value in quality_metrics.values():
                if isinstance(metric_value, (int, float)) and 0 <= metric_value <= 1:
                    valid_metrics.append(metric_value)
            
            if valid_metrics:
                avg_quality = sum(valid_metrics) / len(valid_metrics)
                confidence_factors.append(avg_quality)
        
        # –û–±—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        if confidence_factors:
            return sum(confidence_factors) / len(confidence_factors)
        else:
            return 0.5  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–∞–Ω–Ω—ã—Ö
    
    def get_analyzer_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–µ"""
        return {
            "name": "QwenAnalyzer",
            "version": "1.0.0",
            "description": "AI-powered lyrics analysis using Qwen-3-4B model via Novita AI",
            "author": "Rap Scraper Project",
            "type": self.analyzer_type,
            "supported_features": self.supported_features,
            "model_info": {
                "model_name": self.model_name,
                "provider": "Novita AI",
                "base_url": self.base_url,
                "temperature": self.temperature,
                "max_tokens": self.max_tokens
            },
            "requirements": ["openai", "NOVITA_API_KEY"],
            "available": self.available,
            "config_options": {
                "model_name": "Qwen model to use (default: qwen/qwen3-4b-fp8)",
                "base_url": "API base URL (default: https://api.novita.ai/openai/v1)",
                "temperature": "Generation temperature (default: 0.1)",
                "max_tokens": "Maximum output tokens (default: 1500)",
                "timeout": "Request timeout in seconds (default: 30)",
                "api_key": "Novita API key (can use NOVITA_API_KEY env var)"
            }
        }
    
    @property
    def analyzer_type(self) -> str:
        """–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        return "ai"
    
    @property
    def supported_features(self) -> List[str]:
        """–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞"""
        return [
            "genre_classification",
            "mood_analysis",
            "content_analysis", 
            "technical_analysis",
            "quality_assessment",
            "cultural_context",
            "authenticity_detection",
            "ai_generation_detection",
            "commercial_appeal",
            "lyrical_creativity"
        ]
    
    def preprocess_lyrics(self, lyrics: str) -> str:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è Qwen –º–æ–¥–µ–ª–∏"""
        # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
        lyrics = super().preprocess_lyrics(lyrics)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –º–µ—à–∞—Ç—å –∞–Ω–∞–ª–∏–∑—É
        import re
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Å–∏–º–≤–æ–ª–æ–≤
        lyrics = re.sub(r'(.)\1{3,}', r'\1\1\1', lyrics)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤
        lyrics = re.sub(r'\n{3,}', '\n\n', lyrics)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ URL –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        lyrics = re.sub(r'http[s]?://\S+', '', lyrics)
        lyrics = re.sub(r'[^\w\s\n.,!?\'"-]', '', lyrics)
        
        return lyrics.strip()
    
    def _create_fallback_analysis(self) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞"""
        return {
            "genre_analysis": {
                "primary_genre": "unknown",
                "subgenre": "unknown",
                "confidence": 0.0
            },
            "mood_analysis": {
                "primary_mood": "neutral",
                "emotional_intensity": "unknown",
                "energy_level": "unknown",
                "valence": "neutral"
            },
            "content_analysis": {
                "explicit_content": False,
                "explicit_level": "unknown",
                "main_themes": [],
                "narrative_style": "unknown"
            },
            "technical_analysis": {
                "rhyme_scheme": "unknown",
                "flow_pattern": "unknown",
                "complexity_level": "unknown",
                "wordplay_quality": "unknown",
                "metaphor_usage": "unknown",
                "structure": "unknown"
            },
            "quality_metrics": {
                "lyrical_creativity": 0.0,
                "technical_skill": 0.0,
                "authenticity": 0.0,
                "commercial_appeal": 0.0,
                "originality": 0.0,
                "overall_quality": 0.0,
                "ai_generated_likelihood": 0.0
            },
            "cultural_context": {
                "era_estimate": "unknown",
                "regional_style": "unknown",
                "cultural_references": [],
                "social_commentary": False
            }
        }


# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (–µ—Å–ª–∏ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª)
try:
    from interfaces.analyzer_interface import AnalyzerFactory
    AnalyzerFactory.register("qwen", QwenAnalyzer)
except ImportError:
    pass
