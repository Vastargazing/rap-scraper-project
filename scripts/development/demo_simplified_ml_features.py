#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö ML-—Ñ–∏—á–µ–π (–±–µ–∑ NLTK)

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –±–∞–∑–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ Feature Engineering:
- Rhyme density –∏ —Å—Ö–µ–º—ã —Ä–∏—Ñ–º–æ–≤–∫–∏
- Vocabulary diversity (TTR)
- Metaphor/wordplay detection (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
- Flow patterns (–±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑)
"""

import json
import sys
import time
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.analyzers.simplified_feature_analyzer import (
    SimplifiedFeatureAnalyzer,
    extract_simplified_features,
)


def demo_rhyme_analysis():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Ñ–º"""
    print("üéµ === –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ê–ù–ê–õ–ò–ó–ê –†–ò–§–ú ===\n")

    rhyme_samples = {
        "–ü—Ä–æ—Å—Ç—ã–µ —Ä–∏—Ñ–º—ã (AABB)": """
            –Ø –∏–¥—É –ø–æ –¥–æ—Ä–æ–≥–µ –¥–æ–º–æ–π
            –°–æ –º–Ω–æ–π –º–æ—è –ª—é–±–æ–≤—å –∏ –ø–æ–∫–æ–π
            –í –∫–∞—Ä–º–∞–Ω–µ –∑–≤–µ–Ω—è—Ç –º–æ–Ω–µ—Ç—ã  
            –ö–∞–∫ –ø–µ—Å–Ω–∏ –≤–µ—Å–µ–Ω–Ω–∏–µ –≤–µ—Ç—Ä–∞
        """,
        "–°–ª–æ–∂–Ω—ã–µ —Ä–∏—Ñ–º—ã (ABAB)": """
            –í—Ä–µ–º—è —Ç–µ—á—ë—Ç –∫–∞–∫ —Ä–µ–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω–∞—è
            –í —Ä–∏—Ç–º–µ —Å–µ—Ä–¥—Ü–∞ —Å—Ç—É—á–∏—Ç –º–æ–π —Ñ–ª–æ—É
            –ñ–∏–∑–Ω—å –ø—Ä–æ–ª–µ—Ç–∞–µ—Ç —Å—Ç—Ä–µ–ª–æ–π –±—ã—Å—Ç—Ä–æ—Ç–µ—á–Ω–æ—é
            –Ø –æ—Å—Ç–∞—é—Å—å –∑–¥–µ—Å—å –Ω–∞–∑–ª–æ –≤—Å–µ–º—É –∑–ª—É
        """,
        "–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Ä–∏—Ñ–º—ã": """
            –ë–∏—Ç –∫–∞—á–∞–µ—Ç, —Å–µ—Ä–¥—Ü–µ —Å–∫–∞—á–µ—Ç, –∑–Ω–∞—á–∏—Ç –≤—Å—ë –Ω–æ—Ä–º–∞–ª—å–Ω–æ
            –†–∏—Ñ–º–∞ –∫ —Ä–∏—Ñ–º–µ, —Å—Ç—Ä–æ—á–∫–∞ –∫ —Å—Ç—Ä–æ—á–∫–µ, —Å–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≥—Ä–∞–º–æ—Ç–Ω–æ
            –í –∫–∞–∂–¥–æ–º —Å–ª–æ–≤–µ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—è, –≤ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ—á–∫–µ ‚Äî –ø—Ä–∞–≤–¥–∞
            –≠—Ç–æ —Ä—ç–ø –∏–∑ –≥–ª—É–±–∏–Ω—ã –¥—É—à–∏, –∞ –Ω–µ –ø—É—Å—Ç–∞—è –∑–∞–±–∞–≤–∞
        """,
    }

    analyzer = SimplifiedFeatureAnalyzer()

    for sample_name, lyrics in rhyme_samples.items():
        print(f"üìù {sample_name}:")
        features = extract_simplified_features(lyrics.strip())

        print(f"   –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∏—Ñ–º: {features.get('rhyme_density', 0):.3f}")
        print(f"   –¢–æ—á–Ω—ã–µ —Ä–∏—Ñ–º—ã: {features.get('perfect_rhymes', 0):.0f}")
        print(f"   –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Ä–∏—Ñ–º—ã: {features.get('internal_rhymes', 0):.0f}")
        print(f"   –ê–ª–ª–∏—Ç–µ—Ä–∞—Ü–∏—è: {features.get('alliteration_score', 0):.3f}")
        print()


def demo_vocabulary_diversity():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —Å–ª–æ–≤–∞—Ä—è"""
    print("üìö === –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ê–ù–ê–õ–ò–ó–ê –°–õ–û–í–ê–†–Ø ===\n")

    vocab_samples = {
        "–ë–∞–∑–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å": """
            –Ø –∏–¥—É –¥–æ–º–æ–π –±—ã—Å—Ç—Ä–æ
            –î–æ–º –º–æ–π –¥–æ–º —Ö–æ—Ä–æ—à–∏–π
            –•–æ—Ä–æ—à–æ –¥–æ–º–∞ –±—ã—Å—Ç—Ä–æ
            –ë—ã—Å—Ç—Ä–æ –∏–¥—É –¥–æ–º —Ö–æ—Ä–æ—à–æ
        """,
        "–ë–æ–≥–∞—Ç—ã–π —Å–ª–æ–≤–∞—Ä—å": """
            –ë–ª—É–∂–¥–∞—é –ø–æ –ª–∞–±–∏—Ä–∏–Ω—Ç–∞–º –º–µ–≥–∞–ø–æ–ª–∏—Å–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ
            –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–æ–∑–Ω–∞–Ω–∏—è —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏
            –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–µ—Ä–µ–ø–ª–µ—Ç–∞—é—Ç—Å—è —Å —ç–º–æ—Ü–∏—è–º–∏
            –°–æ–∑–¥–∞–≤–∞—è —Å–∏–º—Ñ–æ–Ω–∏—é –º—ã—Å–ª–µ–π –≤ —Ö–∞–æ—Å–µ —É—Ä–±–∞–Ω–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Å—Ä–µ–¥—ã
        """,
        "–°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å": """
            –ì–æ—Ä–æ–¥–∞ –º–µ–Ω—è—é—Ç—Å—è, –ª—é–¥–∏ –æ—Å—Ç–∞—é—Ç—Å—è –ø—Ä–µ–∂–Ω–∏–º–∏
            –ò—Å—Ç–æ—Ä–∏—è –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è, –Ω–æ –≤ –Ω–æ–≤—ã—Ö –¥–µ–∫–æ—Ä–∞—Ü–∏—è—Ö
            –ú—É–¥—Ä–æ—Å—Ç—å –ø–æ–∫–æ–ª–µ–Ω–∏–π –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –º—É–∑—ã–∫—É
            –†–∏—Ç–º –∂–∏–∑–Ω–∏ —É—Å–∫–æ—Ä—è–µ—Ç—Å—è, –Ω–æ —Å–º—ã—Å–ª –æ—Å—Ç–∞–µ—Ç—Å—è –≤–µ—á–Ω—ã–º
        """,
    }

    for sample_name, lyrics in vocab_samples.items():
        print(f"üìñ {sample_name}:")
        features = extract_simplified_features(lyrics.strip())

        print(f"   TTR Score: {features.get('ttr_score', 0):.3f}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞: {features.get('average_word_length', 0):.1f}")
        print(f"   –î–æ–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª–æ–≤: {features.get('complex_words_ratio', 0):.3f}")
        print()


def demo_metaphor_detection():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –º–µ—Ç–∞—Ñ–æ—Ä"""
    print("üé® === –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ê–ù–ê–õ–ò–ó–ê –ú–ï–¢–ê–§–û–† ===\n")

    metaphor_samples = {
        "–ú–Ω–æ–≥–æ –º–µ—Ç–∞—Ñ–æ—Ä": """
            –ñ–∏–∑–Ω—å –∫–∞–∫ —à–∞—Ö–º–∞—Ç–Ω–∞—è –ø–∞—Ä—Ç–∏—è —Å —Å—É–¥—å–±–æ–π
            –ú–æ–∏ —Å–ª–æ–≤–∞ –∫–∞–∫ –ø—É–ª–∏ –≤ –≤–æ–π–Ω–µ –∑–∞ –ø—Ä–∞–≤–¥—É
            –°–µ—Ä–¥—Ü–µ –≥–æ—Ä–∏—Ç –∫–∞–∫ –æ–≥–æ–Ω—å –≤ –Ω–æ—á–∏
            –í—Ä–µ–º—è —Ç–µ—á—ë—Ç –∫–∞–∫ —Ä–µ–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω–∞—è
            –î—É—à–∞ –ø–∞—Ä–∏—Ç –∫–∞–∫ –ø—Ç–∏—Ü–∞ –≤ –Ω–µ–±–µ—Å–∞—Ö
        """,
        "–ò–≥—Ä–∞ —Å–ª–æ–≤": """
            Money talks, –Ω–æ —è –≥–æ–≤–æ—Ä—é –Ω–∞ —è–∑—ã–∫–µ –¥–µ–Ω–µ–≥
            Flow –∫–∞–∫ —Ä–µ–∫–∞, –Ω–æ —è –ø–ª—ã–≤—É –ø—Ä–æ—Ç–∏–≤ —Ç–µ—á–µ–Ω–∏—è
            Bars –∫–∞–∫ —Ç—é—Ä—å–º–∞, –Ω–æ —è —Å–≤–æ–±–æ–¥–µ–Ω –≤ —Å–≤–æ–∏—Ö —Ä–∏—Ñ–º–∞—Ö
            Beat –∫–∞–∫ —Å–µ—Ä–¥—Ü–µ, –∏ —è —á—É–≤—Å—Ç–≤—É—é –µ–≥–æ –ø—É–ª—å—Å
            Words –∫–∞–∫ –æ—Ä—É–∂–∏–µ, –∏ —è –º–∞—Å—Ç–µ—Ä –±–æ—è
        """,
        "–ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç": """
            –Ø –∏–¥—É –≤ –º–∞–≥–∞–∑–∏–Ω –∫—É–ø–∏—Ç—å —Ö–ª–µ–±
            –í—Å—Ç—Ä–µ—á–∞—é –¥—Ä—É–≥–∞ –Ω–∞ —É–ª–∏—Ü–µ
            –ú—ã –≥–æ–≤–æ—Ä–∏–º –æ –ø–æ–≥–æ–¥–µ
            –ü–æ—Ç–æ–º —Ä–∞—Å—Ö–æ–¥–∏–º—Å—è –ø–æ –¥–æ–º–∞–º
        """,
    }

    for sample_name, lyrics in metaphor_samples.items():
        print(f"üé≠ {sample_name}:")
        features = extract_simplified_features(lyrics.strip())

        print(f"   –ú–µ—Ç–∞—Ñ–æ—Ä—ã: {features.get('metaphor_count', 0):.0f}")
        print(f"   –ò–≥—Ä–∞ —Å–ª–æ–≤: {features.get('wordplay_instances', 0):.0f}")
        print(f"   –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å: {features.get('creativity_score', 0):.3f}")
        print()


def demo_flow_analysis():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–ª–æ—É"""
    print("üéº === –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ê–ù–ê–õ–ò–ó–ê –§–õ–û–£ ===\n")

    flow_samples = {
        "–†–æ–≤–Ω—ã–π —Ñ–ª–æ—É": """
            –ö–∞–∂–¥–∞—è —Å—Ç—Ä–æ—á–∫–∞ –∑–≤—É—á–∏—Ç –æ–¥–∏–Ω–∞–∫–æ–≤–æ
            –†–∏—Ç–º –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è –Ω–∏–∫–æ–≥–¥–∞ —Å–æ–≤—Å–µ–º
            –°–ª–æ–≥–∏ –ª–æ–∂–∞—Ç—Å—è —Ä–æ–≤–Ω–æ –∏ –∫—Ä–∞—Å–∏–≤–æ
            –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π —Ñ–ª–æ—É
        """,
        "–°–ª–æ–∂–Ω—ã–π —Ñ–ª–æ—É": """
            –ë—ã—Å—Ç—Ä–æ-–º–µ–¥–ª–µ–Ω–Ω–æ, —Ç–∏—Ö–æ-–≥—Ä–æ–º–∫–æ ‚Äî —ç—Ç–æ –∏–≥—Ä–∞!
            –°–∏–Ω–∫–æ–ø—ã, –ø–∞—É–∑—ã... (—Å—Ç–æ–ø) ‚Äî –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω—É–ª—è
            –°–ª–æ–≥–∏ –ø—Ä—ã–≥–∞—é—Ç: —Ä–∞–∑-–¥–≤–∞-—Ç—Ä–∏-—á–µ—Ç—ã—Ä–µ-–ø—è—Ç—å
            –ê –ø–æ—Ç–æ–º ‚Äî –¥–ª–∏–Ω–Ω–∞—è –ø–∞—É–∑–∞... —á—Ç–æ–±—ã –¥–∞—Ç—å –ø–æ–¥—É–º–∞—Ç—å
        """,
        "–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–π —Ç–µ–º–ø": """
            –ú–µ–¥–ª–µ–Ω–Ω–æ –Ω–∞—á–∏–Ω–∞—é —Å–≤–æ–π —Ä–∞—Å—Å–∫–∞–∑ –æ —Ç–æ–º
            –ö–∞–∫ –±—ã—Å—Ç—Ä–æ–±—ã—Å—Ç—Ä–æ–±—ã—Å—Ç—Ä–æ –º–æ–∂–µ—Ç –∑–≤—É—á–∞—Ç—å —Ä—ç–ø
            –ü–æ—Ç–æ–º... –æ–ø—è—Ç—å... –∑–∞–º–µ–¥–ª—è—é—Å—å... –∏ —Å–Ω–æ–≤–∞
            –£—Å–∫–æ—Ä—è—é—Å—å-—É—Å–∫–æ—Ä—è—é—Å—å-–¥–æ-–ø—Ä–µ–¥–µ–ª–∞!
        """,
    }

    for sample_name, lyrics in flow_samples.items():
        print(f"üéµ {sample_name}:")
        features = extract_simplified_features(lyrics.strip())

        print(
            f"   –°–ª–æ–≥–æ–≤ –Ω–∞ —Å—Ç—Ä–æ–∫—É: {features.get('average_syllables_per_line', 0):.1f}"
        )
        print(
            f"   –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: {features.get('stress_pattern_consistency', 0):.3f}"
        )
        print(f"   –ü–∞—É–∑—ã –≤–æ —Ñ–ª–æ—É: {features.get('flow_breaks', 0):.0f}")
        print()


def demo_composite_metrics():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–º–ø–æ–∑–∏—Ç–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
    print("üèÜ === –ö–û–ú–ü–û–ó–ò–¢–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ú–ê–°–¢–ï–†–°–¢–í–ê ===\n")

    skill_samples = {
        "–ù–∞—á–∏–Ω–∞—é—â–∏–π": """
            –Ø —Ä—ç–ø–µ—Ä –Ω–æ–≤—ã–π
            –ü–∏—à—É –ø—Ä–æ—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç—ã
            –†–∏—Ñ–º—ã –Ω–µ –æ—á–µ–Ω—å
            –ù–æ —Å—Ç–∞—Ä–∞—é—Å—å –ª—É—á—à–µ
        """,
        "–û–ø—ã—Ç–Ω—ã–π": """
            –ú–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ –æ—Ç—Ç–∞—á–∏–≤–∞–ª –≥–æ–¥–∞–º–∏ –≤ —Å—Ç—É–¥–∏–∏ –∑–≤—É–∫–æ–∑–∞–ø–∏—Å–∏
            –†–∏—Ñ–º—ã —Å–ª–æ–∂–Ω—ã–µ –ø–ª–µ—Ç—É, –∫–∞–∫ –ø–∞—É—Ç–∏–Ω—É –∏—Å–∫—É—Å–Ω–æ  
            –ú–µ—Ç–∞—Ñ–æ—Ä—ã –∏ –∞–ª–ª–µ–≥–æ—Ä–∏–∏ –≤ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ—á–∫–µ –ø—Ä–æ–ø–∏—Å–∞–Ω—ã
            –§–ª–æ—É –º–µ–Ω—è–µ—Ç—Å—è –ø–ª–∞–≤–Ω–æ, —Ç–µ—Ö–Ω–∏–∫–∞ –æ—Ç—Ä–∞–±–æ—Ç–∞–Ω–∞ —á–∏—Å—Ç–æ
        """,
        "–ú–∞—Å—Ç–µ—Ä": """
            –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ª–∏—Ä–∏—á–µ—Å–∫–∏—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π —Å–ª–æ–∂–Ω–æ—Å–æ—á–∏–Ω—ë–Ω–Ω—ã—Ö
            –°–∏–Ω–µ—Å—Ç–µ–∑–∏—è —Å–ª–æ–≤ —Ä–æ–∂–¥–∞–µ—Ç —Å–∏–º—Ñ–æ–Ω–∏–∏ –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ
            –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –∫–∞–ª–∞–º–±—É—Ä—ã –ø–µ—Ä–µ–ø–ª–µ—Ç–∞—é—Ç—Å—è –∏—Å–∫—É—Å–Ω–æ
            –° —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π —Ñ–∏–ª–æ—Å–æ—Ñ–∏–µ–π —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ—Å—Ç–º–æ–¥–µ—Ä–Ω–∏—Å—Ç—Å–∫–æ–π
        """,
    }

    for sample_name, lyrics in skill_samples.items():
        print(f"üéØ {sample_name}:")
        features = extract_simplified_features(lyrics.strip())

        print(f"   –û–±—â–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {features.get('overall_complexity', 0):.3f}")
        print(f"   –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ: {features.get('technical_skill', 0):.3f}")
        print(f"   –•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å: {features.get('artistic_sophistication', 0):.3f}")
        print(f"   –ò–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–æ—Å—Ç—å: {features.get('innovation_score', 0):.3f}")

        # –ü—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
        technical_level = features.get("technical_skill", 0)
        if technical_level > 0.7:
            level_desc = "Expert"
        elif technical_level > 0.5:
            level_desc = "Skilled"
        else:
            level_desc = "Developing"

        print(f"   –£—Ä–æ–≤–µ–Ω—å –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–∞: {level_desc}")
        print()


def demo_performance():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print("‚ö° === –¢–ï–°–¢ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò ===\n")

    test_lyrics = """
    –≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç—ã
    –ê–ª–≥–æ—Ä–∏—Ç–º–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∏—á–µ–π –∏–∑ —Ä—ç–ø-—Ç–µ–∫—Å—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    –†–∏—Ñ–º—ã, –º–µ—Ç–∞—Ñ–æ—Ä—ã, —Ñ–ª–æ—É –∏ —Å–ª–æ–≤–∞—Ä–Ω–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –±—ã—Å—Ç—Ä–æ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –¥–ª—è ML pipeline
    """

    # –¢–µ—Å—Ç –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
    start_time = time.time()
    features = extract_simplified_features(test_lyrics)
    single_time = time.time() - start_time

    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∏—á–µ–π (1 —Ç–µ–∫—Å—Ç): {single_time:.4f}—Å")
    print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ñ–∏—á–µ–π: {len(features)}")

    # –¢–µ—Å—Ç –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
    lyrics_list = [test_lyrics] * 100
    start_time = time.time()
    for lyrics in lyrics_list:
        extract_simplified_features(lyrics)
    batch_time = time.time() - start_time

    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è (100 —Ç–µ–∫—Å—Ç–æ–≤): {batch_time:.4f}—Å")
    print(f"üìà –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {batch_time / 100:.4f}—Å –Ω–∞ —Ç–µ–∫—Å—Ç")
    print(f"üöÄ –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: ~{int(3600 / batch_time * 100)} —Ç–µ–∫—Å—Ç–æ–≤/—á–∞—Å")
    print()


def save_sample_features():
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ —Ñ–∏—á–µ–π"""
    print("üíæ === –°–û–•–†–ê–ù–ï–ù–ò–ï –ü–†–ò–ú–ï–†–ê –§–ò–ß–ï–ô ===\n")

    sample_lyrics = """
    –Ø –ø–æ–¥–Ω–∏–º–∞—é—Å—å –Ω–∞–¥ –≥–æ—Ä–æ–¥–æ–º –∫–∞–∫ —Å–æ–ª–Ω—Ü–µ —Ä–∞—Å—Å–≤–µ—Ç–Ω–æ–µ
    –ú–æ–∏ —Ä–∏—Ñ–º—ã ‚Äî —ç—Ç–æ –ø—É–ª–∏, –ª–µ—Ç—è—â–∏–µ –≤ —Ü–µ–ª—å –º–µ—Ç–∫–æ
    –í –ª–∞–±–∏—Ä–∏–Ω—Ç–µ –∏–∑ —Å–ª–æ–≤ —è –Ω–∞—à—ë–ª –¥–æ—Ä–æ–≥—É –∫ —Å–≤–µ—Ç—É
    –§–ª–æ—É –ª—å—ë—Ç—Å—è –∫–∞–∫ —Ä–µ–∫–∞, –Ω–µ—Å—ë—Ç –º–µ–Ω—è –∫ –ø–æ–±–µ–¥–µ
    
    –í—Ä–µ–º—è ‚Äî –¥–µ–Ω—å–≥–∏, –Ω–æ –º—É–¥—Ä–æ—Å—Ç—å –¥–æ—Ä–æ–∂–µ –∑–æ–ª–æ—Ç–∞
    –í –∏–≥—Ä–µ —Ç–µ–Ω–µ–π —è —Å–æ–∑–¥–∞—é –Ω–æ–≤—É—é —ç–ø–æ—Ö—É
    –°–ª–æ–≤–∞ —Ç–∞–Ω—Ü—É—é—Ç –Ω–∞ –±–∏—Ç–∞—Ö, —Ä–æ–∂–¥–∞—è –º–∞–≥–∏—é –∑–≤—É–∫–∞
    –≠—Ç–æ –∏—Å–∫—É—Å—Å—Ç–≤–æ rap'–∞ ‚Äî –º–æ—è –≤–µ—á–Ω–∞—è –Ω–∞—É–∫–∞
    """

    features = extract_simplified_features(sample_lyrics)

    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
    sample_data = {
        "lyrics": sample_lyrics.strip(),
        "extracted_features": features,
        "feature_count": len(features),
        "extraction_info": {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "analyzer_version": "simplified_v1.0",
            "method": "basic_nlp_without_external_libs",
        },
    }

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    output_file = "results/sample_simplified_ml_features.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(sample_data, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    print(f"üìä –í—Å–µ–≥–æ —Ñ–∏—á–µ–π: {len(features)}")
    print("üîç –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
    for key, value in features.items():
        if "score" in key or "complexity" in key or "skill" in key:
            print(f"   {key}: {value:.3f}")
    print()


def create_feature_comparison():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤"""
    print("üìä === –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó ===\n")

    comparison_samples = {
        "–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ–ø-—Ä—ç–ø": """
            Party party party –≤—Å—é –Ω–æ—á—å –¥–æ —É—Ç—Ä–∞
            Money money money —ç—Ç–æ –º–æ—è –∏–≥—Ä–∞
            –¢–∞–Ω—Ü—É–π —Ç–∞–Ω—Ü—É–π —Ç–∞–Ω—Ü—É–π –ø–æ–∫–∞ –º–æ–ª–æ–¥–æ–π
            –ñ–∏–≤–∏ –∂–∏–≤–∏ –∂–∏–≤–∏ –±—É–¥—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–æ–π
        """,
        "–°–æ—Ü–∏–∞–ª—å–Ω—ã–π —Ä—ç–ø": """
            –£–ª–∏—Ü—ã –≥–æ–≤–æ—Ä—è—Ç –ø—Ä–∞–≤–¥—É —Å–∫–≤–æ–∑—å –∞—Å—Ñ–∞–ª—å—Ç –∏ –±–µ—Ç–æ–Ω
            –ü–æ–∫–æ–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –∏—â–µ—Ç —Å–≤–æ–π –¥–æ–º
            –í —Å–∏—Å—Ç–µ–º–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –≥–¥–µ –¥–µ–Ω—å–≥–∏ —Ä–µ—à–∞—é—Ç –≤—Å—ë
            –ú—ã –ø–∏—à–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç –Ω–æ–≤–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–≤–æ—ë
        """,
        "–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Ä—ç–ø": """
            –î–∏—Å—Å–æ–Ω–∞–Ω—Å –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–¥–∏–≥–º –≤ —É—Ä–±–∞–Ω–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Å—Ä–µ–¥–µ
            –§—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å–æ–∑–Ω–∞–Ω–∏—è —á–µ—Ä–µ–∑ –ø—Ä–∏–∑–º—É –ø–æ—Å—Ç–º–æ–¥–µ—Ä–Ω–∏—Å—Ç—Å–∫–æ–π —ç—Å—Ç–µ—Ç–∏–∫–∏
            –ò–Ω—Ç–µ—Ä—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –Ω–∞—Ä—Ä–∞—Ç–∏–≤–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–æ—Ü–∏–æ–∫—É–ª—å—Ç—É—Ä–Ω—ã—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
            –î–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–∏—Å–∫—É—Ä—Å–∞
        """,
    }

    comparison_results = {}

    for style_name, lyrics in comparison_samples.items():
        features = extract_simplified_features(lyrics.strip())
        comparison_results[style_name] = features

        print(f"üé® {style_name}:")
        print(f"   –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ: {features.get('technical_skill', 0):.3f}")
        print(f"   –•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å: {features.get('artistic_sophistication', 0):.3f}")
        print(f"   –ò–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–æ—Å—Ç—å: {features.get('innovation_score', 0):.3f}")
        print(f"   TTR (—Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ): {features.get('ttr_score', 0):.3f}")
        print(f"   –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∏—Ñ–º: {features.get('rhyme_density', 0):.3f}")
        print()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    with open("results/style_comparison.json", "w", encoding="utf-8") as f:
        json.dump(comparison_results, f, ensure_ascii=False, indent=2)

    print("üíæ –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ style_comparison.json")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üé§ === –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –†–ê–°–®–ò–†–ï–ù–ù–´–• ML-–§–ò–ß–ï–ô (–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è) ===\n")
    print("–ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ Feature Engineering:")
    print("‚úÖ Rhyme density –∏ —Å—Ö–µ–º—ã —Ä–∏—Ñ–º–æ–≤–∫–∏ (–±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑)")
    print("‚úÖ Vocabulary diversity (TTR - Type-Token Ratio)")
    print("‚úÖ Metaphor/wordplay detection (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)")
    print("‚úÖ Flow patterns (–∞–Ω–∞–ª–∏–∑ —Ä–∏—Ç–º–∞)")
    print("‚úÖ –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–∞")
    print("üîß –í–µ—Ä—Å–∏—è: —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è (–±–µ–∑ NLTK –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)")
    print("\n" + "=" * 60 + "\n")

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        demo_rhyme_analysis()
        demo_vocabulary_diversity()
        demo_metaphor_detection()
        demo_flow_analysis()
        demo_composite_metrics()
        demo_performance()
        save_sample_features()
        create_feature_comparison()

        print("üéâ === –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û ===")
        print("\nüìö –ß—Ç–æ –¥–∞–ª—å—à–µ:")
        print("1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ NLTK –¥–ª—è –ø–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏:")
        print("   pip install nltk")
        print("2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ extract_simplified_features() –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ ML")
        print("3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π pipeline:")
        print(
            "   from src.analyzers.simplified_feature_analyzer import extract_simplified_features"
        )
        print("4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–∞–∫–µ—Ç–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        import traceback

        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit_code = main()
