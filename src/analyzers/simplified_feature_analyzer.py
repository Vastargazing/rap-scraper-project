#!/usr/bin/env python3
"""
Simplified Advanced Feature Analyzer (–±–µ–∑ NLTK –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)

–ë–∞–∑–æ–≤–∞—è –≤–µ—Ä—Å–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
Feature Engineering –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö NLP –±–∏–±–ª–∏–æ—Ç–µ–∫.
"""

import re
import math
from collections import Counter, defaultdict
from typing import Dict, List, Tuple, Optional, Set
from pydantic import BaseModel, Field
import logging

logger = logging.getLogger(__name__)

# ===== –£–ü–†–û–©–ï–ù–ù–´–ï –ú–û–î–ï–õ–ò –î–ê–ù–ù–´–• =====

class SimplifiedRhymeAnalysis(BaseModel):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∏—Ñ–º"""
    rhyme_density: float = Field(ge=0.0, le=1.0, description="–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∏—Ñ–º")
    rhyme_detection_confidence: float = Field(ge=0.0, le=1.0, description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ä–∏—Ñ–º")
    end_rhyme_scheme: str = Field(description="–°—Ö–µ–º–∞ —Ä–∏—Ñ–º–æ–≤–∫–∏")
    internal_rhymes: int = Field(ge=0, description="–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Ä–∏—Ñ–º—ã")
    perfect_rhymes: int = Field(ge=0, description="–¢–æ—á–Ω—ã–µ —Ä–∏—Ñ–º—ã")
    alliteration_score: float = Field(ge=0.0, le=1.0, description="–ê–ª–ª–∏—Ç–µ—Ä–∞—Ü–∏—è")
    rhyme_scheme_confidence: float = Field(ge=0.0, le=1.0, description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Å—Ö–µ–º—ã —Ä–∏—Ñ–º")

class SimplifiedVocabularyAnalysis(BaseModel):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
    ttr_score: float = Field(ge=0.0, le=1.0, description="Type-Token Ratio")
    unique_words: int = Field(ge=0, description="–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞")
    total_words: int = Field(ge=0, description="–í—Å–µ–≥–æ —Å–ª–æ–≤")
    average_word_length: float = Field(ge=0.0, description="–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞")
    complex_words_ratio: float = Field(ge=0.0, le=1.0, description="–î–æ–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª–æ–≤")

class SimplifiedMetaphorAnalysis(BaseModel):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–∞—Ñ–æ—Ä"""
    metaphor_count: int = Field(ge=0, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–∞—Ñ–æ—Ä")
    metaphor_confidence: float = Field(ge=0.0, le=1.0, description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–µ—Ç–∞—Ñ–æ—Ä")
    wordplay_instances: int = Field(ge=0, description="–ò–≥—Ä–∞ —Å–ª–æ–≤")
    wordplay_confidence: float = Field(ge=0.0, le=1.0, description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∏–≥—Ä—ã —Å–ª–æ–≤")
    creativity_score: float = Field(ge=0.0, le=1.0, description="–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å")
    creativity_confidence: float = Field(ge=0.0, le=1.0, description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ü–µ–Ω–∫–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏")

class SimplifiedFlowAnalysis(BaseModel):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∏—Ç–º–∞"""
    syllable_count: int = Field(ge=0, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≥–æ–≤")
    average_syllables_per_line: float = Field(ge=0.0, description="–°–ª–æ–≥–æ–≤ –Ω–∞ —Å—Ç—Ä–æ–∫—É")
    stress_pattern_consistency: float = Field(ge=0.0, le=1.0, description="–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å")
    stress_pattern_confidence: float = Field(ge=0.0, le=1.0, description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∞–Ω–∞–ª–∏–∑–µ —É–¥–∞—Ä–µ–Ω–∏–π")
    flow_breaks: int = Field(ge=0, description="–ü–∞—É–∑—ã –≤ –ø–æ—Ç–æ–∫–µ")
    flow_analysis_confidence: float = Field(ge=0.0, le=1.0, description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∞–Ω–∞–ª–∏–∑–µ –ø–æ—Ç–æ–∫–∞")

class SimplifiedAdvancedFeatures(BaseModel):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö —Ñ–∏—á–µ–π"""
    rhyme_analysis: SimplifiedRhymeAnalysis
    vocabulary_analysis: SimplifiedVocabularyAnalysis
    metaphor_analysis: SimplifiedMetaphorAnalysis
    flow_analysis: SimplifiedFlowAnalysis
    
    # –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    overall_complexity: float = Field(ge=0.0, le=1.0)
    artistic_sophistication: float = Field(ge=0.0, le=1.0)
    technical_skill: float = Field(ge=0.0, le=1.0)
    innovation_score: float = Field(ge=0.0, le=1.0)

# ===== –£–ü–†–û–©–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó–ê–¢–û–† =====

class SimplifiedFeatureAnalyzer:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        # –ü—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.metaphor_keywords = [
            '–∫–∞–∫', '—Å–ª–æ–≤–Ω–æ', '–±—É–¥—Ç–æ', '—Ç–æ—á–Ω–æ', '–ø–æ—Ö–æ–∂ –Ω–∞', 'like', 'as'
        ]
        
        self.wordplay_patterns = [
            r'\b(\w+)\s+\w*\1\w*\b',  # –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
            r'\b\w*([–∞–µ–∏–æ—É—ã—ç—è]{2})\w*\s+\w*\1\w*\b',  # –ê—Å—Å–æ–Ω–∞–Ω—Å
        ]
        
        # –†—É—Å—Å–∫–∏–µ –≥–ª–∞—Å–Ω—ã–µ –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Å–ª–æ–≥–æ–≤
        self.vowels = '–∞–µ—ë–∏–æ—É—ã—ç—é—è'
        
        # –°—Ç–æ–ø-—Å–ª–æ–≤–∞
        self.stop_words = {
            '–∏', '–≤', '–Ω–∞', '—Å', '–ø–æ', '–∑–∞', '–∏–∑', '–∫', '—É', '–æ', '–æ—Ç', '–¥–æ', '–¥–ª—è',
            '–Ω–æ', '–∞', '—á—Ç–æ', '–∫–∞–∫', '–Ω–µ', '—è', '—Ç—ã', '–æ–Ω', '–æ–Ω–∞', '–º—ã', '–≤—ã', '–æ–Ω–∏',
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of'
        }

    def analyze_lyrics(self, lyrics: str) -> SimplifiedAdvancedFeatures:
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å —É–ø—Ä–æ—â–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        lines = [line.strip() for line in lyrics.split('\n') if line.strip()]
        words = self._tokenize_lyrics(lyrics)
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        rhyme_analysis = self._analyze_rhymes_simple(lines, words)
        vocabulary_analysis = self._analyze_vocabulary_simple(words)
        metaphor_analysis = self._analyze_metaphors_simple(lyrics, words)
        flow_analysis = self._analyze_flow_simple(lines, words)
        
        # –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        overall_complexity = (
            rhyme_analysis.rhyme_density * 0.25 +
            vocabulary_analysis.ttr_score * 0.25 +
            metaphor_analysis.creativity_score * 0.25 +
            flow_analysis.stress_pattern_consistency * 0.25
        )
        
        artistic_sophistication = (
            metaphor_analysis.creativity_score * 0.4 +
            vocabulary_analysis.ttr_score * 0.3 +
            rhyme_analysis.alliteration_score * 0.3
        )
        
        technical_skill = (
            rhyme_analysis.rhyme_density * 0.4 +
            flow_analysis.stress_pattern_consistency * 0.3 +
            min(vocabulary_analysis.ttr_score * 2, 1.0) * 0.3
        )
        
        innovation_score = (
            metaphor_analysis.creativity_score * 0.5 +
            min(rhyme_analysis.internal_rhymes / 10, 1.0) * 0.3 +
            min(vocabulary_analysis.complex_words_ratio * 2, 1.0) * 0.2
        )
        
        return SimplifiedAdvancedFeatures(
            rhyme_analysis=rhyme_analysis,
            vocabulary_analysis=vocabulary_analysis,
            metaphor_analysis=metaphor_analysis,
            flow_analysis=flow_analysis,
            overall_complexity=overall_complexity,
            artistic_sophistication=artistic_sophistication,
            technical_skill=technical_skill,
            innovation_score=innovation_score
        )

    def _tokenize_lyrics(self, lyrics: str) -> List[str]:
        """–ü—Ä–æ—Å—Ç–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è"""
        words = re.findall(r'\b\w+\b', lyrics.lower())
        return [word for word in words if len(word) > 2 and word not in self.stop_words]

    def _analyze_rhymes_simple(self, lines: List[str], words: List[str]) -> SimplifiedRhymeAnalysis:
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∏—Ñ–º"""
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ü–æ–≤–∫–∏ —Å—Ç—Ä–æ–∫
        line_endings = []
        for line in lines:
            words_in_line = line.strip().split()
            if words_in_line:
                ending = words_in_line[-1].lower().strip('.,!?')
                line_endings.append(ending)
        
        # –°—Ö–µ–º–∞ —Ä–∏—Ñ–º–æ–≤–∫–∏
        rhyme_scheme = self._detect_rhyme_scheme_simple(line_endings)
        
        # –ü–æ–¥—Å—á–µ—Ç —Ä–∏—Ñ–º
        perfect_rhymes = self._count_perfect_rhymes_simple(line_endings)
        internal_rhymes = self._count_internal_rhymes_simple(lines)
        
        # –ê–ª–ª–∏—Ç–µ—Ä–∞—Ü–∏—è
        alliteration_score = self._calculate_alliteration_simple(lines)
        
        # –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∏—Ñ–º
        rhyme_density = perfect_rhymes / max(len(lines), 1)
        
        # Confidence –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ä–∏—Ñ–º: –±–∞–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ä–∏—Ñ–º –∏ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞
        rhyme_detection_confidence = min(
            (perfect_rhymes / max(len(lines) / 2, 1)) * 0.6 +  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∏—Ñ–º
            (1 if len(line_endings) >= 8 else len(line_endings) / 8) * 0.4,  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª–∞
            0.85  # –ú–∞–∫—Å–∏–º—É–º 0.85 –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞
        )
        
        # Confidence –¥–ª—è —Å—Ö–µ–º—ã —Ä–∏—Ñ–º: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Å—Ö–µ–º—ã –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫
        if rhyme_scheme == "insufficient":
            rhyme_scheme_confidence = 0.1
        elif len(set(rhyme_scheme)) == 1:  # –ú–æ–Ω–æ—Ä–∏—Ñ–º–∞
            rhyme_scheme_confidence = 0.9
        elif len(rhyme_scheme) >= 6:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            rhyme_scheme_confidence = 0.75
        else:
            rhyme_scheme_confidence = 0.5
        
        return SimplifiedRhymeAnalysis(
            rhyme_density=min(rhyme_density, 1.0),
            rhyme_detection_confidence=rhyme_detection_confidence,
            end_rhyme_scheme=rhyme_scheme,
            internal_rhymes=internal_rhymes,
            perfect_rhymes=perfect_rhymes,
            alliteration_score=alliteration_score,
            rhyme_scheme_confidence=rhyme_scheme_confidence
        )

    def _detect_rhyme_scheme_simple(self, endings: List[str]) -> str:
        """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ö–µ–º—ã —Ä–∏—Ñ–º"""
        if len(endings) < 4:
            return "insufficient"
        
        scheme = []
        rhyme_groups = {}
        current_letter = 'A'
        
        for ending in endings[:8]:
            found_rhyme = False
            
            for grouped_ending, letter in rhyme_groups.items():
                if self._words_rhyme_simple(ending, grouped_ending):
                    scheme.append(letter)
                    found_rhyme = True
                    break
            
            if not found_rhyme:
                rhyme_groups[ending] = current_letter
                scheme.append(current_letter)
                current_letter = chr(ord(current_letter) + 1)
        
        return ''.join(scheme)

    def _words_rhyme_simple(self, word1: str, word2: str) -> bool:
        """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∏—Ñ–º—ã –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏—é"""
        if len(word1) < 3 or len(word2) < 3:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2-3 —Å–∏–º–≤–æ–ª–∞
        return word1[-2:] == word2[-2:] or word1[-3:] == word2[-3:]

    def _count_perfect_rhymes_simple(self, endings: List[str]) -> int:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–æ—á–Ω—ã—Ö —Ä–∏—Ñ–º"""
        rhyme_count = 0
        for i in range(len(endings)):
            for j in range(i + 1, len(endings)):
                if self._words_rhyme_simple(endings[i], endings[j]):
                    rhyme_count += 1
        return rhyme_count

    def _count_internal_rhymes_simple(self, lines: List[str]) -> int:
        """–ü–æ–¥—Å—á–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Ä–∏—Ñ–º"""
        internal_count = 0
        
        for line in lines:
            words = [w.lower().strip('.,!?') for w in line.split()]
            if len(words) < 2:
                continue
            
            for i in range(len(words) - 1):
                for j in range(i + 1, len(words)):
                    if self._words_rhyme_simple(words[i], words[j]):
                        internal_count += 1
        
        return internal_count

    def _calculate_alliteration_simple(self, lines: List[str]) -> float:
        """–ü–æ–¥—Å—á–µ—Ç –∞–ª–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏"""
        alliteration_count = 0
        total_pairs = 0
        
        for line in lines:
            words = [word.lower() for word in line.split() if len(word) > 2]
            if len(words) < 2:
                continue
            
            total_pairs += len(words) - 1
            
            for i in range(len(words) - 1):
                if words[i][0] == words[i + 1][0]:
                    alliteration_count += 1
        
        return alliteration_count / max(total_pairs, 1)

    def _analyze_vocabulary_simple(self, words: List[str]) -> SimplifiedVocabularyAnalysis:
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
        
        unique_words = len(set(words))
        total_words = len(words)
        
        # TTR
        ttr_score = unique_words / max(total_words, 1)
        
        # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞
        average_word_length = sum(len(word) for word in words) / max(len(words), 1)
        
        # –°–ª–æ–∂–Ω—ã–µ —Å–ª–æ–≤–∞ (–¥–ª–∏–Ω–Ω–µ–µ 6 —Å–∏–º–≤–æ–ª–æ–≤)
        complex_words = sum(1 for word in words if len(word) > 6)
        complex_words_ratio = complex_words / max(total_words, 1)
        
        return SimplifiedVocabularyAnalysis(
            ttr_score=min(ttr_score, 1.0),
            unique_words=unique_words,
            total_words=total_words,
            average_word_length=average_word_length,
            complex_words_ratio=complex_words_ratio
        )

    def _analyze_metaphors_simple(self, lyrics: str, words: List[str]) -> SimplifiedMetaphorAnalysis:
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–∞—Ñ–æ—Ä —Å confidence scores"""
        
        metaphor_count = 0
        metaphor_matches = []
        for keyword in self.metaphor_keywords:
            matches = lyrics.lower().count(keyword)
            metaphor_count += matches
            if matches > 0:
                metaphor_matches.append(keyword)
        
        # Confidence –¥–ª—è –º–µ—Ç–∞—Ñ–æ—Ä: –±–∞–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ –∏—Ö —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–∏
        metaphor_confidence = min(len(metaphor_matches) / max(len(self.metaphor_keywords), 1) + 
                                metaphor_count / max(len(words), 1) * 5, 1.0)
        
        # –ò–≥—Ä–∞ —Å–ª–æ–≤ (–ø—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
        wordplay_count = 0
        wordplay_patterns_found = 0
        for pattern in self.wordplay_patterns:
            matches = re.findall(pattern, lyrics, re.IGNORECASE)
            if matches:
                wordplay_count += len(matches)
                wordplay_patterns_found += 1
        
        # Confidence –¥–ª—è –∏–≥—Ä—ã —Å–ª–æ–≤: –Ω–∏–∑–∫–∞—è, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –º–æ–≥—É—Ç –¥–∞–≤–∞—Ç—å –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è
        wordplay_confidence = min(wordplay_patterns_found / max(len(self.wordplay_patterns), 1) * 0.6 + 
                                wordplay_count / max(len(words), 1) * 3, 0.8)  # –ú–∞–∫—Å–∏–º—É–º 0.8
        
        # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –∏ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–µ–º–æ–≤)
        creativity_score = min((metaphor_count + wordplay_count) / max(len(words), 1) * 10, 1.0)
        
        # Confidence –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏: —Å—Ä–µ–¥–Ω—è—è –º–µ–∂–¥—É confidence –º–µ—Ç–∞—Ñ–æ—Ä –∏ –∏–≥—Ä—ã —Å–ª–æ–≤
        creativity_confidence = (metaphor_confidence + wordplay_confidence) / 2
        
        return SimplifiedMetaphorAnalysis(
            metaphor_count=metaphor_count,
            metaphor_confidence=metaphor_confidence,
            wordplay_instances=wordplay_count,
            wordplay_confidence=wordplay_confidence,
            creativity_score=creativity_score,
            creativity_confidence=creativity_confidence
        )

    def _analyze_flow_simple(self, lines: List[str], words: List[str]) -> SimplifiedFlowAnalysis:
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∏—Ç–º–∞ —Å confidence scores"""
        
        # –ü–æ–¥—Å—á–µ—Ç —Å–ª–æ–≥–æ–≤
        syllable_count = self._count_syllables_simple(words)
        average_syllables_per_line = syllable_count / max(len(lines), 1)
        
        # –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã —Å—Ç—Ä–æ–∫)
        line_lengths = [len(line.split()) for line in lines]
        if line_lengths:
            length_variance = self._calculate_variance(line_lengths)
            stress_consistency = max(0, 1 - length_variance / 10)
            # Confidence –¥–ª—è —É–¥–∞—Ä–µ–Ω–∏–π: –≤—ã—Å–æ–∫–∞—è –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –¥–ª–∏–Ω —Å—Ç—Ä–æ–∫
            stress_pattern_confidence = max(0.3, 1 - length_variance / 8)  # –ú–∏–Ω–∏–º—É–º 0.3
        else:
            stress_consistency = 0
            stress_pattern_confidence = 0.2  # –ù–∏–∑–∫–∞—è confidence –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö
        
        # –ü–∞—É–∑—ã (–∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è)
        flow_breaks = sum(line.count(',') + line.count('.') + line.count('!') + line.count('?') for line in lines)
        
        # Confidence –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ flow: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫ –∏ –∏—Ö –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏
        lines_with_content = sum(1 for line in lines if len(line.strip()) > 5)
        flow_analysis_confidence = min(lines_with_content / max(len(lines), 1) * 0.8 + 
                                     (1 if len(lines) >= 8 else len(lines) / 8) * 0.2, 0.9)
        
        return SimplifiedFlowAnalysis(
            syllable_count=syllable_count,
            average_syllables_per_line=average_syllables_per_line,
            stress_pattern_consistency=stress_consistency,
            stress_pattern_confidence=stress_pattern_confidence,
            flow_breaks=flow_breaks,
            flow_analysis_confidence=flow_analysis_confidence
        )

    def _count_syllables_simple(self, words: List[str]) -> int:
        """–ü—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Å—á–µ—Ç —Å–ª–æ–≥–æ–≤ –ø–æ –≥–ª–∞—Å–Ω—ã–º"""
        total_syllables = 0
        
        for word in words:
            syllables = 0
            prev_was_vowel = False
            
            for char in word.lower():
                is_vowel = char in self.vowels
                if is_vowel and not prev_was_vowel:
                    syllables += 1
                prev_was_vowel = is_vowel
            
            # –ú–∏–Ω–∏–º—É–º 1 —Å–ª–æ–≥ –Ω–∞ —Å–ª–æ–≤–æ
            total_syllables += max(syllables, 1)
        
        return total_syllables

    def _calculate_variance(self, values: List[int]) -> float:
        """–†–∞—Å—á–µ—Ç –¥–∏—Å–ø–µ—Ä—Å–∏–∏"""
        if not values:
            return 0
        
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        return variance


# ===== –£–¢–ò–õ–ò–¢–´ =====

def extract_simplified_features(lyrics: str) -> Dict[str, float]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É–ø—Ä–æ—â–µ–Ω–Ω—ã—Ö —Ñ–∏—á–µ–π –≤ –ø–ª–æ—Å–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Å confidence scores"""
    
    analyzer = SimplifiedFeatureAnalyzer()
    features = analyzer.analyze_lyrics(lyrics)
    
    return {
        # Rhyme features
        'rhyme_density': features.rhyme_analysis.rhyme_density,
        'rhyme_detection_confidence': features.rhyme_analysis.rhyme_detection_confidence,
        'perfect_rhymes': float(features.rhyme_analysis.perfect_rhymes),
        'internal_rhymes': float(features.rhyme_analysis.internal_rhymes),
        'alliteration_score': features.rhyme_analysis.alliteration_score,
        'rhyme_scheme_confidence': features.rhyme_analysis.rhyme_scheme_confidence,
        
        # Vocabulary features
        'ttr_score': features.vocabulary_analysis.ttr_score,
        'average_word_length': features.vocabulary_analysis.average_word_length,
        'complex_words_ratio': features.vocabulary_analysis.complex_words_ratio,
        
        # Metaphor features
        'metaphor_count': float(features.metaphor_analysis.metaphor_count),
        'metaphor_confidence': features.metaphor_analysis.metaphor_confidence,
        'wordplay_instances': float(features.metaphor_analysis.wordplay_instances),
        'wordplay_confidence': features.metaphor_analysis.wordplay_confidence,
        'creativity_score': features.metaphor_analysis.creativity_score,
        'creativity_confidence': features.metaphor_analysis.creativity_confidence,
        
        # Flow features
        'average_syllables_per_line': features.flow_analysis.average_syllables_per_line,
        'stress_pattern_consistency': features.flow_analysis.stress_pattern_consistency,
        'stress_pattern_confidence': features.flow_analysis.stress_pattern_confidence,
        'flow_breaks': float(features.flow_analysis.flow_breaks),
        'flow_analysis_confidence': features.flow_analysis.flow_analysis_confidence,
        
        # Composite features
        'overall_complexity': features.overall_complexity,
        'artistic_sophistication': features.artistic_sophistication,
        'technical_skill': features.technical_skill,
        'innovation_score': features.innovation_score,
    }


def demo_simplified_analysis():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    
    sample_lyrics = """
    –Ø –ø–æ–¥–Ω–∏–º–∞—é—Å—å –∫–∞–∫ —Å–æ–ª–Ω—Ü–µ –Ω–∞–¥ –≥–æ—Ä–æ–¥–æ–º —Å–µ—Ä—ã–º
    –ú–æ–∏ —Å–ª–æ–≤–∞ –∫–∞–∫ –ø—É–ª–∏, –ø–æ–ø–∞–¥–∞—é—Ç –≤ —Ü–µ–ª—å –≤–µ—Ä–Ω–æ
    –í –ª–∞–±–∏—Ä–∏–Ω—Ç–µ –∏–∑ —Å—Ç—Ä–æ—á–µ–∫ —è –Ω–∞—à—ë–ª —Å–≤–æ—é –¥–æ—Ä–æ–≥—É
    –†–∏—Ñ–º—ã –ª—å—é—Ç—Å—è –∫–∞–∫ —Ä–µ–∫–∞, –Ω–µ—Å—É—Ç –º–µ–Ω—è –∫ –∏—Ç–æ–≥—É
    
    –í—Ä–µ–º—è ‚Äî –¥–µ–Ω—å–≥–∏, –¥–µ–Ω—å–≥–∏ ‚Äî –≤–ª–∞—Å—Ç—å, –≤–ª–∞—Å—Ç—å ‚Äî —ç—Ç–æ –∏–ª–ª—é–∑–∏—è
    –í –∏–≥—Ä–µ —Ç–µ–Ω–µ–π –∏ –æ—Ç—Ä–∞–∂–µ–Ω–∏–π —è —Å–æ–∑–¥–∞—é –∫–æ–Ω—Ñ—É–∑–∏—é
    –ú–æ–π —Ñ–ª–æ—É –∫–∞–∫ –≤–æ–¥–æ–ø–∞–¥, —Å—Ç—Ä–µ–º–∏—Ç–µ–ª—å–Ω—ã–π –∏ —á–∏—Å—Ç—ã–π
    –°–ª–æ–≤–∞ —Ç–∞–Ω—Ü—É—é—Ç –Ω–∞ –±–∏—Ç–∞—Ö, –¥–≤–∏–∂–µ–Ω–∏—è –∞—Ä—Ç–∏—Å—Ç–∏—á–Ω—ã
    """
    
    analyzer = SimplifiedFeatureAnalyzer()
    features = analyzer.analyze_lyrics(sample_lyrics)
    
    print("=== –£–ü–†–û–©–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –†–≠–ü–ê ===")
    print(f"üéµ Rhyme Density: {features.rhyme_analysis.rhyme_density:.3f}")
    print(f"üìö TTR Score: {features.vocabulary_analysis.ttr_score:.3f}")
    print(f"üé® Creativity Score: {features.metaphor_analysis.creativity_score:.3f}")
    print(f"üéØ Technical Skill: {features.technical_skill:.3f}")
    print(f"üí° Innovation Score: {features.innovation_score:.3f}")
    
    # –ü–ª–æ—Å–∫–∏–µ —Ñ–∏—á–∏
    flat_features = extract_simplified_features(sample_lyrics)
    print(f"\nüìä –í—Å–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ —Ñ–∏—á–µ–π: {len(flat_features)}")
    
    return features


if __name__ == "__main__":
    demo_simplified_analysis()
